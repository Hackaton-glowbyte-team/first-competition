{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5606014",
   "metadata": {},
   "source": [
    "## Энергетический оракул\n",
    "Ноутбук команды #12\n",
    "\n",
    "Работа выполнена на основе модели LightGBM\n",
    "\n",
    "\n",
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4351135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost.callback import TrainingCallback\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "random_state = 12345\n",
    "NUM_ITERATIONS = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45891200",
   "metadata": {},
   "source": [
    "#### 1.1 Функции для расшифровки прогноза погоды в колонке 'weather_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece12617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "\n",
    "# функция формирует колонки 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability', 'has_rain_probability'\n",
    "# в колонках число, которое 0 при отсутсвии упоминания явления в weather_pred или степень упоминания\n",
    "# функция дает в колонках номер первого списка, элемент которого есть в строке плюс 1\n",
    "# списки cloudy_list, rainy_list, windy_list, clear_list можно модифицировать\n",
    "# соответственно, можно экспериментировать с расположением значений в списках\n",
    "# например, сейчас 'дождь', 'снег', 'д+сн' - первая степень  дождя, а 'гроз', 'ливень' - вторая\n",
    "# а можно сделать снег второй, а грозу с ливнем убрать в третью\n",
    "# также сделал отдельный список для \"ясности\", чтобы выделить 'ясно' и 'солнечно'\n",
    "\n",
    "def in_what_list(weather, big_list):\n",
    "    for list_number, small_list in enumerate(big_list):\n",
    "        if any(word in weather for word in small_list):\n",
    "            return list_number+1\n",
    "    return 0\n",
    "\n",
    "def weather_split2(row):\n",
    "    weather = row['weather_pred']\n",
    "    cloudy_list = [['проясн', 'пер.об.', 'п/об'], ['пасм', 'обл']]\n",
    "    rainy_list = [['дождь', 'снег', 'д+сн'], ['гроз', 'ливень']]\n",
    "    windy_list = [['вет'],['штор']]\n",
    "    clear_list = [['проясн'], ['ясно'], ['солнеч']]\n",
    "    numbers = re.findall(r'\\d+', weather)\n",
    "    cloudy = in_what_list(weather, cloudy_list)\n",
    "    rainy = in_what_list(weather, rainy_list)\n",
    "    windy = in_what_list(weather, windy_list)\n",
    "    clear = in_what_list(weather, clear_list)\n",
    "    rain_probability = 0 if len(numbers)==0 else int(numbers[0])\n",
    "    has_rain_probability = int(len(numbers)==0)\n",
    "    return cloudy, rainy, windy, clear, rain_probability, has_rain_probability\n",
    "\n",
    "def fill_weather_columns(df):\n",
    "    df['weather_pred'] = df['weather_pred'].fillna('')\n",
    "    df['cloudy'], df['rainy'], df['windy'], df['clear'], df['rain_probability'], df['has_rain_probability'] = \\\n",
    "                zip(*df.apply(weather_split2, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39d660",
   "metadata": {},
   "source": [
    "#### 1.2 Функции для загрузки данных о ВВП \n",
    "данные загружаются из файла 'data/VVP.csv'\n",
    "\n",
    "Некоторые научные работы указывают на прямую связь величины потребления электричества и показателя ВВП, который отражает ситуацию в экономике. Данные по экономике публикуются различными министерствами с разной периодичностью. Для использования в работе были взяты фактические данные по ВВП с сайта investing, который агрегирует публикации Минэкономразвития. Данные за месяц побликуются с месячной задержкой, поэтому модель использует для прогнозирования данные за прошлые месяцы, которые известны.   \n",
    "  \n",
    "Ссылка на данные: https://ru.investing.com/economic-calendar/russian-monthly-gdp-407\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3dd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция добавляет данные о ВВП из файла 'data/VVP.csv' в датасет\n",
    "\n",
    "def add_vvp2(data, file_source = 'data/VVP.csv'):\n",
    "    \"\"\"\n",
    "    сырой датафрем подаем на вход\n",
    "    \"\"\"\n",
    "    # обработаем файл с динамикой ВВП\n",
    "    vvp = pd.read_csv(file_source)\n",
    "    # преобразуем дату файла-источника в формат datetime64 и дропнем один столбик\n",
    "    vvp['date'] = pd.to_datetime(vvp['date'], format ='%Y-%m-%d %H:%M:%S')\n",
    "    vvp.drop('for_month',axis=1,inplace=True) \n",
    "    \n",
    "    # обработаем основной фрейм - создадим столбец для соединения, который потом удалим\n",
    "    data['date_temp'] = pd.to_datetime(data['date'], format = '%Y-%m-%d' )\n",
    "    data['date_temp'] = data['date_temp'] + pd.to_timedelta(data['time'] , 'H')\n",
    "    \n",
    "    # соединяем основной фрейм и ВВП по дате объявления показтеля ВВП\n",
    "    for idx in reversed(vvp.index):\n",
    "        data.loc[data['date_temp']>=vvp.date[idx],'VVP'] = vvp.VVP_perc[idx]\n",
    "        \n",
    "    data.drop('date_temp',axis=1,inplace=True)   \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe769599",
   "metadata": {},
   "source": [
    "#### 1.3 Функции для загрузки архива данных о фактической погоде\n",
    "данные загружаются из файла 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "Изначально данные для формирования таблицы \"preprocessing_loaded_table\" были взяты из с сайта [https://rp5.ru](https://rp5.ru/Архив_погоды_в_Храброво,_им._императрицы_Елизаветы_Петровны_(аэропорт),_METAR), где хранятся архивы погоды в аэрапорту Калининграда, за период с 31.12.2018 по 30.09.2023\n",
    "\n",
    "Описание данных в таблице:\n",
    "- Местное время в Храброво / им. императрицы Елизаветы Петровны (аэропорт) - Дата / Местное время\n",
    "- T -  Темпиратура воздуха\n",
    "- Po - Давление на уровне станции\n",
    "- P - Давление приведённое к уровню моря\n",
    "- U - Относительная влажность\n",
    "- DD - Направление ветра\n",
    "- Ff - Скорость ветра\n",
    "- ff10 - Максимальное значение порыва ветра\n",
    "- WW - Особое явление текущей погоды (осадки)\n",
    "- W'W' - Явление недавней погоды, имеющее оперативное значение\n",
    "- с - Общая облачность\n",
    "- VV - Горизонтальная дальность видимости\n",
    "- Td - Темпиратура точки росы\n",
    "\n",
    "Данные, которые были взяты из данной таблицы и загружаются из 'data/preprocessing_loaded_table.csv':\n",
    "- P - не подверглось изменению\n",
    "- U - не подверглось изменению\n",
    "- Td - не подверглась изменению\n",
    "\n",
    " WW - разделили на 4 категории:\n",
    "- Нет осадков (где были пропуски)\n",
    "- слабый дождь\n",
    "- сильный дождь\n",
    "- снег\n",
    "\n",
    "DD - создали 4 столбца, соответствующих сторонам горизонта, которые принимали значения 0; 0.5 и 1 в зависимости от силы ветра в конкретном направлении\n",
    "- N - north\n",
    "- S - south\n",
    "- W - west\n",
    "- E - east\n",
    "\n",
    "В дальнейшем эти данные использовались с лагом в сутки: в поля на завтрашний день записывались данные сегодняшнего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb3456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для работы с данными о фактической погоде из 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "# Кодировка информации об осадках из колонки WW\n",
    "def true_weather_WW_replace(ww):\n",
    "    if ww=='нет осадков':\n",
    "        return 0\n",
    "    elif ww=='слабый дождь':\n",
    "        return 1\n",
    "    elif (ww=='сильный дождь') or (ww=='снег'):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Вычисление Timestamp из даты и времени\n",
    "def row_plus_hours_to_index(row):\n",
    "    return row['date'] + pd.to_timedelta(row['time'] , 'H')\n",
    "\n",
    "# Функция для сдвига на сутки (в скачанном датасете разбивка по 30 мин, поэтому timeshift=48)\n",
    "def shift_features_fact(df, timeshift=48):\n",
    "    list_fact_columns=list(df.columns)\n",
    "    list_fact_columns.remove('date_tw')\n",
    "    new_df = df.copy()\n",
    "    for column in list_fact_columns:\n",
    "        new_df[column] = new_df[column].shift(timeshift)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5eb669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления метрики mae по дням из почасовых массивов данных\n",
    "\n",
    "def mae_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    return mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "# Функция для вычисления метрик по дням из почасовых массивов данных\n",
    "\n",
    "def metrics_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    mae = mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "    mape = mean_absolute_percentage_error(y_true_grouped, y_pred_grouped)\n",
    "    r2 = r2_score(y_true_grouped, y_pred_grouped)\n",
    "    return mae, mape, r2\n",
    "\n",
    "def metrics_hour(y_true, y_pred): \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808c109",
   "metadata": {},
   "source": [
    "#### 1.5 Чтение файлов с данными\n",
    "Данные объединяются в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a4ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начало открытого теста: 2023-04-01 00:00:00     конец открытого теста: 2023-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# читаем исходные датасеты и складываем в один\n",
    "train_ds = pd.read_csv('data/train_dataset.csv')\n",
    "test_ds = pd.read_csv('data/test_dataset.csv')\n",
    "train_ds = pd.concat([train_ds, test_ds])\n",
    "\n",
    "# запоминаем дату начала тестовых данных, потом также поступим и с закрытым датасетом\n",
    "open_test_begin = pd.to_datetime(test_ds['date']).min()\n",
    "open_test_end = pd.to_datetime(test_ds['date']).max() + pd.to_timedelta(1,'d')\n",
    "print('начало открытого теста:', open_test_begin, '    конец открытого теста:', open_test_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237ce32",
   "metadata": {},
   "source": [
    "#### 1.6 Формирование колонок с производными от даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16090ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем дату и делаем из нее колонки\n",
    "train_ds['date'] = pd.to_datetime(train_ds['date'])\n",
    "train_ds['year'] = train_ds['date'].dt.year\n",
    "train_ds['month'] = train_ds['date'].dt.month\n",
    "train_ds['day_of_week'] = train_ds['date'].dt.dayofweek\n",
    "train_ds['day'] = train_ds['date'].dt.day\n",
    "train_ds['day_of_year'] = train_ds['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98567815",
   "metadata": {},
   "source": [
    "#### 1.7 Подгрузка данных о праздниках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03029389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление данных о праздниках из файла 'data/holidays.csv'\n",
    "\n",
    "df_holidays = pd.read_csv('data/holidays.csv')\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "\n",
    "# Assuming df_holidays and train_ds are your dataframes\n",
    "train_ds = pd.merge(train_ds, df_holidays, on='date', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "train_ds['holidays'].fillna(0, inplace=True)\n",
    "train_ds['preholidays'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "train_ds['holidays'] = train_ds['holidays'].astype(int)\n",
    "train_ds['preholidays'] = train_ds['preholidays'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d592f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-12-31 00:00:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_holidays['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ace845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>holidays</th>\n",
       "      <th>preholidays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, holidays, preholidays]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_holidays[df_holidays.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdfa6e",
   "metadata": {},
   "source": [
    "#### 1.8 Формирование колонок со значением целевого признака в предыдущие дни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91cfdcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/2993370237.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_ds['temp_last_day'].fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Добавление колонок с временными лагами\n",
    "\n",
    "# создаем столбец 'temp_last_day'\n",
    "train_ds['temp_last_day'] = train_ds['temp'].shift(24)\n",
    "\n",
    "# заполняем пропущенные значения в 'temp_last_day'\n",
    "train_ds['temp_last_day'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# создаем столбцы с временными лагами для 'target'\n",
    "lags = [24, 48, 72, 7*24, 14*24]\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'] = train_ds['target'].shift(lag)\n",
    "\n",
    "# заполняем пропущенные значения в столбцах с лагами\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c4022",
   "metadata": {},
   "source": [
    "#### 1.9 Формирование колонок с ВВП и данными о погоде посредством ранее описанных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79aa7c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>P</th>\n",
       "      <th>U</th>\n",
       "      <th>WW</th>\n",
       "      <th>Td</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>W</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 00:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 00:30:00</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 01:00:00</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 01:30:00</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31 02:00:00</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82146</th>\n",
       "      <td>2023-09-30 21:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82147</th>\n",
       "      <td>2023-09-30 22:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82148</th>\n",
       "      <td>2023-09-30 22:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>сильный дождь</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82149</th>\n",
       "      <td>2023-09-30 23:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>сильный дождь</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82150</th>\n",
       "      <td>2023-09-30 23:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82151 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date      P      U             WW    Td    N    S    W  \\\n",
       "0      2018-12-31 00:00:00  763.5  100.0   слабый дождь   2.0  1.0  0.0  0.0   \n",
       "1      2018-12-31 00:30:00  764.3   93.0   слабый дождь   1.0  1.0  0.0  0.0   \n",
       "2      2018-12-31 01:00:00  764.3   93.0   слабый дождь   1.0  1.0  0.0  0.0   \n",
       "3      2018-12-31 01:30:00  765.0   93.0   слабый дождь   2.0  1.0  0.0  0.0   \n",
       "4      2018-12-31 02:00:00  765.0   93.0    нет осадков   2.0  1.0  0.0  0.0   \n",
       "...                    ...    ...    ...            ...   ...  ...  ...  ...   \n",
       "82146  2023-09-30 21:30:00  763.5   82.0    нет осадков  12.0  0.0  0.0  1.0   \n",
       "82147  2023-09-30 22:00:00  763.5   82.0    нет осадков  12.0  0.5  0.0  1.0   \n",
       "82148  2023-09-30 22:30:00  763.5   77.0  сильный дождь  11.0  0.0  0.0  1.0   \n",
       "82149  2023-09-30 23:00:00  763.5   94.0  сильный дождь  13.0  0.5  0.0  1.0   \n",
       "82150  2023-09-30 23:30:00  763.5   94.0    нет осадков  13.0  0.0  0.5  1.0   \n",
       "\n",
       "         E  \n",
       "0      0.0  \n",
       "1      0.5  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "82146  0.0  \n",
       "82147  0.0  \n",
       "82148  0.0  \n",
       "82149  0.0  \n",
       "82150  0.0  \n",
       "\n",
       "[82151 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# применяем функцию добавления ВВП\n",
    "train_ds = add_vvp2(train_ds)\n",
    "\n",
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "train_ds = fill_weather_columns(train_ds)\n",
    "\n",
    "\n",
    "# Читаем файл с архивом фактической погоды\n",
    "df_true_weather = pd.read_csv('data/preprocessing_loaded_table.csv')\n",
    "display(df_true_weather)\n",
    "\n",
    "# Форматируем колонки\n",
    "df_true_weather['WW'] = df_true_weather['WW'].apply(true_weather_WW_replace)\n",
    "df_true_weather['date'] = pd.to_datetime(df_true_weather['date'])\n",
    "df_true_weather = df_true_weather.rename(columns={'date':'date_tw'})\n",
    "# Применяем сдвиг на сутки, чтобы не заглядывать в будущее\n",
    "df_true_weather = shift_features_fact(df_true_weather)\n",
    "# Добавляем в датасет\n",
    "train_ds['date_hours'] = train_ds.apply(row_plus_hours_to_index, axis=1)\n",
    "train_ds = train_ds.merge(df_true_weather, left_on='date_hours', right_on='date_tw')\n",
    "train_ds = train_ds.drop(['date_hours', 'date_tw'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.10 Формирование колонок со средними значениями цели и фактической температуры за предыдущий день и срезы по нему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ba74908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds[['last_day_avg_target', 'last_day_avg_temp']] = train_ds[['date', 'target', 'temp']].groupby(by='date').transform('mean').shift(24)\n",
    "\n",
    "#def mean_evening(values, evening=19):\n",
    "#    return values[evening:].mean()\n",
    "\n",
    "#evening_slices = [19, 22]\n",
    "   \n",
    "#for evening_slice in evening_slices:\n",
    "#    train_ds[['last_evening_avg_target_'+str(evening_slice), 'last_evening_avg_temp_'+str(evening_slice)]] = \\\n",
    "#        train_ds[['date', 'target', 'temp']].groupby(by='date').transform(mean_evening, evening=evening_slice).shift(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[['last_day_avg_target', 'last_day_avg_temp']] = train_ds[['date', 'target', 'temp']].groupby(by='date').transform('mean').shift(24)\n",
    "\n",
    "def mean_evening(values, evening=19):\n",
    "    return values[evening:].mean()\n",
    "\n",
    "evening_slices = [19, 22]\n",
    "    \n",
    "for evening_slice in evening_slices:\n",
    "    train_ds[['last_evening_avg_target_'+str(evening_slice), 'last_evening_avg_temp_'+str(evening_slice)]] = \\\n",
    "        train_ds[['date', 'target', 'temp']].groupby(by='date').transform(mean_evening, evening=evening_slice).shift(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40027, 41)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.11 Формирование колонок с почасовыми лагами для всех сформированных ранее готовых признаков\n",
    "\n",
    "Сначала готовим список названий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем признаки. Все лишние колонки здесь отбрасываем, кроме 'date', которую уберем позже \n",
    "\n",
    "feature_cols = list(train_ds.columns)\n",
    "\n",
    "# выбрасываем взгляд в прошлое и расшифрованную погоду\n",
    "drop_list = ['target', 'day_of_year', 'weather_pred', 'weather_fact', 'temp']\n",
    "\n",
    "# выбрасываем признаки, найденные процедурно в процессе оптимизации\n",
    "# КОМАНДЕ: здесь можно добавлять признаки на выброс с целью оптимизации\n",
    "drop_list = drop_list + ['target_lag_48', 'target_lag_168'] #, 'temp_pred'] #, 'target_lag_336'] \n",
    "\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потом добавляем лаги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "FEATURE_WINDOW_SIZE = 24\n",
    "feature_cols_no_date = feature_cols.copy()\n",
    "feature_cols_no_date.remove('date')\n",
    "\n",
    "\n",
    "for lag in range(1,FEATURE_WINDOW_SIZE):\n",
    "    for column in feature_cols_no_date:\n",
    "        train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.11 Формирование колонок с лагами для цели и фактической температуры\n",
    "\n",
    "Заполняем значениями NaN все поля этих лагов, которые относятся к текущему дню, чтобы не допустить утечки. Т.е. для каждого часа используем только лаги, которые превосходят номер часа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d55bd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/1660665095.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds.target.shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/1660665095.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/1660665095.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds.target.shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/1660665095.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/1660665095.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds.target.shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_26380/1660665095.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n"
     ]
    }
   ],
   "source": [
    "target_lags=[1, 5, 9]\n",
    "\n",
    "for lag in target_lags:\n",
    "    train_ds['target_'+str(lag)] = train_ds.target.shift(lag).where(train_ds['time']<lag, np.NaN)\n",
    "    train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc76ee",
   "metadata": {},
   "source": [
    "#### 1.12 Демонстрация сформированного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a939b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'target', 'temp', 'temp_pred', 'weather_pred',\n",
       "       'weather_fact', 'year', 'month', 'day_of_week',\n",
       "       ...\n",
       "       'last_evening_avg_target_19_23', 'last_evening_avg_temp_19_23',\n",
       "       'last_evening_avg_target_22_23', 'last_evening_avg_temp_22_23',\n",
       "       'target_1', 'temp_1', 'target_5', 'temp_5', 'target_9', 'temp_9'],\n",
       "      dtype='object', length=806)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Итоговый набор колонок\n",
    "train_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f51e77ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>target</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_pred</th>\n",
       "      <th>weather_pred</th>\n",
       "      <th>weather_fact</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>last_evening_avg_target_19_23</th>\n",
       "      <th>last_evening_avg_temp_19_23</th>\n",
       "      <th>last_evening_avg_target_22_23</th>\n",
       "      <th>last_evening_avg_temp_22_23</th>\n",
       "      <th>target_1</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>target_5</th>\n",
       "      <th>temp_5</th>\n",
       "      <th>target_9</th>\n",
       "      <th>temp_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>481.510</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>462.872</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>449.718</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>430.908</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>415.163</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  time   target  temp  temp_pred weather_pred weather_fact  year  \\\n",
       "0 2019-01-01     0  481.510   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "1 2019-01-01     1  462.872   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "2 2019-01-01     2  449.718   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "3 2019-01-01     3  430.908   4.3        2.0  пасм, ветер  ветер, пасм  2019   \n",
       "4 2019-01-01     4  415.163   4.3        2.0  пасм, ветер  ветер, пасм  2019   \n",
       "\n",
       "   month  day_of_week  ...  last_evening_avg_target_19_23  \\\n",
       "0      1            1  ...                            NaN   \n",
       "1      1            1  ...                            NaN   \n",
       "2      1            1  ...                            NaN   \n",
       "3      1            1  ...                            NaN   \n",
       "4      1            1  ...                            NaN   \n",
       "\n",
       "   last_evening_avg_temp_19_23  last_evening_avg_target_22_23  \\\n",
       "0                          NaN                            NaN   \n",
       "1                          NaN                            NaN   \n",
       "2                          NaN                            NaN   \n",
       "3                          NaN                            NaN   \n",
       "4                          NaN                            NaN   \n",
       "\n",
       "   last_evening_avg_temp_22_23  target_1  temp_1  target_5  temp_5  target_9  \\\n",
       "0                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "1                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "2                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "3                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "4                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "\n",
       "   temp_9  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  \n",
       "\n",
       "[5 rows x 806 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69383cb",
   "metadata": {},
   "source": [
    "#### 1.13 Исключение лишних колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65d6619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем признаки. Список формируем заново из всех текущих колонок.\n",
    "feature_cols = list(train_ds.columns)\n",
    "\n",
    "# Отбрасываем колонки из ранее заготовленного списка на выброс. На этом этапе уходят колонки с утечками.\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f34c90",
   "metadata": {},
   "source": [
    "#### 1.14 Выделение наборов данных для обучения, валидации и тестирования\n",
    "\n",
    "Выделялось два набора данных для обучения и валидации:\n",
    "1. Обучение на данных с 2019 по 2021 с валидацией на 2022\n",
    "2. Обучение на данных с 2019 по 2022 с валидацией на первом квартале 2023\n",
    "\n",
    "Первый набор позволяет оценить влияние сезонности на обучение и предсказания, второй позволяет обучить модель на большем объеме данных и на более актуальных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a2b8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем набор датасетов для обучения и проверки\n",
    "\n",
    "features = train_ds[feature_cols]\n",
    "target = train_ds['target']\n",
    "\n",
    "# Функция для выделения временных интервалов из таблиц признаков и целей\n",
    "# на этом этапе отбрасываем колонку 'date'\n",
    "def features_interval(features, target, date1, date2):\n",
    "    features_interval = features[ (features['date']>=date1) & (features['date']<date2) ]\n",
    "    target_interval = target[features_interval.index]\n",
    "    features_interval = features_interval.drop('date', axis=1)\n",
    "    return features_interval, target_interval\n",
    "\n",
    "# для первичного подбора гиперпараметров будем обучать на 19-21 годах, валидировать по 2022\n",
    "features_train, target_train = features_interval(features, target, '2019-01-01', '2022-01-01')\n",
    "features_valid, target_valid = features_interval(features, target, '2022-01-01', '2023-01-01')\n",
    "\n",
    "# отбор признаков будем производить, обучая на 19-22 и проверяя по первому кварталу 2023\n",
    "# с дополнительным контролем на вариантах из первичного обучения\n",
    "features_2022, target_2022 = features_interval(features, target, '2019-01-01', '2023-01-01')\n",
    "features_2023, target_2023 = features_interval(features, target, '2023-01-01', open_test_begin)\n",
    "\n",
    "# для проверки на тестовой выборке будем учиться на всем тренировочном датасете\n",
    "features_all_train, target_all_train = features_interval(features, target, '2019-01-01', open_test_begin)\n",
    "features_open_test, target_open_test = features_interval(features, target, open_test_begin, open_test_end)\n",
    "\n",
    "# формируем наборы данных по кварталам 2022 года, чтобы посмотреть по ним метрику отдельно\n",
    "dates = ['2022-01-01', '2022-04-01', '2022-07-01', '2022-10-01', '2023-01-01']\n",
    "quarters = []\n",
    "for i in range(4):\n",
    "    f, t = features_interval(features, target, dates[i], dates[i+1])\n",
    "    quarters.append({'features':f, 'target':t})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a967384f",
   "metadata": {},
   "source": [
    "### 2. Обучение моделей\n",
    "\n",
    "В настоящей работе обучаются модели LightGBM и XGBoost, финальное предсказание получается усреднением результатов.\n",
    "\n",
    "#### 2.1 Гиперпараметры LightGBM\n",
    "Были подобраны следующие значения гиперпараметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7772cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves':15, 'learning_rate':0.02, 'feature_fraction':1, 'num_iterations':NUM_ITERATIONS, 'random_state':random_state, 'objective':'regression_l1', 'n_jobs':-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbcf5c",
   "metadata": {},
   "source": [
    "#### 2.2 Обучение на данных за 2019-2021 годы и предсказание на 2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73bc8d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 74674\n",
      "[LightGBM] [Info] Number of data points in the train set: 26217, number of used features: 798\n",
      "[LightGBM] [Info] Start training from score 464.106506\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "mae for days - 134.5512819709116\n",
      "mae for hours - 7.704952314260031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Демонстрация предсказания с подобранными гиперпараметрами\n",
    "# Тренируем на 19-21 годах, предсказываем за 2022\n",
    "\n",
    "lgbm_model = lgb.LGBMRegressor(**params)\n",
    "lgbm_model.fit(features_train, target_train)\n",
    "\n",
    "y_pred = lgbm_model.predict(features_valid)\n",
    "print(f'mae for days - {mae_day(target_valid, y_pred)}')\n",
    "print(f'mae for hours - {mean_absolute_error(target_valid, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df9b4216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "1 квартал mae = 150.50830191521797\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "2 квартал mae = 138.5046988017369\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 квартал mae = 119.29967120607014\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "4 квартал mae = 137.64030313502752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Предсказываем отдельно по четырем кварталам 2022 года\n",
    "\n",
    "for i, quarter in enumerate(quarters):\n",
    "    mae = mae_day(quarter['target'], lgbm_model.predict(quarter['features']))\n",
    "    print(f'{i+1} квартал mae = {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4f07f",
   "metadata": {},
   "source": [
    "Как видно по предсказаниям, в задаче наблюдается значительная сезонность: предсказания на первый квартал 2022 года получились хуже, чем на прочие периоды. Какой сюрприз. В целом, из графического представления видно, что предказание в целом адекватно описывает динамику целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "931f1498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae = 131.64385081519103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Предсказываем той же моделью (19-21) тренировочный кусок 2023 (первый квартал)\n",
    "mae = mae_day(target_2023, lgbm_model.predict(features_2023))\n",
    "print(f'mae = {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f69ef2",
   "metadata": {},
   "source": [
    "### 3 Проверка метрик на тестовом датасете\n",
    "##### 3.1 Модель LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88929019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 75442\n",
      "[LightGBM] [Info] Number of data points in the train set: 37108, number of used features: 798\n",
      "[LightGBM] [Info] Start training from score 473.062988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(feature_fraction=1, learning_rate=0.02, n_jobs=-1,\n",
       "              num_iterations=10000, num_leaves=15, objective=&#x27;regression_l1&#x27;,\n",
       "              random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(feature_fraction=1, learning_rate=0.02, n_jobs=-1,\n",
       "              num_iterations=10000, num_leaves=15, objective=&#x27;regression_l1&#x27;,\n",
       "              random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(feature_fraction=1, learning_rate=0.02, n_jobs=-1,\n",
       "              num_iterations=10000, num_leaves=15, objective='regression_l1',\n",
       "              random_state=12345)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "# Здесь обучаем на всем тренировочном датасете\n",
    "params = {'num_leaves':15, 'learning_rate':0.02, 'feature_fraction':1, 'num_iterations':10000, 'random_state':random_state, 'objective':'regression_l1', 'n_jobs':-1}\n",
    "\n",
    "lgbm_model_all_train = lgb.LGBMRegressor(**params)\n",
    "lgbm_model_all_train.fit(features_all_train, target_all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM</td>\n",
       "      <td>3.176235</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.996797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM</td>\n",
       "      <td>6.123915</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.985995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Выборка       MAE      MAPE        R2\n",
       "0  тренировочная LGBM   3.176235  0.006670  0.996797\n",
       "1       тестовая LGBM   6.123915  0.014347  0.985995"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_predict_train = lgbm_model_all_train.predict(features_all_train)\n",
    "l_predict_test = lgbm_model_all_train.predict(features_open_test)\n",
    "\n",
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, l_predict_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, l_predict_test)\n",
    "\n",
    "FEATURES=''\n",
    "results = pd.DataFrame([[f'тренировочная LGBM {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая LGBM {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c00fb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение важности признаков\n",
    "importance = lgbm_model_all_train.feature_importances_\n",
    "feature_name = features_open_test.columns\n",
    "# создание DataFrame\n",
    "importance_df_lgbm = pd.DataFrame({'feature': feature_name, 'importance': importance})\n",
    "# сортировка по важности\n",
    "importance_df_lgbm = importance_df_lgbm.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41359208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>target_lag_24</td>\n",
       "      <td>3341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>target_lag_336</td>\n",
       "      <td>1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>target_lag_72</td>\n",
       "      <td>1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>target_lag_24_1</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>target_lag_72_23</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>year_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>year_19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>year_16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>year_6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>preholidays_12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance\n",
       "9       target_lag_24        3341\n",
       "11     target_lag_336        1548\n",
       "10      target_lag_72        1283\n",
       "42    target_lag_24_1         950\n",
       "769  target_lag_72_23         860\n",
       "..                ...         ...\n",
       "101            year_3           1\n",
       "629           year_19           1\n",
       "530           year_16           0\n",
       "200            year_6           0\n",
       "403    preholidays_12           0\n",
       "\n",
       "[798 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Модель XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['preholidays',\n",
    "            #'has_rain_probability', \n",
    "            # 'W', 'E'\n",
    "            ]\n",
    "n_values = range(1, 24)\n",
    "preholidays = ['preholidays_{}'.format(n) for n in n_values]\n",
    "#has_rain = ['has_rain_probability_{}'.format(n) for n in n_values]\n",
    "#W_wind = ['W_{}'.format(n) for n in n_values]\n",
    "#E_wind = ['E_{}'.format(n) for n in n_values]\n",
    "\n",
    "drop_list = drop_list + preholidays #+ has_rain + W_wind + E_wind\n",
    "\n",
    "feat_xgb_train = features_all_train.drop(columns=drop_list)\n",
    "feat_xgb_test = features_open_test.drop(columns=drop_list)\n",
    "#feat_xgb_train.columns, feat_xgb_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    max_depth=7,\n",
    "    n_estimators=1190, #n_estimators=195, #\n",
    "    learning_rate=0.009, #learning_rate=0.1, #\n",
    "    tree_method='exact',\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    gamma=2,\n",
    "    colsample_bytree=1,\n",
    "    random_state=random_state\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/xgboost/sklearn.py:885: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Time for last iteration: -0.5425820350646973\n",
      "Iteration: 1 Time for last iteration: -0.3460252285003662\n",
      "Iteration: 2 Time for last iteration: -0.32907676696777344\n",
      "Iteration: 3 Time for last iteration: -0.3087449073791504\n",
      "Iteration: 4 Time for last iteration: -0.34874892234802246\n",
      "Iteration: 5 Time for last iteration: -0.3235149383544922\n",
      "Iteration: 6 Time for last iteration: -0.33764195442199707\n",
      "Iteration: 7 Time for last iteration: -0.32900500297546387\n",
      "Iteration: 8 Time for last iteration: -0.3262290954589844\n",
      "Iteration: 9 Time for last iteration: -0.35271191596984863\n",
      "Iteration: 10 Time for last iteration: -0.3164999485015869\n",
      "Iteration: 11 Time for last iteration: -0.33231210708618164\n",
      "Iteration: 12 Time for last iteration: -0.31270384788513184\n",
      "Iteration: 13 Time for last iteration: -0.32414793968200684\n",
      "Iteration: 14 Time for last iteration: -0.3220200538635254\n",
      "Iteration: 15 Time for last iteration: -0.3180198669433594\n",
      "Iteration: 16 Time for last iteration: -0.31389689445495605\n",
      "Iteration: 17 Time for last iteration: -0.31725597381591797\n",
      "Iteration: 18 Time for last iteration: -0.3166069984436035\n",
      "Iteration: 19 Time for last iteration: -0.31560826301574707\n",
      "Iteration: 20 Time for last iteration: -0.311417818069458\n",
      "Iteration: 21 Time for last iteration: -0.3186769485473633\n",
      "Iteration: 22 Time for last iteration: -0.31069183349609375\n",
      "Iteration: 23 Time for last iteration: -0.3147420883178711\n",
      "Iteration: 24 Time for last iteration: -0.31646180152893066\n",
      "Iteration: 25 Time for last iteration: -0.31173133850097656\n",
      "Iteration: 26 Time for last iteration: -0.3167738914489746\n",
      "Iteration: 27 Time for last iteration: -0.3328540325164795\n",
      "Iteration: 28 Time for last iteration: -0.3135349750518799\n",
      "Iteration: 29 Time for last iteration: -0.32527899742126465\n",
      "Iteration: 30 Time for last iteration: -0.3574540615081787\n",
      "Iteration: 31 Time for last iteration: -0.3252701759338379\n",
      "Iteration: 32 Time for last iteration: -0.3153247833251953\n",
      "Iteration: 33 Time for last iteration: -0.3624446392059326\n",
      "Iteration: 34 Time for last iteration: -0.3523073196411133\n",
      "Iteration: 35 Time for last iteration: -0.3293330669403076\n",
      "Iteration: 36 Time for last iteration: -0.3393290042877197\n",
      "Iteration: 37 Time for last iteration: -0.3434031009674072\n",
      "Iteration: 38 Time for last iteration: -0.3580188751220703\n",
      "Iteration: 39 Time for last iteration: -0.3660099506378174\n",
      "Iteration: 40 Time for last iteration: -0.4589390754699707\n",
      "Iteration: 41 Time for last iteration: -0.34296298027038574\n",
      "Iteration: 42 Time for last iteration: -0.3350341320037842\n",
      "Iteration: 43 Time for last iteration: -0.37340617179870605\n",
      "Iteration: 44 Time for last iteration: -0.3230419158935547\n",
      "Iteration: 45 Time for last iteration: -0.3200540542602539\n",
      "Iteration: 46 Time for last iteration: -0.3249051570892334\n",
      "Iteration: 47 Time for last iteration: -0.32634902000427246\n",
      "Iteration: 48 Time for last iteration: -0.3213818073272705\n",
      "Iteration: 49 Time for last iteration: -0.3251218795776367\n",
      "Iteration: 50 Time for last iteration: -0.3183019161224365\n",
      "Iteration: 51 Time for last iteration: -0.3235139846801758\n",
      "Iteration: 52 Time for last iteration: -0.34337806701660156\n",
      "Iteration: 53 Time for last iteration: -0.3309462070465088\n",
      "Iteration: 54 Time for last iteration: -0.3205301761627197\n",
      "Iteration: 55 Time for last iteration: -0.3455851078033447\n",
      "Iteration: 56 Time for last iteration: -0.31615209579467773\n",
      "Iteration: 57 Time for last iteration: -0.32341694831848145\n",
      "Iteration: 58 Time for last iteration: -0.319108247756958\n",
      "Iteration: 59 Time for last iteration: -0.3190641403198242\n",
      "Iteration: 60 Time for last iteration: -0.3216238021850586\n",
      "Iteration: 61 Time for last iteration: -0.3195679187774658\n",
      "Iteration: 62 Time for last iteration: -0.31841397285461426\n",
      "Iteration: 63 Time for last iteration: -0.3235621452331543\n",
      "Iteration: 64 Time for last iteration: -0.32091283798217773\n",
      "Iteration: 65 Time for last iteration: -0.32579874992370605\n",
      "Iteration: 66 Time for last iteration: -0.3222987651824951\n",
      "Iteration: 67 Time for last iteration: -0.33127903938293457\n",
      "Iteration: 68 Time for last iteration: -0.32041501998901367\n",
      "Iteration: 69 Time for last iteration: -0.3190009593963623\n",
      "Iteration: 70 Time for last iteration: -0.32459425926208496\n",
      "Iteration: 71 Time for last iteration: -0.36713099479675293\n",
      "Iteration: 72 Time for last iteration: -0.3362245559692383\n",
      "Iteration: 73 Time for last iteration: -0.3386878967285156\n",
      "Iteration: 74 Time for last iteration: -0.3406667709350586\n",
      "Iteration: 75 Time for last iteration: -0.34648585319519043\n",
      "Iteration: 76 Time for last iteration: -0.33898186683654785\n",
      "Iteration: 77 Time for last iteration: -0.39563488960266113\n",
      "Iteration: 78 Time for last iteration: -0.3410499095916748\n",
      "Iteration: 79 Time for last iteration: -0.366304874420166\n",
      "Iteration: 80 Time for last iteration: -0.332977294921875\n",
      "Iteration: 81 Time for last iteration: -0.3301260471343994\n",
      "Iteration: 82 Time for last iteration: -0.3296489715576172\n",
      "Iteration: 83 Time for last iteration: -0.3289520740509033\n",
      "Iteration: 84 Time for last iteration: -0.33293890953063965\n",
      "Iteration: 85 Time for last iteration: -0.3264200687408447\n",
      "Iteration: 86 Time for last iteration: -0.3223609924316406\n",
      "Iteration: 87 Time for last iteration: -0.3602328300476074\n",
      "Iteration: 88 Time for last iteration: -0.3458518981933594\n",
      "Iteration: 89 Time for last iteration: -0.3338160514831543\n",
      "Iteration: 90 Time for last iteration: -0.3210182189941406\n",
      "Iteration: 91 Time for last iteration: -0.3311150074005127\n",
      "Iteration: 92 Time for last iteration: -0.32501673698425293\n",
      "Iteration: 93 Time for last iteration: -0.31923508644104004\n",
      "Iteration: 94 Time for last iteration: -0.31751012802124023\n",
      "Iteration: 95 Time for last iteration: -0.32150793075561523\n",
      "Iteration: 96 Time for last iteration: -0.3296949863433838\n",
      "Iteration: 97 Time for last iteration: -0.3227970600128174\n",
      "Iteration: 98 Time for last iteration: -0.3214879035949707\n",
      "Iteration: 99 Time for last iteration: -0.3251628875732422\n",
      "Iteration: 100 Time for last iteration: -0.3230719566345215\n",
      "Iteration: 101 Time for last iteration: -0.3223590850830078\n",
      "Iteration: 102 Time for last iteration: -0.3275442123413086\n",
      "Iteration: 103 Time for last iteration: -0.335097074508667\n",
      "Iteration: 104 Time for last iteration: -0.3286709785461426\n",
      "Iteration: 105 Time for last iteration: -0.32833290100097656\n",
      "Iteration: 106 Time for last iteration: -0.3205420970916748\n",
      "Iteration: 107 Time for last iteration: -0.3286869525909424\n",
      "Iteration: 108 Time for last iteration: -0.3350517749786377\n",
      "Iteration: 109 Time for last iteration: -0.3427920341491699\n",
      "Iteration: 110 Time for last iteration: -0.3360912799835205\n",
      "Iteration: 111 Time for last iteration: -0.3248159885406494\n",
      "Iteration: 112 Time for last iteration: -0.3372030258178711\n",
      "Iteration: 113 Time for last iteration: -0.3315751552581787\n",
      "Iteration: 114 Time for last iteration: -0.32953977584838867\n",
      "Iteration: 115 Time for last iteration: -0.3222770690917969\n",
      "Iteration: 116 Time for last iteration: -0.3245871067047119\n",
      "Iteration: 117 Time for last iteration: -0.3226938247680664\n",
      "Iteration: 118 Time for last iteration: -0.3182699680328369\n",
      "Iteration: 119 Time for last iteration: -0.3229687213897705\n",
      "Iteration: 120 Time for last iteration: -0.32446789741516113\n",
      "Iteration: 121 Time for last iteration: -0.3272378444671631\n",
      "Iteration: 122 Time for last iteration: -0.32152700424194336\n",
      "Iteration: 123 Time for last iteration: -0.3294410705566406\n",
      "Iteration: 124 Time for last iteration: -0.3832521438598633\n",
      "Iteration: 125 Time for last iteration: -0.3296799659729004\n",
      "Iteration: 126 Time for last iteration: -0.32802891731262207\n",
      "Iteration: 127 Time for last iteration: -0.35115885734558105\n",
      "Iteration: 128 Time for last iteration: -0.35484814643859863\n",
      "Iteration: 129 Time for last iteration: -0.32369089126586914\n",
      "Iteration: 130 Time for last iteration: -0.33175110816955566\n",
      "Iteration: 131 Time for last iteration: -0.3258991241455078\n",
      "Iteration: 132 Time for last iteration: -0.3627138137817383\n",
      "Iteration: 133 Time for last iteration: -0.3208179473876953\n",
      "Iteration: 134 Time for last iteration: -0.323228120803833\n",
      "Iteration: 135 Time for last iteration: -0.33568620681762695\n",
      "Iteration: 136 Time for last iteration: -0.36455297470092773\n",
      "Iteration: 137 Time for last iteration: -0.3263509273529053\n",
      "Iteration: 138 Time for last iteration: -0.33471012115478516\n",
      "Iteration: 139 Time for last iteration: -0.32264113426208496\n",
      "Iteration: 140 Time for last iteration: -0.32645583152770996\n",
      "Iteration: 141 Time for last iteration: -0.3223106861114502\n",
      "Iteration: 142 Time for last iteration: -0.3276832103729248\n",
      "Iteration: 143 Time for last iteration: -0.32950592041015625\n",
      "Iteration: 144 Time for last iteration: -0.3372671604156494\n",
      "Iteration: 145 Time for last iteration: -0.33709287643432617\n",
      "Iteration: 146 Time for last iteration: -0.3417489528656006\n",
      "Iteration: 147 Time for last iteration: -0.3360919952392578\n",
      "Iteration: 148 Time for last iteration: -0.3230929374694824\n",
      "Iteration: 149 Time for last iteration: -0.32945895195007324\n",
      "Iteration: 150 Time for last iteration: -0.3237881660461426\n",
      "Iteration: 151 Time for last iteration: -0.31874513626098633\n",
      "Iteration: 152 Time for last iteration: -0.3215920925140381\n",
      "Iteration: 153 Time for last iteration: -0.3245198726654053\n",
      "Iteration: 154 Time for last iteration: -0.33965015411376953\n",
      "Iteration: 155 Time for last iteration: -0.3223280906677246\n",
      "Iteration: 156 Time for last iteration: -0.31954121589660645\n",
      "Iteration: 157 Time for last iteration: -0.32905125617980957\n",
      "Iteration: 158 Time for last iteration: -0.322904109954834\n",
      "Iteration: 159 Time for last iteration: -0.3199920654296875\n",
      "Iteration: 160 Time for last iteration: -0.32616114616394043\n",
      "Iteration: 161 Time for last iteration: -0.3217349052429199\n",
      "Iteration: 162 Time for last iteration: -0.3254683017730713\n",
      "Iteration: 163 Time for last iteration: -0.3253951072692871\n",
      "Iteration: 164 Time for last iteration: -0.3251628875732422\n",
      "Iteration: 165 Time for last iteration: -0.3228631019592285\n",
      "Iteration: 166 Time for last iteration: -0.33473896980285645\n",
      "Iteration: 167 Time for last iteration: -0.34665489196777344\n",
      "Iteration: 168 Time for last iteration: -0.32569074630737305\n",
      "Iteration: 169 Time for last iteration: -0.3242371082305908\n",
      "Iteration: 170 Time for last iteration: -0.32409000396728516\n",
      "Iteration: 171 Time for last iteration: -0.3191049098968506\n",
      "Iteration: 172 Time for last iteration: -0.32080698013305664\n",
      "Iteration: 173 Time for last iteration: -0.31691980361938477\n",
      "Iteration: 174 Time for last iteration: -0.3271160125732422\n",
      "Iteration: 175 Time for last iteration: -0.3220250606536865\n",
      "Iteration: 176 Time for last iteration: -0.31788206100463867\n",
      "Iteration: 177 Time for last iteration: -0.32081007957458496\n",
      "Iteration: 178 Time for last iteration: -0.3333148956298828\n",
      "Iteration: 179 Time for last iteration: -0.32767176628112793\n",
      "Iteration: 180 Time for last iteration: -0.34915828704833984\n",
      "Iteration: 181 Time for last iteration: -0.3398568630218506\n",
      "Iteration: 182 Time for last iteration: -0.3803677558898926\n",
      "Iteration: 183 Time for last iteration: -0.35462188720703125\n",
      "Iteration: 184 Time for last iteration: -0.3677539825439453\n",
      "Iteration: 185 Time for last iteration: -0.3918170928955078\n",
      "Iteration: 186 Time for last iteration: -0.3231532573699951\n",
      "Iteration: 187 Time for last iteration: -0.36089587211608887\n",
      "Iteration: 188 Time for last iteration: -0.331740140914917\n",
      "Iteration: 189 Time for last iteration: -0.33205509185791016\n",
      "Iteration: 190 Time for last iteration: -0.3438689708709717\n",
      "Iteration: 191 Time for last iteration: -0.3231348991394043\n",
      "Iteration: 192 Time for last iteration: -0.34688496589660645\n",
      "Iteration: 193 Time for last iteration: -0.3316071033477783\n",
      "Iteration: 194 Time for last iteration: -0.3491029739379883\n",
      "Iteration: 195 Time for last iteration: -0.3596799373626709\n",
      "Iteration: 196 Time for last iteration: -0.33098912239074707\n",
      "Iteration: 197 Time for last iteration: -0.3425118923187256\n",
      "Iteration: 198 Time for last iteration: -0.3435051441192627\n",
      "Iteration: 199 Time for last iteration: -0.32850217819213867\n",
      "Iteration: 200 Time for last iteration: -0.349200963973999\n",
      "Iteration: 201 Time for last iteration: -0.32233476638793945\n",
      "Iteration: 202 Time for last iteration: -0.3393137454986572\n",
      "Iteration: 203 Time for last iteration: -0.32671380043029785\n",
      "Iteration: 204 Time for last iteration: -0.3525257110595703\n",
      "Iteration: 205 Time for last iteration: -0.3480839729309082\n",
      "Iteration: 206 Time for last iteration: -0.3308889865875244\n",
      "Iteration: 207 Time for last iteration: -0.3419809341430664\n",
      "Iteration: 208 Time for last iteration: -0.3246290683746338\n",
      "Iteration: 209 Time for last iteration: -0.36121606826782227\n",
      "Iteration: 210 Time for last iteration: -0.3294548988342285\n",
      "Iteration: 211 Time for last iteration: -0.3533601760864258\n",
      "Iteration: 212 Time for last iteration: -0.34047389030456543\n",
      "Iteration: 213 Time for last iteration: -0.36005139350891113\n",
      "Iteration: 214 Time for last iteration: -0.34790587425231934\n",
      "Iteration: 215 Time for last iteration: -0.36316990852355957\n",
      "Iteration: 216 Time for last iteration: -0.33159303665161133\n",
      "Iteration: 217 Time for last iteration: -0.3266439437866211\n",
      "Iteration: 218 Time for last iteration: -0.3461740016937256\n",
      "Iteration: 219 Time for last iteration: -0.3291010856628418\n",
      "Iteration: 220 Time for last iteration: -0.3356320858001709\n",
      "Iteration: 221 Time for last iteration: -0.36482882499694824\n",
      "Iteration: 222 Time for last iteration: -0.3348581790924072\n",
      "Iteration: 223 Time for last iteration: -0.3241868019104004\n",
      "Iteration: 224 Time for last iteration: -0.32363390922546387\n",
      "Iteration: 225 Time for last iteration: -0.32201385498046875\n",
      "Iteration: 226 Time for last iteration: -0.32427430152893066\n",
      "Iteration: 227 Time for last iteration: -0.33007311820983887\n",
      "Iteration: 228 Time for last iteration: -0.3391869068145752\n",
      "Iteration: 229 Time for last iteration: -0.3305809497833252\n",
      "Iteration: 230 Time for last iteration: -0.33785510063171387\n",
      "Iteration: 231 Time for last iteration: -0.354356050491333\n",
      "Iteration: 232 Time for last iteration: -0.36156797409057617\n",
      "Iteration: 233 Time for last iteration: -0.333219051361084\n",
      "Iteration: 234 Time for last iteration: -0.3324599266052246\n",
      "Iteration: 235 Time for last iteration: -0.3309812545776367\n",
      "Iteration: 236 Time for last iteration: -0.33323168754577637\n",
      "Iteration: 237 Time for last iteration: -0.3314228057861328\n",
      "Iteration: 238 Time for last iteration: -0.37408995628356934\n",
      "Iteration: 239 Time for last iteration: -0.4344758987426758\n",
      "Iteration: 240 Time for last iteration: -0.34224367141723633\n",
      "Iteration: 241 Time for last iteration: -0.3246891498565674\n",
      "Iteration: 242 Time for last iteration: -0.326369047164917\n",
      "Iteration: 243 Time for last iteration: -0.3174457550048828\n",
      "Iteration: 244 Time for last iteration: -0.3273611068725586\n",
      "Iteration: 245 Time for last iteration: -0.3258838653564453\n",
      "Iteration: 246 Time for last iteration: -0.332381010055542\n",
      "Iteration: 247 Time for last iteration: -0.3381321430206299\n",
      "Iteration: 248 Time for last iteration: -0.33539795875549316\n",
      "Iteration: 249 Time for last iteration: -0.34485816955566406\n",
      "Iteration: 250 Time for last iteration: -0.3420448303222656\n",
      "Iteration: 251 Time for last iteration: -0.34850287437438965\n",
      "Iteration: 252 Time for last iteration: -0.3362298011779785\n",
      "Iteration: 253 Time for last iteration: -0.3323080539703369\n",
      "Iteration: 254 Time for last iteration: -0.32405662536621094\n",
      "Iteration: 255 Time for last iteration: -0.3217918872833252\n",
      "Iteration: 256 Time for last iteration: -0.33664417266845703\n",
      "Iteration: 257 Time for last iteration: -0.3177609443664551\n",
      "Iteration: 258 Time for last iteration: -0.3263847827911377\n",
      "Iteration: 259 Time for last iteration: -0.3224482536315918\n",
      "Iteration: 260 Time for last iteration: -0.3164968490600586\n",
      "Iteration: 261 Time for last iteration: -0.3231050968170166\n",
      "Iteration: 262 Time for last iteration: -0.3202779293060303\n",
      "Iteration: 263 Time for last iteration: -0.3252129554748535\n",
      "Iteration: 264 Time for last iteration: -0.32187795639038086\n",
      "Iteration: 265 Time for last iteration: -0.3321208953857422\n",
      "Iteration: 266 Time for last iteration: -0.32718515396118164\n",
      "Iteration: 267 Time for last iteration: -0.3163490295410156\n",
      "Iteration: 268 Time for last iteration: -0.3192260265350342\n",
      "Iteration: 269 Time for last iteration: -0.3238668441772461\n",
      "Iteration: 270 Time for last iteration: -0.3177499771118164\n",
      "Iteration: 271 Time for last iteration: -0.32648515701293945\n",
      "Iteration: 272 Time for last iteration: -0.3165876865386963\n",
      "Iteration: 273 Time for last iteration: -0.3127329349517822\n",
      "Iteration: 274 Time for last iteration: -0.3160109519958496\n",
      "Iteration: 275 Time for last iteration: -0.3174619674682617\n",
      "Iteration: 276 Time for last iteration: -0.3214097023010254\n",
      "Iteration: 277 Time for last iteration: -0.3155989646911621\n",
      "Iteration: 278 Time for last iteration: -0.32117295265197754\n",
      "Iteration: 279 Time for last iteration: -0.344005823135376\n",
      "Iteration: 280 Time for last iteration: -0.34419894218444824\n",
      "Iteration: 281 Time for last iteration: -0.32553791999816895\n",
      "Iteration: 282 Time for last iteration: -0.3428502082824707\n",
      "Iteration: 283 Time for last iteration: -0.33356475830078125\n",
      "Iteration: 284 Time for last iteration: -0.32883405685424805\n",
      "Iteration: 285 Time for last iteration: -0.3191978931427002\n",
      "Iteration: 286 Time for last iteration: -0.3158552646636963\n",
      "Iteration: 287 Time for last iteration: -0.32038307189941406\n",
      "Iteration: 288 Time for last iteration: -0.31414794921875\n",
      "Iteration: 289 Time for last iteration: -0.32778191566467285\n",
      "Iteration: 290 Time for last iteration: -0.32347798347473145\n",
      "Iteration: 291 Time for last iteration: -0.315396785736084\n",
      "Iteration: 292 Time for last iteration: -0.31524205207824707\n",
      "Iteration: 293 Time for last iteration: -0.3133351802825928\n",
      "Iteration: 294 Time for last iteration: -0.3149378299713135\n",
      "Iteration: 295 Time for last iteration: -0.33003807067871094\n",
      "Iteration: 296 Time for last iteration: -0.3255951404571533\n",
      "Iteration: 297 Time for last iteration: -0.314241886138916\n",
      "Iteration: 298 Time for last iteration: -0.31831908226013184\n",
      "Iteration: 299 Time for last iteration: -0.31942081451416016\n",
      "Iteration: 300 Time for last iteration: -0.3327000141143799\n",
      "Iteration: 301 Time for last iteration: -0.31690311431884766\n",
      "Iteration: 302 Time for last iteration: -0.3305089473724365\n",
      "Iteration: 303 Time for last iteration: -0.3445911407470703\n",
      "Iteration: 304 Time for last iteration: -0.3149237632751465\n",
      "Iteration: 305 Time for last iteration: -0.31224989891052246\n",
      "Iteration: 306 Time for last iteration: -0.32266974449157715\n",
      "Iteration: 307 Time for last iteration: -0.3253931999206543\n",
      "Iteration: 308 Time for last iteration: -0.3260490894317627\n",
      "Iteration: 309 Time for last iteration: -0.3197360038757324\n",
      "Iteration: 310 Time for last iteration: -0.31730103492736816\n",
      "Iteration: 311 Time for last iteration: -0.3191659450531006\n",
      "Iteration: 312 Time for last iteration: -0.31662893295288086\n",
      "Iteration: 313 Time for last iteration: -0.3488428592681885\n",
      "Iteration: 314 Time for last iteration: -0.328265905380249\n",
      "Iteration: 315 Time for last iteration: -0.3269808292388916\n",
      "Iteration: 316 Time for last iteration: -0.32613277435302734\n",
      "Iteration: 317 Time for last iteration: -0.3245828151702881\n",
      "Iteration: 318 Time for last iteration: -0.3115830421447754\n",
      "Iteration: 319 Time for last iteration: -0.3261990547180176\n",
      "Iteration: 320 Time for last iteration: -0.33393096923828125\n",
      "Iteration: 321 Time for last iteration: -0.33214712142944336\n",
      "Iteration: 322 Time for last iteration: -0.3590388298034668\n",
      "Iteration: 323 Time for last iteration: -0.33259010314941406\n",
      "Iteration: 324 Time for last iteration: -0.3388848304748535\n",
      "Iteration: 325 Time for last iteration: -0.33120083808898926\n",
      "Iteration: 326 Time for last iteration: -0.3364102840423584\n",
      "Iteration: 327 Time for last iteration: -0.32927989959716797\n",
      "Iteration: 328 Time for last iteration: -0.364105224609375\n",
      "Iteration: 329 Time for last iteration: -0.3499479293823242\n",
      "Iteration: 330 Time for last iteration: -0.32941412925720215\n",
      "Iteration: 331 Time for last iteration: -0.3284318447113037\n",
      "Iteration: 332 Time for last iteration: -0.3385941982269287\n",
      "Iteration: 333 Time for last iteration: -0.3295609951019287\n",
      "Iteration: 334 Time for last iteration: -0.3319110870361328\n",
      "Iteration: 335 Time for last iteration: -0.3283541202545166\n",
      "Iteration: 336 Time for last iteration: -0.33173322677612305\n",
      "Iteration: 337 Time for last iteration: -0.32915425300598145\n",
      "Iteration: 338 Time for last iteration: -0.33219408988952637\n",
      "Iteration: 339 Time for last iteration: -0.3354489803314209\n",
      "Iteration: 340 Time for last iteration: -0.33048295974731445\n",
      "Iteration: 341 Time for last iteration: -0.3334059715270996\n",
      "Iteration: 342 Time for last iteration: -0.3238399028778076\n",
      "Iteration: 343 Time for last iteration: -0.32914090156555176\n",
      "Iteration: 344 Time for last iteration: -0.3307061195373535\n",
      "Iteration: 345 Time for last iteration: -0.33705902099609375\n",
      "Iteration: 346 Time for last iteration: -0.33364105224609375\n",
      "Iteration: 347 Time for last iteration: -0.33585596084594727\n",
      "Iteration: 348 Time for last iteration: -0.3726041316986084\n",
      "Iteration: 349 Time for last iteration: -0.3308851718902588\n",
      "Iteration: 350 Time for last iteration: -0.33400511741638184\n",
      "Iteration: 351 Time for last iteration: -0.3293190002441406\n",
      "Iteration: 352 Time for last iteration: -0.32471299171447754\n",
      "Iteration: 353 Time for last iteration: -0.33755064010620117\n",
      "Iteration: 354 Time for last iteration: -0.33325695991516113\n",
      "Iteration: 355 Time for last iteration: -0.3413271903991699\n",
      "Iteration: 356 Time for last iteration: -0.3725900650024414\n",
      "Iteration: 357 Time for last iteration: -0.3315908908843994\n",
      "Iteration: 358 Time for last iteration: -0.3326117992401123\n",
      "Iteration: 359 Time for last iteration: -0.32538604736328125\n",
      "Iteration: 360 Time for last iteration: -0.32884979248046875\n",
      "Iteration: 361 Time for last iteration: -0.3376190662384033\n",
      "Iteration: 362 Time for last iteration: -0.34317898750305176\n",
      "Iteration: 363 Time for last iteration: -0.33455586433410645\n",
      "Iteration: 364 Time for last iteration: -0.33431386947631836\n",
      "Iteration: 365 Time for last iteration: -0.3293440341949463\n",
      "Iteration: 366 Time for last iteration: -0.3206498622894287\n",
      "Iteration: 367 Time for last iteration: -0.34897518157958984\n",
      "Iteration: 368 Time for last iteration: -0.33281588554382324\n",
      "Iteration: 369 Time for last iteration: -0.3333899974822998\n",
      "Iteration: 370 Time for last iteration: -0.3330070972442627\n",
      "Iteration: 371 Time for last iteration: -0.3333299160003662\n",
      "Iteration: 372 Time for last iteration: -0.3309822082519531\n",
      "Iteration: 373 Time for last iteration: -0.3201580047607422\n",
      "Iteration: 374 Time for last iteration: -0.3311960697174072\n",
      "Iteration: 375 Time for last iteration: -0.32666778564453125\n",
      "Iteration: 376 Time for last iteration: -0.3754448890686035\n",
      "Iteration: 377 Time for last iteration: -0.36572909355163574\n",
      "Iteration: 378 Time for last iteration: -0.3317539691925049\n",
      "Iteration: 379 Time for last iteration: -0.3402895927429199\n",
      "Iteration: 380 Time for last iteration: -0.3558638095855713\n",
      "Iteration: 381 Time for last iteration: -0.3563981056213379\n",
      "Iteration: 382 Time for last iteration: -0.3432948589324951\n",
      "Iteration: 383 Time for last iteration: -0.37282395362854004\n",
      "Iteration: 384 Time for last iteration: -0.3814551830291748\n",
      "Iteration: 385 Time for last iteration: -0.34424686431884766\n",
      "Iteration: 386 Time for last iteration: -0.36438488960266113\n",
      "Iteration: 387 Time for last iteration: -0.3420600891113281\n",
      "Iteration: 388 Time for last iteration: -0.34464406967163086\n",
      "Iteration: 389 Time for last iteration: -0.33116912841796875\n",
      "Iteration: 390 Time for last iteration: -0.37563419342041016\n",
      "Iteration: 391 Time for last iteration: -0.3705110549926758\n",
      "Iteration: 392 Time for last iteration: -0.3684561252593994\n",
      "Iteration: 393 Time for last iteration: -0.368030309677124\n",
      "Iteration: 394 Time for last iteration: -0.36105990409851074\n",
      "Iteration: 395 Time for last iteration: -0.3703029155731201\n",
      "Iteration: 396 Time for last iteration: -0.36005711555480957\n",
      "Iteration: 397 Time for last iteration: -0.40210986137390137\n",
      "Iteration: 398 Time for last iteration: -0.40254807472229004\n",
      "Iteration: 399 Time for last iteration: -0.43331003189086914\n",
      "Iteration: 400 Time for last iteration: -0.42975687980651855\n",
      "Iteration: 401 Time for last iteration: -0.44652795791625977\n",
      "Iteration: 402 Time for last iteration: -0.4345428943634033\n",
      "Iteration: 403 Time for last iteration: -0.49942994117736816\n",
      "Iteration: 404 Time for last iteration: -0.41217494010925293\n",
      "Iteration: 405 Time for last iteration: -0.42344021797180176\n",
      "Iteration: 406 Time for last iteration: -0.4369337558746338\n",
      "Iteration: 407 Time for last iteration: -0.42790865898132324\n",
      "Iteration: 408 Time for last iteration: -0.4235689640045166\n",
      "Iteration: 409 Time for last iteration: -0.4296438694000244\n",
      "Iteration: 410 Time for last iteration: -0.4133749008178711\n",
      "Iteration: 411 Time for last iteration: -0.4658203125\n",
      "Iteration: 412 Time for last iteration: -0.5262317657470703\n",
      "Iteration: 413 Time for last iteration: -0.44115519523620605\n",
      "Iteration: 414 Time for last iteration: -0.46106505393981934\n",
      "Iteration: 415 Time for last iteration: -0.4566030502319336\n",
      "Iteration: 416 Time for last iteration: -0.4777240753173828\n",
      "Iteration: 417 Time for last iteration: -0.5069680213928223\n",
      "Iteration: 418 Time for last iteration: -0.4141886234283447\n",
      "Iteration: 419 Time for last iteration: -0.40822601318359375\n",
      "Iteration: 420 Time for last iteration: -0.4314076900482178\n",
      "Iteration: 421 Time for last iteration: -0.42589402198791504\n",
      "Iteration: 422 Time for last iteration: -0.3422830104827881\n",
      "Iteration: 423 Time for last iteration: -0.3305339813232422\n",
      "Iteration: 424 Time for last iteration: -0.34906697273254395\n",
      "Iteration: 425 Time for last iteration: -0.36473608016967773\n",
      "Iteration: 426 Time for last iteration: -0.3891258239746094\n",
      "Iteration: 427 Time for last iteration: -0.4144172668457031\n",
      "Iteration: 428 Time for last iteration: -0.33922481536865234\n",
      "Iteration: 429 Time for last iteration: -0.3460240364074707\n",
      "Iteration: 430 Time for last iteration: -0.467663049697876\n",
      "Iteration: 431 Time for last iteration: -0.4217100143432617\n",
      "Iteration: 432 Time for last iteration: -0.42288732528686523\n",
      "Iteration: 433 Time for last iteration: -0.4189188480377197\n",
      "Iteration: 434 Time for last iteration: -0.4074985980987549\n",
      "Iteration: 435 Time for last iteration: -0.4246509075164795\n",
      "Iteration: 436 Time for last iteration: -0.4290781021118164\n",
      "Iteration: 437 Time for last iteration: -0.424457311630249\n",
      "Iteration: 438 Time for last iteration: -0.42699313163757324\n",
      "Iteration: 439 Time for last iteration: -0.4173409938812256\n",
      "Iteration: 440 Time for last iteration: -0.43778204917907715\n",
      "Iteration: 441 Time for last iteration: -0.42052602767944336\n",
      "Iteration: 442 Time for last iteration: -0.413104772567749\n",
      "Iteration: 443 Time for last iteration: -0.41051697731018066\n",
      "Iteration: 444 Time for last iteration: -0.4389078617095947\n",
      "Iteration: 445 Time for last iteration: -0.41886425018310547\n",
      "Iteration: 446 Time for last iteration: -0.40782999992370605\n",
      "Iteration: 447 Time for last iteration: -0.39986324310302734\n",
      "Iteration: 448 Time for last iteration: -0.4226560592651367\n",
      "Iteration: 449 Time for last iteration: -0.4211580753326416\n",
      "Iteration: 450 Time for last iteration: -0.41504597663879395\n",
      "Iteration: 451 Time for last iteration: -0.4089939594268799\n",
      "Iteration: 452 Time for last iteration: -0.43117809295654297\n",
      "Iteration: 453 Time for last iteration: -0.4044051170349121\n",
      "Iteration: 454 Time for last iteration: -0.40999817848205566\n",
      "Iteration: 455 Time for last iteration: -0.4500408172607422\n",
      "Iteration: 456 Time for last iteration: -0.45598793029785156\n",
      "Iteration: 457 Time for last iteration: -0.40258312225341797\n",
      "Iteration: 458 Time for last iteration: -0.4120478630065918\n",
      "Iteration: 459 Time for last iteration: -0.4240550994873047\n",
      "Iteration: 460 Time for last iteration: -0.427325963973999\n",
      "Iteration: 461 Time for last iteration: -0.4026377201080322\n",
      "Iteration: 462 Time for last iteration: -0.40650010108947754\n",
      "Iteration: 463 Time for last iteration: -0.41510510444641113\n",
      "Iteration: 464 Time for last iteration: -0.4332859516143799\n",
      "Iteration: 465 Time for last iteration: -0.48177194595336914\n",
      "Iteration: 466 Time for last iteration: -0.4180171489715576\n",
      "Iteration: 467 Time for last iteration: -0.40674424171447754\n",
      "Iteration: 468 Time for last iteration: -0.41124892234802246\n",
      "Iteration: 469 Time for last iteration: -0.42291903495788574\n",
      "Iteration: 470 Time for last iteration: -0.4144909381866455\n",
      "Iteration: 471 Time for last iteration: -0.4019920825958252\n",
      "Iteration: 472 Time for last iteration: -0.4324181079864502\n",
      "Iteration: 473 Time for last iteration: -0.4219682216644287\n",
      "Iteration: 474 Time for last iteration: -0.4098801612854004\n",
      "Iteration: 475 Time for last iteration: -0.4228050708770752\n",
      "Iteration: 476 Time for last iteration: -0.4099719524383545\n",
      "Iteration: 477 Time for last iteration: -0.40776491165161133\n",
      "Iteration: 478 Time for last iteration: -0.4164087772369385\n",
      "Iteration: 479 Time for last iteration: -0.40986013412475586\n",
      "Iteration: 480 Time for last iteration: -0.4161388874053955\n",
      "Iteration: 481 Time for last iteration: -0.411945104598999\n",
      "Iteration: 482 Time for last iteration: -0.4059329032897949\n",
      "Iteration: 483 Time for last iteration: -0.42099833488464355\n",
      "Iteration: 484 Time for last iteration: -0.410567045211792\n",
      "Iteration: 485 Time for last iteration: -0.41214489936828613\n",
      "Iteration: 486 Time for last iteration: -0.406876802444458\n",
      "Iteration: 487 Time for last iteration: -0.40561795234680176\n",
      "Iteration: 488 Time for last iteration: -0.4043750762939453\n",
      "Iteration: 489 Time for last iteration: -0.4134972095489502\n",
      "Iteration: 490 Time for last iteration: -0.408444881439209\n",
      "Iteration: 491 Time for last iteration: -0.4175541400909424\n",
      "Iteration: 492 Time for last iteration: -0.42729997634887695\n",
      "Iteration: 493 Time for last iteration: -0.4307382106781006\n",
      "Iteration: 494 Time for last iteration: -0.45864176750183105\n",
      "Iteration: 495 Time for last iteration: -0.41420698165893555\n",
      "Iteration: 496 Time for last iteration: -0.4160120487213135\n",
      "Iteration: 497 Time for last iteration: -0.40447306632995605\n",
      "Iteration: 498 Time for last iteration: -0.4113471508026123\n",
      "Iteration: 499 Time for last iteration: -0.43540096282958984\n",
      "Iteration: 500 Time for last iteration: -0.41118788719177246\n",
      "Iteration: 501 Time for last iteration: -0.405789852142334\n",
      "Iteration: 502 Time for last iteration: -0.40718889236450195\n",
      "Iteration: 503 Time for last iteration: -0.42153120040893555\n",
      "Iteration: 504 Time for last iteration: -0.40091609954833984\n",
      "Iteration: 505 Time for last iteration: -0.41023826599121094\n",
      "Iteration: 506 Time for last iteration: -0.41402506828308105\n",
      "Iteration: 507 Time for last iteration: -0.4055600166320801\n",
      "Iteration: 508 Time for last iteration: -0.4370908737182617\n",
      "Iteration: 509 Time for last iteration: -0.4169478416442871\n",
      "Iteration: 510 Time for last iteration: -0.4004671573638916\n",
      "Iteration: 511 Time for last iteration: -0.4108707904815674\n",
      "Iteration: 512 Time for last iteration: -0.41385602951049805\n",
      "Iteration: 513 Time for last iteration: -0.41951417922973633\n",
      "Iteration: 514 Time for last iteration: -0.40958571434020996\n",
      "Iteration: 515 Time for last iteration: -0.4104728698730469\n",
      "Iteration: 516 Time for last iteration: -0.4189019203186035\n",
      "Iteration: 517 Time for last iteration: -0.426347017288208\n",
      "Iteration: 518 Time for last iteration: -0.4416778087615967\n",
      "Iteration: 519 Time for last iteration: -0.40577006340026855\n",
      "Iteration: 520 Time for last iteration: -0.4316120147705078\n",
      "Iteration: 521 Time for last iteration: -0.5758378505706787\n",
      "Iteration: 522 Time for last iteration: -0.41026735305786133\n",
      "Iteration: 523 Time for last iteration: -0.412200927734375\n",
      "Iteration: 524 Time for last iteration: -0.39569997787475586\n",
      "Iteration: 525 Time for last iteration: -0.4061272144317627\n",
      "Iteration: 526 Time for last iteration: -0.4073798656463623\n",
      "Iteration: 527 Time for last iteration: -0.41338586807250977\n",
      "Iteration: 528 Time for last iteration: -0.41342687606811523\n",
      "Iteration: 529 Time for last iteration: -0.397550106048584\n",
      "Iteration: 530 Time for last iteration: -0.40971803665161133\n",
      "Iteration: 531 Time for last iteration: -0.4033489227294922\n",
      "Iteration: 532 Time for last iteration: -0.48984599113464355\n",
      "Iteration: 533 Time for last iteration: -0.4198012351989746\n",
      "Iteration: 534 Time for last iteration: -0.44631409645080566\n",
      "Iteration: 535 Time for last iteration: -0.48432493209838867\n",
      "Iteration: 536 Time for last iteration: -0.35469913482666016\n",
      "Iteration: 537 Time for last iteration: -0.3396871089935303\n",
      "Iteration: 538 Time for last iteration: -0.33403706550598145\n",
      "Iteration: 539 Time for last iteration: -0.3338906764984131\n",
      "Iteration: 540 Time for last iteration: -0.4130270481109619\n",
      "Iteration: 541 Time for last iteration: -0.32416415214538574\n",
      "Iteration: 542 Time for last iteration: -0.33228492736816406\n",
      "Iteration: 543 Time for last iteration: -0.33439207077026367\n",
      "Iteration: 544 Time for last iteration: -0.3389780521392822\n",
      "Iteration: 545 Time for last iteration: -0.3446950912475586\n",
      "Iteration: 546 Time for last iteration: -0.40175580978393555\n",
      "Iteration: 547 Time for last iteration: -0.39591312408447266\n",
      "Iteration: 548 Time for last iteration: -0.558992862701416\n",
      "Iteration: 549 Time for last iteration: -0.4548640251159668\n",
      "Iteration: 550 Time for last iteration: -0.42861104011535645\n",
      "Iteration: 551 Time for last iteration: -0.6209280490875244\n",
      "Iteration: 552 Time for last iteration: -0.3325190544128418\n",
      "Iteration: 553 Time for last iteration: -0.33160901069641113\n",
      "Iteration: 554 Time for last iteration: -0.33537912368774414\n",
      "Iteration: 555 Time for last iteration: -0.3333590030670166\n",
      "Iteration: 556 Time for last iteration: -0.33786630630493164\n",
      "Iteration: 557 Time for last iteration: -0.32863688468933105\n",
      "Iteration: 558 Time for last iteration: -0.3247349262237549\n",
      "Iteration: 559 Time for last iteration: -0.33496594429016113\n",
      "Iteration: 560 Time for last iteration: -0.3377048969268799\n",
      "Iteration: 561 Time for last iteration: -0.3361051082611084\n",
      "Iteration: 562 Time for last iteration: -0.3254380226135254\n",
      "Iteration: 563 Time for last iteration: -0.38271212577819824\n",
      "Iteration: 564 Time for last iteration: -0.3176999092102051\n",
      "Iteration: 565 Time for last iteration: -0.3224630355834961\n",
      "Iteration: 566 Time for last iteration: -0.3159139156341553\n",
      "Iteration: 567 Time for last iteration: -0.3413059711456299\n",
      "Iteration: 568 Time for last iteration: -0.3238530158996582\n",
      "Iteration: 569 Time for last iteration: -0.3358309268951416\n",
      "Iteration: 570 Time for last iteration: -0.3355748653411865\n",
      "Iteration: 571 Time for last iteration: -0.32592010498046875\n",
      "Iteration: 572 Time for last iteration: -0.325455904006958\n",
      "Iteration: 573 Time for last iteration: -0.32882213592529297\n",
      "Iteration: 574 Time for last iteration: -0.33246588706970215\n",
      "Iteration: 575 Time for last iteration: -0.39678406715393066\n",
      "Iteration: 576 Time for last iteration: -0.41188907623291016\n",
      "Iteration: 577 Time for last iteration: -0.5494368076324463\n",
      "Iteration: 578 Time for last iteration: -0.3444678783416748\n",
      "Iteration: 579 Time for last iteration: -0.33754897117614746\n",
      "Iteration: 580 Time for last iteration: -0.39348673820495605\n",
      "Iteration: 581 Time for last iteration: -0.3473479747772217\n",
      "Iteration: 582 Time for last iteration: -0.3561410903930664\n",
      "Iteration: 583 Time for last iteration: -0.327258825302124\n",
      "Iteration: 584 Time for last iteration: -0.35019540786743164\n",
      "Iteration: 585 Time for last iteration: -0.34285402297973633\n",
      "Iteration: 586 Time for last iteration: -0.32445406913757324\n",
      "Iteration: 587 Time for last iteration: -0.36278605461120605\n",
      "Iteration: 588 Time for last iteration: -0.3335597515106201\n",
      "Iteration: 589 Time for last iteration: -0.34586215019226074\n",
      "Iteration: 590 Time for last iteration: -0.3541839122772217\n",
      "Iteration: 591 Time for last iteration: -0.343311071395874\n",
      "Iteration: 592 Time for last iteration: -0.3331477642059326\n",
      "Iteration: 593 Time for last iteration: -0.3370211124420166\n",
      "Iteration: 594 Time for last iteration: -0.3752870559692383\n",
      "Iteration: 595 Time for last iteration: -0.33345794677734375\n",
      "Iteration: 596 Time for last iteration: -0.3457207679748535\n",
      "Iteration: 597 Time for last iteration: -0.32006001472473145\n",
      "Iteration: 598 Time for last iteration: -0.33033108711242676\n",
      "Iteration: 599 Time for last iteration: -0.33109498023986816\n",
      "Iteration: 600 Time for last iteration: -0.3354310989379883\n",
      "Iteration: 601 Time for last iteration: -0.36140894889831543\n",
      "Iteration: 602 Time for last iteration: -0.339083194732666\n",
      "Iteration: 603 Time for last iteration: -0.3461179733276367\n",
      "Iteration: 604 Time for last iteration: -0.35509705543518066\n",
      "Iteration: 605 Time for last iteration: -0.397371768951416\n",
      "Iteration: 606 Time for last iteration: -0.3440070152282715\n",
      "Iteration: 607 Time for last iteration: -0.36945223808288574\n",
      "Iteration: 608 Time for last iteration: -0.3151998519897461\n",
      "Iteration: 609 Time for last iteration: -0.3283519744873047\n",
      "Iteration: 610 Time for last iteration: -0.3248109817504883\n",
      "Iteration: 611 Time for last iteration: -0.3523879051208496\n",
      "Iteration: 612 Time for last iteration: -0.36641502380371094\n",
      "Iteration: 613 Time for last iteration: -0.32683300971984863\n",
      "Iteration: 614 Time for last iteration: -0.3583056926727295\n",
      "Iteration: 615 Time for last iteration: -0.3325161933898926\n",
      "Iteration: 616 Time for last iteration: -0.3515939712524414\n",
      "Iteration: 617 Time for last iteration: -0.3700602054595947\n",
      "Iteration: 618 Time for last iteration: -0.3271980285644531\n",
      "Iteration: 619 Time for last iteration: -0.3576650619506836\n",
      "Iteration: 620 Time for last iteration: -0.3748030662536621\n",
      "Iteration: 621 Time for last iteration: -0.3928802013397217\n",
      "Iteration: 622 Time for last iteration: -0.3379178047180176\n",
      "Iteration: 623 Time for last iteration: -0.5095548629760742\n",
      "Iteration: 624 Time for last iteration: -0.4261586666107178\n",
      "Iteration: 625 Time for last iteration: -0.3779418468475342\n",
      "Iteration: 626 Time for last iteration: -0.38244104385375977\n",
      "Iteration: 627 Time for last iteration: -0.36711978912353516\n",
      "Iteration: 628 Time for last iteration: -0.35274696350097656\n",
      "Iteration: 629 Time for last iteration: -0.33759498596191406\n",
      "Iteration: 630 Time for last iteration: -0.3476731777191162\n",
      "Iteration: 631 Time for last iteration: -0.3265037536621094\n",
      "Iteration: 632 Time for last iteration: -0.34876012802124023\n",
      "Iteration: 633 Time for last iteration: -0.33638501167297363\n",
      "Iteration: 634 Time for last iteration: -0.43071699142456055\n",
      "Iteration: 635 Time for last iteration: -0.38971805572509766\n",
      "Iteration: 636 Time for last iteration: -0.40282607078552246\n",
      "Iteration: 637 Time for last iteration: -0.37820911407470703\n",
      "Iteration: 638 Time for last iteration: -0.3800959587097168\n",
      "Iteration: 639 Time for last iteration: -0.37782716751098633\n",
      "Iteration: 640 Time for last iteration: -0.3764221668243408\n",
      "Iteration: 641 Time for last iteration: -0.4256172180175781\n",
      "Iteration: 642 Time for last iteration: -0.4174468517303467\n",
      "Iteration: 643 Time for last iteration: -0.39613795280456543\n",
      "Iteration: 644 Time for last iteration: -0.3724679946899414\n",
      "Iteration: 645 Time for last iteration: -0.3588688373565674\n",
      "Iteration: 646 Time for last iteration: -0.36506199836730957\n",
      "Iteration: 647 Time for last iteration: -0.3740112781524658\n",
      "Iteration: 648 Time for last iteration: -0.40760087966918945\n",
      "Iteration: 649 Time for last iteration: -0.42974424362182617\n",
      "Iteration: 650 Time for last iteration: -0.43765878677368164\n",
      "Iteration: 651 Time for last iteration: -0.3904540538787842\n",
      "Iteration: 652 Time for last iteration: -0.409865140914917\n",
      "Iteration: 653 Time for last iteration: -0.4025602340698242\n",
      "Iteration: 654 Time for last iteration: -0.3889636993408203\n",
      "Iteration: 655 Time for last iteration: -0.349193811416626\n",
      "Iteration: 656 Time for last iteration: -0.361098051071167\n",
      "Iteration: 657 Time for last iteration: -0.350294828414917\n",
      "Iteration: 658 Time for last iteration: -0.4375317096710205\n",
      "Iteration: 659 Time for last iteration: -0.34643006324768066\n",
      "Iteration: 660 Time for last iteration: -0.3462860584259033\n",
      "Iteration: 661 Time for last iteration: -0.3727569580078125\n",
      "Iteration: 662 Time for last iteration: -0.3790888786315918\n",
      "Iteration: 663 Time for last iteration: -0.3890061378479004\n",
      "Iteration: 664 Time for last iteration: -0.3752901554107666\n",
      "Iteration: 665 Time for last iteration: -0.3584282398223877\n",
      "Iteration: 666 Time for last iteration: -0.3999199867248535\n",
      "Iteration: 667 Time for last iteration: -0.3794891834259033\n",
      "Iteration: 668 Time for last iteration: -0.37157297134399414\n",
      "Iteration: 669 Time for last iteration: -0.359713077545166\n",
      "Iteration: 670 Time for last iteration: -0.3823699951171875\n",
      "Iteration: 671 Time for last iteration: -0.38193511962890625\n",
      "Iteration: 672 Time for last iteration: -0.3819890022277832\n",
      "Iteration: 673 Time for last iteration: -0.3381330966949463\n",
      "Iteration: 674 Time for last iteration: -0.3771698474884033\n",
      "Iteration: 675 Time for last iteration: -0.3648059368133545\n",
      "Iteration: 676 Time for last iteration: -0.34641027450561523\n",
      "Iteration: 677 Time for last iteration: -0.33989715576171875\n",
      "Iteration: 678 Time for last iteration: -0.38298821449279785\n",
      "Iteration: 679 Time for last iteration: -0.3809797763824463\n",
      "Iteration: 680 Time for last iteration: -0.39731693267822266\n",
      "Iteration: 681 Time for last iteration: -0.3982429504394531\n",
      "Iteration: 682 Time for last iteration: -0.4194672107696533\n",
      "Iteration: 683 Time for last iteration: -0.4034130573272705\n",
      "Iteration: 684 Time for last iteration: -0.50868821144104\n",
      "Iteration: 685 Time for last iteration: -0.3980231285095215\n",
      "Iteration: 686 Time for last iteration: -0.3924062252044678\n",
      "Iteration: 687 Time for last iteration: -0.37120985984802246\n",
      "Iteration: 688 Time for last iteration: -0.351290225982666\n",
      "Iteration: 689 Time for last iteration: -0.35483217239379883\n",
      "Iteration: 690 Time for last iteration: -0.3515288829803467\n",
      "Iteration: 691 Time for last iteration: -0.3913078308105469\n",
      "Iteration: 692 Time for last iteration: -0.42325711250305176\n",
      "Iteration: 693 Time for last iteration: -0.4369828701019287\n",
      "Iteration: 694 Time for last iteration: -0.4759218692779541\n",
      "Iteration: 695 Time for last iteration: -0.42670488357543945\n",
      "Iteration: 696 Time for last iteration: -0.3868579864501953\n",
      "Iteration: 697 Time for last iteration: -0.5239620208740234\n",
      "Iteration: 698 Time for last iteration: -0.3908200263977051\n",
      "Iteration: 699 Time for last iteration: -0.36170506477355957\n",
      "Iteration: 700 Time for last iteration: -0.4564049243927002\n",
      "Iteration: 701 Time for last iteration: -0.35945701599121094\n",
      "Iteration: 702 Time for last iteration: -0.46466994285583496\n",
      "Iteration: 703 Time for last iteration: -0.4158589839935303\n",
      "Iteration: 704 Time for last iteration: -0.3483588695526123\n",
      "Iteration: 705 Time for last iteration: -0.40686893463134766\n",
      "Iteration: 706 Time for last iteration: -0.413254976272583\n",
      "Iteration: 707 Time for last iteration: -0.43323206901550293\n",
      "Iteration: 708 Time for last iteration: -0.5729091167449951\n",
      "Iteration: 709 Time for last iteration: -0.39415407180786133\n",
      "Iteration: 710 Time for last iteration: -0.4058058261871338\n",
      "Iteration: 711 Time for last iteration: -0.4451179504394531\n",
      "Iteration: 712 Time for last iteration: -0.30774807929992676\n",
      "Iteration: 713 Time for last iteration: -0.3953249454498291\n",
      "Iteration: 714 Time for last iteration: -0.35971593856811523\n",
      "Iteration: 715 Time for last iteration: -0.36254000663757324\n",
      "Iteration: 716 Time for last iteration: -0.39647912979125977\n",
      "Iteration: 717 Time for last iteration: -0.3551301956176758\n",
      "Iteration: 718 Time for last iteration: -0.37411999702453613\n",
      "Iteration: 719 Time for last iteration: -0.47862887382507324\n",
      "Iteration: 720 Time for last iteration: -0.35448217391967773\n",
      "Iteration: 721 Time for last iteration: -0.3607749938964844\n",
      "Iteration: 722 Time for last iteration: -0.3412609100341797\n",
      "Iteration: 723 Time for last iteration: -0.38330698013305664\n",
      "Iteration: 724 Time for last iteration: -0.44506311416625977\n",
      "Iteration: 725 Time for last iteration: -0.365966796875\n",
      "Iteration: 726 Time for last iteration: -0.4793999195098877\n",
      "Iteration: 727 Time for last iteration: -0.4340832233428955\n",
      "Iteration: 728 Time for last iteration: -0.4345877170562744\n",
      "Iteration: 729 Time for last iteration: -0.4659230709075928\n",
      "Iteration: 730 Time for last iteration: -0.4313199520111084\n",
      "Iteration: 731 Time for last iteration: -0.40114808082580566\n",
      "Iteration: 732 Time for last iteration: -0.4303412437438965\n",
      "Iteration: 733 Time for last iteration: -0.38060593605041504\n",
      "Iteration: 734 Time for last iteration: -0.38047003746032715\n",
      "Iteration: 735 Time for last iteration: -0.3965299129486084\n",
      "Iteration: 736 Time for last iteration: -0.396604061126709\n",
      "Iteration: 737 Time for last iteration: -0.3414340019226074\n",
      "Iteration: 738 Time for last iteration: -0.3273029327392578\n",
      "Iteration: 739 Time for last iteration: -0.32010483741760254\n",
      "Iteration: 740 Time for last iteration: -0.32088303565979004\n",
      "Iteration: 741 Time for last iteration: -0.3840959072113037\n",
      "Iteration: 742 Time for last iteration: -0.35039520263671875\n",
      "Iteration: 743 Time for last iteration: -0.3679187297821045\n",
      "Iteration: 744 Time for last iteration: -0.39549708366394043\n",
      "Iteration: 745 Time for last iteration: -0.5909292697906494\n",
      "Iteration: 746 Time for last iteration: -0.5932230949401855\n",
      "Iteration: 747 Time for last iteration: -0.43992090225219727\n",
      "Iteration: 748 Time for last iteration: -0.3250401020050049\n",
      "Iteration: 749 Time for last iteration: -0.32064008712768555\n",
      "Iteration: 750 Time for last iteration: -0.39836907386779785\n",
      "Iteration: 751 Time for last iteration: -0.32730889320373535\n",
      "Iteration: 752 Time for last iteration: -0.36063098907470703\n",
      "Iteration: 753 Time for last iteration: -0.36838507652282715\n",
      "Iteration: 754 Time for last iteration: -0.35430192947387695\n",
      "Iteration: 755 Time for last iteration: -0.3504331111907959\n",
      "Iteration: 756 Time for last iteration: -0.45678162574768066\n",
      "Iteration: 757 Time for last iteration: -0.5315477848052979\n",
      "Iteration: 758 Time for last iteration: -0.4266200065612793\n",
      "Iteration: 759 Time for last iteration: -0.3144948482513428\n",
      "Iteration: 760 Time for last iteration: -0.33089208602905273\n",
      "Iteration: 761 Time for last iteration: -0.33704590797424316\n",
      "Iteration: 762 Time for last iteration: -0.31457996368408203\n",
      "Iteration: 763 Time for last iteration: -0.3259561061859131\n",
      "Iteration: 764 Time for last iteration: -0.3355672359466553\n",
      "Iteration: 765 Time for last iteration: -0.31640172004699707\n",
      "Iteration: 766 Time for last iteration: -0.323775053024292\n",
      "Iteration: 767 Time for last iteration: -0.34136199951171875\n",
      "Iteration: 768 Time for last iteration: -0.3215620517730713\n",
      "Iteration: 769 Time for last iteration: -0.3069002628326416\n",
      "Iteration: 770 Time for last iteration: -0.30766797065734863\n",
      "Iteration: 771 Time for last iteration: -0.33794379234313965\n",
      "Iteration: 772 Time for last iteration: -0.4311537742614746\n",
      "Iteration: 773 Time for last iteration: -0.3077101707458496\n",
      "Iteration: 774 Time for last iteration: -0.3203868865966797\n",
      "Iteration: 775 Time for last iteration: -0.3273160457611084\n",
      "Iteration: 776 Time for last iteration: -0.3011157512664795\n",
      "Iteration: 777 Time for last iteration: -0.3159947395324707\n",
      "Iteration: 778 Time for last iteration: -0.3229827880859375\n",
      "Iteration: 779 Time for last iteration: -0.31077003479003906\n",
      "Iteration: 780 Time for last iteration: -0.3255460262298584\n",
      "Iteration: 781 Time for last iteration: -0.3346390724182129\n",
      "Iteration: 782 Time for last iteration: -0.30834102630615234\n",
      "Iteration: 783 Time for last iteration: -0.31623125076293945\n",
      "Iteration: 784 Time for last iteration: -0.36238527297973633\n",
      "Iteration: 785 Time for last iteration: -0.4776129722595215\n",
      "Iteration: 786 Time for last iteration: -0.35417890548706055\n",
      "Iteration: 787 Time for last iteration: -0.4992520809173584\n",
      "Iteration: 788 Time for last iteration: -0.32979869842529297\n",
      "Iteration: 789 Time for last iteration: -0.3255960941314697\n",
      "Iteration: 790 Time for last iteration: -0.3132798671722412\n",
      "Iteration: 791 Time for last iteration: -0.31037187576293945\n",
      "Iteration: 792 Time for last iteration: -0.33457207679748535\n",
      "Iteration: 793 Time for last iteration: -0.2994418144226074\n",
      "Iteration: 794 Time for last iteration: -0.3231029510498047\n",
      "Iteration: 795 Time for last iteration: -0.2991640567779541\n",
      "Iteration: 796 Time for last iteration: -0.3090388774871826\n",
      "Iteration: 797 Time for last iteration: -0.3154590129852295\n",
      "Iteration: 798 Time for last iteration: -0.3029639720916748\n",
      "Iteration: 799 Time for last iteration: -0.3068559169769287\n",
      "Iteration: 800 Time for last iteration: -0.29450392723083496\n",
      "Iteration: 801 Time for last iteration: -0.30641794204711914\n",
      "Iteration: 802 Time for last iteration: -0.33317017555236816\n",
      "Iteration: 803 Time for last iteration: -0.31637024879455566\n",
      "Iteration: 804 Time for last iteration: -0.30733323097229004\n",
      "Iteration: 805 Time for last iteration: -0.3220207691192627\n",
      "Iteration: 806 Time for last iteration: -0.3274879455566406\n",
      "Iteration: 807 Time for last iteration: -0.2946591377258301\n",
      "Iteration: 808 Time for last iteration: -0.30384325981140137\n",
      "Iteration: 809 Time for last iteration: -0.3116769790649414\n",
      "Iteration: 810 Time for last iteration: -0.30599212646484375\n",
      "Iteration: 811 Time for last iteration: -0.31998419761657715\n",
      "Iteration: 812 Time for last iteration: -0.29677271842956543\n",
      "Iteration: 813 Time for last iteration: -0.3053898811340332\n",
      "Iteration: 814 Time for last iteration: -0.3189213275909424\n",
      "Iteration: 815 Time for last iteration: -0.30043721199035645\n",
      "Iteration: 816 Time for last iteration: -0.29865503311157227\n",
      "Iteration: 817 Time for last iteration: -0.3163740634918213\n",
      "Iteration: 818 Time for last iteration: -0.3244149684906006\n",
      "Iteration: 819 Time for last iteration: -0.2929098606109619\n",
      "Iteration: 820 Time for last iteration: -0.390423059463501\n",
      "Iteration: 821 Time for last iteration: -0.32761335372924805\n",
      "Iteration: 822 Time for last iteration: -0.31391286849975586\n",
      "Iteration: 823 Time for last iteration: -0.3248591423034668\n",
      "Iteration: 824 Time for last iteration: -0.2972559928894043\n",
      "Iteration: 825 Time for last iteration: -0.30344581604003906\n",
      "Iteration: 826 Time for last iteration: -0.3144559860229492\n",
      "Iteration: 827 Time for last iteration: -0.34107112884521484\n",
      "Iteration: 828 Time for last iteration: -0.31871914863586426\n",
      "Iteration: 829 Time for last iteration: -0.328596830368042\n",
      "Iteration: 830 Time for last iteration: -0.31087779998779297\n",
      "Iteration: 831 Time for last iteration: -0.32827281951904297\n",
      "Iteration: 832 Time for last iteration: -0.32137179374694824\n",
      "Iteration: 833 Time for last iteration: -0.3144819736480713\n",
      "Iteration: 834 Time for last iteration: -0.32247304916381836\n",
      "Iteration: 835 Time for last iteration: -0.3307919502258301\n",
      "Iteration: 836 Time for last iteration: -0.3013949394226074\n",
      "Iteration: 837 Time for last iteration: -0.3254430294036865\n",
      "Iteration: 838 Time for last iteration: -0.3542671203613281\n",
      "Iteration: 839 Time for last iteration: -0.31040406227111816\n",
      "Iteration: 840 Time for last iteration: -0.3109431266784668\n",
      "Iteration: 841 Time for last iteration: -0.3156898021697998\n",
      "Iteration: 842 Time for last iteration: -0.3014099597930908\n",
      "Iteration: 843 Time for last iteration: -0.31610798835754395\n",
      "Iteration: 844 Time for last iteration: -0.31444716453552246\n",
      "Iteration: 845 Time for last iteration: -0.29442310333251953\n",
      "Iteration: 846 Time for last iteration: -0.3097250461578369\n",
      "Iteration: 847 Time for last iteration: -0.30455493927001953\n",
      "Iteration: 848 Time for last iteration: -0.32760071754455566\n",
      "Iteration: 849 Time for last iteration: -0.3067190647125244\n",
      "Iteration: 850 Time for last iteration: -0.31215906143188477\n",
      "Iteration: 851 Time for last iteration: -0.2955758571624756\n",
      "Iteration: 852 Time for last iteration: -0.3236110210418701\n",
      "Iteration: 853 Time for last iteration: -0.3309178352355957\n",
      "Iteration: 854 Time for last iteration: -0.3316202163696289\n",
      "Iteration: 855 Time for last iteration: -0.3696708679199219\n",
      "Iteration: 856 Time for last iteration: -0.33733701705932617\n",
      "Iteration: 857 Time for last iteration: -0.3479311466217041\n",
      "Iteration: 858 Time for last iteration: -0.30652594566345215\n",
      "Iteration: 859 Time for last iteration: -0.33017492294311523\n",
      "Iteration: 860 Time for last iteration: -0.3179938793182373\n",
      "Iteration: 861 Time for last iteration: -0.32358717918395996\n",
      "Iteration: 862 Time for last iteration: -0.3081369400024414\n",
      "Iteration: 863 Time for last iteration: -0.2998318672180176\n",
      "Iteration: 864 Time for last iteration: -0.30175304412841797\n",
      "Iteration: 865 Time for last iteration: -0.30209922790527344\n",
      "Iteration: 866 Time for last iteration: -0.3348522186279297\n",
      "Iteration: 867 Time for last iteration: -0.3224599361419678\n",
      "Iteration: 868 Time for last iteration: -0.3311929702758789\n",
      "Iteration: 869 Time for last iteration: -0.3176307678222656\n",
      "Iteration: 870 Time for last iteration: -0.3040928840637207\n",
      "Iteration: 871 Time for last iteration: -0.3356647491455078\n",
      "Iteration: 872 Time for last iteration: -0.3382720947265625\n",
      "Iteration: 873 Time for last iteration: -0.3559389114379883\n",
      "Iteration: 874 Time for last iteration: -0.3197140693664551\n",
      "Iteration: 875 Time for last iteration: -0.3036191463470459\n",
      "Iteration: 876 Time for last iteration: -0.34136486053466797\n",
      "Iteration: 877 Time for last iteration: -0.3207709789276123\n",
      "Iteration: 878 Time for last iteration: -0.3379948139190674\n",
      "Iteration: 879 Time for last iteration: -0.32109785079956055\n",
      "Iteration: 880 Time for last iteration: -0.2985870838165283\n",
      "Iteration: 881 Time for last iteration: -0.322232723236084\n",
      "Iteration: 882 Time for last iteration: -0.2916090488433838\n",
      "Iteration: 883 Time for last iteration: -0.29808998107910156\n",
      "Iteration: 884 Time for last iteration: -0.3182952404022217\n",
      "Iteration: 885 Time for last iteration: -0.3477318286895752\n",
      "Iteration: 886 Time for last iteration: -0.3511967658996582\n",
      "Iteration: 887 Time for last iteration: -0.3364291191101074\n",
      "Iteration: 888 Time for last iteration: -0.355759859085083\n",
      "Iteration: 889 Time for last iteration: -0.3037130832672119\n",
      "Iteration: 890 Time for last iteration: -0.3577842712402344\n",
      "Iteration: 891 Time for last iteration: -0.35117602348327637\n",
      "Iteration: 892 Time for last iteration: -0.3316948413848877\n",
      "Iteration: 893 Time for last iteration: -0.36467814445495605\n",
      "Iteration: 894 Time for last iteration: -0.348499059677124\n",
      "Iteration: 895 Time for last iteration: -0.36850833892822266\n",
      "Iteration: 896 Time for last iteration: -0.3087010383605957\n",
      "Iteration: 897 Time for last iteration: -0.3411130905151367\n",
      "Iteration: 898 Time for last iteration: -0.30266594886779785\n",
      "Iteration: 899 Time for last iteration: -0.3498828411102295\n",
      "Iteration: 900 Time for last iteration: -0.3292069435119629\n",
      "Iteration: 901 Time for last iteration: -0.31552886962890625\n",
      "Iteration: 902 Time for last iteration: -0.36062002182006836\n",
      "Iteration: 903 Time for last iteration: -0.42415928840637207\n",
      "Iteration: 904 Time for last iteration: -0.4849412441253662\n",
      "Iteration: 905 Time for last iteration: -0.39122986793518066\n",
      "Iteration: 906 Time for last iteration: -0.34417295455932617\n",
      "Iteration: 907 Time for last iteration: -0.4430069923400879\n",
      "Iteration: 908 Time for last iteration: -0.3522951602935791\n",
      "Iteration: 909 Time for last iteration: -0.34104275703430176\n",
      "Iteration: 910 Time for last iteration: -0.3388090133666992\n",
      "Iteration: 911 Time for last iteration: -0.351635217666626\n",
      "Iteration: 912 Time for last iteration: -0.34688878059387207\n",
      "Iteration: 913 Time for last iteration: -0.3600139617919922\n",
      "Iteration: 914 Time for last iteration: -0.3862147331237793\n",
      "Iteration: 915 Time for last iteration: -0.33643484115600586\n",
      "Iteration: 916 Time for last iteration: -0.40482115745544434\n",
      "Iteration: 917 Time for last iteration: -0.38570284843444824\n",
      "Iteration: 918 Time for last iteration: -0.37592601776123047\n",
      "Iteration: 919 Time for last iteration: -0.4141349792480469\n",
      "Iteration: 920 Time for last iteration: -0.4112248420715332\n",
      "Iteration: 921 Time for last iteration: -0.4921290874481201\n",
      "Iteration: 922 Time for last iteration: -0.34543800354003906\n",
      "Iteration: 923 Time for last iteration: -0.36428284645080566\n",
      "Iteration: 924 Time for last iteration: -0.3300468921661377\n",
      "Iteration: 925 Time for last iteration: -0.35929012298583984\n",
      "Iteration: 926 Time for last iteration: -0.3785829544067383\n",
      "Iteration: 927 Time for last iteration: -0.39436960220336914\n",
      "Iteration: 928 Time for last iteration: -0.39124584197998047\n",
      "Iteration: 929 Time for last iteration: -0.40630602836608887\n",
      "Iteration: 930 Time for last iteration: -0.4341461658477783\n",
      "Iteration: 931 Time for last iteration: -0.4667050838470459\n",
      "Iteration: 932 Time for last iteration: -0.38614702224731445\n",
      "Iteration: 933 Time for last iteration: -0.3535449504852295\n",
      "Iteration: 934 Time for last iteration: -0.37789368629455566\n",
      "Iteration: 935 Time for last iteration: -0.38036036491394043\n",
      "Iteration: 936 Time for last iteration: -0.37066006660461426\n",
      "Iteration: 937 Time for last iteration: -0.40891432762145996\n",
      "Iteration: 938 Time for last iteration: -0.40114903450012207\n",
      "Iteration: 939 Time for last iteration: -0.33260393142700195\n",
      "Iteration: 940 Time for last iteration: -0.42716312408447266\n",
      "Iteration: 941 Time for last iteration: -0.35095882415771484\n",
      "Iteration: 942 Time for last iteration: -0.3598756790161133\n",
      "Iteration: 943 Time for last iteration: -0.3829681873321533\n",
      "Iteration: 944 Time for last iteration: -0.35813403129577637\n",
      "Iteration: 945 Time for last iteration: -0.349625825881958\n",
      "Iteration: 946 Time for last iteration: -0.35199594497680664\n",
      "Iteration: 947 Time for last iteration: -0.3640167713165283\n",
      "Iteration: 948 Time for last iteration: -0.3825709819793701\n",
      "Iteration: 949 Time for last iteration: -0.36130380630493164\n",
      "Iteration: 950 Time for last iteration: -0.32949304580688477\n",
      "Iteration: 951 Time for last iteration: -0.33603978157043457\n",
      "Iteration: 952 Time for last iteration: -0.338284969329834\n",
      "Iteration: 953 Time for last iteration: -0.3640577793121338\n",
      "Iteration: 954 Time for last iteration: -0.3605058193206787\n",
      "Iteration: 955 Time for last iteration: -0.33539390563964844\n",
      "Iteration: 956 Time for last iteration: -0.3297131061553955\n",
      "Iteration: 957 Time for last iteration: -0.34998202323913574\n",
      "Iteration: 958 Time for last iteration: -0.3393700122833252\n",
      "Iteration: 959 Time for last iteration: -0.3264179229736328\n",
      "Iteration: 960 Time for last iteration: -0.3213920593261719\n",
      "Iteration: 961 Time for last iteration: -0.3470799922943115\n",
      "Iteration: 962 Time for last iteration: -0.3532731533050537\n",
      "Iteration: 963 Time for last iteration: -0.39078783988952637\n",
      "Iteration: 964 Time for last iteration: -0.35280299186706543\n",
      "Iteration: 965 Time for last iteration: -0.32485294342041016\n",
      "Iteration: 966 Time for last iteration: -0.3252131938934326\n",
      "Iteration: 967 Time for last iteration: -0.3072052001953125\n",
      "Iteration: 968 Time for last iteration: -0.3526923656463623\n",
      "Iteration: 969 Time for last iteration: -0.3111898899078369\n",
      "Iteration: 970 Time for last iteration: -0.3184678554534912\n",
      "Iteration: 971 Time for last iteration: -0.31514906883239746\n",
      "Iteration: 972 Time for last iteration: -0.37122035026550293\n",
      "Iteration: 973 Time for last iteration: -0.318126916885376\n",
      "Iteration: 974 Time for last iteration: -0.34052300453186035\n",
      "Iteration: 975 Time for last iteration: -0.3539237976074219\n",
      "Iteration: 976 Time for last iteration: -0.3736231327056885\n",
      "Iteration: 977 Time for last iteration: -0.40126490592956543\n",
      "Iteration: 978 Time for last iteration: -0.3544600009918213\n",
      "Iteration: 979 Time for last iteration: -0.33084630966186523\n",
      "Iteration: 980 Time for last iteration: -0.3423337936401367\n",
      "Iteration: 981 Time for last iteration: -0.3962538242340088\n",
      "Iteration: 982 Time for last iteration: -0.3293452262878418\n",
      "Iteration: 983 Time for last iteration: -0.3615891933441162\n",
      "Iteration: 984 Time for last iteration: -0.3156130313873291\n",
      "Iteration: 985 Time for last iteration: -0.3674919605255127\n",
      "Iteration: 986 Time for last iteration: -0.3073756694793701\n",
      "Iteration: 987 Time for last iteration: -0.6293087005615234\n",
      "Iteration: 988 Time for last iteration: -0.4092390537261963\n",
      "Iteration: 989 Time for last iteration: -0.4121847152709961\n",
      "Iteration: 990 Time for last iteration: -0.3948056697845459\n",
      "Iteration: 991 Time for last iteration: -0.33766794204711914\n",
      "Iteration: 992 Time for last iteration: -0.31471800804138184\n",
      "Iteration: 993 Time for last iteration: -0.30064892768859863\n",
      "Iteration: 994 Time for last iteration: -0.4878699779510498\n",
      "Iteration: 995 Time for last iteration: -0.34415197372436523\n",
      "Iteration: 996 Time for last iteration: -0.36169910430908203\n",
      "Iteration: 997 Time for last iteration: -0.39483094215393066\n",
      "Iteration: 998 Time for last iteration: -0.370589017868042\n",
      "Iteration: 999 Time for last iteration: -0.40438103675842285\n",
      "Iteration: 1000 Time for last iteration: -0.4294252395629883\n",
      "Iteration: 1001 Time for last iteration: -0.4101886749267578\n",
      "Iteration: 1002 Time for last iteration: -0.4202101230621338\n",
      "Iteration: 1003 Time for last iteration: -0.45439791679382324\n",
      "Iteration: 1004 Time for last iteration: -0.38259196281433105\n",
      "Iteration: 1005 Time for last iteration: -0.39990687370300293\n",
      "Iteration: 1006 Time for last iteration: -0.3793637752532959\n",
      "Iteration: 1007 Time for last iteration: -0.3443930149078369\n",
      "Iteration: 1008 Time for last iteration: -0.40017008781433105\n",
      "Iteration: 1009 Time for last iteration: -0.37392687797546387\n",
      "Iteration: 1010 Time for last iteration: -0.43425893783569336\n",
      "Iteration: 1011 Time for last iteration: -0.3807492256164551\n",
      "Iteration: 1012 Time for last iteration: -0.3233451843261719\n",
      "Iteration: 1013 Time for last iteration: -0.34485507011413574\n",
      "Iteration: 1014 Time for last iteration: -0.4429931640625\n",
      "Iteration: 1015 Time for last iteration: -0.41222095489501953\n",
      "Iteration: 1016 Time for last iteration: -0.40863513946533203\n",
      "Iteration: 1017 Time for last iteration: -0.4124329090118408\n",
      "Iteration: 1018 Time for last iteration: -0.7054929733276367\n",
      "Iteration: 1019 Time for last iteration: -0.5079629421234131\n",
      "Iteration: 1020 Time for last iteration: -0.7210040092468262\n",
      "Iteration: 1021 Time for last iteration: -0.6240231990814209\n",
      "Iteration: 1022 Time for last iteration: -0.5479919910430908\n",
      "Iteration: 1023 Time for last iteration: -0.41555309295654297\n",
      "Iteration: 1024 Time for last iteration: -0.32690906524658203\n",
      "Iteration: 1025 Time for last iteration: -0.302476167678833\n",
      "Iteration: 1026 Time for last iteration: -0.2998321056365967\n",
      "Iteration: 1027 Time for last iteration: -0.3168320655822754\n",
      "Iteration: 1028 Time for last iteration: -0.3067629337310791\n",
      "Iteration: 1029 Time for last iteration: -0.36374998092651367\n",
      "Iteration: 1030 Time for last iteration: -0.2998647689819336\n",
      "Iteration: 1031 Time for last iteration: -0.3293800354003906\n",
      "Iteration: 1032 Time for last iteration: -0.28766822814941406\n",
      "Iteration: 1033 Time for last iteration: -0.3024330139160156\n",
      "Iteration: 1034 Time for last iteration: -0.3094630241394043\n",
      "Iteration: 1035 Time for last iteration: -0.3053269386291504\n",
      "Iteration: 1036 Time for last iteration: -0.3209359645843506\n",
      "Iteration: 1037 Time for last iteration: -0.33362817764282227\n",
      "Iteration: 1038 Time for last iteration: -0.3185310363769531\n",
      "Iteration: 1039 Time for last iteration: -0.32016491889953613\n",
      "Iteration: 1040 Time for last iteration: -0.29939985275268555\n",
      "Iteration: 1041 Time for last iteration: -0.29023194313049316\n",
      "Iteration: 1042 Time for last iteration: -0.34636807441711426\n",
      "Iteration: 1043 Time for last iteration: -0.30286574363708496\n",
      "Iteration: 1044 Time for last iteration: -0.3077719211578369\n",
      "Iteration: 1045 Time for last iteration: -0.2950468063354492\n",
      "Iteration: 1046 Time for last iteration: -0.3230319023132324\n",
      "Iteration: 1047 Time for last iteration: -0.3159010410308838\n",
      "Iteration: 1048 Time for last iteration: -0.3382151126861572\n",
      "Iteration: 1049 Time for last iteration: -0.33808302879333496\n",
      "Iteration: 1050 Time for last iteration: -0.34677791595458984\n",
      "Iteration: 1051 Time for last iteration: -0.30437684059143066\n",
      "Iteration: 1052 Time for last iteration: -0.33373379707336426\n",
      "Iteration: 1053 Time for last iteration: -0.34801578521728516\n",
      "Iteration: 1054 Time for last iteration: -0.3257560729980469\n",
      "Iteration: 1055 Time for last iteration: -0.34290099143981934\n",
      "Iteration: 1056 Time for last iteration: -0.31189918518066406\n",
      "Iteration: 1057 Time for last iteration: -0.31645917892456055\n",
      "Iteration: 1058 Time for last iteration: -0.30106306076049805\n",
      "Iteration: 1059 Time for last iteration: -0.3240017890930176\n",
      "Iteration: 1060 Time for last iteration: -0.3456132411956787\n",
      "Iteration: 1061 Time for last iteration: -0.311779260635376\n",
      "Iteration: 1062 Time for last iteration: -0.36980199813842773\n",
      "Iteration: 1063 Time for last iteration: -0.34245872497558594\n",
      "Iteration: 1064 Time for last iteration: -0.30388498306274414\n",
      "Iteration: 1065 Time for last iteration: -0.2873373031616211\n",
      "Iteration: 1066 Time for last iteration: -0.31386232376098633\n",
      "Iteration: 1067 Time for last iteration: -0.3349449634552002\n",
      "Iteration: 1068 Time for last iteration: -0.31843090057373047\n",
      "Iteration: 1069 Time for last iteration: -0.32472896575927734\n",
      "Iteration: 1070 Time for last iteration: -0.299440860748291\n",
      "Iteration: 1071 Time for last iteration: -0.30547308921813965\n",
      "Iteration: 1072 Time for last iteration: -0.29906582832336426\n",
      "Iteration: 1073 Time for last iteration: -0.3339352607727051\n",
      "Iteration: 1074 Time for last iteration: -0.29846930503845215\n",
      "Iteration: 1075 Time for last iteration: -0.31742310523986816\n",
      "Iteration: 1076 Time for last iteration: -0.2851099967956543\n",
      "Iteration: 1077 Time for last iteration: -0.3257782459259033\n",
      "Iteration: 1078 Time for last iteration: -0.3172180652618408\n",
      "Iteration: 1079 Time for last iteration: -0.33890771865844727\n",
      "Iteration: 1080 Time for last iteration: -0.317824125289917\n",
      "Iteration: 1081 Time for last iteration: -0.3329441547393799\n",
      "Iteration: 1082 Time for last iteration: -0.33978700637817383\n",
      "Iteration: 1083 Time for last iteration: -0.3452589511871338\n",
      "Iteration: 1084 Time for last iteration: -0.3646979331970215\n",
      "Iteration: 1085 Time for last iteration: -0.35889196395874023\n",
      "Iteration: 1086 Time for last iteration: -0.2970399856567383\n",
      "Iteration: 1087 Time for last iteration: -0.29571104049682617\n",
      "Iteration: 1088 Time for last iteration: -0.3333308696746826\n",
      "Iteration: 1089 Time for last iteration: -0.3792078495025635\n",
      "Iteration: 1090 Time for last iteration: -0.33653688430786133\n",
      "Iteration: 1091 Time for last iteration: -0.3326432704925537\n",
      "Iteration: 1092 Time for last iteration: -0.3579270839691162\n",
      "Iteration: 1093 Time for last iteration: -0.33377790451049805\n",
      "Iteration: 1094 Time for last iteration: -0.31731200218200684\n",
      "Iteration: 1095 Time for last iteration: -0.29856300354003906\n",
      "Iteration: 1096 Time for last iteration: -0.2919318675994873\n",
      "Iteration: 1097 Time for last iteration: -0.3323850631713867\n",
      "Iteration: 1098 Time for last iteration: -0.3159158229827881\n",
      "Iteration: 1099 Time for last iteration: -0.297760009765625\n",
      "Iteration: 1100 Time for last iteration: -0.317180871963501\n",
      "Iteration: 1101 Time for last iteration: -0.32981085777282715\n",
      "Iteration: 1102 Time for last iteration: -0.31525611877441406\n",
      "Iteration: 1103 Time for last iteration: -0.28864002227783203\n",
      "Iteration: 1104 Time for last iteration: -0.34478163719177246\n",
      "Iteration: 1105 Time for last iteration: -0.3120698928833008\n",
      "Iteration: 1106 Time for last iteration: -0.3290410041809082\n",
      "Iteration: 1107 Time for last iteration: -0.30838608741760254\n",
      "Iteration: 1108 Time for last iteration: -0.3476238250732422\n",
      "Iteration: 1109 Time for last iteration: -0.30143213272094727\n",
      "Iteration: 1110 Time for last iteration: -0.32689380645751953\n",
      "Iteration: 1111 Time for last iteration: -0.3316528797149658\n",
      "Iteration: 1112 Time for last iteration: -0.37512922286987305\n",
      "Iteration: 1113 Time for last iteration: -0.31461501121520996\n",
      "Iteration: 1114 Time for last iteration: -0.3063077926635742\n",
      "Iteration: 1115 Time for last iteration: -0.2963380813598633\n",
      "Iteration: 1116 Time for last iteration: -0.31555676460266113\n",
      "Iteration: 1117 Time for last iteration: -0.3247251510620117\n",
      "Iteration: 1118 Time for last iteration: -0.3175327777862549\n",
      "Iteration: 1119 Time for last iteration: -0.31917786598205566\n",
      "Iteration: 1120 Time for last iteration: -0.3314781188964844\n",
      "Iteration: 1121 Time for last iteration: -0.30481910705566406\n",
      "Iteration: 1122 Time for last iteration: -0.31937313079833984\n",
      "Iteration: 1123 Time for last iteration: -0.36374807357788086\n",
      "Iteration: 1124 Time for last iteration: -0.3656902313232422\n",
      "Iteration: 1125 Time for last iteration: -0.32639598846435547\n",
      "Iteration: 1126 Time for last iteration: -0.30861735343933105\n",
      "Iteration: 1127 Time for last iteration: -0.3277320861816406\n",
      "Iteration: 1128 Time for last iteration: -0.2933809757232666\n",
      "Iteration: 1129 Time for last iteration: -0.3469400405883789\n",
      "Iteration: 1130 Time for last iteration: -0.31730198860168457\n",
      "Iteration: 1131 Time for last iteration: -0.3185300827026367\n",
      "Iteration: 1132 Time for last iteration: -0.3213667869567871\n",
      "Iteration: 1133 Time for last iteration: -0.35564303398132324\n",
      "Iteration: 1134 Time for last iteration: -0.36798095703125\n",
      "Iteration: 1135 Time for last iteration: -0.3570690155029297\n",
      "Iteration: 1136 Time for last iteration: -0.32703113555908203\n",
      "Iteration: 1137 Time for last iteration: -0.33455491065979004\n",
      "Iteration: 1138 Time for last iteration: -0.30745816230773926\n",
      "Iteration: 1139 Time for last iteration: -0.29201674461364746\n",
      "Iteration: 1140 Time for last iteration: -0.34020495414733887\n",
      "Iteration: 1141 Time for last iteration: -0.3223607540130615\n",
      "Iteration: 1142 Time for last iteration: -0.29418277740478516\n",
      "Iteration: 1143 Time for last iteration: -0.3328368663787842\n",
      "Iteration: 1144 Time for last iteration: -0.3057548999786377\n",
      "Iteration: 1145 Time for last iteration: -0.30264925956726074\n",
      "Iteration: 1146 Time for last iteration: -0.33580875396728516\n",
      "Iteration: 1147 Time for last iteration: -0.3379030227661133\n",
      "Iteration: 1148 Time for last iteration: -0.3106110095977783\n",
      "Iteration: 1149 Time for last iteration: -0.3337268829345703\n",
      "Iteration: 1150 Time for last iteration: -0.335158109664917\n",
      "Iteration: 1151 Time for last iteration: -0.3010408878326416\n",
      "Iteration: 1152 Time for last iteration: -0.30185484886169434\n",
      "Iteration: 1153 Time for last iteration: -0.2952580451965332\n",
      "Iteration: 1154 Time for last iteration: -0.3137500286102295\n",
      "Iteration: 1155 Time for last iteration: -0.33468103408813477\n",
      "Iteration: 1156 Time for last iteration: -0.32944321632385254\n",
      "Iteration: 1157 Time for last iteration: -0.3272969722747803\n",
      "Iteration: 1158 Time for last iteration: -0.316633939743042\n",
      "Iteration: 1159 Time for last iteration: -0.30489397048950195\n",
      "Iteration: 1160 Time for last iteration: -0.32032108306884766\n",
      "Iteration: 1161 Time for last iteration: -0.39316368103027344\n",
      "Iteration: 1162 Time for last iteration: -0.3578500747680664\n",
      "Iteration: 1163 Time for last iteration: -0.3237729072570801\n",
      "Iteration: 1164 Time for last iteration: -0.30939602851867676\n",
      "Iteration: 1165 Time for last iteration: -0.33617305755615234\n",
      "Iteration: 1166 Time for last iteration: -0.30150294303894043\n",
      "Iteration: 1167 Time for last iteration: -0.2949252128601074\n",
      "Iteration: 1168 Time for last iteration: -0.3249638080596924\n",
      "Iteration: 1169 Time for last iteration: -0.348491907119751\n",
      "Iteration: 1170 Time for last iteration: -0.31407999992370605\n",
      "Iteration: 1171 Time for last iteration: -0.319307804107666\n",
      "Iteration: 1172 Time for last iteration: -0.3074800968170166\n",
      "Iteration: 1173 Time for last iteration: -0.3255038261413574\n",
      "Iteration: 1174 Time for last iteration: -0.32741308212280273\n",
      "Iteration: 1175 Time for last iteration: -0.3214750289916992\n",
      "Iteration: 1176 Time for last iteration: -0.29825925827026367\n",
      "Iteration: 1177 Time for last iteration: -0.30086278915405273\n",
      "Iteration: 1178 Time for last iteration: -0.3107640743255615\n",
      "Iteration: 1179 Time for last iteration: -0.28814196586608887\n",
      "Iteration: 1180 Time for last iteration: -0.3466660976409912\n",
      "Iteration: 1181 Time for last iteration: -0.3326871395111084\n",
      "Iteration: 1182 Time for last iteration: -0.2950870990753174\n",
      "Iteration: 1183 Time for last iteration: -0.29632997512817383\n",
      "Iteration: 1184 Time for last iteration: -0.32362794876098633\n",
      "Iteration: 1185 Time for last iteration: -0.3377499580383301\n",
      "Iteration: 1186 Time for last iteration: -0.3188290596008301\n",
      "Iteration: 1187 Time for last iteration: -0.2966902256011963\n",
      "Iteration: 1188 Time for last iteration: -0.33045387268066406\n",
      "Iteration: 1189 Time for last iteration: -0.3163762092590332\n"
     ]
    }
   ],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "\n",
    "\n",
    "class IterationInfoCallback(TrainingCallback):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        print('Iteration:', epoch, 'Time for last iteration:', self.start_time - time.time())\n",
    "        self.start_time = time.time()\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "xgb_model_all_train = xgb_model.fit(feat_xgb_train, target_all_train, callbacks=[IterationInfoCallback()])\n",
    "xgb_predict_test = xgb_model_all_train.predict(feat_xgb_test)\n",
    "xgb_predict_train = xgb_model_all_train.predict(feat_xgb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM</td>\n",
       "      <td>3.176235</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.996797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM</td>\n",
       "      <td>6.123915</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.985995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная XGB</td>\n",
       "      <td>3.847216</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.997486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая XGB</td>\n",
       "      <td>6.143893</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.984871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Выборка       MAE      MAPE        R2\n",
       "0  тренировочная LGBM   3.176235  0.006670  0.996797\n",
       "1       тестовая LGBM   6.123915  0.014347  0.985995\n",
       "0   тренировочная XGB   3.847216  0.008094  0.997486\n",
       "1        тестовая XGB   6.143893  0.014411  0.984871"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, xgb_predict_train )\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, xgb_predict_test )\n",
    "\n",
    "results = pd.concat([results,\n",
    "pd.DataFrame([[f'тренировочная XGB {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая XGB {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "205f9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = xgb_model.feature_importances_\n",
    "# предположим, что 'X' - это ваши данные\n",
    "feature_name = feat_xgb_test.columns\n",
    "# создание DataFrame\n",
    "importance_df_xgb = pd.DataFrame({'feature': feature_name, 'importance': importance})\n",
    "# сортировка по важности\n",
    "importance_df_xgb = importance_df_xgb.sort_values(by='importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fd63ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>target_lag_24</td>\n",
       "      <td>0.503236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>day_of_week_6</td>\n",
       "      <td>0.016354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>day_of_week_4</td>\n",
       "      <td>0.011443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>last_evening_avg_target_19_9</td>\n",
       "      <td>0.010987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>day_of_week_21</td>\n",
       "      <td>0.010505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>clear_17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>year_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>year_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>has_rain_probability_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>year_6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  importance\n",
       "8                   target_lag_24    0.503236\n",
       "196                 day_of_week_6    0.016354\n",
       "132                 day_of_week_4    0.011443\n",
       "316  last_evening_avg_target_19_9    0.010987\n",
       "676                day_of_week_21    0.010505\n",
       "..                            ...         ...\n",
       "559                      clear_17    0.000000\n",
       "66                         year_2    0.000000\n",
       "386                       year_12    0.000000\n",
       "401       has_rain_probability_12    0.000000\n",
       "194                        year_6    0.000000\n",
       "\n",
       "[774 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3365ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(importance_df_lgbm, importance_df_xgb, on='feature', how='outer', suffixes=('_lgbm', '_xgb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09e15c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_lgbm</th>\n",
       "      <th>importance_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target_lag_24</td>\n",
       "      <td>3341</td>\n",
       "      <td>0.503236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target_lag_336</td>\n",
       "      <td>1548</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target_lag_72</td>\n",
       "      <td>1283</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target_lag_24_1</td>\n",
       "      <td>950</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>target_lag_72_23</td>\n",
       "      <td>860</td>\n",
       "      <td>0.002217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>year_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>year_19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>year_16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>year_6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>preholidays_12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance_lgbm  importance_xgb\n",
       "0       target_lag_24             3341        0.503236\n",
       "1      target_lag_336             1548        0.006494\n",
       "2       target_lag_72             1283        0.002909\n",
       "3     target_lag_24_1              950        0.000855\n",
       "4    target_lag_72_23              860        0.002217\n",
       "..                ...              ...             ...\n",
       "793            year_3                1        0.001493\n",
       "794           year_19                1        0.000000\n",
       "795           year_16                0        0.000000\n",
       "796            year_6                0        0.000000\n",
       "797    preholidays_12                0             NaN\n",
       "\n",
       "[798 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe31a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена NaN на 0 в столбце 'importance_xgb'\n",
    "merged_df['importance_xgb'].fillna(0, inplace=True)\n",
    "\n",
    "# Нормализация важности признаков\n",
    "merged_df['importance_lgbm'] = merged_df['importance_lgbm'] / merged_df['importance_lgbm'].max()\n",
    "merged_df['importance_xgb'] = merged_df['importance_xgb'] / merged_df['importance_xgb'].max()\n",
    "\n",
    "# Создание столбца 'importance_ensemble', который является средним значением 'importance_lgbm' и 'importance_xgb'\n",
    "merged_df['importance_ensemble'] = (merged_df['importance_lgbm'] + merged_df['importance_xgb']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecf1b32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_lgbm</th>\n",
       "      <th>importance_xgb</th>\n",
       "      <th>importance_ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target_lag_24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target_lag_336</td>\n",
       "      <td>0.463334</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>0.238120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target_lag_72</td>\n",
       "      <td>0.384017</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.194899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target_lag_24_1</td>\n",
       "      <td>0.284346</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.143022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>target_lag_72_23</td>\n",
       "      <td>0.257408</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.130906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>year_3</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.001633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>year_19</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>year_16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>year_6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>preholidays_12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance_lgbm  importance_xgb  importance_ensemble\n",
       "0       target_lag_24         1.000000        1.000000             1.000000\n",
       "1      target_lag_336         0.463334        0.012905             0.238120\n",
       "2       target_lag_72         0.384017        0.005781             0.194899\n",
       "3     target_lag_24_1         0.284346        0.001698             0.143022\n",
       "4    target_lag_72_23         0.257408        0.004405             0.130906\n",
       "..                ...              ...             ...                  ...\n",
       "793            year_3         0.000299        0.002966             0.001633\n",
       "794           year_19         0.000299        0.000000             0.000150\n",
       "795           year_16         0.000000        0.000000             0.000000\n",
       "796            year_6         0.000000        0.000000             0.000000\n",
       "797    preholidays_12         0.000000        0.000000             0.000000\n",
       "\n",
       "[798 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c55ddba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ab34de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_excel('feature_importance.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Объединяем результаты ансамбля моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_simple_ensemble_train = (xgb_predict_train + l_predict_train)/2\n",
    "predict_simple_ensemble_test = (xgb_predict_test + l_predict_test)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, predict_simple_ensemble_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, predict_simple_ensemble_test)\n",
    "\n",
    "results_ensemble = results\n",
    "results_ensemble = pd.concat([results_ensemble,\n",
    "pd.DataFrame([[f'тренировочная ансамбля  {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая ансамбля {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM</td>\n",
       "      <td>3.176235</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.996797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM</td>\n",
       "      <td>6.123915</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.985995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная XGB</td>\n",
       "      <td>3.847216</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.997486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая XGB</td>\n",
       "      <td>6.143893</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.984871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная ансамбля</td>\n",
       "      <td>3.398171</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.997498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая ансамбля</td>\n",
       "      <td>5.962481</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.986196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Выборка       MAE      MAPE        R2\n",
       "0       тренировочная LGBM   3.176235  0.006670  0.996797\n",
       "1            тестовая LGBM   6.123915  0.014347  0.985995\n",
       "0        тренировочная XGB   3.847216  0.008094  0.997486\n",
       "1             тестовая XGB   6.143893  0.014411  0.984871\n",
       "0  тренировочная ансамбля    3.398171  0.007138  0.997498\n",
       "1        тестовая ансамбля   5.962481  0.013958  0.986196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_ensemble)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
