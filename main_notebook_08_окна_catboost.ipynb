{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5606014",
   "metadata": {},
   "source": [
    "## Энергетический оракул\n",
    "Ноутбук команды #12\n",
    "\n",
    "Работа выполнена на основе модели LightGBM\n",
    "\n",
    "\n",
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4351135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost.callback import TrainingCallback\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "random_state = 12345\n",
    "NUM_ITERATIONS = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45891200",
   "metadata": {},
   "source": [
    "#### 1.1 Функции для расшифровки прогноза погоды в колонке 'weather_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece12617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "\n",
    "# функция формирует колонки 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability', 'has_rain_probability'\n",
    "# в колонках число, которое 0 при отсутсвии упоминания явления в weather_pred или степень упоминания\n",
    "# функция дает в колонках номер первого списка, элемент которого есть в строке плюс 1\n",
    "# списки cloudy_list, rainy_list, windy_list, clear_list можно модифицировать\n",
    "# соответственно, можно экспериментировать с расположением значений в списках\n",
    "# например, сейчас 'дождь', 'снег', 'д+сн' - первая степень  дождя, а 'гроз', 'ливень' - вторая\n",
    "# а можно сделать снег второй, а грозу с ливнем убрать в третью\n",
    "# также сделал отдельный список для \"ясности\", чтобы выделить 'ясно' и 'солнечно'\n",
    "\n",
    "def in_what_list(weather, big_list):\n",
    "    for list_number, small_list in enumerate(big_list):\n",
    "        if any(word in weather for word in small_list):\n",
    "            return list_number+1\n",
    "    return 0\n",
    "\n",
    "def weather_split2(row):\n",
    "    weather = row['weather_pred']\n",
    "    cloudy_list = [['проясн', 'пер.об.', 'п/об'], ['пасм', 'обл']]\n",
    "    rainy_list = [['дождь', 'снег', 'д+сн'], ['гроз', 'ливень']]\n",
    "    windy_list = [['вет'],['штор']]\n",
    "    clear_list = [['проясн'], ['ясно'], ['солнеч']]\n",
    "    numbers = re.findall(r'\\d+', weather)\n",
    "    cloudy = in_what_list(weather, cloudy_list)\n",
    "    rainy = in_what_list(weather, rainy_list)\n",
    "    windy = in_what_list(weather, windy_list)\n",
    "    clear = in_what_list(weather, clear_list)\n",
    "    rain_probability = 0 if len(numbers)==0 else int(numbers[0])\n",
    "    has_rain_probability = int(len(numbers)==0)\n",
    "    return cloudy, rainy, windy, clear, rain_probability, has_rain_probability\n",
    "\n",
    "def fill_weather_columns(df):\n",
    "    df['weather_pred'] = df['weather_pred'].fillna('')\n",
    "    df['cloudy'], df['rainy'], df['windy'], df['clear'], df['rain_probability'], df['has_rain_probability'] = \\\n",
    "                zip(*df.apply(weather_split2, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39d660",
   "metadata": {},
   "source": [
    "#### 1.2 Функции для загрузки данных о ВВП \n",
    "данные загружаются из файла 'data/VVP.csv'\n",
    "\n",
    "Некоторые научные работы указывают на прямую связь величины потребления электричества и показателя ВВП, который отражает ситуацию в экономике. Данные по экономике публикуются различными министерствами с разной периодичностью. Для использования в работе были взяты фактические данные по ВВП с сайта investing, который агрегирует публикации Минэкономразвития. Данные за месяц побликуются с месячной задержкой, поэтому модель использует для прогнозирования данные за прошлые месяцы, которые известны.   \n",
    "  \n",
    "Ссылка на данные: https://ru.investing.com/economic-calendar/russian-monthly-gdp-407\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3dd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция добавляет данные о ВВП из файла 'data/VVP.csv' в датасет\n",
    "\n",
    "def add_vvp2(data, file_source = 'data/VVP.csv'):\n",
    "    \"\"\"\n",
    "    сырой датафрем подаем на вход\n",
    "    \"\"\"\n",
    "    # обработаем файл с динамикой ВВП\n",
    "    vvp = pd.read_csv(file_source)\n",
    "    # преобразуем дату файла-источника в формат datetime64 и дропнем один столбик\n",
    "    vvp['date'] = pd.to_datetime(vvp['date'], format ='%Y-%m-%d %H:%M:%S')\n",
    "    vvp.drop('for_month',axis=1,inplace=True) \n",
    "    \n",
    "    # обработаем основной фрейм - создадим столбец для соединения, который потом удалим\n",
    "    data['date_temp'] = pd.to_datetime(data['date'], format = '%Y-%m-%d' )\n",
    "    data['date_temp'] = data['date_temp'] + pd.to_timedelta(data['time'] , 'H')\n",
    "    \n",
    "    # соединяем основной фрейм и ВВП по дате объявления показтеля ВВП\n",
    "    for idx in reversed(vvp.index):\n",
    "        data.loc[data['date_temp']>=vvp.date[idx],'VVP'] = vvp.VVP_perc[idx]\n",
    "        \n",
    "    data.drop('date_temp',axis=1,inplace=True)   \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe769599",
   "metadata": {},
   "source": [
    "#### 1.3 Функции для загрузки архива данных о фактической погоде\n",
    "данные загружаются из файла 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "Изначально данные для формирования таблицы \"preprocessing_loaded_table\" были взяты из с сайта [https://rp5.ru](https://rp5.ru/Архив_погоды_в_Храброво,_им._императрицы_Елизаветы_Петровны_(аэропорт),_METAR), где хранятся архивы погоды в аэрапорту Калининграда, за период с 31.12.2018 по 30.09.2023\n",
    "\n",
    "Описание данных в таблице:\n",
    "- Местное время в Храброво / им. императрицы Елизаветы Петровны (аэропорт) - Дата / Местное время\n",
    "- T -  Темпиратура воздуха\n",
    "- Po - Давление на уровне станции\n",
    "- P - Давление приведённое к уровню моря\n",
    "- U - Относительная влажность\n",
    "- DD - Направление ветра\n",
    "- Ff - Скорость ветра\n",
    "- ff10 - Максимальное значение порыва ветра\n",
    "- WW - Особое явление текущей погоды (осадки)\n",
    "- W'W' - Явление недавней погоды, имеющее оперативное значение\n",
    "- с - Общая облачность\n",
    "- VV - Горизонтальная дальность видимости\n",
    "- Td - Темпиратура точки росы\n",
    "\n",
    "Данные, которые были взяты из данной таблицы и загружаются из 'data/preprocessing_loaded_table.csv':\n",
    "- P - не подверглось изменению\n",
    "- U - не подверглось изменению\n",
    "- Td - не подверглась изменению\n",
    "\n",
    " WW - разделили на 4 категории:\n",
    "- Нет осадков (где были пропуски)\n",
    "- слабый дождь\n",
    "- сильный дождь\n",
    "- снег\n",
    "\n",
    "DD - создали 4 столбца, соответствующих сторонам горизонта, которые принимали значения 0; 0.5 и 1 в зависимости от силы ветра в конкретном направлении\n",
    "- N - north\n",
    "- S - south\n",
    "- W - west\n",
    "- E - east\n",
    "\n",
    "В дальнейшем эти данные использовались с лагом в сутки: в поля на завтрашний день записывались данные сегодняшнего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb3456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для работы с данными о фактической погоде из 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "# Кодировка информации об осадках из колонки WW\n",
    "def true_weather_WW_replace(ww):\n",
    "    if ww=='нет осадков':\n",
    "        return 0\n",
    "    elif ww=='слабый дождь':\n",
    "        return 1\n",
    "    elif (ww=='сильный дождь') or (ww=='снег'):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Вычисление Timestamp из даты и времени\n",
    "def row_plus_hours_to_index(row):\n",
    "    return row['date'] + pd.to_timedelta(row['time'] , 'H')\n",
    "\n",
    "# Функция для сдвига на сутки (в скачанном датасете разбивка по 30 мин, поэтому timeshift=48)\n",
    "def shift_features_fact(df, timeshift=48):\n",
    "    list_fact_columns=list(df.columns)\n",
    "    list_fact_columns.remove('date_tw')\n",
    "    new_df = df.copy()\n",
    "    for column in list_fact_columns:\n",
    "        new_df[column] = new_df[column].shift(timeshift)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5eb669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления метрики mae по дням из почасовых массивов данных\n",
    "\n",
    "def mae_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    return mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "# Функция для вычисления метрик по дням из почасовых массивов данных\n",
    "\n",
    "def metrics_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    mae = mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "    mape = mean_absolute_percentage_error(y_true_grouped, y_pred_grouped)\n",
    "    r2 = r2_score(y_true_grouped, y_pred_grouped)\n",
    "    return mae, mape, r2\n",
    "\n",
    "def metrics_hour(y_true, y_pred): \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808c109",
   "metadata": {},
   "source": [
    "#### 1.5 Чтение файлов с данными\n",
    "Данные объединяются в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a4ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начало открытого теста: 2023-04-01 00:00:00     конец открытого теста: 2023-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# читаем исходные датасеты и складываем в один\n",
    "train_ds = pd.read_csv('data/train_dataset.csv')\n",
    "test_ds = pd.read_csv('data/test_dataset.csv')\n",
    "train_ds = pd.concat([train_ds, test_ds])\n",
    "\n",
    "# запоминаем дату начала тестовых данных, потом также поступим и с закрытым датасетом\n",
    "open_test_begin = pd.to_datetime(test_ds['date']).min()\n",
    "open_test_end = pd.to_datetime(test_ds['date']).max() + pd.to_timedelta(1,'d')\n",
    "print('начало открытого теста:', open_test_begin, '    конец открытого теста:', open_test_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237ce32",
   "metadata": {},
   "source": [
    "#### 1.6 Формирование колонок с производными от даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16090ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем дату и делаем из нее колонки\n",
    "train_ds['date'] = pd.to_datetime(train_ds['date'])\n",
    "train_ds['year'] = train_ds['date'].dt.year\n",
    "train_ds['month'] = train_ds['date'].dt.month\n",
    "train_ds['day_of_week'] = train_ds['date'].dt.dayofweek\n",
    "train_ds['day'] = train_ds['date'].dt.day\n",
    "train_ds['day_of_year'] = train_ds['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98567815",
   "metadata": {},
   "source": [
    "#### 1.7 Подгрузка данных о праздниках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03029389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление данных о праздниках из файла 'data/holidays.csv'\n",
    "\n",
    "df_holidays = pd.read_csv('data/holidays.csv')\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "\n",
    "# Assuming df_holidays and train_ds are your dataframes\n",
    "train_ds = pd.merge(train_ds, df_holidays, on='date', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "train_ds['holidays'].fillna(0, inplace=True)\n",
    "train_ds['preholidays'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "train_ds['holidays'] = train_ds['holidays'].astype(int)\n",
    "train_ds['preholidays'] = train_ds['preholidays'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d592f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-12-31 00:00:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_holidays['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ace845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>holidays</th>\n",
       "      <th>preholidays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, holidays, preholidays]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_holidays[df_holidays.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdfa6e",
   "metadata": {},
   "source": [
    "#### 1.8 Формирование колонок со значением целевого признака в предыдущие дни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91cfdcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/2993370237.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_ds['temp_last_day'].fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Добавление колонок с временными лагами\n",
    "\n",
    "# создаем столбец 'temp_last_day'\n",
    "train_ds['temp_last_day'] = train_ds['temp'].shift(24)\n",
    "\n",
    "# заполняем пропущенные значения в 'temp_last_day'\n",
    "train_ds['temp_last_day'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# создаем столбцы с временными лагами для 'target'\n",
    "lags = [24, 48, 72, 7*24, 14*24]\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'] = train_ds['target'].shift(lag)\n",
    "\n",
    "# заполняем пропущенные значения в столбцах с лагами\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c4022",
   "metadata": {},
   "source": [
    "#### 1.9 Формирование колонок с ВВП и данными о погоде посредством ранее описанных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79aa7c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>P</th>\n",
       "      <th>U</th>\n",
       "      <th>WW</th>\n",
       "      <th>Td</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>W</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 00:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 00:30:00</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 01:00:00</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 01:30:00</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31 02:00:00</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82146</th>\n",
       "      <td>2023-09-30 21:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82147</th>\n",
       "      <td>2023-09-30 22:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82148</th>\n",
       "      <td>2023-09-30 22:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>сильный дождь</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82149</th>\n",
       "      <td>2023-09-30 23:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>сильный дождь</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82150</th>\n",
       "      <td>2023-09-30 23:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82151 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date      P      U             WW    Td    N    S    W  \\\n",
       "0      2018-12-31 00:00:00  763.5  100.0   слабый дождь   2.0  1.0  0.0  0.0   \n",
       "1      2018-12-31 00:30:00  764.3   93.0   слабый дождь   1.0  1.0  0.0  0.0   \n",
       "2      2018-12-31 01:00:00  764.3   93.0   слабый дождь   1.0  1.0  0.0  0.0   \n",
       "3      2018-12-31 01:30:00  765.0   93.0   слабый дождь   2.0  1.0  0.0  0.0   \n",
       "4      2018-12-31 02:00:00  765.0   93.0    нет осадков   2.0  1.0  0.0  0.0   \n",
       "...                    ...    ...    ...            ...   ...  ...  ...  ...   \n",
       "82146  2023-09-30 21:30:00  763.5   82.0    нет осадков  12.0  0.0  0.0  1.0   \n",
       "82147  2023-09-30 22:00:00  763.5   82.0    нет осадков  12.0  0.5  0.0  1.0   \n",
       "82148  2023-09-30 22:30:00  763.5   77.0  сильный дождь  11.0  0.0  0.0  1.0   \n",
       "82149  2023-09-30 23:00:00  763.5   94.0  сильный дождь  13.0  0.5  0.0  1.0   \n",
       "82150  2023-09-30 23:30:00  763.5   94.0    нет осадков  13.0  0.0  0.5  1.0   \n",
       "\n",
       "         E  \n",
       "0      0.0  \n",
       "1      0.5  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "82146  0.0  \n",
       "82147  0.0  \n",
       "82148  0.0  \n",
       "82149  0.0  \n",
       "82150  0.0  \n",
       "\n",
       "[82151 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# применяем функцию добавления ВВП\n",
    "train_ds = add_vvp2(train_ds)\n",
    "\n",
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "train_ds = fill_weather_columns(train_ds)\n",
    "\n",
    "\n",
    "# Читаем файл с архивом фактической погоды\n",
    "df_true_weather = pd.read_csv('data/preprocessing_loaded_table.csv')\n",
    "display(df_true_weather)\n",
    "\n",
    "# Форматируем колонки\n",
    "df_true_weather['WW'] = df_true_weather['WW'].apply(true_weather_WW_replace)\n",
    "df_true_weather['date'] = pd.to_datetime(df_true_weather['date'])\n",
    "df_true_weather = df_true_weather.rename(columns={'date':'date_tw'})\n",
    "# Применяем сдвиг на сутки, чтобы не заглядывать в будущее\n",
    "df_true_weather = shift_features_fact(df_true_weather)\n",
    "# Добавляем в датасет\n",
    "train_ds['date_hours'] = train_ds.apply(row_plus_hours_to_index, axis=1)\n",
    "train_ds = train_ds.merge(df_true_weather, left_on='date_hours', right_on='date_tw')\n",
    "train_ds = train_ds.drop(['date_hours', 'date_tw'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.10 Формирование колонок со средними значениями цели и фактической температуры за предыдущий день и срезы по нему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ba74908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds[['last_day_avg_target', 'last_day_avg_temp']] = train_ds[['date', 'target', 'temp']].groupby(by='date').transform('mean').shift(24)\n",
    "\n",
    "#def mean_evening(values, evening=19):\n",
    "#    return values[evening:].mean()\n",
    "\n",
    "#evening_slices = [19, 22]\n",
    "   \n",
    "#for evening_slice in evening_slices:\n",
    "#    train_ds[['last_evening_avg_target_'+str(evening_slice), 'last_evening_avg_temp_'+str(evening_slice)]] = \\\n",
    "#        train_ds[['date', 'target', 'temp']].groupby(by='date').transform(mean_evening, evening=evening_slice).shift(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5607815",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[['last_day_avg_target', 'last_day_avg_temp']] = train_ds[['date', 'target', 'temp']].groupby(by='date').transform('mean').shift(24)\n",
    "\n",
    "def mean_evening(values, evening=19):\n",
    "    return values[evening:].mean()\n",
    "\n",
    "evening_slices = [19, 22]\n",
    "    \n",
    "for evening_slice in evening_slices:\n",
    "    train_ds[['last_evening_avg_target_'+str(evening_slice), 'last_evening_avg_temp_'+str(evening_slice)]] = \\\n",
    "        train_ds[['date', 'target', 'temp']].groupby(by='date').transform(mean_evening, evening=evening_slice).shift(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9efa20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40027, 41)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.11 Формирование колонок с почасовыми лагами для всех сформированных ранее готовых признаков\n",
    "\n",
    "Сначала готовим список названий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8841abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем признаки. Все лишние колонки здесь отбрасываем, кроме 'date', которую уберем позже \n",
    "\n",
    "feature_cols = list(train_ds.columns)\n",
    "\n",
    "# выбрасываем взгляд в прошлое и расшифрованную погоду\n",
    "drop_list = ['target', 'day_of_year', 'weather_pred', 'weather_fact', 'temp']\n",
    "\n",
    "# выбрасываем признаки, найденные процедурно в процессе оптимизации\n",
    "# КОМАНДЕ: здесь можно добавлять признаки на выброс с целью оптимизации\n",
    "drop_list = drop_list + ['target_lag_48', 'target_lag_168'] #, 'temp_pred'] #, 'target_lag_336'] \n",
    "\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потом добавляем лаги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9aab343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "FEATURE_WINDOW_SIZE = 24\n",
    "feature_cols_no_date = feature_cols.copy()\n",
    "feature_cols_no_date.remove('date')\n",
    "\n",
    "\n",
    "for lag in range(1,FEATURE_WINDOW_SIZE):\n",
    "    for column in feature_cols_no_date:\n",
    "        train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.11 Формирование колонок с лагами для цели и фактической температуры\n",
    "\n",
    "Заполняем значениями NaN все поля этих лагов, которые относятся к текущему дню, чтобы не допустить утечки. Т.е. для каждого часа используем только лаги, которые превосходят номер часа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d55bd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/1660665095.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds.target.shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/1660665095.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/1660665095.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds.target.shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/1660665095.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/1660665095.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds.target.shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_15917/1660665095.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n"
     ]
    }
   ],
   "source": [
    "target_lags=[1, 5, 9]\n",
    "\n",
    "for lag in target_lags:\n",
    "    train_ds['target_'+str(lag)] = train_ds.target.shift(lag).where(train_ds['time']<lag, np.NaN)\n",
    "    train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc76ee",
   "metadata": {},
   "source": [
    "#### 1.12 Демонстрация сформированного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a939b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'target', 'temp', 'temp_pred', 'weather_pred',\n",
       "       'weather_fact', 'year', 'month', 'day_of_week',\n",
       "       ...\n",
       "       'last_evening_avg_target_19_23', 'last_evening_avg_temp_19_23',\n",
       "       'last_evening_avg_target_22_23', 'last_evening_avg_temp_22_23',\n",
       "       'target_1', 'temp_1', 'target_5', 'temp_5', 'target_9', 'temp_9'],\n",
       "      dtype='object', length=806)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Итоговый набор колонок\n",
    "train_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f51e77ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>target</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_pred</th>\n",
       "      <th>weather_pred</th>\n",
       "      <th>weather_fact</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>last_evening_avg_target_19_23</th>\n",
       "      <th>last_evening_avg_temp_19_23</th>\n",
       "      <th>last_evening_avg_target_22_23</th>\n",
       "      <th>last_evening_avg_temp_22_23</th>\n",
       "      <th>target_1</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>target_5</th>\n",
       "      <th>temp_5</th>\n",
       "      <th>target_9</th>\n",
       "      <th>temp_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>481.510</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>462.872</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>449.718</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>430.908</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>415.163</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  time   target  temp  temp_pred weather_pred weather_fact  year  \\\n",
       "0 2019-01-01     0  481.510   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "1 2019-01-01     1  462.872   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "2 2019-01-01     2  449.718   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "3 2019-01-01     3  430.908   4.3        2.0  пасм, ветер  ветер, пасм  2019   \n",
       "4 2019-01-01     4  415.163   4.3        2.0  пасм, ветер  ветер, пасм  2019   \n",
       "\n",
       "   month  day_of_week  ...  last_evening_avg_target_19_23  \\\n",
       "0      1            1  ...                            NaN   \n",
       "1      1            1  ...                            NaN   \n",
       "2      1            1  ...                            NaN   \n",
       "3      1            1  ...                            NaN   \n",
       "4      1            1  ...                            NaN   \n",
       "\n",
       "   last_evening_avg_temp_19_23  last_evening_avg_target_22_23  \\\n",
       "0                          NaN                            NaN   \n",
       "1                          NaN                            NaN   \n",
       "2                          NaN                            NaN   \n",
       "3                          NaN                            NaN   \n",
       "4                          NaN                            NaN   \n",
       "\n",
       "   last_evening_avg_temp_22_23  target_1  temp_1  target_5  temp_5  target_9  \\\n",
       "0                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "1                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "2                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "3                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "4                          NaN       NaN     NaN       NaN     NaN       NaN   \n",
       "\n",
       "   temp_9  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  \n",
       "\n",
       "[5 rows x 806 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69383cb",
   "metadata": {},
   "source": [
    "#### 1.13 Исключение лишних колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65d6619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем признаки. Список формируем заново из всех текущих колонок.\n",
    "feature_cols = list(train_ds.columns)\n",
    "\n",
    "# Отбрасываем колонки из ранее заготовленного списка на выброс. На этом этапе уходят колонки с утечками.\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f34c90",
   "metadata": {},
   "source": [
    "#### 1.14 Выделение наборов данных для обучения, валидации и тестирования\n",
    "\n",
    "Выделялось два набора данных для обучения и валидации:\n",
    "1. Обучение на данных с 2019 по 2021 с валидацией на 2022\n",
    "2. Обучение на данных с 2019 по 2022 с валидацией на первом квартале 2023\n",
    "\n",
    "Первый набор позволяет оценить влияние сезонности на обучение и предсказания, второй позволяет обучить модель на большем объеме данных и на более актуальных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a2b8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем набор датасетов для обучения и проверки\n",
    "\n",
    "features = train_ds[feature_cols]\n",
    "target = train_ds['target']\n",
    "\n",
    "# Функция для выделения временных интервалов из таблиц признаков и целей\n",
    "# на этом этапе отбрасываем колонку 'date'\n",
    "def features_interval(features, target, date1, date2):\n",
    "    features_interval = features[ (features['date']>=date1) & (features['date']<date2) ]\n",
    "    target_interval = target[features_interval.index]\n",
    "    features_interval = features_interval.drop('date', axis=1)\n",
    "    return features_interval, target_interval\n",
    "\n",
    "# для первичного подбора гиперпараметров будем обучать на 19-21 годах, валидировать по 2022\n",
    "features_train, target_train = features_interval(features, target, '2019-01-01', '2022-01-01')\n",
    "features_valid, target_valid = features_interval(features, target, '2022-01-01', '2023-01-01')\n",
    "\n",
    "# отбор признаков будем производить, обучая на 19-22 и проверяя по первому кварталу 2023\n",
    "# с дополнительным контролем на вариантах из первичного обучения\n",
    "features_2022, target_2022 = features_interval(features, target, '2019-01-01', '2023-01-01')\n",
    "features_2023, target_2023 = features_interval(features, target, '2023-01-01', open_test_begin)\n",
    "\n",
    "# для проверки на тестовой выборке будем учиться на всем тренировочном датасете\n",
    "features_all_train, target_all_train = features_interval(features, target, '2019-01-01', open_test_begin)\n",
    "features_open_test, target_open_test = features_interval(features, target, open_test_begin, open_test_end)\n",
    "\n",
    "# формируем наборы данных по кварталам 2022 года, чтобы посмотреть по ним метрику отдельно\n",
    "dates = ['2022-01-01', '2022-04-01', '2022-07-01', '2022-10-01', '2023-01-01']\n",
    "quarters = []\n",
    "for i in range(4):\n",
    "    f, t = features_interval(features, target, dates[i], dates[i+1])\n",
    "    quarters.append({'features':f, 'target':t})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a967384f",
   "metadata": {},
   "source": [
    "### 2. Обучение моделей\n",
    "\n",
    "В настоящей работе обучаются модели LightGBM и XGBoost, финальное предсказание получается усреднением результатов.\n",
    "\n",
    "#### 2.1 Гиперпараметры LightGBM\n",
    "Были подобраны следующие значения гиперпараметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7772cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves':15, 'learning_rate':0.02, 'feature_fraction':1, 'num_iterations':NUM_ITERATIONS, 'random_state':random_state, 'objective':'regression_l1', 'n_jobs':-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbcf5c",
   "metadata": {},
   "source": [
    "#### 2.2 Обучение на данных за 2019-2021 годы и предсказание на 2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73bc8d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 74674\n",
      "[LightGBM] [Info] Number of data points in the train set: 26217, number of used features: 798\n",
      "[LightGBM] [Info] Start training from score 464.106506\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "mae for days - 134.5512819709116\n",
      "mae for hours - 7.704952314260031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Демонстрация предсказания с подобранными гиперпараметрами\n",
    "# Тренируем на 19-21 годах, предсказываем за 2022\n",
    "\n",
    "lgbm_model = lgb.LGBMRegressor(**params)\n",
    "lgbm_model.fit(features_train, target_train)\n",
    "\n",
    "y_pred = lgbm_model.predict(features_valid)\n",
    "print(f'mae for days - {mae_day(target_valid, y_pred)}')\n",
    "print(f'mae for hours - {mean_absolute_error(target_valid, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df9b4216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "1 квартал mae = 150.50830191521797\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 квартал mae = 138.5046988017369\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "3 квартал mae = 119.29967120607014\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "4 квартал mae = 137.64030313502752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Предсказываем отдельно по четырем кварталам 2022 года\n",
    "\n",
    "for i, quarter in enumerate(quarters):\n",
    "    mae = mae_day(quarter['target'], lgbm_model.predict(quarter['features']))\n",
    "    print(f'{i+1} квартал mae = {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4f07f",
   "metadata": {},
   "source": [
    "Как видно по предсказаниям, в задаче наблюдается значительная сезонность: предсказания на первый квартал 2022 года получились хуже, чем на прочие периоды. Какой сюрприз. В целом, из графического представления видно, что предказание в целом адекватно описывает динамику целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "931f1498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae = 131.64385081519103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "# Предсказываем той же моделью (19-21) тренировочный кусок 2023 (первый квартал)\n",
    "mae = mae_day(target_2023, lgbm_model.predict(features_2023))\n",
    "print(f'mae = {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f69ef2",
   "metadata": {},
   "source": [
    "### 3 Проверка метрик на тестовом датасете\n",
    "##### 3.1 Модель LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88929019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 75442\n",
      "[LightGBM] [Info] Number of data points in the train set: 37108, number of used features: 798\n",
      "[LightGBM] [Info] Start training from score 473.062988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(feature_fraction=1, learning_rate=0.02, n_jobs=-1,\n",
       "              num_iterations=10000, num_leaves=15, objective=&#x27;regression_l1&#x27;,\n",
       "              random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(feature_fraction=1, learning_rate=0.02, n_jobs=-1,\n",
       "              num_iterations=10000, num_leaves=15, objective=&#x27;regression_l1&#x27;,\n",
       "              random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(feature_fraction=1, learning_rate=0.02, n_jobs=-1,\n",
       "              num_iterations=10000, num_leaves=15, objective='regression_l1',\n",
       "              random_state=12345)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "# Здесь обучаем на всем тренировочном датасете\n",
    "params = {'num_leaves':15, 'learning_rate':0.02, 'feature_fraction':1, 'num_iterations':10000, 'random_state':random_state, 'objective':'regression_l1', 'n_jobs':-1}\n",
    "\n",
    "lgbm_model_all_train = lgb.LGBMRegressor(**params)\n",
    "lgbm_model_all_train.fit(features_all_train, target_all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed3605e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM</td>\n",
       "      <td>3.176235</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.996797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM</td>\n",
       "      <td>6.123915</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.985995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Выборка       MAE      MAPE        R2\n",
       "0  тренировочная LGBM   3.176235  0.006670  0.996797\n",
       "1       тестовая LGBM   6.123915  0.014347  0.985995"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_predict_train = lgbm_model_all_train.predict(features_all_train)\n",
    "l_predict_test = lgbm_model_all_train.predict(features_open_test)\n",
    "\n",
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, l_predict_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, l_predict_test)\n",
    "\n",
    "FEATURES=''\n",
    "results = pd.DataFrame([[f'тренировочная LGBM {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая LGBM {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c00fb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение важности признаков\n",
    "importance = lgbm_model_all_train.feature_importances_\n",
    "feature_name = features_open_test.columns\n",
    "# создание DataFrame\n",
    "importance_df_lgbm = pd.DataFrame({'feature': feature_name, 'importance': importance})\n",
    "# сортировка по важности\n",
    "importance_df_lgbm = importance_df_lgbm.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41359208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>target_lag_24</td>\n",
       "      <td>3341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>target_lag_336</td>\n",
       "      <td>1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>target_lag_72</td>\n",
       "      <td>1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>target_lag_24_1</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>target_lag_72_23</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>year_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>year_19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>year_16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>year_6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>preholidays_12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance\n",
       "9       target_lag_24        3341\n",
       "11     target_lag_336        1548\n",
       "10      target_lag_72        1283\n",
       "42    target_lag_24_1         950\n",
       "769  target_lag_72_23         860\n",
       "..                ...         ...\n",
       "101            year_3           1\n",
       "629           year_19           1\n",
       "530           year_16           0\n",
       "200            year_6           0\n",
       "403    preholidays_12           0\n",
       "\n",
       "[798 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c8193a",
   "metadata": {},
   "source": [
    "##### 3.2 Модель XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dop_drop_XGB = [\n",
    "    #'windy_18', 'U_15', 'N_6', 'W_21', 'W_23', 'rainy_8', 'N_16', 'WW_4', 'E_7', 'S_10', 'clear_21', 'U_21', 'W_15', 'U_14', 'year_13', \n",
    "    #'E_13', 'E_5', 'windy_14', 'U_16', 'clear_15', 'W_7', 'S_22', 'W_14', 'WW_10', 'windy_21',\n",
    "    #'U_10', 'S_9', 'clear_8', 'S_11', 'U_18', 'W_20', 'windy_15', 'Td_5', 'S_21', 'U_12',\n",
    "    #'N_22', 'U_8', 'cloudy_16', 'U_13', 'W_18', 'S_8', 'U_11', 'N_1', 'WW_7', 'E_8', 'W_12', 'WW_5', 'W_16', 'has_rain_probability_6', \n",
    "    #'U_9', 'U_6', 'WW_14', 'E_2', 'has_rain_probability', 'W_4', 'E_11', 'W_11', 'E', 'windy_20', 'WW_13', 'WW_22', 'WW_20', 'N',\n",
    "    #'WW_21', 'N_2', 'E_12', 'E_21', 'year_4', 'WW_6', 'E_14', 'E_1', 'W_2', 'W_9', 'S_12', 'WW_19', 'WW_17', 'E_16', 'S_13', \n",
    "    #'WW_15', 'year_18', 'E_23', 'E_22', 'rainy_15', 'N_10', 'WW_11', 'E_20', 'S_4', 'W_1', 'E_4', 'E_9', 'has_rain_probability_15', \n",
    "    #'WW_16', 'has_rain_probability_19', 'E_3', 'WW_12', 'WW_18', 'E_15', 'has_rain_probability_16', 'year_15', 'year_9',\n",
    "    'has_rain_probability_8', 'year_8', 'has_rain_probability_11', 'year_16', 'year_7', 'has_rain_probability_3', \n",
    "    'year_17', 'has_rain_probability_13', 'year_19', 'clear_17', 'year_2', 'year_12', 'has_rain_probability_12', 'year_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f432964",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list_main = ['preholidays',\n",
    "            #'has_rain_probability', \n",
    "             #'W', 'E'\n",
    "            ]\n",
    "n_values = range(1, 24)\n",
    "preholidays = ['preholidays_{}'.format(n) for n in n_values]\n",
    "#has_rain = ['has_rain_probability_{}'.format(n) for n in n_values]\n",
    "#W_wind = ['W_{}'.format(n) for n in n_values]\n",
    "#E_wind = ['E_{}'.format(n) for n in n_values]\n",
    "\n",
    "drop_list = drop_list_main + preholidays + dop_drop_XGB #+ has_rain + W_wind + E_wind # \n",
    "\n",
    "feat_xgb_train = features_all_train.drop(columns=drop_list)\n",
    "feat_xgb_test = features_open_test.drop(columns=drop_list)\n",
    "#feat_xgb_train.columns, feat_xgb_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddbbfd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    max_depth=7,\n",
    "    n_estimators=1190, #n_estimators=195, #\n",
    "    learning_rate=0.009, #learning_rate=0.1, #\n",
    "    tree_method='exact',\n",
    "    #tree_method ='gpu_hist',\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    gamma=2,\n",
    "    colsample_bytree=1,\n",
    "    random_state=random_state\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85ba1779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/xgboost/sklearn.py:885: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Time for last iteration: -0.589637041091919\n",
      "Iteration: 1 Time for last iteration: -0.37102198600769043\n",
      "Iteration: 2 Time for last iteration: -0.3379659652709961\n",
      "Iteration: 3 Time for last iteration: -0.45894694328308105\n",
      "Iteration: 4 Time for last iteration: -0.32599902153015137\n",
      "Iteration: 5 Time for last iteration: -0.3119640350341797\n",
      "Iteration: 6 Time for last iteration: -0.3071258068084717\n",
      "Iteration: 7 Time for last iteration: -0.3217008113861084\n",
      "Iteration: 8 Time for last iteration: -0.31131911277770996\n",
      "Iteration: 9 Time for last iteration: -0.33135199546813965\n",
      "Iteration: 10 Time for last iteration: -0.32219696044921875\n",
      "Iteration: 11 Time for last iteration: -0.3083341121673584\n",
      "Iteration: 12 Time for last iteration: -0.30073022842407227\n",
      "Iteration: 13 Time for last iteration: -0.32784414291381836\n",
      "Iteration: 14 Time for last iteration: -0.33263516426086426\n",
      "Iteration: 15 Time for last iteration: -0.3357889652252197\n",
      "Iteration: 16 Time for last iteration: -0.33057188987731934\n",
      "Iteration: 17 Time for last iteration: -0.32405996322631836\n",
      "Iteration: 18 Time for last iteration: -0.45517683029174805\n",
      "Iteration: 19 Time for last iteration: -0.3122279644012451\n",
      "Iteration: 20 Time for last iteration: -0.31244778633117676\n",
      "Iteration: 21 Time for last iteration: -0.3264131546020508\n",
      "Iteration: 22 Time for last iteration: -0.3292407989501953\n",
      "Iteration: 23 Time for last iteration: -0.31046199798583984\n",
      "Iteration: 24 Time for last iteration: -0.33542490005493164\n",
      "Iteration: 25 Time for last iteration: -0.3412148952484131\n",
      "Iteration: 26 Time for last iteration: -0.37273597717285156\n",
      "Iteration: 27 Time for last iteration: -0.35574889183044434\n",
      "Iteration: 28 Time for last iteration: -0.46430516242980957\n",
      "Iteration: 29 Time for last iteration: -0.33054113388061523\n",
      "Iteration: 30 Time for last iteration: -0.3063690662384033\n",
      "Iteration: 31 Time for last iteration: -0.32961320877075195\n",
      "Iteration: 32 Time for last iteration: -0.35852599143981934\n",
      "Iteration: 33 Time for last iteration: -0.3849761486053467\n",
      "Iteration: 34 Time for last iteration: -0.3498270511627197\n",
      "Iteration: 35 Time for last iteration: -0.34558725357055664\n",
      "Iteration: 36 Time for last iteration: -0.346790075302124\n",
      "Iteration: 37 Time for last iteration: -0.4371528625488281\n",
      "Iteration: 38 Time for last iteration: -0.3162269592285156\n",
      "Iteration: 39 Time for last iteration: -0.32466912269592285\n",
      "Iteration: 40 Time for last iteration: -0.31156086921691895\n",
      "Iteration: 41 Time for last iteration: -0.3362100124359131\n",
      "Iteration: 42 Time for last iteration: -0.32067394256591797\n",
      "Iteration: 43 Time for last iteration: -0.3139009475708008\n",
      "Iteration: 44 Time for last iteration: -0.3188190460205078\n",
      "Iteration: 45 Time for last iteration: -0.3500840663909912\n",
      "Iteration: 46 Time for last iteration: -0.31343793869018555\n",
      "Iteration: 47 Time for last iteration: -0.3060622215270996\n",
      "Iteration: 48 Time for last iteration: -0.31696605682373047\n",
      "Iteration: 49 Time for last iteration: -0.3184990882873535\n",
      "Iteration: 50 Time for last iteration: -0.30909204483032227\n",
      "Iteration: 51 Time for last iteration: -0.3312520980834961\n",
      "Iteration: 52 Time for last iteration: -0.31318092346191406\n",
      "Iteration: 53 Time for last iteration: -0.3123199939727783\n",
      "Iteration: 54 Time for last iteration: -0.307919979095459\n",
      "Iteration: 55 Time for last iteration: -0.3921852111816406\n",
      "Iteration: 56 Time for last iteration: -0.3520979881286621\n",
      "Iteration: 57 Time for last iteration: -0.32732295989990234\n",
      "Iteration: 58 Time for last iteration: -0.35332775115966797\n",
      "Iteration: 59 Time for last iteration: -0.3134450912475586\n",
      "Iteration: 60 Time for last iteration: -0.3053460121154785\n",
      "Iteration: 61 Time for last iteration: -0.31890106201171875\n",
      "Iteration: 62 Time for last iteration: -0.32514190673828125\n",
      "Iteration: 63 Time for last iteration: -0.3138439655303955\n",
      "Iteration: 64 Time for last iteration: -0.3446199893951416\n",
      "Iteration: 65 Time for last iteration: -0.3291759490966797\n",
      "Iteration: 66 Time for last iteration: -0.339008092880249\n",
      "Iteration: 67 Time for last iteration: -0.3231079578399658\n",
      "Iteration: 68 Time for last iteration: -0.3136467933654785\n",
      "Iteration: 69 Time for last iteration: -0.3471240997314453\n",
      "Iteration: 70 Time for last iteration: -0.32623887062072754\n",
      "Iteration: 71 Time for last iteration: -0.30533385276794434\n",
      "Iteration: 72 Time for last iteration: -0.3111262321472168\n",
      "Iteration: 73 Time for last iteration: -0.3102691173553467\n",
      "Iteration: 74 Time for last iteration: -0.3139991760253906\n",
      "Iteration: 75 Time for last iteration: -0.3050057888031006\n",
      "Iteration: 76 Time for last iteration: -0.4696478843688965\n",
      "Iteration: 77 Time for last iteration: -0.3187370300292969\n",
      "Iteration: 78 Time for last iteration: -0.31052684783935547\n",
      "Iteration: 79 Time for last iteration: -0.3461339473724365\n",
      "Iteration: 80 Time for last iteration: -0.32962989807128906\n",
      "Iteration: 81 Time for last iteration: -0.33114194869995117\n",
      "Iteration: 82 Time for last iteration: -0.3575611114501953\n",
      "Iteration: 83 Time for last iteration: -0.44899916648864746\n",
      "Iteration: 84 Time for last iteration: -0.3183929920196533\n",
      "Iteration: 85 Time for last iteration: -0.32219505310058594\n",
      "Iteration: 86 Time for last iteration: -0.32738518714904785\n",
      "Iteration: 87 Time for last iteration: -0.321718692779541\n",
      "Iteration: 88 Time for last iteration: -0.33838629722595215\n",
      "Iteration: 89 Time for last iteration: -0.3328390121459961\n",
      "Iteration: 90 Time for last iteration: -0.31348490715026855\n",
      "Iteration: 91 Time for last iteration: -0.318572998046875\n",
      "Iteration: 92 Time for last iteration: -0.3042581081390381\n",
      "Iteration: 93 Time for last iteration: -0.3076186180114746\n",
      "Iteration: 94 Time for last iteration: -0.30739402770996094\n",
      "Iteration: 95 Time for last iteration: -0.30379605293273926\n",
      "Iteration: 96 Time for last iteration: -0.3024148941040039\n",
      "Iteration: 97 Time for last iteration: -0.3074822425842285\n",
      "Iteration: 98 Time for last iteration: -0.3313589096069336\n",
      "Iteration: 99 Time for last iteration: -0.395460844039917\n",
      "Iteration: 100 Time for last iteration: -0.3343210220336914\n",
      "Iteration: 101 Time for last iteration: -0.31793880462646484\n",
      "Iteration: 102 Time for last iteration: -0.34271812438964844\n",
      "Iteration: 103 Time for last iteration: -0.3314187526702881\n",
      "Iteration: 104 Time for last iteration: -0.4465658664703369\n",
      "Iteration: 105 Time for last iteration: -0.35360288619995117\n",
      "Iteration: 106 Time for last iteration: -0.36974596977233887\n",
      "Iteration: 107 Time for last iteration: -0.4167160987854004\n",
      "Iteration: 108 Time for last iteration: -0.3600482940673828\n",
      "Iteration: 109 Time for last iteration: -0.338590145111084\n",
      "Iteration: 110 Time for last iteration: -0.33676815032958984\n",
      "Iteration: 111 Time for last iteration: -0.310291051864624\n",
      "Iteration: 112 Time for last iteration: -0.3488919734954834\n",
      "Iteration: 113 Time for last iteration: -0.3167228698730469\n",
      "Iteration: 114 Time for last iteration: -0.3339269161224365\n",
      "Iteration: 115 Time for last iteration: -0.318450927734375\n",
      "Iteration: 116 Time for last iteration: -0.3362140655517578\n",
      "Iteration: 117 Time for last iteration: -0.34407496452331543\n",
      "Iteration: 118 Time for last iteration: -0.34241509437561035\n",
      "Iteration: 119 Time for last iteration: -0.33063292503356934\n",
      "Iteration: 120 Time for last iteration: -0.32279229164123535\n",
      "Iteration: 121 Time for last iteration: -0.31638288497924805\n",
      "Iteration: 122 Time for last iteration: -0.3776230812072754\n",
      "Iteration: 123 Time for last iteration: -0.3381659984588623\n",
      "Iteration: 124 Time for last iteration: -0.3345499038696289\n",
      "Iteration: 125 Time for last iteration: -0.31865715980529785\n",
      "Iteration: 126 Time for last iteration: -0.31424784660339355\n",
      "Iteration: 127 Time for last iteration: -0.31664109230041504\n",
      "Iteration: 128 Time for last iteration: -0.3368220329284668\n",
      "Iteration: 129 Time for last iteration: -0.3169898986816406\n",
      "Iteration: 130 Time for last iteration: -0.3157479763031006\n",
      "Iteration: 131 Time for last iteration: -0.318666934967041\n",
      "Iteration: 132 Time for last iteration: -0.3163750171661377\n",
      "Iteration: 133 Time for last iteration: -0.3230862617492676\n",
      "Iteration: 134 Time for last iteration: -0.33661699295043945\n",
      "Iteration: 135 Time for last iteration: -0.3288090229034424\n",
      "Iteration: 136 Time for last iteration: -0.3312849998474121\n",
      "Iteration: 137 Time for last iteration: -0.3343491554260254\n",
      "Iteration: 138 Time for last iteration: -0.3192880153656006\n",
      "Iteration: 139 Time for last iteration: -0.3676149845123291\n",
      "Iteration: 140 Time for last iteration: -0.31563711166381836\n",
      "Iteration: 141 Time for last iteration: -0.31051182746887207\n",
      "Iteration: 142 Time for last iteration: -0.3945338726043701\n",
      "Iteration: 143 Time for last iteration: -0.3224482536315918\n",
      "Iteration: 144 Time for last iteration: -0.31746816635131836\n",
      "Iteration: 145 Time for last iteration: -0.35205698013305664\n",
      "Iteration: 146 Time for last iteration: -0.3221621513366699\n",
      "Iteration: 147 Time for last iteration: -0.3168478012084961\n",
      "Iteration: 148 Time for last iteration: -0.31514406204223633\n",
      "Iteration: 149 Time for last iteration: -0.315626859664917\n",
      "Iteration: 150 Time for last iteration: -0.30968499183654785\n",
      "Iteration: 151 Time for last iteration: -0.31162405014038086\n",
      "Iteration: 152 Time for last iteration: -0.31620097160339355\n",
      "Iteration: 153 Time for last iteration: -0.31493496894836426\n",
      "Iteration: 154 Time for last iteration: -0.3295888900756836\n",
      "Iteration: 155 Time for last iteration: -0.3107938766479492\n",
      "Iteration: 156 Time for last iteration: -0.31287598609924316\n",
      "Iteration: 157 Time for last iteration: -0.3155078887939453\n",
      "Iteration: 158 Time for last iteration: -0.31449031829833984\n",
      "Iteration: 159 Time for last iteration: -0.3036348819732666\n",
      "Iteration: 160 Time for last iteration: -0.3220360279083252\n",
      "Iteration: 161 Time for last iteration: -0.31220078468322754\n",
      "Iteration: 162 Time for last iteration: -0.3142092227935791\n",
      "Iteration: 163 Time for last iteration: -0.31148695945739746\n",
      "Iteration: 164 Time for last iteration: -0.31264734268188477\n",
      "Iteration: 165 Time for last iteration: -0.3052639961242676\n",
      "Iteration: 166 Time for last iteration: -0.3077387809753418\n",
      "Iteration: 167 Time for last iteration: -0.3168821334838867\n",
      "Iteration: 168 Time for last iteration: -0.3069939613342285\n",
      "Iteration: 169 Time for last iteration: -0.31517887115478516\n",
      "Iteration: 170 Time for last iteration: -0.3131711483001709\n",
      "Iteration: 171 Time for last iteration: -0.3108220100402832\n",
      "Iteration: 172 Time for last iteration: -0.3057992458343506\n",
      "Iteration: 173 Time for last iteration: -0.31221795082092285\n",
      "Iteration: 174 Time for last iteration: -0.3092081546783447\n",
      "Iteration: 175 Time for last iteration: -0.3089747428894043\n",
      "Iteration: 176 Time for last iteration: -0.30273985862731934\n",
      "Iteration: 177 Time for last iteration: -0.30512094497680664\n",
      "Iteration: 178 Time for last iteration: -0.35151100158691406\n",
      "Iteration: 179 Time for last iteration: -0.31825923919677734\n",
      "Iteration: 180 Time for last iteration: -0.3127901554107666\n",
      "Iteration: 181 Time for last iteration: -0.3159019947052002\n",
      "Iteration: 182 Time for last iteration: -0.30687379837036133\n",
      "Iteration: 183 Time for last iteration: -0.303617000579834\n",
      "Iteration: 184 Time for last iteration: -0.3030431270599365\n",
      "Iteration: 185 Time for last iteration: -0.31609177589416504\n",
      "Iteration: 186 Time for last iteration: -0.3061246871948242\n",
      "Iteration: 187 Time for last iteration: -0.3110771179199219\n",
      "Iteration: 188 Time for last iteration: -0.311326265335083\n",
      "Iteration: 189 Time for last iteration: -0.31215476989746094\n",
      "Iteration: 190 Time for last iteration: -0.3088240623474121\n",
      "Iteration: 191 Time for last iteration: -0.3089408874511719\n",
      "Iteration: 192 Time for last iteration: -0.3483541011810303\n",
      "Iteration: 193 Time for last iteration: -0.3101341724395752\n",
      "Iteration: 194 Time for last iteration: -0.3068101406097412\n",
      "Iteration: 195 Time for last iteration: -0.3025941848754883\n",
      "Iteration: 196 Time for last iteration: -0.3044240474700928\n",
      "Iteration: 197 Time for last iteration: -0.3035159111022949\n",
      "Iteration: 198 Time for last iteration: -0.3035759925842285\n",
      "Iteration: 199 Time for last iteration: -0.31658291816711426\n",
      "Iteration: 200 Time for last iteration: -0.32381272315979004\n",
      "Iteration: 201 Time for last iteration: -0.30323100090026855\n",
      "Iteration: 202 Time for last iteration: -0.30652809143066406\n",
      "Iteration: 203 Time for last iteration: -0.30503106117248535\n",
      "Iteration: 204 Time for last iteration: -0.31731295585632324\n",
      "Iteration: 205 Time for last iteration: -0.3228437900543213\n",
      "Iteration: 206 Time for last iteration: -0.32614779472351074\n",
      "Iteration: 207 Time for last iteration: -0.3183259963989258\n",
      "Iteration: 208 Time for last iteration: -0.31131887435913086\n",
      "Iteration: 209 Time for last iteration: -0.304110050201416\n",
      "Iteration: 210 Time for last iteration: -0.3071169853210449\n",
      "Iteration: 211 Time for last iteration: -0.32074594497680664\n",
      "Iteration: 212 Time for last iteration: -0.3173339366912842\n",
      "Iteration: 213 Time for last iteration: -0.3113369941711426\n",
      "Iteration: 214 Time for last iteration: -0.3100931644439697\n",
      "Iteration: 215 Time for last iteration: -0.30150485038757324\n",
      "Iteration: 216 Time for last iteration: -0.3025178909301758\n",
      "Iteration: 217 Time for last iteration: -0.3049349784851074\n",
      "Iteration: 218 Time for last iteration: -0.32273006439208984\n",
      "Iteration: 219 Time for last iteration: -0.3104410171508789\n",
      "Iteration: 220 Time for last iteration: -0.3086845874786377\n",
      "Iteration: 221 Time for last iteration: -0.3075380325317383\n",
      "Iteration: 222 Time for last iteration: -0.3067760467529297\n",
      "Iteration: 223 Time for last iteration: -0.3075709342956543\n",
      "Iteration: 224 Time for last iteration: -0.3097798824310303\n",
      "Iteration: 225 Time for last iteration: -0.32401418685913086\n",
      "Iteration: 226 Time for last iteration: -0.3118159770965576\n",
      "Iteration: 227 Time for last iteration: -0.30391407012939453\n",
      "Iteration: 228 Time for last iteration: -0.30498266220092773\n",
      "Iteration: 229 Time for last iteration: -0.303469181060791\n",
      "Iteration: 230 Time for last iteration: -0.308380126953125\n",
      "Iteration: 231 Time for last iteration: -0.3117411136627197\n",
      "Iteration: 232 Time for last iteration: -0.30823802947998047\n",
      "Iteration: 233 Time for last iteration: -0.3081400394439697\n",
      "Iteration: 234 Time for last iteration: -0.3067209720611572\n",
      "Iteration: 235 Time for last iteration: -0.30626487731933594\n",
      "Iteration: 236 Time for last iteration: -0.3038179874420166\n",
      "Iteration: 237 Time for last iteration: -0.3120920658111572\n",
      "Iteration: 238 Time for last iteration: -0.3104832172393799\n",
      "Iteration: 239 Time for last iteration: -0.3107140064239502\n",
      "Iteration: 240 Time for last iteration: -0.304797887802124\n",
      "Iteration: 241 Time for last iteration: -0.3125321865081787\n",
      "Iteration: 242 Time for last iteration: -0.3246347904205322\n",
      "Iteration: 243 Time for last iteration: -0.31641578674316406\n",
      "Iteration: 244 Time for last iteration: -0.3089141845703125\n",
      "Iteration: 245 Time for last iteration: -0.3223869800567627\n",
      "Iteration: 246 Time for last iteration: -0.3106350898742676\n",
      "Iteration: 247 Time for last iteration: -0.30231595039367676\n",
      "Iteration: 248 Time for last iteration: -0.3058769702911377\n",
      "Iteration: 249 Time for last iteration: -0.30867910385131836\n",
      "Iteration: 250 Time for last iteration: -0.3126070499420166\n",
      "Iteration: 251 Time for last iteration: -0.30790185928344727\n",
      "Iteration: 252 Time for last iteration: -0.30769896507263184\n",
      "Iteration: 253 Time for last iteration: -0.3083949089050293\n",
      "Iteration: 254 Time for last iteration: -0.3082578182220459\n",
      "Iteration: 255 Time for last iteration: -0.30591607093811035\n",
      "Iteration: 256 Time for last iteration: -0.3077230453491211\n",
      "Iteration: 257 Time for last iteration: -0.315140962600708\n",
      "Iteration: 258 Time for last iteration: -0.3085019588470459\n",
      "Iteration: 259 Time for last iteration: -0.3021361827850342\n",
      "Iteration: 260 Time for last iteration: -0.3019258975982666\n",
      "Iteration: 261 Time for last iteration: -0.3059041500091553\n",
      "Iteration: 262 Time for last iteration: -0.3015329837799072\n",
      "Iteration: 263 Time for last iteration: -0.3113830089569092\n",
      "Iteration: 264 Time for last iteration: -0.3162379264831543\n",
      "Iteration: 265 Time for last iteration: -0.30592894554138184\n",
      "Iteration: 266 Time for last iteration: -0.30577874183654785\n",
      "Iteration: 267 Time for last iteration: -0.3056168556213379\n",
      "Iteration: 268 Time for last iteration: -0.3035440444946289\n",
      "Iteration: 269 Time for last iteration: -0.3060290813446045\n",
      "Iteration: 270 Time for last iteration: -0.31561899185180664\n",
      "Iteration: 271 Time for last iteration: -0.3069651126861572\n",
      "Iteration: 272 Time for last iteration: -0.2999279499053955\n",
      "Iteration: 273 Time for last iteration: -0.30484890937805176\n",
      "Iteration: 274 Time for last iteration: -0.3056058883666992\n",
      "Iteration: 275 Time for last iteration: -0.3051779270172119\n",
      "Iteration: 276 Time for last iteration: -0.32576417922973633\n",
      "Iteration: 277 Time for last iteration: -0.30914783477783203\n",
      "Iteration: 278 Time for last iteration: -0.316788911819458\n",
      "Iteration: 279 Time for last iteration: -0.3165278434753418\n",
      "Iteration: 280 Time for last iteration: -0.30325913429260254\n",
      "Iteration: 281 Time for last iteration: -0.3018028736114502\n",
      "Iteration: 282 Time for last iteration: -0.3067028522491455\n",
      "Iteration: 283 Time for last iteration: -0.3044099807739258\n",
      "Iteration: 284 Time for last iteration: -0.3199751377105713\n",
      "Iteration: 285 Time for last iteration: -0.30721473693847656\n",
      "Iteration: 286 Time for last iteration: -0.30628180503845215\n",
      "Iteration: 287 Time for last iteration: -0.3071908950805664\n",
      "Iteration: 288 Time for last iteration: -0.30401086807250977\n",
      "Iteration: 289 Time for last iteration: -0.31506919860839844\n",
      "Iteration: 290 Time for last iteration: -0.3072340488433838\n",
      "Iteration: 291 Time for last iteration: -0.30751514434814453\n",
      "Iteration: 292 Time for last iteration: -0.3057899475097656\n",
      "Iteration: 293 Time for last iteration: -0.3076810836791992\n",
      "Iteration: 294 Time for last iteration: -0.29990696907043457\n",
      "Iteration: 295 Time for last iteration: -0.31339502334594727\n",
      "Iteration: 296 Time for last iteration: -0.3049581050872803\n",
      "Iteration: 297 Time for last iteration: -0.3104879856109619\n",
      "Iteration: 298 Time for last iteration: -0.31053614616394043\n",
      "Iteration: 299 Time for last iteration: -0.30219101905822754\n",
      "Iteration: 300 Time for last iteration: -0.30532097816467285\n",
      "Iteration: 301 Time for last iteration: -0.3023250102996826\n",
      "Iteration: 302 Time for last iteration: -0.3101999759674072\n",
      "Iteration: 303 Time for last iteration: -0.31176114082336426\n",
      "Iteration: 304 Time for last iteration: -0.308290958404541\n",
      "Iteration: 305 Time for last iteration: -0.30274367332458496\n",
      "Iteration: 306 Time for last iteration: -0.3046441078186035\n",
      "Iteration: 307 Time for last iteration: -0.30364012718200684\n",
      "Iteration: 308 Time for last iteration: -0.30626678466796875\n",
      "Iteration: 309 Time for last iteration: -0.3117039203643799\n",
      "Iteration: 310 Time for last iteration: -0.3205687999725342\n",
      "Iteration: 311 Time for last iteration: -0.3146500587463379\n",
      "Iteration: 312 Time for last iteration: -0.322390079498291\n",
      "Iteration: 313 Time for last iteration: -0.33762288093566895\n",
      "Iteration: 314 Time for last iteration: -0.3123300075531006\n",
      "Iteration: 315 Time for last iteration: -0.3062601089477539\n",
      "Iteration: 316 Time for last iteration: -0.3113880157470703\n",
      "Iteration: 317 Time for last iteration: -0.3116610050201416\n",
      "Iteration: 318 Time for last iteration: -0.3100731372833252\n",
      "Iteration: 319 Time for last iteration: -0.30242013931274414\n",
      "Iteration: 320 Time for last iteration: -0.3011150360107422\n",
      "Iteration: 321 Time for last iteration: -0.3063788414001465\n",
      "Iteration: 322 Time for last iteration: -0.3087759017944336\n",
      "Iteration: 323 Time for last iteration: -0.3083159923553467\n",
      "Iteration: 324 Time for last iteration: -0.329132080078125\n",
      "Iteration: 325 Time for last iteration: -0.32111406326293945\n",
      "Iteration: 326 Time for last iteration: -0.3095088005065918\n",
      "Iteration: 327 Time for last iteration: -0.31278204917907715\n",
      "Iteration: 328 Time for last iteration: -0.3085670471191406\n",
      "Iteration: 329 Time for last iteration: -0.30805182456970215\n",
      "Iteration: 330 Time for last iteration: -0.3083944320678711\n",
      "Iteration: 331 Time for last iteration: -0.31969571113586426\n",
      "Iteration: 332 Time for last iteration: -0.31588101387023926\n",
      "Iteration: 333 Time for last iteration: -0.3216068744659424\n",
      "Iteration: 334 Time for last iteration: -0.3123588562011719\n",
      "Iteration: 335 Time for last iteration: -0.30918002128601074\n",
      "Iteration: 336 Time for last iteration: -0.31044793128967285\n",
      "Iteration: 337 Time for last iteration: -0.31365513801574707\n",
      "Iteration: 338 Time for last iteration: -0.3302767276763916\n",
      "Iteration: 339 Time for last iteration: -0.3102400302886963\n",
      "Iteration: 340 Time for last iteration: -0.31218981742858887\n",
      "Iteration: 341 Time for last iteration: -0.31784558296203613\n",
      "Iteration: 342 Time for last iteration: -0.31034016609191895\n",
      "Iteration: 343 Time for last iteration: -0.3043360710144043\n",
      "Iteration: 344 Time for last iteration: -0.313737154006958\n",
      "Iteration: 345 Time for last iteration: -0.31282997131347656\n",
      "Iteration: 346 Time for last iteration: -0.31905221939086914\n",
      "Iteration: 347 Time for last iteration: -0.3256571292877197\n",
      "Iteration: 348 Time for last iteration: -0.316478967666626\n",
      "Iteration: 349 Time for last iteration: -0.3245532512664795\n",
      "Iteration: 350 Time for last iteration: -0.3205130100250244\n",
      "Iteration: 351 Time for last iteration: -0.31221604347229004\n",
      "Iteration: 352 Time for last iteration: -0.3086841106414795\n",
      "Iteration: 353 Time for last iteration: -0.3099651336669922\n",
      "Iteration: 354 Time for last iteration: -0.30726027488708496\n",
      "Iteration: 355 Time for last iteration: -0.3075699806213379\n",
      "Iteration: 356 Time for last iteration: -0.30864596366882324\n",
      "Iteration: 357 Time for last iteration: -0.3041410446166992\n",
      "Iteration: 358 Time for last iteration: -0.3089017868041992\n",
      "Iteration: 359 Time for last iteration: -0.3063528537750244\n",
      "Iteration: 360 Time for last iteration: -0.30773305892944336\n",
      "Iteration: 361 Time for last iteration: -0.3117060661315918\n",
      "Iteration: 362 Time for last iteration: -0.3090171813964844\n",
      "Iteration: 363 Time for last iteration: -0.3072524070739746\n",
      "Iteration: 364 Time for last iteration: -0.31412196159362793\n",
      "Iteration: 365 Time for last iteration: -0.30142998695373535\n",
      "Iteration: 366 Time for last iteration: -0.30184197425842285\n",
      "Iteration: 367 Time for last iteration: -0.30669593811035156\n",
      "Iteration: 368 Time for last iteration: -0.30256199836730957\n",
      "Iteration: 369 Time for last iteration: -0.31559085845947266\n",
      "Iteration: 370 Time for last iteration: -0.30695390701293945\n",
      "Iteration: 371 Time for last iteration: -0.3193380832672119\n",
      "Iteration: 372 Time for last iteration: -0.3114900588989258\n",
      "Iteration: 373 Time for last iteration: -0.32614588737487793\n",
      "Iteration: 374 Time for last iteration: -0.3174159526824951\n",
      "Iteration: 375 Time for last iteration: -0.3155341148376465\n",
      "Iteration: 376 Time for last iteration: -0.30457615852355957\n",
      "Iteration: 377 Time for last iteration: -0.3087191581726074\n",
      "Iteration: 378 Time for last iteration: -0.302243709564209\n",
      "Iteration: 379 Time for last iteration: -0.30835819244384766\n",
      "Iteration: 380 Time for last iteration: -0.30556368827819824\n",
      "Iteration: 381 Time for last iteration: -0.3032572269439697\n",
      "Iteration: 382 Time for last iteration: -0.3154010772705078\n",
      "Iteration: 383 Time for last iteration: -0.3255329132080078\n",
      "Iteration: 384 Time for last iteration: -0.31557726860046387\n",
      "Iteration: 385 Time for last iteration: -0.31430816650390625\n",
      "Iteration: 386 Time for last iteration: -0.34628915786743164\n",
      "Iteration: 387 Time for last iteration: -0.30437278747558594\n",
      "Iteration: 388 Time for last iteration: -0.30219388008117676\n",
      "Iteration: 389 Time for last iteration: -0.3022651672363281\n",
      "Iteration: 390 Time for last iteration: -0.30529189109802246\n",
      "Iteration: 391 Time for last iteration: -0.2991790771484375\n",
      "Iteration: 392 Time for last iteration: -0.30614566802978516\n",
      "Iteration: 393 Time for last iteration: -0.30707716941833496\n",
      "Iteration: 394 Time for last iteration: -0.30341291427612305\n",
      "Iteration: 395 Time for last iteration: -0.29816126823425293\n",
      "Iteration: 396 Time for last iteration: -0.3023831844329834\n",
      "Iteration: 397 Time for last iteration: -0.30019116401672363\n",
      "Iteration: 398 Time for last iteration: -0.30672788619995117\n",
      "Iteration: 399 Time for last iteration: -0.301555871963501\n",
      "Iteration: 400 Time for last iteration: -0.3062570095062256\n",
      "Iteration: 401 Time for last iteration: -0.3081090450286865\n",
      "Iteration: 402 Time for last iteration: -0.31766700744628906\n",
      "Iteration: 403 Time for last iteration: -0.29898810386657715\n",
      "Iteration: 404 Time for last iteration: -0.30910825729370117\n",
      "Iteration: 405 Time for last iteration: -0.3065989017486572\n",
      "Iteration: 406 Time for last iteration: -0.32543182373046875\n",
      "Iteration: 407 Time for last iteration: -0.32425713539123535\n",
      "Iteration: 408 Time for last iteration: -0.3270449638366699\n",
      "Iteration: 409 Time for last iteration: -0.32344579696655273\n",
      "Iteration: 410 Time for last iteration: -0.3070950508117676\n",
      "Iteration: 411 Time for last iteration: -0.31966304779052734\n",
      "Iteration: 412 Time for last iteration: -0.31882715225219727\n",
      "Iteration: 413 Time for last iteration: -0.31021904945373535\n",
      "Iteration: 414 Time for last iteration: -0.3158581256866455\n",
      "Iteration: 415 Time for last iteration: -0.31754517555236816\n",
      "Iteration: 416 Time for last iteration: -0.3041708469390869\n",
      "Iteration: 417 Time for last iteration: -0.3122110366821289\n",
      "Iteration: 418 Time for last iteration: -0.30604004859924316\n",
      "Iteration: 419 Time for last iteration: -0.3131141662597656\n",
      "Iteration: 420 Time for last iteration: -0.35897397994995117\n",
      "Iteration: 421 Time for last iteration: -0.30756402015686035\n",
      "Iteration: 422 Time for last iteration: -0.2998840808868408\n",
      "Iteration: 423 Time for last iteration: -0.3171112537384033\n",
      "Iteration: 424 Time for last iteration: -0.298626184463501\n",
      "Iteration: 425 Time for last iteration: -0.30342912673950195\n",
      "Iteration: 426 Time for last iteration: -0.30585384368896484\n",
      "Iteration: 427 Time for last iteration: -0.3113572597503662\n",
      "Iteration: 428 Time for last iteration: -0.303555965423584\n",
      "Iteration: 429 Time for last iteration: -0.3035390377044678\n",
      "Iteration: 430 Time for last iteration: -0.3058810234069824\n",
      "Iteration: 431 Time for last iteration: -0.3076300621032715\n",
      "Iteration: 432 Time for last iteration: -0.3045840263366699\n",
      "Iteration: 433 Time for last iteration: -0.30907201766967773\n",
      "Iteration: 434 Time for last iteration: -0.30545496940612793\n",
      "Iteration: 435 Time for last iteration: -0.314129114151001\n",
      "Iteration: 436 Time for last iteration: -0.3033878803253174\n",
      "Iteration: 437 Time for last iteration: -0.3001708984375\n",
      "Iteration: 438 Time for last iteration: -0.30209898948669434\n",
      "Iteration: 439 Time for last iteration: -0.3100926876068115\n",
      "Iteration: 440 Time for last iteration: -0.30770111083984375\n",
      "Iteration: 441 Time for last iteration: -0.30748701095581055\n",
      "Iteration: 442 Time for last iteration: -0.3093090057373047\n",
      "Iteration: 443 Time for last iteration: -0.305009126663208\n",
      "Iteration: 444 Time for last iteration: -0.29842138290405273\n",
      "Iteration: 445 Time for last iteration: -0.2996196746826172\n",
      "Iteration: 446 Time for last iteration: -0.31395411491394043\n",
      "Iteration: 447 Time for last iteration: -0.30268001556396484\n",
      "Iteration: 448 Time for last iteration: -0.2998650074005127\n",
      "Iteration: 449 Time for last iteration: -0.3054158687591553\n",
      "Iteration: 450 Time for last iteration: -0.30750393867492676\n",
      "Iteration: 451 Time for last iteration: -0.2991220951080322\n",
      "Iteration: 452 Time for last iteration: -0.30632925033569336\n",
      "Iteration: 453 Time for last iteration: -0.30953025817871094\n",
      "Iteration: 454 Time for last iteration: -0.3351268768310547\n",
      "Iteration: 455 Time for last iteration: -0.3061220645904541\n",
      "Iteration: 456 Time for last iteration: -0.31992006301879883\n",
      "Iteration: 457 Time for last iteration: -0.4612462520599365\n",
      "Iteration: 458 Time for last iteration: -0.31791090965270996\n",
      "Iteration: 459 Time for last iteration: -0.31481504440307617\n",
      "Iteration: 460 Time for last iteration: -0.31410884857177734\n",
      "Iteration: 461 Time for last iteration: -0.3154590129852295\n",
      "Iteration: 462 Time for last iteration: -0.3118288516998291\n",
      "Iteration: 463 Time for last iteration: -0.31651973724365234\n",
      "Iteration: 464 Time for last iteration: -0.31137704849243164\n",
      "Iteration: 465 Time for last iteration: -0.3134610652923584\n",
      "Iteration: 466 Time for last iteration: -0.3289060592651367\n",
      "Iteration: 467 Time for last iteration: -0.30344390869140625\n",
      "Iteration: 468 Time for last iteration: -0.3207828998565674\n",
      "Iteration: 469 Time for last iteration: -0.3098928928375244\n",
      "Iteration: 470 Time for last iteration: -0.30504703521728516\n",
      "Iteration: 471 Time for last iteration: -0.30745887756347656\n",
      "Iteration: 472 Time for last iteration: -0.318803071975708\n",
      "Iteration: 473 Time for last iteration: -0.3093297481536865\n",
      "Iteration: 474 Time for last iteration: -0.3105127811431885\n",
      "Iteration: 475 Time for last iteration: -0.30429887771606445\n",
      "Iteration: 476 Time for last iteration: -0.30362892150878906\n",
      "Iteration: 477 Time for last iteration: -0.31048107147216797\n",
      "Iteration: 478 Time for last iteration: -0.31862711906433105\n",
      "Iteration: 479 Time for last iteration: -0.3121531009674072\n",
      "Iteration: 480 Time for last iteration: -0.31298112869262695\n",
      "Iteration: 481 Time for last iteration: -0.31505799293518066\n",
      "Iteration: 482 Time for last iteration: -0.30846595764160156\n",
      "Iteration: 483 Time for last iteration: -0.2973167896270752\n",
      "Iteration: 484 Time for last iteration: -0.30065202713012695\n",
      "Iteration: 485 Time for last iteration: -0.308243989944458\n",
      "Iteration: 486 Time for last iteration: -0.30451107025146484\n",
      "Iteration: 487 Time for last iteration: -0.3059067726135254\n",
      "Iteration: 488 Time for last iteration: -0.3196859359741211\n",
      "Iteration: 489 Time for last iteration: -0.3084120750427246\n",
      "Iteration: 490 Time for last iteration: -0.3021712303161621\n",
      "Iteration: 491 Time for last iteration: -0.32177186012268066\n",
      "Iteration: 492 Time for last iteration: -0.3148322105407715\n",
      "Iteration: 493 Time for last iteration: -0.3043031692504883\n",
      "Iteration: 494 Time for last iteration: -0.2996647357940674\n",
      "Iteration: 495 Time for last iteration: -0.3078041076660156\n",
      "Iteration: 496 Time for last iteration: -0.30066609382629395\n",
      "Iteration: 497 Time for last iteration: -0.2975449562072754\n",
      "Iteration: 498 Time for last iteration: -0.3019866943359375\n",
      "Iteration: 499 Time for last iteration: -0.3102700710296631\n",
      "Iteration: 500 Time for last iteration: -0.30094218254089355\n",
      "Iteration: 501 Time for last iteration: -0.30333900451660156\n",
      "Iteration: 502 Time for last iteration: -0.3012211322784424\n",
      "Iteration: 503 Time for last iteration: -0.312000036239624\n",
      "Iteration: 504 Time for last iteration: -0.3301811218261719\n",
      "Iteration: 505 Time for last iteration: -0.32327890396118164\n",
      "Iteration: 506 Time for last iteration: -0.3130769729614258\n",
      "Iteration: 507 Time for last iteration: -0.3077230453491211\n",
      "Iteration: 508 Time for last iteration: -0.30361080169677734\n",
      "Iteration: 509 Time for last iteration: -0.29790806770324707\n",
      "Iteration: 510 Time for last iteration: -0.30147600173950195\n",
      "Iteration: 511 Time for last iteration: -0.3128180503845215\n",
      "Iteration: 512 Time for last iteration: -0.31896090507507324\n",
      "Iteration: 513 Time for last iteration: -0.3097407817840576\n",
      "Iteration: 514 Time for last iteration: -0.299271821975708\n",
      "Iteration: 515 Time for last iteration: -0.2999889850616455\n",
      "Iteration: 516 Time for last iteration: -0.303692102432251\n",
      "Iteration: 517 Time for last iteration: -0.3203299045562744\n",
      "Iteration: 518 Time for last iteration: -0.35794568061828613\n",
      "Iteration: 519 Time for last iteration: -0.3059070110321045\n",
      "Iteration: 520 Time for last iteration: -0.3092360496520996\n",
      "Iteration: 521 Time for last iteration: -0.31203413009643555\n",
      "Iteration: 522 Time for last iteration: -0.304196834564209\n",
      "Iteration: 523 Time for last iteration: -0.3383910655975342\n",
      "Iteration: 524 Time for last iteration: -0.3211250305175781\n",
      "Iteration: 525 Time for last iteration: -0.3533308506011963\n",
      "Iteration: 526 Time for last iteration: -0.351409912109375\n",
      "Iteration: 527 Time for last iteration: -0.3416619300842285\n",
      "Iteration: 528 Time for last iteration: -0.3266592025756836\n",
      "Iteration: 529 Time for last iteration: -0.3055131435394287\n",
      "Iteration: 530 Time for last iteration: -0.33878183364868164\n",
      "Iteration: 531 Time for last iteration: -0.32214999198913574\n",
      "Iteration: 532 Time for last iteration: -0.31711721420288086\n",
      "Iteration: 533 Time for last iteration: -0.3172798156738281\n",
      "Iteration: 534 Time for last iteration: -0.32637596130371094\n",
      "Iteration: 535 Time for last iteration: -0.31771183013916016\n",
      "Iteration: 536 Time for last iteration: -0.3119223117828369\n",
      "Iteration: 537 Time for last iteration: -0.32353711128234863\n",
      "Iteration: 538 Time for last iteration: -0.31791210174560547\n",
      "Iteration: 539 Time for last iteration: -0.32864904403686523\n",
      "Iteration: 540 Time for last iteration: -0.31570005416870117\n",
      "Iteration: 541 Time for last iteration: -0.30911993980407715\n",
      "Iteration: 542 Time for last iteration: -0.31557679176330566\n",
      "Iteration: 543 Time for last iteration: -0.33929014205932617\n",
      "Iteration: 544 Time for last iteration: -0.30351996421813965\n",
      "Iteration: 545 Time for last iteration: -0.3190648555755615\n",
      "Iteration: 546 Time for last iteration: -0.33020687103271484\n",
      "Iteration: 547 Time for last iteration: -0.315654993057251\n",
      "Iteration: 548 Time for last iteration: -0.3129138946533203\n",
      "Iteration: 549 Time for last iteration: -0.31128764152526855\n",
      "Iteration: 550 Time for last iteration: -0.3188939094543457\n",
      "Iteration: 551 Time for last iteration: -0.329409122467041\n",
      "Iteration: 552 Time for last iteration: -0.31680917739868164\n",
      "Iteration: 553 Time for last iteration: -0.32029199600219727\n",
      "Iteration: 554 Time for last iteration: -0.32215189933776855\n",
      "Iteration: 555 Time for last iteration: -0.30427980422973633\n",
      "Iteration: 556 Time for last iteration: -0.30799007415771484\n",
      "Iteration: 557 Time for last iteration: -0.3127317428588867\n",
      "Iteration: 558 Time for last iteration: -0.3062913417816162\n",
      "Iteration: 559 Time for last iteration: -0.30814290046691895\n",
      "Iteration: 560 Time for last iteration: -0.31333303451538086\n",
      "Iteration: 561 Time for last iteration: -0.3066370487213135\n",
      "Iteration: 562 Time for last iteration: -0.3185920715332031\n",
      "Iteration: 563 Time for last iteration: -0.3523447513580322\n",
      "Iteration: 564 Time for last iteration: -0.33226513862609863\n",
      "Iteration: 565 Time for last iteration: -0.32834506034851074\n",
      "Iteration: 566 Time for last iteration: -0.3101050853729248\n",
      "Iteration: 567 Time for last iteration: -0.42410802841186523\n",
      "Iteration: 568 Time for last iteration: -0.3343179225921631\n",
      "Iteration: 569 Time for last iteration: -0.32238268852233887\n",
      "Iteration: 570 Time for last iteration: -0.3272418975830078\n",
      "Iteration: 571 Time for last iteration: -0.31464409828186035\n",
      "Iteration: 572 Time for last iteration: -0.32125115394592285\n",
      "Iteration: 573 Time for last iteration: -0.33365297317504883\n",
      "Iteration: 574 Time for last iteration: -0.3107798099517822\n",
      "Iteration: 575 Time for last iteration: -0.32613396644592285\n",
      "Iteration: 576 Time for last iteration: -0.34931087493896484\n",
      "Iteration: 577 Time for last iteration: -0.33630895614624023\n",
      "Iteration: 578 Time for last iteration: -0.32878780364990234\n",
      "Iteration: 579 Time for last iteration: -0.3012807369232178\n",
      "Iteration: 580 Time for last iteration: -0.35970616340637207\n",
      "Iteration: 581 Time for last iteration: -0.3198080062866211\n",
      "Iteration: 582 Time for last iteration: -0.31046509742736816\n",
      "Iteration: 583 Time for last iteration: -0.2939567565917969\n",
      "Iteration: 584 Time for last iteration: -0.30557703971862793\n",
      "Iteration: 585 Time for last iteration: -0.30344390869140625\n",
      "Iteration: 586 Time for last iteration: -0.29520082473754883\n",
      "Iteration: 587 Time for last iteration: -0.3042948246002197\n",
      "Iteration: 588 Time for last iteration: -0.2993278503417969\n",
      "Iteration: 589 Time for last iteration: -0.30657482147216797\n",
      "Iteration: 590 Time for last iteration: -0.31142687797546387\n",
      "Iteration: 591 Time for last iteration: -0.3138759136199951\n",
      "Iteration: 592 Time for last iteration: -0.29540514945983887\n",
      "Iteration: 593 Time for last iteration: -0.29656076431274414\n",
      "Iteration: 594 Time for last iteration: -0.3064839839935303\n",
      "Iteration: 595 Time for last iteration: -0.30383825302124023\n",
      "Iteration: 596 Time for last iteration: -0.30362820625305176\n",
      "Iteration: 597 Time for last iteration: -0.3011801242828369\n",
      "Iteration: 598 Time for last iteration: -0.3087773323059082\n",
      "Iteration: 599 Time for last iteration: -0.33525729179382324\n",
      "Iteration: 600 Time for last iteration: -0.33328676223754883\n",
      "Iteration: 601 Time for last iteration: -0.323026180267334\n",
      "Iteration: 602 Time for last iteration: -0.31280517578125\n",
      "Iteration: 603 Time for last iteration: -0.311154842376709\n",
      "Iteration: 604 Time for last iteration: -0.32645201683044434\n",
      "Iteration: 605 Time for last iteration: -0.3092160224914551\n",
      "Iteration: 606 Time for last iteration: -0.31018614768981934\n",
      "Iteration: 607 Time for last iteration: -0.3041369915008545\n",
      "Iteration: 608 Time for last iteration: -0.30069398880004883\n",
      "Iteration: 609 Time for last iteration: -0.29992198944091797\n",
      "Iteration: 610 Time for last iteration: -0.29781317710876465\n",
      "Iteration: 611 Time for last iteration: -0.2946162223815918\n",
      "Iteration: 612 Time for last iteration: -0.3001842498779297\n",
      "Iteration: 613 Time for last iteration: -0.2987840175628662\n",
      "Iteration: 614 Time for last iteration: -0.30501580238342285\n",
      "Iteration: 615 Time for last iteration: -0.30482983589172363\n",
      "Iteration: 616 Time for last iteration: -0.2995328903198242\n",
      "Iteration: 617 Time for last iteration: -0.2993779182434082\n",
      "Iteration: 618 Time for last iteration: -0.29947519302368164\n",
      "Iteration: 619 Time for last iteration: -0.30764222145080566\n",
      "Iteration: 620 Time for last iteration: -0.300915002822876\n",
      "Iteration: 621 Time for last iteration: -0.30121517181396484\n",
      "Iteration: 622 Time for last iteration: -0.296741247177124\n",
      "Iteration: 623 Time for last iteration: -0.2985367774963379\n",
      "Iteration: 624 Time for last iteration: -0.3063969612121582\n",
      "Iteration: 625 Time for last iteration: -0.29779601097106934\n",
      "Iteration: 626 Time for last iteration: -0.3076767921447754\n",
      "Iteration: 627 Time for last iteration: -0.3031020164489746\n",
      "Iteration: 628 Time for last iteration: -0.3488290309906006\n",
      "Iteration: 629 Time for last iteration: -0.2920949459075928\n",
      "Iteration: 630 Time for last iteration: -0.29905104637145996\n",
      "Iteration: 631 Time for last iteration: -0.30600595474243164\n",
      "Iteration: 632 Time for last iteration: -0.315187931060791\n",
      "Iteration: 633 Time for last iteration: -0.29647397994995117\n",
      "Iteration: 634 Time for last iteration: -0.3099379539489746\n",
      "Iteration: 635 Time for last iteration: -0.29990601539611816\n",
      "Iteration: 636 Time for last iteration: -0.31398606300354004\n",
      "Iteration: 637 Time for last iteration: -0.3021240234375\n",
      "Iteration: 638 Time for last iteration: -0.29868388175964355\n",
      "Iteration: 639 Time for last iteration: -0.2975039482116699\n",
      "Iteration: 640 Time for last iteration: -0.29946398735046387\n",
      "Iteration: 641 Time for last iteration: -0.30463480949401855\n",
      "Iteration: 642 Time for last iteration: -0.30163097381591797\n",
      "Iteration: 643 Time for last iteration: -0.29947686195373535\n",
      "Iteration: 644 Time for last iteration: -0.301239013671875\n",
      "Iteration: 645 Time for last iteration: -0.2972290515899658\n",
      "Iteration: 646 Time for last iteration: -0.2998220920562744\n",
      "Iteration: 647 Time for last iteration: -0.3013651371002197\n",
      "Iteration: 648 Time for last iteration: -0.3015861511230469\n",
      "Iteration: 649 Time for last iteration: -0.2987701892852783\n",
      "Iteration: 650 Time for last iteration: -0.29592394828796387\n",
      "Iteration: 651 Time for last iteration: -0.3033621311187744\n",
      "Iteration: 652 Time for last iteration: -0.2948470115661621\n",
      "Iteration: 653 Time for last iteration: -0.3030071258544922\n",
      "Iteration: 654 Time for last iteration: -0.31386232376098633\n",
      "Iteration: 655 Time for last iteration: -0.2930319309234619\n",
      "Iteration: 656 Time for last iteration: -0.29790687561035156\n",
      "Iteration: 657 Time for last iteration: -0.2965869903564453\n",
      "Iteration: 658 Time for last iteration: -0.2946171760559082\n",
      "Iteration: 659 Time for last iteration: -0.29808497428894043\n",
      "Iteration: 660 Time for last iteration: -0.302811861038208\n",
      "Iteration: 661 Time for last iteration: -0.29558706283569336\n",
      "Iteration: 662 Time for last iteration: -0.2962973117828369\n",
      "Iteration: 663 Time for last iteration: -0.29712986946105957\n",
      "Iteration: 664 Time for last iteration: -0.2960970401763916\n",
      "Iteration: 665 Time for last iteration: -0.3004899024963379\n",
      "Iteration: 666 Time for last iteration: -0.29855799674987793\n",
      "Iteration: 667 Time for last iteration: -0.2903401851654053\n",
      "Iteration: 668 Time for last iteration: -0.3045938014984131\n",
      "Iteration: 669 Time for last iteration: -0.30110883712768555\n",
      "Iteration: 670 Time for last iteration: -0.33542394638061523\n",
      "Iteration: 671 Time for last iteration: -0.33979201316833496\n",
      "Iteration: 672 Time for last iteration: -0.30351901054382324\n",
      "Iteration: 673 Time for last iteration: -0.2953610420227051\n",
      "Iteration: 674 Time for last iteration: -0.30240297317504883\n",
      "Iteration: 675 Time for last iteration: -0.310992956161499\n",
      "Iteration: 676 Time for last iteration: -0.29610228538513184\n",
      "Iteration: 677 Time for last iteration: -0.29717397689819336\n",
      "Iteration: 678 Time for last iteration: -0.3097727298736572\n",
      "Iteration: 679 Time for last iteration: -0.3855009078979492\n",
      "Iteration: 680 Time for last iteration: -0.3071019649505615\n",
      "Iteration: 681 Time for last iteration: -0.301389217376709\n",
      "Iteration: 682 Time for last iteration: -0.30539798736572266\n",
      "Iteration: 683 Time for last iteration: -0.29949498176574707\n",
      "Iteration: 684 Time for last iteration: -0.31101274490356445\n",
      "Iteration: 685 Time for last iteration: -0.3039820194244385\n",
      "Iteration: 686 Time for last iteration: -0.2969200611114502\n",
      "Iteration: 687 Time for last iteration: -0.3151710033416748\n",
      "Iteration: 688 Time for last iteration: -0.3004448413848877\n",
      "Iteration: 689 Time for last iteration: -0.30613088607788086\n",
      "Iteration: 690 Time for last iteration: -0.29805994033813477\n",
      "Iteration: 691 Time for last iteration: -0.30890703201293945\n",
      "Iteration: 692 Time for last iteration: -0.3116800785064697\n",
      "Iteration: 693 Time for last iteration: -0.29870104789733887\n",
      "Iteration: 694 Time for last iteration: -0.29979586601257324\n",
      "Iteration: 695 Time for last iteration: -0.305772066116333\n",
      "Iteration: 696 Time for last iteration: -0.297990083694458\n",
      "Iteration: 697 Time for last iteration: -0.3071763515472412\n",
      "Iteration: 698 Time for last iteration: -0.2937331199645996\n",
      "Iteration: 699 Time for last iteration: -0.3014647960662842\n",
      "Iteration: 700 Time for last iteration: -0.3168978691101074\n",
      "Iteration: 701 Time for last iteration: -0.3027517795562744\n",
      "Iteration: 702 Time for last iteration: -0.3150489330291748\n",
      "Iteration: 703 Time for last iteration: -0.3122391700744629\n",
      "Iteration: 704 Time for last iteration: -0.29433107376098633\n",
      "Iteration: 705 Time for last iteration: -0.3233819007873535\n",
      "Iteration: 706 Time for last iteration: -0.30575990676879883\n",
      "Iteration: 707 Time for last iteration: -0.3094489574432373\n",
      "Iteration: 708 Time for last iteration: -0.2994551658630371\n",
      "Iteration: 709 Time for last iteration: -0.3011941909790039\n",
      "Iteration: 710 Time for last iteration: -0.3118772506713867\n",
      "Iteration: 711 Time for last iteration: -0.29462575912475586\n",
      "Iteration: 712 Time for last iteration: -0.2942378520965576\n",
      "Iteration: 713 Time for last iteration: -0.31673312187194824\n",
      "Iteration: 714 Time for last iteration: -0.3054180145263672\n",
      "Iteration: 715 Time for last iteration: -0.3049759864807129\n",
      "Iteration: 716 Time for last iteration: -0.3119370937347412\n",
      "Iteration: 717 Time for last iteration: -0.30457377433776855\n",
      "Iteration: 718 Time for last iteration: -0.28971385955810547\n",
      "Iteration: 719 Time for last iteration: -0.3218228816986084\n",
      "Iteration: 720 Time for last iteration: -0.31110215187072754\n",
      "Iteration: 721 Time for last iteration: -0.2994568347930908\n",
      "Iteration: 722 Time for last iteration: -0.29590392112731934\n",
      "Iteration: 723 Time for last iteration: -0.30777907371520996\n",
      "Iteration: 724 Time for last iteration: -0.3287169933319092\n",
      "Iteration: 725 Time for last iteration: -0.28833913803100586\n",
      "Iteration: 726 Time for last iteration: -0.309952974319458\n",
      "Iteration: 727 Time for last iteration: -0.2970590591430664\n",
      "Iteration: 728 Time for last iteration: -0.3014378547668457\n",
      "Iteration: 729 Time for last iteration: -0.30751895904541016\n",
      "Iteration: 730 Time for last iteration: -0.3080558776855469\n",
      "Iteration: 731 Time for last iteration: -0.2865641117095947\n",
      "Iteration: 732 Time for last iteration: -0.29317212104797363\n",
      "Iteration: 733 Time for last iteration: -0.311413049697876\n",
      "Iteration: 734 Time for last iteration: -0.3048398494720459\n",
      "Iteration: 735 Time for last iteration: -0.2958550453186035\n",
      "Iteration: 736 Time for last iteration: -0.32427477836608887\n",
      "Iteration: 737 Time for last iteration: -0.3121669292449951\n",
      "Iteration: 738 Time for last iteration: -0.29810619354248047\n",
      "Iteration: 739 Time for last iteration: -0.291126012802124\n",
      "Iteration: 740 Time for last iteration: -0.2875180244445801\n",
      "Iteration: 741 Time for last iteration: -0.32608771324157715\n",
      "Iteration: 742 Time for last iteration: -0.29358887672424316\n",
      "Iteration: 743 Time for last iteration: -0.3379659652709961\n",
      "Iteration: 744 Time for last iteration: -0.3022620677947998\n",
      "Iteration: 745 Time for last iteration: -0.31487321853637695\n",
      "Iteration: 746 Time for last iteration: -0.2938249111175537\n",
      "Iteration: 747 Time for last iteration: -0.3015167713165283\n",
      "Iteration: 748 Time for last iteration: -0.297745943069458\n",
      "Iteration: 749 Time for last iteration: -0.2895500659942627\n",
      "Iteration: 750 Time for last iteration: -0.3159928321838379\n",
      "Iteration: 751 Time for last iteration: -0.3024907112121582\n",
      "Iteration: 752 Time for last iteration: -0.29448866844177246\n",
      "Iteration: 753 Time for last iteration: -0.31472110748291016\n",
      "Iteration: 754 Time for last iteration: -0.3100008964538574\n",
      "Iteration: 755 Time for last iteration: -0.28984880447387695\n",
      "Iteration: 756 Time for last iteration: -0.2968480587005615\n",
      "Iteration: 757 Time for last iteration: -0.2963082790374756\n",
      "Iteration: 758 Time for last iteration: -0.3151559829711914\n",
      "Iteration: 759 Time for last iteration: -0.3084442615509033\n",
      "Iteration: 760 Time for last iteration: -0.30252623558044434\n",
      "Iteration: 761 Time for last iteration: -0.3110041618347168\n",
      "Iteration: 762 Time for last iteration: -0.2894260883331299\n",
      "Iteration: 763 Time for last iteration: -0.35278987884521484\n",
      "Iteration: 764 Time for last iteration: -0.33081698417663574\n",
      "Iteration: 765 Time for last iteration: -0.35010600090026855\n",
      "Iteration: 766 Time for last iteration: -0.294680118560791\n",
      "Iteration: 767 Time for last iteration: -0.3136019706726074\n",
      "Iteration: 768 Time for last iteration: -0.2981078624725342\n",
      "Iteration: 769 Time for last iteration: -0.2948911190032959\n",
      "Iteration: 770 Time for last iteration: -0.2938852310180664\n",
      "Iteration: 771 Time for last iteration: -0.31165194511413574\n",
      "Iteration: 772 Time for last iteration: -0.30741286277770996\n",
      "Iteration: 773 Time for last iteration: -0.3007988929748535\n",
      "Iteration: 774 Time for last iteration: -0.3172719478607178\n",
      "Iteration: 775 Time for last iteration: -0.30698275566101074\n",
      "Iteration: 776 Time for last iteration: -0.2943260669708252\n",
      "Iteration: 777 Time for last iteration: -0.30881524085998535\n",
      "Iteration: 778 Time for last iteration: -0.30419015884399414\n",
      "Iteration: 779 Time for last iteration: -0.3056509494781494\n",
      "Iteration: 780 Time for last iteration: -0.2925708293914795\n",
      "Iteration: 781 Time for last iteration: -0.314302921295166\n",
      "Iteration: 782 Time for last iteration: -0.2864491939544678\n",
      "Iteration: 783 Time for last iteration: -0.292722225189209\n",
      "Iteration: 784 Time for last iteration: -0.3293330669403076\n",
      "Iteration: 785 Time for last iteration: -0.29406118392944336\n",
      "Iteration: 786 Time for last iteration: -0.281419038772583\n",
      "Iteration: 787 Time for last iteration: -0.29971885681152344\n",
      "Iteration: 788 Time for last iteration: -0.28604888916015625\n",
      "Iteration: 789 Time for last iteration: -0.3041849136352539\n",
      "Iteration: 790 Time for last iteration: -0.29327893257141113\n",
      "Iteration: 791 Time for last iteration: -0.2943730354309082\n",
      "Iteration: 792 Time for last iteration: -0.3154120445251465\n",
      "Iteration: 793 Time for last iteration: -0.2855722904205322\n",
      "Iteration: 794 Time for last iteration: -0.3097357749938965\n",
      "Iteration: 795 Time for last iteration: -0.283505916595459\n",
      "Iteration: 796 Time for last iteration: -0.28905797004699707\n",
      "Iteration: 797 Time for last iteration: -0.2928750514984131\n",
      "Iteration: 798 Time for last iteration: -0.3046591281890869\n",
      "Iteration: 799 Time for last iteration: -0.328125\n",
      "Iteration: 800 Time for last iteration: -0.30359601974487305\n",
      "Iteration: 801 Time for last iteration: -0.31953883171081543\n",
      "Iteration: 802 Time for last iteration: -0.3575003147125244\n",
      "Iteration: 803 Time for last iteration: -0.29470086097717285\n",
      "Iteration: 804 Time for last iteration: -0.30037474632263184\n",
      "Iteration: 805 Time for last iteration: -0.310560941696167\n",
      "Iteration: 806 Time for last iteration: -0.3158409595489502\n",
      "Iteration: 807 Time for last iteration: -0.2910420894622803\n",
      "Iteration: 808 Time for last iteration: -0.28625917434692383\n",
      "Iteration: 809 Time for last iteration: -0.28275609016418457\n",
      "Iteration: 810 Time for last iteration: -0.29733920097351074\n",
      "Iteration: 811 Time for last iteration: -0.297544002532959\n",
      "Iteration: 812 Time for last iteration: -0.28775668144226074\n",
      "Iteration: 813 Time for last iteration: -0.30071496963500977\n",
      "Iteration: 814 Time for last iteration: -0.3083488941192627\n",
      "Iteration: 815 Time for last iteration: -0.29941487312316895\n",
      "Iteration: 816 Time for last iteration: -0.27992796897888184\n",
      "Iteration: 817 Time for last iteration: -0.29398298263549805\n",
      "Iteration: 818 Time for last iteration: -0.3051290512084961\n",
      "Iteration: 819 Time for last iteration: -0.27474308013916016\n",
      "Iteration: 820 Time for last iteration: -0.31058192253112793\n",
      "Iteration: 821 Time for last iteration: -0.294719934463501\n",
      "Iteration: 822 Time for last iteration: -0.2846810817718506\n",
      "Iteration: 823 Time for last iteration: -0.3122098445892334\n",
      "Iteration: 824 Time for last iteration: -0.281141996383667\n",
      "Iteration: 825 Time for last iteration: -0.2913179397583008\n",
      "Iteration: 826 Time for last iteration: -0.2920379638671875\n",
      "Iteration: 827 Time for last iteration: -0.30776238441467285\n",
      "Iteration: 828 Time for last iteration: -0.29674315452575684\n",
      "Iteration: 829 Time for last iteration: -0.30381107330322266\n",
      "Iteration: 830 Time for last iteration: -0.2873349189758301\n",
      "Iteration: 831 Time for last iteration: -0.29418110847473145\n",
      "Iteration: 832 Time for last iteration: -0.2945678234100342\n",
      "Iteration: 833 Time for last iteration: -0.2827780246734619\n",
      "Iteration: 834 Time for last iteration: -0.28908276557922363\n",
      "Iteration: 835 Time for last iteration: -0.3036658763885498\n",
      "Iteration: 836 Time for last iteration: -0.2834339141845703\n",
      "Iteration: 837 Time for last iteration: -0.29584193229675293\n",
      "Iteration: 838 Time for last iteration: -0.3009488582611084\n",
      "Iteration: 839 Time for last iteration: -0.2861969470977783\n",
      "Iteration: 840 Time for last iteration: -0.2921609878540039\n",
      "Iteration: 841 Time for last iteration: -0.29575610160827637\n",
      "Iteration: 842 Time for last iteration: -0.2933359146118164\n",
      "Iteration: 843 Time for last iteration: -0.29219913482666016\n",
      "Iteration: 844 Time for last iteration: -0.3029508590698242\n",
      "Iteration: 845 Time for last iteration: -0.2792789936065674\n",
      "Iteration: 846 Time for last iteration: -0.2946619987487793\n",
      "Iteration: 847 Time for last iteration: -0.2849998474121094\n",
      "Iteration: 848 Time for last iteration: -0.2990138530731201\n",
      "Iteration: 849 Time for last iteration: -0.295651912689209\n",
      "Iteration: 850 Time for last iteration: -0.3116002082824707\n",
      "Iteration: 851 Time for last iteration: -0.2944931983947754\n",
      "Iteration: 852 Time for last iteration: -0.31430697441101074\n",
      "Iteration: 853 Time for last iteration: -0.3046560287475586\n",
      "Iteration: 854 Time for last iteration: -0.2937650680541992\n",
      "Iteration: 855 Time for last iteration: -0.30115699768066406\n",
      "Iteration: 856 Time for last iteration: -0.29959869384765625\n",
      "Iteration: 857 Time for last iteration: -0.2955930233001709\n",
      "Iteration: 858 Time for last iteration: -0.2762749195098877\n",
      "Iteration: 859 Time for last iteration: -0.3079831600189209\n",
      "Iteration: 860 Time for last iteration: -0.30341506004333496\n",
      "Iteration: 861 Time for last iteration: -0.2945101261138916\n",
      "Iteration: 862 Time for last iteration: -0.2823176383972168\n",
      "Iteration: 863 Time for last iteration: -0.28756093978881836\n",
      "Iteration: 864 Time for last iteration: -0.2866501808166504\n",
      "Iteration: 865 Time for last iteration: -0.2771427631378174\n",
      "Iteration: 866 Time for last iteration: -0.29921913146972656\n",
      "Iteration: 867 Time for last iteration: -0.28502416610717773\n",
      "Iteration: 868 Time for last iteration: -0.304624080657959\n",
      "Iteration: 869 Time for last iteration: -0.29856300354003906\n",
      "Iteration: 870 Time for last iteration: -0.2771580219268799\n",
      "Iteration: 871 Time for last iteration: -0.30264925956726074\n",
      "Iteration: 872 Time for last iteration: -0.3041548728942871\n",
      "Iteration: 873 Time for last iteration: -0.3120918273925781\n",
      "Iteration: 874 Time for last iteration: -0.2947211265563965\n",
      "Iteration: 875 Time for last iteration: -0.28046703338623047\n",
      "Iteration: 876 Time for last iteration: -0.309053897857666\n",
      "Iteration: 877 Time for last iteration: -0.28723883628845215\n",
      "Iteration: 878 Time for last iteration: -0.29119420051574707\n",
      "Iteration: 879 Time for last iteration: -0.30025410652160645\n",
      "Iteration: 880 Time for last iteration: -0.3242676258087158\n",
      "Iteration: 881 Time for last iteration: -0.3018350601196289\n",
      "Iteration: 882 Time for last iteration: -0.27550697326660156\n",
      "Iteration: 883 Time for last iteration: -0.31139469146728516\n",
      "Iteration: 884 Time for last iteration: -0.30066919326782227\n",
      "Iteration: 885 Time for last iteration: -0.2933969497680664\n",
      "Iteration: 886 Time for last iteration: -0.3064398765563965\n",
      "Iteration: 887 Time for last iteration: -0.2894589900970459\n",
      "Iteration: 888 Time for last iteration: -0.30142712593078613\n",
      "Iteration: 889 Time for last iteration: -0.26799917221069336\n",
      "Iteration: 890 Time for last iteration: -0.3089437484741211\n",
      "Iteration: 891 Time for last iteration: -0.28753185272216797\n",
      "Iteration: 892 Time for last iteration: -0.271557092666626\n",
      "Iteration: 893 Time for last iteration: -0.3137478828430176\n",
      "Iteration: 894 Time for last iteration: -0.29788804054260254\n",
      "Iteration: 895 Time for last iteration: -0.3033130168914795\n",
      "Iteration: 896 Time for last iteration: -0.2769742012023926\n",
      "Iteration: 897 Time for last iteration: -0.31212902069091797\n",
      "Iteration: 898 Time for last iteration: -0.2619802951812744\n",
      "Iteration: 899 Time for last iteration: -0.29820895195007324\n",
      "Iteration: 900 Time for last iteration: -0.2832372188568115\n",
      "Iteration: 901 Time for last iteration: -0.29279279708862305\n",
      "Iteration: 902 Time for last iteration: -0.2808561325073242\n",
      "Iteration: 903 Time for last iteration: -0.29758501052856445\n",
      "Iteration: 904 Time for last iteration: -0.2999098300933838\n",
      "Iteration: 905 Time for last iteration: -0.2987189292907715\n",
      "Iteration: 906 Time for last iteration: -0.26437807083129883\n",
      "Iteration: 907 Time for last iteration: -0.2921478748321533\n",
      "Iteration: 908 Time for last iteration: -0.28748226165771484\n",
      "Iteration: 909 Time for last iteration: -0.3085169792175293\n",
      "Iteration: 910 Time for last iteration: -0.30701112747192383\n",
      "Iteration: 911 Time for last iteration: -0.34048008918762207\n",
      "Iteration: 912 Time for last iteration: -0.32061123847961426\n",
      "Iteration: 913 Time for last iteration: -0.2765970230102539\n",
      "Iteration: 914 Time for last iteration: -0.30286216735839844\n",
      "Iteration: 915 Time for last iteration: -0.30436110496520996\n",
      "Iteration: 916 Time for last iteration: -0.31213998794555664\n",
      "Iteration: 917 Time for last iteration: -0.3084831237792969\n",
      "Iteration: 918 Time for last iteration: -0.304760217666626\n",
      "Iteration: 919 Time for last iteration: -0.2841489315032959\n",
      "Iteration: 920 Time for last iteration: -0.2995021343231201\n",
      "Iteration: 921 Time for last iteration: -0.28827595710754395\n",
      "Iteration: 922 Time for last iteration: -0.2969670295715332\n",
      "Iteration: 923 Time for last iteration: -0.3092789649963379\n",
      "Iteration: 924 Time for last iteration: -0.292600154876709\n",
      "Iteration: 925 Time for last iteration: -0.3515620231628418\n",
      "Iteration: 926 Time for last iteration: -0.3011760711669922\n",
      "Iteration: 927 Time for last iteration: -0.30285120010375977\n",
      "Iteration: 928 Time for last iteration: -0.302232027053833\n",
      "Iteration: 929 Time for last iteration: -0.28542089462280273\n",
      "Iteration: 930 Time for last iteration: -0.3024413585662842\n",
      "Iteration: 931 Time for last iteration: -0.3075871467590332\n",
      "Iteration: 932 Time for last iteration: -0.30830883979797363\n",
      "Iteration: 933 Time for last iteration: -0.2971158027648926\n",
      "Iteration: 934 Time for last iteration: -0.30750083923339844\n",
      "Iteration: 935 Time for last iteration: -0.2953159809112549\n",
      "Iteration: 936 Time for last iteration: -0.29856395721435547\n",
      "Iteration: 937 Time for last iteration: -0.3099977970123291\n",
      "Iteration: 938 Time for last iteration: -0.30153703689575195\n",
      "Iteration: 939 Time for last iteration: -0.29749608039855957\n",
      "Iteration: 940 Time for last iteration: -0.29825735092163086\n",
      "Iteration: 941 Time for last iteration: -0.27965688705444336\n",
      "Iteration: 942 Time for last iteration: -0.3061213493347168\n",
      "Iteration: 943 Time for last iteration: -0.28222012519836426\n",
      "Iteration: 944 Time for last iteration: -0.2968137264251709\n",
      "Iteration: 945 Time for last iteration: -0.30561208724975586\n",
      "Iteration: 946 Time for last iteration: -0.3214750289916992\n",
      "Iteration: 947 Time for last iteration: -0.275043249130249\n",
      "Iteration: 948 Time for last iteration: -0.30767393112182617\n",
      "Iteration: 949 Time for last iteration: -0.29134106636047363\n",
      "Iteration: 950 Time for last iteration: -0.2902040481567383\n",
      "Iteration: 951 Time for last iteration: -0.2920968532562256\n",
      "Iteration: 952 Time for last iteration: -0.2992279529571533\n",
      "Iteration: 953 Time for last iteration: -0.2975459098815918\n",
      "Iteration: 954 Time for last iteration: -0.3016700744628906\n",
      "Iteration: 955 Time for last iteration: -0.2992539405822754\n",
      "Iteration: 956 Time for last iteration: -0.2813682556152344\n",
      "Iteration: 957 Time for last iteration: -0.3023359775543213\n",
      "Iteration: 958 Time for last iteration: -0.2716209888458252\n",
      "Iteration: 959 Time for last iteration: -0.29377007484436035\n",
      "Iteration: 960 Time for last iteration: -0.2664361000061035\n",
      "Iteration: 961 Time for last iteration: -0.2933049201965332\n",
      "Iteration: 962 Time for last iteration: -0.29962921142578125\n",
      "Iteration: 963 Time for last iteration: -0.30248403549194336\n",
      "Iteration: 964 Time for last iteration: -0.2951371669769287\n",
      "Iteration: 965 Time for last iteration: -0.2846040725708008\n",
      "Iteration: 966 Time for last iteration: -0.2797989845275879\n",
      "Iteration: 967 Time for last iteration: -0.29582691192626953\n",
      "Iteration: 968 Time for last iteration: -0.2942178249359131\n",
      "Iteration: 969 Time for last iteration: -0.30404019355773926\n",
      "Iteration: 970 Time for last iteration: -0.2776148319244385\n",
      "Iteration: 971 Time for last iteration: -0.2849090099334717\n",
      "Iteration: 972 Time for last iteration: -0.3079521656036377\n",
      "Iteration: 973 Time for last iteration: -0.2969028949737549\n",
      "Iteration: 974 Time for last iteration: -0.28838491439819336\n",
      "Iteration: 975 Time for last iteration: -0.3010382652282715\n",
      "Iteration: 976 Time for last iteration: -0.27543210983276367\n",
      "Iteration: 977 Time for last iteration: -0.30643200874328613\n",
      "Iteration: 978 Time for last iteration: -0.2848320007324219\n",
      "Iteration: 979 Time for last iteration: -0.29410696029663086\n",
      "Iteration: 980 Time for last iteration: -0.30098700523376465\n",
      "Iteration: 981 Time for last iteration: -0.28978586196899414\n",
      "Iteration: 982 Time for last iteration: -0.29687976837158203\n",
      "Iteration: 983 Time for last iteration: -0.30909013748168945\n",
      "Iteration: 984 Time for last iteration: -0.2790501117706299\n",
      "Iteration: 985 Time for last iteration: -0.31786274909973145\n",
      "Iteration: 986 Time for last iteration: -0.28733181953430176\n",
      "Iteration: 987 Time for last iteration: -0.3117649555206299\n",
      "Iteration: 988 Time for last iteration: -0.28395795822143555\n",
      "Iteration: 989 Time for last iteration: -0.2784440517425537\n",
      "Iteration: 990 Time for last iteration: -0.28397393226623535\n",
      "Iteration: 991 Time for last iteration: -0.29791903495788574\n",
      "Iteration: 992 Time for last iteration: -0.2793717384338379\n",
      "Iteration: 993 Time for last iteration: -0.2655141353607178\n",
      "Iteration: 994 Time for last iteration: -0.29055023193359375\n",
      "Iteration: 995 Time for last iteration: -0.29334497451782227\n",
      "Iteration: 996 Time for last iteration: -0.2912421226501465\n",
      "Iteration: 997 Time for last iteration: -0.2854189872741699\n",
      "Iteration: 998 Time for last iteration: -0.27968406677246094\n",
      "Iteration: 999 Time for last iteration: -0.2704470157623291\n",
      "Iteration: 1000 Time for last iteration: -0.2771940231323242\n",
      "Iteration: 1001 Time for last iteration: -0.3010990619659424\n",
      "Iteration: 1002 Time for last iteration: -0.28342103958129883\n",
      "Iteration: 1003 Time for last iteration: -0.3230421543121338\n",
      "Iteration: 1004 Time for last iteration: -0.32950925827026367\n",
      "Iteration: 1005 Time for last iteration: -0.3571739196777344\n",
      "Iteration: 1006 Time for last iteration: -0.303236722946167\n",
      "Iteration: 1007 Time for last iteration: -0.2936282157897949\n",
      "Iteration: 1008 Time for last iteration: -0.3033030033111572\n",
      "Iteration: 1009 Time for last iteration: -0.2695322036743164\n",
      "Iteration: 1010 Time for last iteration: -0.2941172122955322\n",
      "Iteration: 1011 Time for last iteration: -0.276792049407959\n",
      "Iteration: 1012 Time for last iteration: -0.274838924407959\n",
      "Iteration: 1013 Time for last iteration: -0.26990318298339844\n",
      "Iteration: 1014 Time for last iteration: -0.3037567138671875\n",
      "Iteration: 1015 Time for last iteration: -0.30365705490112305\n",
      "Iteration: 1016 Time for last iteration: -0.2755770683288574\n",
      "Iteration: 1017 Time for last iteration: -0.28429484367370605\n",
      "Iteration: 1018 Time for last iteration: -0.28635597229003906\n",
      "Iteration: 1019 Time for last iteration: -0.30507898330688477\n",
      "Iteration: 1020 Time for last iteration: -0.2940480709075928\n",
      "Iteration: 1021 Time for last iteration: -0.3053321838378906\n",
      "Iteration: 1022 Time for last iteration: -0.3112010955810547\n",
      "Iteration: 1023 Time for last iteration: -0.2859220504760742\n",
      "Iteration: 1024 Time for last iteration: -0.29018115997314453\n",
      "Iteration: 1025 Time for last iteration: -0.2773611545562744\n",
      "Iteration: 1026 Time for last iteration: -0.2727839946746826\n",
      "Iteration: 1027 Time for last iteration: -0.28679609298706055\n",
      "Iteration: 1028 Time for last iteration: -0.2845149040222168\n",
      "Iteration: 1029 Time for last iteration: -0.30877113342285156\n",
      "Iteration: 1030 Time for last iteration: -0.2698979377746582\n",
      "Iteration: 1031 Time for last iteration: -0.2983381748199463\n",
      "Iteration: 1032 Time for last iteration: -0.2660391330718994\n",
      "Iteration: 1033 Time for last iteration: -0.28505802154541016\n",
      "Iteration: 1034 Time for last iteration: -0.28157591819763184\n",
      "Iteration: 1035 Time for last iteration: -0.2909212112426758\n",
      "Iteration: 1036 Time for last iteration: -0.2965970039367676\n",
      "Iteration: 1037 Time for last iteration: -0.3074948787689209\n",
      "Iteration: 1038 Time for last iteration: -0.30059194564819336\n",
      "Iteration: 1039 Time for last iteration: -0.30120301246643066\n",
      "Iteration: 1040 Time for last iteration: -0.28318285942077637\n",
      "Iteration: 1041 Time for last iteration: -0.27072811126708984\n",
      "Iteration: 1042 Time for last iteration: -0.31964898109436035\n",
      "Iteration: 1043 Time for last iteration: -0.28448486328125\n",
      "Iteration: 1044 Time for last iteration: -0.28169870376586914\n",
      "Iteration: 1045 Time for last iteration: -0.272601842880249\n",
      "Iteration: 1046 Time for last iteration: -0.29676270484924316\n",
      "Iteration: 1047 Time for last iteration: -0.28197407722473145\n",
      "Iteration: 1048 Time for last iteration: -0.3047196865081787\n",
      "Iteration: 1049 Time for last iteration: -0.3006160259246826\n",
      "Iteration: 1050 Time for last iteration: -0.27868008613586426\n",
      "Iteration: 1051 Time for last iteration: -0.2707068920135498\n",
      "Iteration: 1052 Time for last iteration: -0.29533886909484863\n",
      "Iteration: 1053 Time for last iteration: -0.30979299545288086\n",
      "Iteration: 1054 Time for last iteration: -0.28159523010253906\n",
      "Iteration: 1055 Time for last iteration: -0.29361891746520996\n",
      "Iteration: 1056 Time for last iteration: -0.27715301513671875\n",
      "Iteration: 1057 Time for last iteration: -0.2956521511077881\n",
      "Iteration: 1058 Time for last iteration: -0.2783949375152588\n",
      "Iteration: 1059 Time for last iteration: -0.29578113555908203\n",
      "Iteration: 1060 Time for last iteration: -0.3020491600036621\n",
      "Iteration: 1061 Time for last iteration: -0.28311920166015625\n",
      "Iteration: 1062 Time for last iteration: -0.3126869201660156\n",
      "Iteration: 1063 Time for last iteration: -0.2871558666229248\n",
      "Iteration: 1064 Time for last iteration: -0.27715206146240234\n",
      "Iteration: 1065 Time for last iteration: -0.2634577751159668\n",
      "Iteration: 1066 Time for last iteration: -0.27817296981811523\n",
      "Iteration: 1067 Time for last iteration: -0.30315113067626953\n",
      "Iteration: 1068 Time for last iteration: -0.28438305854797363\n",
      "Iteration: 1069 Time for last iteration: -0.2954390048980713\n",
      "Iteration: 1070 Time for last iteration: -0.2742159366607666\n",
      "Iteration: 1071 Time for last iteration: -0.2798628807067871\n",
      "Iteration: 1072 Time for last iteration: -0.2748260498046875\n",
      "Iteration: 1073 Time for last iteration: -0.3053569793701172\n",
      "Iteration: 1074 Time for last iteration: -0.2723851203918457\n",
      "Iteration: 1075 Time for last iteration: -0.28985023498535156\n",
      "Iteration: 1076 Time for last iteration: -0.2625439167022705\n",
      "Iteration: 1077 Time for last iteration: -0.2938051223754883\n",
      "Iteration: 1078 Time for last iteration: -0.31746816635131836\n",
      "Iteration: 1079 Time for last iteration: -0.30877113342285156\n",
      "Iteration: 1080 Time for last iteration: -0.3052380084991455\n",
      "Iteration: 1081 Time for last iteration: -0.317136287689209\n",
      "Iteration: 1082 Time for last iteration: -0.28723812103271484\n",
      "Iteration: 1083 Time for last iteration: -0.3096609115600586\n",
      "Iteration: 1084 Time for last iteration: -0.29093194007873535\n",
      "Iteration: 1085 Time for last iteration: -0.31029391288757324\n",
      "Iteration: 1086 Time for last iteration: -0.27353620529174805\n",
      "Iteration: 1087 Time for last iteration: -0.2644498348236084\n",
      "Iteration: 1088 Time for last iteration: -0.29595208168029785\n",
      "Iteration: 1089 Time for last iteration: -0.2888178825378418\n",
      "Iteration: 1090 Time for last iteration: -0.2781047821044922\n",
      "Iteration: 1091 Time for last iteration: -0.2825441360473633\n",
      "Iteration: 1092 Time for last iteration: -0.3103659152984619\n",
      "Iteration: 1093 Time for last iteration: -0.2704136371612549\n",
      "Iteration: 1094 Time for last iteration: -0.28707194328308105\n",
      "Iteration: 1095 Time for last iteration: -0.27407193183898926\n",
      "Iteration: 1096 Time for last iteration: -0.27013206481933594\n",
      "Iteration: 1097 Time for last iteration: -0.29661107063293457\n",
      "Iteration: 1098 Time for last iteration: -0.28319787979125977\n",
      "Iteration: 1099 Time for last iteration: -0.27228593826293945\n",
      "Iteration: 1100 Time for last iteration: -0.29219603538513184\n",
      "Iteration: 1101 Time for last iteration: -0.30670905113220215\n",
      "Iteration: 1102 Time for last iteration: -0.27787208557128906\n",
      "Iteration: 1103 Time for last iteration: -0.26653313636779785\n",
      "Iteration: 1104 Time for last iteration: -0.2927870750427246\n",
      "Iteration: 1105 Time for last iteration: -0.278501033782959\n",
      "Iteration: 1106 Time for last iteration: -0.3034970760345459\n",
      "Iteration: 1107 Time for last iteration: -0.27593493461608887\n",
      "Iteration: 1108 Time for last iteration: -0.3133432865142822\n",
      "Iteration: 1109 Time for last iteration: -0.2977750301361084\n",
      "Iteration: 1110 Time for last iteration: -0.3082270622253418\n",
      "Iteration: 1111 Time for last iteration: -0.30885791778564453\n",
      "Iteration: 1112 Time for last iteration: -0.29654598236083984\n",
      "Iteration: 1113 Time for last iteration: -0.28036999702453613\n",
      "Iteration: 1114 Time for last iteration: -0.2791459560394287\n",
      "Iteration: 1115 Time for last iteration: -0.27544069290161133\n",
      "Iteration: 1116 Time for last iteration: -0.3040578365325928\n",
      "Iteration: 1117 Time for last iteration: -0.3076331615447998\n",
      "Iteration: 1118 Time for last iteration: -0.3017573356628418\n",
      "Iteration: 1119 Time for last iteration: -0.29030418395996094\n",
      "Iteration: 1120 Time for last iteration: -0.3080761432647705\n",
      "Iteration: 1121 Time for last iteration: -0.2816011905670166\n",
      "Iteration: 1122 Time for last iteration: -0.30001091957092285\n",
      "Iteration: 1123 Time for last iteration: -0.31969308853149414\n",
      "Iteration: 1124 Time for last iteration: -0.29346680641174316\n",
      "Iteration: 1125 Time for last iteration: -0.2816638946533203\n",
      "Iteration: 1126 Time for last iteration: -0.28034090995788574\n",
      "Iteration: 1127 Time for last iteration: -0.29645204544067383\n",
      "Iteration: 1128 Time for last iteration: -0.27073216438293457\n",
      "Iteration: 1129 Time for last iteration: -0.31395602226257324\n",
      "Iteration: 1130 Time for last iteration: -0.3321187496185303\n",
      "Iteration: 1131 Time for last iteration: -0.2926790714263916\n",
      "Iteration: 1132 Time for last iteration: -0.29386091232299805\n",
      "Iteration: 1133 Time for last iteration: -0.28948307037353516\n",
      "Iteration: 1134 Time for last iteration: -0.3069722652435303\n",
      "Iteration: 1135 Time for last iteration: -0.2931640148162842\n",
      "Iteration: 1136 Time for last iteration: -0.29970788955688477\n",
      "Iteration: 1137 Time for last iteration: -0.308549165725708\n",
      "Iteration: 1138 Time for last iteration: -0.28850603103637695\n",
      "Iteration: 1139 Time for last iteration: -0.27973198890686035\n",
      "Iteration: 1140 Time for last iteration: -0.31023526191711426\n",
      "Iteration: 1141 Time for last iteration: -0.29505014419555664\n",
      "Iteration: 1142 Time for last iteration: -0.2977778911590576\n",
      "Iteration: 1143 Time for last iteration: -0.3092498779296875\n",
      "Iteration: 1144 Time for last iteration: -0.2804269790649414\n",
      "Iteration: 1145 Time for last iteration: -0.2848351001739502\n",
      "Iteration: 1146 Time for last iteration: -0.34040284156799316\n",
      "Iteration: 1147 Time for last iteration: -0.3168652057647705\n",
      "Iteration: 1148 Time for last iteration: -0.28057217597961426\n",
      "Iteration: 1149 Time for last iteration: -0.30613279342651367\n",
      "Iteration: 1150 Time for last iteration: -0.29772520065307617\n",
      "Iteration: 1151 Time for last iteration: -0.2812809944152832\n",
      "Iteration: 1152 Time for last iteration: -0.30574703216552734\n",
      "Iteration: 1153 Time for last iteration: -0.28249311447143555\n",
      "Iteration: 1154 Time for last iteration: -0.28237104415893555\n",
      "Iteration: 1155 Time for last iteration: -0.31366705894470215\n",
      "Iteration: 1156 Time for last iteration: -0.3130302429199219\n",
      "Iteration: 1157 Time for last iteration: -0.2999300956726074\n",
      "Iteration: 1158 Time for last iteration: -0.2820589542388916\n",
      "Iteration: 1159 Time for last iteration: -0.27408599853515625\n",
      "Iteration: 1160 Time for last iteration: -0.26899099349975586\n",
      "Iteration: 1161 Time for last iteration: -0.30128908157348633\n",
      "Iteration: 1162 Time for last iteration: -0.2949361801147461\n",
      "Iteration: 1163 Time for last iteration: -0.2986280918121338\n",
      "Iteration: 1164 Time for last iteration: -0.27824997901916504\n",
      "Iteration: 1165 Time for last iteration: -0.3076009750366211\n",
      "Iteration: 1166 Time for last iteration: -0.2737860679626465\n",
      "Iteration: 1167 Time for last iteration: -0.2675027847290039\n",
      "Iteration: 1168 Time for last iteration: -0.30437397956848145\n",
      "Iteration: 1169 Time for last iteration: -0.3035881519317627\n",
      "Iteration: 1170 Time for last iteration: -0.29117894172668457\n",
      "Iteration: 1171 Time for last iteration: -0.29346799850463867\n",
      "Iteration: 1172 Time for last iteration: -0.28345799446105957\n",
      "Iteration: 1173 Time for last iteration: -0.30855584144592285\n",
      "Iteration: 1174 Time for last iteration: -0.3011939525604248\n",
      "Iteration: 1175 Time for last iteration: -0.30924415588378906\n",
      "Iteration: 1176 Time for last iteration: -0.2826881408691406\n",
      "Iteration: 1177 Time for last iteration: -0.2913978099822998\n",
      "Iteration: 1178 Time for last iteration: -0.2807891368865967\n",
      "Iteration: 1179 Time for last iteration: -0.2672557830810547\n",
      "Iteration: 1180 Time for last iteration: -0.3425180912017822\n",
      "Iteration: 1181 Time for last iteration: -0.32759690284729004\n",
      "Iteration: 1182 Time for last iteration: -0.27689504623413086\n",
      "Iteration: 1183 Time for last iteration: -0.27781105041503906\n",
      "Iteration: 1184 Time for last iteration: -0.3074469566345215\n",
      "Iteration: 1185 Time for last iteration: -0.30593204498291016\n",
      "Iteration: 1186 Time for last iteration: -0.29197096824645996\n",
      "Iteration: 1187 Time for last iteration: -0.2759580612182617\n",
      "Iteration: 1188 Time for last iteration: -0.30145812034606934\n",
      "Iteration: 1189 Time for last iteration: -0.2897520065307617\n"
     ]
    }
   ],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "\n",
    "\n",
    "class IterationInfoCallback(TrainingCallback):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        print('Iteration:', epoch, 'Time for last iteration:', self.start_time - time.time())\n",
    "        self.start_time = time.time()\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "xgb_model_all_train = xgb_model.fit(feat_xgb_train, target_all_train, callbacks=[IterationInfoCallback()])\n",
    "xgb_predict_test = xgb_model_all_train.predict(feat_xgb_test)\n",
    "xgb_predict_train = xgb_model_all_train.predict(feat_xgb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "299be36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM</td>\n",
       "      <td>3.176235</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.996797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM</td>\n",
       "      <td>6.123915</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.985995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная XGB</td>\n",
       "      <td>3.847216</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.997486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая XGB</td>\n",
       "      <td>6.143893</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.984871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Выборка       MAE      MAPE        R2\n",
       "0  тренировочная LGBM   3.176235  0.006670  0.996797\n",
       "1       тестовая LGBM   6.123915  0.014347  0.985995\n",
       "0   тренировочная XGB   3.847216  0.008094  0.997486\n",
       "1        тестовая XGB   6.143893  0.014411  0.984871"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, xgb_predict_train )\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, xgb_predict_test )\n",
    "\n",
    "results = pd.concat([results,\n",
    "pd.DataFrame([[f'тренировочная XGB {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая XGB {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list_cat = ['year_5', 'temp_1', 'clear_16', 'has_rain_probability_19', 'year_19', 'year_20', 'N_14', 'has_rain_probability_12', 'E_4', 'clear_15', 'windy_20', 'year_12', 'has_rain_probability_17', 'year_16', 'year_4', 'rainy_16', 'has_rain_probability_11', 'clear_20', 'clear_14', 'has_rain_probability_8', 'E_9', 'E_3', 'E_15', 'windy_21', 'N_12', 'year_3', 'N_18', 'has_rain_probability_18', 'clear_7', 'WW_15', 'has_rain_probability_21', 'N_10', 'holidays_15', 'E_21', 'S_15', 'N_13', 'windy_14', 'E_10', 'S_9', 'E_5', 'WW_12', 'N_19', 'WW_14', 'WW_21', 'S_8', 'N_7', 'windy_19', 'has_rain_probability_15', 'S_14', 'E_18', 'WW_23', 'WW_13', 'year_6', 'S_12', 'clear_18', 'has_rain_probability_14', 'W_8', 'S_21', 'WW_20', 'windy_13', 'clear_8', 'rainy_17', 'WW_18', 'N_8', 'has_rain_probability_10', 'S_13', 'year_13', 'rainy_18', 'W_21', 'rainy_15', 'E_19', 'N_11', 'N_9', 'year_21', 'W_6', 'E_8', 'S_22', 'S_17', 'WW_22', 'clear_6', 'S_3', 'year_17', 'WW_17', 'clear_19', 'W_15', 'W_11', 'WW_16', 'year_22', 'WW_8', 'WW_6', 'year_18', 'has_rain_probability_20', 'WW_9', 'rainy_11', 'year_7', 'rainy_12', 'cloudy_20', 'E_2', 'W_12', 'W_13', 'W_4']\n",
    "#drop_list_cat_2 = ['has_rain_probability_5', 'has_rain_probability', 'has_rain_probability_1', 'E_12', 'has_rain_probability_6', 'has_rain_probability_13', 'year_11', 'clear_4', 'N_5', 'windy_15', 'clear_21', 'has_rain_probability_9', 'N_17', 'WW_7', 'W_9', 'clear_12', 'cloudy_16', 'windy_5', 'E_22', 'E_16', 'W_10', 'E', 'N_6', 'N_2', 'E_6', 'N_3', 'clear_17', 'has_rain_probability_22', 'S_5', 'rainy_14', 'clear_13', 'N_4', 'temp_5', 'W_22', 'target_5', 'has_rain_probability_7', 'windy_8', 'S_11', 'N_16', 'W', 'W_19', 'E_11', 'S_10', 'year_8', 'windy_22', 'clear_3', 'E_20', 'W_1', 'cloudy_22', 'clear_22', 'cloudy_21', 'E_23', 'Td_3', 'cloudy_18', 'has_rain_probability_16', 'windy_18', 'WW_10', 'Td_4', 'W_16', 'E_14', 'W_23', 'windy_17', 'WW_19', 'WW_11', 'year_15', 'W_7', 'rainy_8', 'S_7', 'windy_16']\n",
    "drop_list_main = ['preholidays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year_5',\n",
       " 'temp_1',\n",
       " 'clear_16',\n",
       " 'has_rain_probability_19',\n",
       " 'year_19',\n",
       " 'year_20',\n",
       " 'N_14',\n",
       " 'has_rain_probability_12',\n",
       " 'E_4',\n",
       " 'clear_15',\n",
       " 'windy_20',\n",
       " 'year_12',\n",
       " 'has_rain_probability_17',\n",
       " 'year_16',\n",
       " 'year_4',\n",
       " 'rainy_16',\n",
       " 'has_rain_probability_11',\n",
       " 'clear_20',\n",
       " 'clear_14',\n",
       " 'has_rain_probability_8',\n",
       " 'E_9',\n",
       " 'E_3',\n",
       " 'E_15',\n",
       " 'windy_21',\n",
       " 'N_12',\n",
       " 'year_3',\n",
       " 'N_18',\n",
       " 'has_rain_probability_18',\n",
       " 'clear_7',\n",
       " 'WW_15',\n",
       " 'has_rain_probability_21',\n",
       " 'N_10',\n",
       " 'holidays_15',\n",
       " 'E_21',\n",
       " 'S_15',\n",
       " 'N_13',\n",
       " 'windy_14',\n",
       " 'E_10',\n",
       " 'S_9',\n",
       " 'E_5',\n",
       " 'WW_12',\n",
       " 'N_19',\n",
       " 'WW_14',\n",
       " 'WW_21',\n",
       " 'S_8',\n",
       " 'N_7',\n",
       " 'windy_19',\n",
       " 'has_rain_probability_15',\n",
       " 'S_14',\n",
       " 'E_18',\n",
       " 'WW_23',\n",
       " 'WW_13',\n",
       " 'year_6',\n",
       " 'S_12',\n",
       " 'clear_18',\n",
       " 'has_rain_probability_14',\n",
       " 'W_8',\n",
       " 'S_21',\n",
       " 'WW_20',\n",
       " 'windy_13',\n",
       " 'clear_8',\n",
       " 'rainy_17',\n",
       " 'WW_18',\n",
       " 'N_8',\n",
       " 'has_rain_probability_10',\n",
       " 'S_13',\n",
       " 'year_13',\n",
       " 'rainy_18',\n",
       " 'W_21',\n",
       " 'rainy_15',\n",
       " 'E_19',\n",
       " 'N_11',\n",
       " 'N_9',\n",
       " 'year_21',\n",
       " 'W_6',\n",
       " 'E_8',\n",
       " 'S_22',\n",
       " 'S_17',\n",
       " 'WW_22',\n",
       " 'clear_6',\n",
       " 'S_3',\n",
       " 'year_17',\n",
       " 'WW_17',\n",
       " 'clear_19',\n",
       " 'W_15',\n",
       " 'W_11',\n",
       " 'WW_16',\n",
       " 'year_22',\n",
       " 'WW_8',\n",
       " 'WW_6',\n",
       " 'year_18',\n",
       " 'has_rain_probability_20',\n",
       " 'WW_9',\n",
       " 'rainy_11',\n",
       " 'year_7',\n",
       " 'rainy_12',\n",
       " 'cloudy_20',\n",
       " 'E_2',\n",
       " 'W_12',\n",
       " 'W_13',\n",
       " 'W_4',\n",
       " 'preholidays',\n",
       " 'preholidays_1',\n",
       " 'preholidays_2',\n",
       " 'preholidays_3',\n",
       " 'preholidays_4',\n",
       " 'preholidays_5',\n",
       " 'preholidays_6',\n",
       " 'preholidays_7',\n",
       " 'preholidays_8',\n",
       " 'preholidays_9',\n",
       " 'preholidays_10',\n",
       " 'preholidays_11',\n",
       " 'preholidays_12',\n",
       " 'preholidays_13',\n",
       " 'preholidays_14',\n",
       " 'preholidays_15',\n",
       " 'preholidays_16',\n",
       " 'preholidays_17',\n",
       " 'preholidays_18',\n",
       " 'preholidays_19',\n",
       " 'preholidays_20',\n",
       " 'preholidays_21',\n",
       " 'preholidays_22',\n",
       " 'preholidays_23']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_list_cat = drop_list_cat + drop_list_main + preholidays #+ drop_list_cat_2\n",
    "\n",
    "drop_list_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cat_test =  features_open_test.drop(columns=drop_list_cat)\n",
    "feat_cat_train = features_all_train.drop(columns=drop_list_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bf063a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 100.1330132\ttotal: 82.2ms\tremaining: 31m 31s\n",
      "1:\tlearn: 98.8216133\ttotal: 107ms\tremaining: 20m 32s\n",
      "2:\tlearn: 97.5124716\ttotal: 131ms\tremaining: 16m 47s\n",
      "3:\tlearn: 96.2239934\ttotal: 155ms\tremaining: 14m 48s\n",
      "4:\tlearn: 94.9620050\ttotal: 180ms\tremaining: 13m 47s\n",
      "5:\tlearn: 93.7293400\ttotal: 204ms\tremaining: 13m\n",
      "6:\tlearn: 92.4949322\ttotal: 228ms\tremaining: 12m 28s\n",
      "7:\tlearn: 91.2929641\ttotal: 253ms\tremaining: 12m 8s\n",
      "8:\tlearn: 90.0725597\ttotal: 282ms\tremaining: 11m 59s\n",
      "9:\tlearn: 88.8928864\ttotal: 305ms\tremaining: 11m 40s\n",
      "10:\tlearn: 87.7333891\ttotal: 328ms\tremaining: 11m 26s\n",
      "11:\tlearn: 86.6028491\ttotal: 356ms\tremaining: 11m 21s\n",
      "12:\tlearn: 85.4649452\ttotal: 379ms\tremaining: 11m 9s\n",
      "13:\tlearn: 84.3530342\ttotal: 402ms\tremaining: 11m\n",
      "14:\tlearn: 83.2683863\ttotal: 427ms\tremaining: 10m 54s\n",
      "15:\tlearn: 82.1820219\ttotal: 453ms\tremaining: 10m 51s\n",
      "16:\tlearn: 81.1426084\ttotal: 476ms\tremaining: 10m 42s\n",
      "17:\tlearn: 80.0851611\ttotal: 498ms\tremaining: 10m 35s\n",
      "18:\tlearn: 79.0395376\ttotal: 521ms\tremaining: 10m 30s\n",
      "19:\tlearn: 77.9983373\ttotal: 546ms\tremaining: 10m 27s\n",
      "20:\tlearn: 76.9978993\ttotal: 567ms\tremaining: 10m 20s\n",
      "21:\tlearn: 76.0145731\ttotal: 591ms\tremaining: 10m 16s\n",
      "22:\tlearn: 75.0551253\ttotal: 613ms\tremaining: 10m 12s\n",
      "23:\tlearn: 74.1144300\ttotal: 640ms\tremaining: 10m 12s\n",
      "24:\tlearn: 73.1568446\ttotal: 662ms\tremaining: 10m 8s\n",
      "25:\tlearn: 72.2009310\ttotal: 684ms\tremaining: 10m 4s\n",
      "26:\tlearn: 71.2636868\ttotal: 710ms\tremaining: 10m 4s\n",
      "27:\tlearn: 70.3477115\ttotal: 735ms\tremaining: 10m 2s\n",
      "28:\tlearn: 69.4514725\ttotal: 757ms\tremaining: 9m 59s\n",
      "29:\tlearn: 68.5872679\ttotal: 779ms\tremaining: 9m 56s\n",
      "30:\tlearn: 67.7029925\ttotal: 806ms\tremaining: 9m 57s\n",
      "31:\tlearn: 66.8521594\ttotal: 828ms\tremaining: 9m 54s\n",
      "32:\tlearn: 65.9909344\ttotal: 852ms\tremaining: 9m 53s\n",
      "33:\tlearn: 65.1668127\ttotal: 879ms\tremaining: 9m 53s\n",
      "34:\tlearn: 64.3466838\ttotal: 901ms\tremaining: 9m 51s\n",
      "35:\tlearn: 63.5518430\ttotal: 923ms\tremaining: 9m 48s\n",
      "36:\tlearn: 62.7616290\ttotal: 949ms\tremaining: 9m 48s\n",
      "37:\tlearn: 61.9822155\ttotal: 972ms\tremaining: 9m 47s\n",
      "38:\tlearn: 61.2097357\ttotal: 996ms\tremaining: 9m 46s\n",
      "39:\tlearn: 60.4710968\ttotal: 1.02s\tremaining: 9m 44s\n",
      "40:\tlearn: 59.7220187\ttotal: 1.04s\tremaining: 9m 45s\n",
      "41:\tlearn: 59.0003195\ttotal: 1.07s\tremaining: 9m 44s\n",
      "42:\tlearn: 58.2668002\ttotal: 1.09s\tremaining: 9m 42s\n",
      "43:\tlearn: 57.5478749\ttotal: 1.11s\tremaining: 9m 41s\n",
      "44:\tlearn: 56.8608048\ttotal: 1.14s\tremaining: 9m 41s\n",
      "45:\tlearn: 56.1726791\ttotal: 1.16s\tremaining: 9m 40s\n",
      "46:\tlearn: 55.4672393\ttotal: 1.19s\tremaining: 9m 39s\n",
      "47:\tlearn: 54.7998266\ttotal: 1.21s\tremaining: 9m 40s\n",
      "48:\tlearn: 54.1286548\ttotal: 1.24s\tremaining: 9m 38s\n",
      "49:\tlearn: 53.4859001\ttotal: 1.26s\tremaining: 9m 37s\n",
      "50:\tlearn: 52.8316186\ttotal: 1.28s\tremaining: 9m 36s\n",
      "51:\tlearn: 52.1904784\ttotal: 1.3s\tremaining: 9m 36s\n",
      "52:\tlearn: 51.5806048\ttotal: 1.33s\tremaining: 9m 35s\n",
      "53:\tlearn: 50.9469976\ttotal: 1.35s\tremaining: 9m 34s\n",
      "54:\tlearn: 50.3318625\ttotal: 1.38s\tremaining: 9m 34s\n",
      "55:\tlearn: 49.7222282\ttotal: 1.4s\tremaining: 9m 34s\n",
      "56:\tlearn: 49.1525028\ttotal: 1.42s\tremaining: 9m 32s\n",
      "57:\tlearn: 48.5802018\ttotal: 1.44s\tremaining: 9m 31s\n",
      "58:\tlearn: 48.0060364\ttotal: 1.47s\tremaining: 9m 32s\n",
      "59:\tlearn: 47.4450530\ttotal: 1.49s\tremaining: 9m 31s\n",
      "60:\tlearn: 46.8759977\ttotal: 1.52s\tremaining: 9m 30s\n",
      "61:\tlearn: 46.3467697\ttotal: 1.54s\tremaining: 9m 30s\n",
      "62:\tlearn: 45.8101790\ttotal: 1.57s\tremaining: 9m 31s\n",
      "63:\tlearn: 45.2877876\ttotal: 1.59s\tremaining: 9m 29s\n",
      "64:\tlearn: 44.7551532\ttotal: 1.61s\tremaining: 9m 28s\n",
      "65:\tlearn: 44.2286118\ttotal: 1.63s\tremaining: 9m 27s\n",
      "66:\tlearn: 43.7335942\ttotal: 1.66s\tremaining: 9m 28s\n",
      "67:\tlearn: 43.2427643\ttotal: 1.68s\tremaining: 9m 27s\n",
      "68:\tlearn: 42.7599325\ttotal: 1.7s\tremaining: 9m 26s\n",
      "69:\tlearn: 42.2606698\ttotal: 1.73s\tremaining: 9m 25s\n",
      "70:\tlearn: 41.7992168\ttotal: 1.75s\tremaining: 9m 26s\n",
      "71:\tlearn: 41.3179907\ttotal: 1.77s\tremaining: 9m 25s\n",
      "72:\tlearn: 40.8544846\ttotal: 1.8s\tremaining: 9m 24s\n",
      "73:\tlearn: 40.3955463\ttotal: 1.82s\tremaining: 9m 23s\n",
      "74:\tlearn: 39.9454535\ttotal: 1.85s\tremaining: 9m 24s\n",
      "75:\tlearn: 39.5086022\ttotal: 1.87s\tremaining: 9m 23s\n",
      "76:\tlearn: 39.0710026\ttotal: 1.89s\tremaining: 9m 22s\n",
      "77:\tlearn: 38.6394638\ttotal: 1.91s\tremaining: 9m 21s\n",
      "78:\tlearn: 38.2157570\ttotal: 1.94s\tremaining: 9m 22s\n",
      "79:\tlearn: 37.7904788\ttotal: 1.96s\tremaining: 9m 21s\n",
      "80:\tlearn: 37.3728737\ttotal: 1.98s\tremaining: 9m 20s\n",
      "81:\tlearn: 36.9763875\ttotal: 2s\tremaining: 9m 20s\n",
      "82:\tlearn: 36.5817783\ttotal: 2.03s\tremaining: 9m 21s\n",
      "83:\tlearn: 36.1859181\ttotal: 2.06s\tremaining: 9m 20s\n",
      "84:\tlearn: 35.7951944\ttotal: 2.08s\tremaining: 9m 19s\n",
      "85:\tlearn: 35.4177281\ttotal: 2.1s\tremaining: 9m 19s\n",
      "86:\tlearn: 35.0287691\ttotal: 2.12s\tremaining: 9m 19s\n",
      "87:\tlearn: 34.6591375\ttotal: 2.15s\tremaining: 9m 18s\n",
      "88:\tlearn: 34.3010486\ttotal: 2.17s\tremaining: 9m 18s\n",
      "89:\tlearn: 33.9308811\ttotal: 2.19s\tremaining: 9m 17s\n",
      "90:\tlearn: 33.5717982\ttotal: 2.21s\tremaining: 9m 17s\n",
      "91:\tlearn: 33.2216735\ttotal: 2.23s\tremaining: 9m 16s\n",
      "92:\tlearn: 32.8686393\ttotal: 2.26s\tremaining: 9m 15s\n",
      "93:\tlearn: 32.5267536\ttotal: 2.28s\tremaining: 9m 15s\n",
      "94:\tlearn: 32.1870772\ttotal: 2.3s\tremaining: 9m 15s\n",
      "95:\tlearn: 31.8664875\ttotal: 2.33s\tremaining: 9m 15s\n",
      "96:\tlearn: 31.5345110\ttotal: 2.36s\tremaining: 9m 17s\n",
      "97:\tlearn: 31.2243922\ttotal: 2.39s\tremaining: 9m 18s\n",
      "98:\tlearn: 30.9029626\ttotal: 2.41s\tremaining: 9m 18s\n",
      "99:\tlearn: 30.6086771\ttotal: 2.43s\tremaining: 9m 17s\n",
      "100:\tlearn: 30.2942634\ttotal: 2.46s\tremaining: 9m 16s\n",
      "101:\tlearn: 29.9948156\ttotal: 2.48s\tremaining: 9m 17s\n",
      "102:\tlearn: 29.7159162\ttotal: 2.5s\tremaining: 9m 16s\n",
      "103:\tlearn: 29.4327823\ttotal: 2.52s\tremaining: 9m 16s\n",
      "104:\tlearn: 29.1588664\ttotal: 2.55s\tremaining: 9m 16s\n",
      "105:\tlearn: 28.8956676\ttotal: 2.57s\tremaining: 9m 15s\n",
      "106:\tlearn: 28.6298363\ttotal: 2.6s\tremaining: 9m 15s\n",
      "107:\tlearn: 28.3667981\ttotal: 2.62s\tremaining: 9m 14s\n",
      "108:\tlearn: 28.1011471\ttotal: 2.64s\tremaining: 9m 14s\n",
      "109:\tlearn: 27.8490970\ttotal: 2.66s\tremaining: 9m 14s\n",
      "110:\tlearn: 27.5874327\ttotal: 2.68s\tremaining: 9m 13s\n",
      "111:\tlearn: 27.3310420\ttotal: 2.71s\tremaining: 9m 13s\n",
      "112:\tlearn: 27.0742858\ttotal: 2.73s\tremaining: 9m 12s\n",
      "113:\tlearn: 26.8424855\ttotal: 2.75s\tremaining: 9m 11s\n",
      "114:\tlearn: 26.6086144\ttotal: 2.77s\tremaining: 9m 11s\n",
      "115:\tlearn: 26.3688132\ttotal: 2.79s\tremaining: 9m 11s\n",
      "116:\tlearn: 26.1429431\ttotal: 2.82s\tremaining: 9m 10s\n",
      "117:\tlearn: 25.9188633\ttotal: 2.84s\tremaining: 9m 10s\n",
      "118:\tlearn: 25.6901818\ttotal: 2.86s\tremaining: 9m 10s\n",
      "119:\tlearn: 25.4672796\ttotal: 2.88s\tremaining: 9m 10s\n",
      "120:\tlearn: 25.2518745\ttotal: 2.91s\tremaining: 9m 9s\n",
      "121:\tlearn: 25.0283232\ttotal: 2.93s\tremaining: 9m 9s\n",
      "122:\tlearn: 24.8115167\ttotal: 2.96s\tremaining: 9m 9s\n",
      "123:\tlearn: 24.6060082\ttotal: 2.98s\tremaining: 9m 9s\n",
      "124:\tlearn: 24.4097428\ttotal: 3s\tremaining: 9m 8s\n",
      "125:\tlearn: 24.2123224\ttotal: 3.02s\tremaining: 9m 8s\n",
      "126:\tlearn: 24.0250638\ttotal: 3.05s\tremaining: 9m 8s\n",
      "127:\tlearn: 23.8300266\ttotal: 3.07s\tremaining: 9m 8s\n",
      "128:\tlearn: 23.6366207\ttotal: 3.09s\tremaining: 9m 7s\n",
      "129:\tlearn: 23.4427671\ttotal: 3.11s\tremaining: 9m 7s\n",
      "130:\tlearn: 23.2535981\ttotal: 3.13s\tremaining: 9m 7s\n",
      "131:\tlearn: 23.0749292\ttotal: 3.16s\tremaining: 9m 6s\n",
      "132:\tlearn: 22.8959981\ttotal: 3.18s\tremaining: 9m 7s\n",
      "133:\tlearn: 22.7174494\ttotal: 3.2s\tremaining: 9m 6s\n",
      "134:\tlearn: 22.5483436\ttotal: 3.23s\tremaining: 9m 6s\n",
      "135:\tlearn: 22.3791301\ttotal: 3.25s\tremaining: 9m 6s\n",
      "136:\tlearn: 22.2165327\ttotal: 3.27s\tremaining: 9m 6s\n",
      "137:\tlearn: 22.0458526\ttotal: 3.29s\tremaining: 9m 5s\n",
      "138:\tlearn: 21.8888839\ttotal: 3.32s\tremaining: 9m 5s\n",
      "139:\tlearn: 21.7332814\ttotal: 3.34s\tremaining: 9m 5s\n",
      "140:\tlearn: 21.5779792\ttotal: 3.37s\tremaining: 9m 6s\n",
      "141:\tlearn: 21.4280673\ttotal: 3.39s\tremaining: 9m 5s\n",
      "142:\tlearn: 21.2800972\ttotal: 3.41s\tremaining: 9m 4s\n",
      "143:\tlearn: 21.1354111\ttotal: 3.43s\tremaining: 9m 4s\n",
      "144:\tlearn: 20.9920749\ttotal: 3.45s\tremaining: 9m 4s\n",
      "145:\tlearn: 20.8515949\ttotal: 3.47s\tremaining: 9m 3s\n",
      "146:\tlearn: 20.7134256\ttotal: 3.49s\tremaining: 9m 3s\n",
      "147:\tlearn: 20.5750195\ttotal: 3.52s\tremaining: 9m 2s\n",
      "148:\tlearn: 20.4311907\ttotal: 3.54s\tremaining: 9m 2s\n",
      "149:\tlearn: 20.3052552\ttotal: 3.56s\tremaining: 9m 1s\n",
      "150:\tlearn: 20.1753539\ttotal: 3.58s\tremaining: 9m 2s\n",
      "151:\tlearn: 20.0453169\ttotal: 3.6s\tremaining: 9m 1s\n",
      "152:\tlearn: 19.9154986\ttotal: 3.62s\tremaining: 9m 1s\n",
      "153:\tlearn: 19.7911987\ttotal: 3.65s\tremaining: 9m 1s\n",
      "154:\tlearn: 19.6737645\ttotal: 3.67s\tremaining: 9m\n",
      "155:\tlearn: 19.5629505\ttotal: 3.69s\tremaining: 9m\n",
      "156:\tlearn: 19.4472900\ttotal: 3.71s\tremaining: 9m\n",
      "157:\tlearn: 19.3387899\ttotal: 3.73s\tremaining: 8m 59s\n",
      "158:\tlearn: 19.2251478\ttotal: 3.75s\tremaining: 8m 59s\n",
      "159:\tlearn: 19.1205229\ttotal: 3.77s\tremaining: 8m 59s\n",
      "160:\tlearn: 19.0158487\ttotal: 3.8s\tremaining: 8m 59s\n",
      "161:\tlearn: 18.9122501\ttotal: 3.82s\tremaining: 8m 58s\n",
      "162:\tlearn: 18.8134902\ttotal: 3.84s\tremaining: 8m 58s\n",
      "163:\tlearn: 18.7094868\ttotal: 3.87s\tremaining: 8m 58s\n",
      "164:\tlearn: 18.6024316\ttotal: 3.89s\tremaining: 8m 58s\n",
      "165:\tlearn: 18.5075028\ttotal: 3.91s\tremaining: 8m 57s\n",
      "166:\tlearn: 18.4093134\ttotal: 3.94s\tremaining: 8m 58s\n",
      "167:\tlearn: 18.3231559\ttotal: 3.96s\tremaining: 8m 58s\n",
      "168:\tlearn: 18.2266323\ttotal: 3.98s\tremaining: 8m 57s\n",
      "169:\tlearn: 18.1350365\ttotal: 4s\tremaining: 8m 57s\n",
      "170:\tlearn: 18.0444993\ttotal: 4.02s\tremaining: 8m 57s\n",
      "171:\tlearn: 17.9528262\ttotal: 4.04s\tremaining: 8m 56s\n",
      "172:\tlearn: 17.8667875\ttotal: 4.07s\tremaining: 8m 57s\n",
      "173:\tlearn: 17.7834578\ttotal: 4.09s\tremaining: 8m 56s\n",
      "174:\tlearn: 17.6988111\ttotal: 4.11s\tremaining: 8m 56s\n",
      "175:\tlearn: 17.6178730\ttotal: 4.14s\tremaining: 8m 56s\n",
      "176:\tlearn: 17.5305113\ttotal: 4.16s\tremaining: 8m 56s\n",
      "177:\tlearn: 17.4475090\ttotal: 4.18s\tremaining: 8m 56s\n",
      "178:\tlearn: 17.3678728\ttotal: 4.21s\tremaining: 8m 56s\n",
      "179:\tlearn: 17.2887857\ttotal: 4.23s\tremaining: 8m 55s\n",
      "180:\tlearn: 17.2132030\ttotal: 4.25s\tremaining: 8m 55s\n",
      "181:\tlearn: 17.1327875\ttotal: 4.27s\tremaining: 8m 55s\n",
      "182:\tlearn: 17.0604350\ttotal: 4.29s\tremaining: 8m 55s\n",
      "183:\tlearn: 16.9931049\ttotal: 4.31s\tremaining: 8m 54s\n",
      "184:\tlearn: 16.9217507\ttotal: 4.34s\tremaining: 8m 54s\n",
      "185:\tlearn: 16.8465645\ttotal: 4.36s\tremaining: 8m 54s\n",
      "186:\tlearn: 16.7761816\ttotal: 4.38s\tremaining: 8m 54s\n",
      "187:\tlearn: 16.7069013\ttotal: 4.4s\tremaining: 8m 54s\n",
      "188:\tlearn: 16.6341795\ttotal: 4.42s\tremaining: 8m 54s\n",
      "189:\tlearn: 16.5650984\ttotal: 4.45s\tremaining: 8m 53s\n",
      "190:\tlearn: 16.5036773\ttotal: 4.47s\tremaining: 8m 53s\n",
      "191:\tlearn: 16.4374175\ttotal: 4.49s\tremaining: 8m 53s\n",
      "192:\tlearn: 16.3685714\ttotal: 4.51s\tremaining: 8m 53s\n",
      "193:\tlearn: 16.3049924\ttotal: 4.54s\tremaining: 8m 53s\n",
      "194:\tlearn: 16.2495899\ttotal: 4.55s\tremaining: 8m 52s\n",
      "195:\tlearn: 16.1898501\ttotal: 4.58s\tremaining: 8m 53s\n",
      "196:\tlearn: 16.1310291\ttotal: 4.61s\tremaining: 8m 53s\n",
      "197:\tlearn: 16.0776276\ttotal: 4.62s\tremaining: 8m 52s\n",
      "198:\tlearn: 16.0253803\ttotal: 4.64s\tremaining: 8m 52s\n",
      "199:\tlearn: 15.9679455\ttotal: 4.67s\tremaining: 8m 52s\n",
      "200:\tlearn: 15.9135144\ttotal: 4.69s\tremaining: 8m 51s\n",
      "201:\tlearn: 15.8589165\ttotal: 4.71s\tremaining: 8m 51s\n",
      "202:\tlearn: 15.8065728\ttotal: 4.73s\tremaining: 8m 51s\n",
      "203:\tlearn: 15.7528047\ttotal: 4.75s\tremaining: 8m 51s\n",
      "204:\tlearn: 15.6999086\ttotal: 4.77s\tremaining: 8m 50s\n",
      "205:\tlearn: 15.6450191\ttotal: 4.79s\tremaining: 8m 50s\n",
      "206:\tlearn: 15.5967152\ttotal: 4.82s\tremaining: 8m 50s\n",
      "207:\tlearn: 15.5520833\ttotal: 4.84s\tremaining: 8m 50s\n",
      "208:\tlearn: 15.5050489\ttotal: 4.86s\tremaining: 8m 49s\n",
      "209:\tlearn: 15.4595039\ttotal: 4.88s\tremaining: 8m 49s\n",
      "210:\tlearn: 15.4137983\ttotal: 4.9s\tremaining: 8m 49s\n",
      "211:\tlearn: 15.3663109\ttotal: 4.92s\tremaining: 8m 49s\n",
      "212:\tlearn: 15.3220661\ttotal: 4.94s\tremaining: 8m 48s\n",
      "213:\tlearn: 15.2782986\ttotal: 4.96s\tremaining: 8m 48s\n",
      "214:\tlearn: 15.2337967\ttotal: 4.99s\tremaining: 8m 48s\n",
      "215:\tlearn: 15.1853106\ttotal: 5.01s\tremaining: 8m 48s\n",
      "216:\tlearn: 15.1450425\ttotal: 5.03s\tremaining: 8m 48s\n",
      "217:\tlearn: 15.1018839\ttotal: 5.05s\tremaining: 8m 48s\n",
      "218:\tlearn: 15.0654506\ttotal: 5.07s\tremaining: 8m 47s\n",
      "219:\tlearn: 15.0260793\ttotal: 5.09s\tremaining: 8m 47s\n",
      "220:\tlearn: 14.9864875\ttotal: 5.12s\tremaining: 8m 47s\n",
      "221:\tlearn: 14.9455732\ttotal: 5.14s\tremaining: 8m 47s\n",
      "222:\tlearn: 14.8987584\ttotal: 5.16s\tremaining: 8m 47s\n",
      "223:\tlearn: 14.8566944\ttotal: 5.19s\tremaining: 8m 47s\n",
      "224:\tlearn: 14.8199310\ttotal: 5.21s\tremaining: 8m 47s\n",
      "225:\tlearn: 14.7825312\ttotal: 5.23s\tremaining: 8m 46s\n",
      "226:\tlearn: 14.7449071\ttotal: 5.25s\tremaining: 8m 46s\n",
      "227:\tlearn: 14.7072238\ttotal: 5.27s\tremaining: 8m 46s\n",
      "228:\tlearn: 14.6761398\ttotal: 5.29s\tremaining: 8m 46s\n",
      "229:\tlearn: 14.6367787\ttotal: 5.31s\tremaining: 8m 46s\n",
      "230:\tlearn: 14.6026207\ttotal: 5.34s\tremaining: 8m 45s\n",
      "231:\tlearn: 14.5654026\ttotal: 5.36s\tremaining: 8m 45s\n",
      "232:\tlearn: 14.5305717\ttotal: 5.38s\tremaining: 8m 45s\n",
      "233:\tlearn: 14.4952706\ttotal: 5.4s\tremaining: 8m 45s\n",
      "234:\tlearn: 14.4632069\ttotal: 5.42s\tremaining: 8m 45s\n",
      "235:\tlearn: 14.4222467\ttotal: 5.45s\tremaining: 8m 45s\n",
      "236:\tlearn: 14.3881315\ttotal: 5.47s\tremaining: 8m 45s\n",
      "237:\tlearn: 14.3554010\ttotal: 5.49s\tremaining: 8m 45s\n",
      "238:\tlearn: 14.3235417\ttotal: 5.51s\tremaining: 8m 44s\n",
      "239:\tlearn: 14.2906247\ttotal: 5.54s\tremaining: 8m 45s\n",
      "240:\tlearn: 14.2585237\ttotal: 5.55s\tremaining: 8m 44s\n",
      "241:\tlearn: 14.2232086\ttotal: 5.58s\tremaining: 8m 44s\n",
      "242:\tlearn: 14.1959704\ttotal: 5.6s\tremaining: 8m 44s\n",
      "243:\tlearn: 14.1676364\ttotal: 5.62s\tremaining: 8m 44s\n",
      "244:\tlearn: 14.1412861\ttotal: 5.64s\tremaining: 8m 43s\n",
      "245:\tlearn: 14.1138846\ttotal: 5.66s\tremaining: 8m 43s\n",
      "246:\tlearn: 14.0844095\ttotal: 5.68s\tremaining: 8m 43s\n",
      "247:\tlearn: 14.0548793\ttotal: 5.7s\tremaining: 8m 43s\n",
      "248:\tlearn: 14.0277599\ttotal: 5.73s\tremaining: 8m 43s\n",
      "249:\tlearn: 14.0027605\ttotal: 5.75s\tremaining: 8m 43s\n",
      "250:\tlearn: 13.9745284\ttotal: 5.77s\tremaining: 8m 42s\n",
      "251:\tlearn: 13.9445769\ttotal: 5.79s\tremaining: 8m 43s\n",
      "252:\tlearn: 13.9142395\ttotal: 5.82s\tremaining: 8m 43s\n",
      "253:\tlearn: 13.8810018\ttotal: 5.84s\tremaining: 8m 43s\n",
      "254:\tlearn: 13.8548865\ttotal: 5.86s\tremaining: 8m 43s\n",
      "255:\tlearn: 13.8292127\ttotal: 5.89s\tremaining: 8m 43s\n",
      "256:\tlearn: 13.8043923\ttotal: 5.91s\tremaining: 8m 42s\n",
      "257:\tlearn: 13.7770851\ttotal: 5.93s\tremaining: 8m 42s\n",
      "258:\tlearn: 13.7555177\ttotal: 5.95s\tremaining: 8m 42s\n",
      "259:\tlearn: 13.7272065\ttotal: 5.97s\tremaining: 8m 42s\n",
      "260:\tlearn: 13.6982702\ttotal: 5.99s\tremaining: 8m 42s\n",
      "261:\tlearn: 13.6716446\ttotal: 6.01s\tremaining: 8m 41s\n",
      "262:\tlearn: 13.6487017\ttotal: 6.04s\tremaining: 8m 41s\n",
      "263:\tlearn: 13.6173239\ttotal: 6.06s\tremaining: 8m 41s\n",
      "264:\tlearn: 13.5931699\ttotal: 6.09s\tremaining: 8m 42s\n",
      "265:\tlearn: 13.5711720\ttotal: 6.11s\tremaining: 8m 42s\n",
      "266:\tlearn: 13.5482875\ttotal: 6.13s\tremaining: 8m 42s\n",
      "267:\tlearn: 13.5178388\ttotal: 6.16s\tremaining: 8m 42s\n",
      "268:\tlearn: 13.4937395\ttotal: 6.18s\tremaining: 8m 42s\n",
      "269:\tlearn: 13.4657987\ttotal: 6.21s\tremaining: 8m 42s\n",
      "270:\tlearn: 13.4443617\ttotal: 6.22s\tremaining: 8m 42s\n",
      "271:\tlearn: 13.4187031\ttotal: 6.25s\tremaining: 8m 41s\n",
      "272:\tlearn: 13.3948254\ttotal: 6.27s\tremaining: 8m 41s\n",
      "273:\tlearn: 13.3740775\ttotal: 6.29s\tremaining: 8m 41s\n",
      "274:\tlearn: 13.3535947\ttotal: 6.31s\tremaining: 8m 41s\n",
      "275:\tlearn: 13.3338528\ttotal: 6.33s\tremaining: 8m 41s\n",
      "276:\tlearn: 13.3075393\ttotal: 6.36s\tremaining: 8m 41s\n",
      "277:\tlearn: 13.2840800\ttotal: 6.38s\tremaining: 8m 41s\n",
      "278:\tlearn: 13.2662835\ttotal: 6.4s\tremaining: 8m 40s\n",
      "279:\tlearn: 13.2500213\ttotal: 6.42s\tremaining: 8m 40s\n",
      "280:\tlearn: 13.2270799\ttotal: 6.44s\tremaining: 8m 40s\n",
      "281:\tlearn: 13.2088411\ttotal: 6.46s\tremaining: 8m 40s\n",
      "282:\tlearn: 13.1879258\ttotal: 6.49s\tremaining: 8m 40s\n",
      "283:\tlearn: 13.1711804\ttotal: 6.5s\tremaining: 8m 40s\n",
      "284:\tlearn: 13.1540591\ttotal: 6.53s\tremaining: 8m 40s\n",
      "285:\tlearn: 13.1329221\ttotal: 6.55s\tremaining: 8m 40s\n",
      "286:\tlearn: 13.1155908\ttotal: 6.57s\tremaining: 8m 39s\n",
      "287:\tlearn: 13.0967759\ttotal: 6.59s\tremaining: 8m 40s\n",
      "288:\tlearn: 13.0801191\ttotal: 6.62s\tremaining: 8m 39s\n",
      "289:\tlearn: 13.0633645\ttotal: 6.63s\tremaining: 8m 39s\n",
      "290:\tlearn: 13.0450760\ttotal: 6.66s\tremaining: 8m 39s\n",
      "291:\tlearn: 13.0257152\ttotal: 6.68s\tremaining: 8m 39s\n",
      "292:\tlearn: 13.0083135\ttotal: 6.7s\tremaining: 8m 39s\n",
      "293:\tlearn: 12.9927331\ttotal: 6.72s\tremaining: 8m 39s\n",
      "294:\tlearn: 12.9749337\ttotal: 6.75s\tremaining: 8m 39s\n",
      "295:\tlearn: 12.9589966\ttotal: 6.77s\tremaining: 8m 39s\n",
      "296:\tlearn: 12.9361052\ttotal: 6.79s\tremaining: 8m 39s\n",
      "297:\tlearn: 12.9202942\ttotal: 6.82s\tremaining: 8m 39s\n",
      "298:\tlearn: 12.9040648\ttotal: 6.84s\tremaining: 8m 39s\n",
      "299:\tlearn: 12.8811426\ttotal: 6.87s\tremaining: 8m 39s\n",
      "300:\tlearn: 12.8642249\ttotal: 6.89s\tremaining: 8m 39s\n",
      "301:\tlearn: 12.8468428\ttotal: 6.92s\tremaining: 8m 39s\n",
      "302:\tlearn: 12.8267008\ttotal: 6.94s\tremaining: 8m 39s\n",
      "303:\tlearn: 12.8091903\ttotal: 6.96s\tremaining: 8m 39s\n",
      "304:\tlearn: 12.7919621\ttotal: 6.98s\tremaining: 8m 39s\n",
      "305:\tlearn: 12.7774182\ttotal: 7s\tremaining: 8m 39s\n",
      "306:\tlearn: 12.7618570\ttotal: 7.02s\tremaining: 8m 39s\n",
      "307:\tlearn: 12.7442367\ttotal: 7.04s\tremaining: 8m 39s\n",
      "308:\tlearn: 12.7317859\ttotal: 7.06s\tremaining: 8m 38s\n",
      "309:\tlearn: 12.7188171\ttotal: 7.08s\tremaining: 8m 38s\n",
      "310:\tlearn: 12.7042351\ttotal: 7.1s\tremaining: 8m 38s\n",
      "311:\tlearn: 12.6873070\ttotal: 7.12s\tremaining: 8m 38s\n",
      "312:\tlearn: 12.6721227\ttotal: 7.15s\tremaining: 8m 38s\n",
      "313:\tlearn: 12.6587460\ttotal: 7.17s\tremaining: 8m 37s\n",
      "314:\tlearn: 12.6460188\ttotal: 7.18s\tremaining: 8m 37s\n",
      "315:\tlearn: 12.6294078\ttotal: 7.21s\tremaining: 8m 37s\n",
      "316:\tlearn: 12.6146823\ttotal: 7.24s\tremaining: 8m 37s\n",
      "317:\tlearn: 12.6039330\ttotal: 7.26s\tremaining: 8m 37s\n",
      "318:\tlearn: 12.5877567\ttotal: 7.28s\tremaining: 8m 37s\n",
      "319:\tlearn: 12.5769755\ttotal: 7.3s\tremaining: 8m 37s\n",
      "320:\tlearn: 12.5589357\ttotal: 7.33s\tremaining: 8m 37s\n",
      "321:\tlearn: 12.5429781\ttotal: 7.35s\tremaining: 8m 37s\n",
      "322:\tlearn: 12.5307343\ttotal: 7.37s\tremaining: 8m 37s\n",
      "323:\tlearn: 12.5157010\ttotal: 7.4s\tremaining: 8m 37s\n",
      "324:\tlearn: 12.5033606\ttotal: 7.41s\tremaining: 8m 37s\n",
      "325:\tlearn: 12.4889752\ttotal: 7.43s\tremaining: 8m 37s\n",
      "326:\tlearn: 12.4790276\ttotal: 7.46s\tremaining: 8m 37s\n",
      "327:\tlearn: 12.4678448\ttotal: 7.47s\tremaining: 8m 36s\n",
      "328:\tlearn: 12.4573842\ttotal: 7.49s\tremaining: 8m 36s\n",
      "329:\tlearn: 12.4452555\ttotal: 7.51s\tremaining: 8m 36s\n",
      "330:\tlearn: 12.4329459\ttotal: 7.54s\tremaining: 8m 36s\n",
      "331:\tlearn: 12.4214268\ttotal: 7.56s\tremaining: 8m 36s\n",
      "332:\tlearn: 12.4114909\ttotal: 7.58s\tremaining: 8m 36s\n",
      "333:\tlearn: 12.4021827\ttotal: 7.6s\tremaining: 8m 36s\n",
      "334:\tlearn: 12.3868265\ttotal: 7.62s\tremaining: 8m 35s\n",
      "335:\tlearn: 12.3760848\ttotal: 7.64s\tremaining: 8m 35s\n",
      "336:\tlearn: 12.3637323\ttotal: 7.66s\tremaining: 8m 35s\n",
      "337:\tlearn: 12.3520954\ttotal: 7.68s\tremaining: 8m 35s\n",
      "338:\tlearn: 12.3431591\ttotal: 7.7s\tremaining: 8m 34s\n",
      "339:\tlearn: 12.3325952\ttotal: 7.72s\tremaining: 8m 34s\n",
      "340:\tlearn: 12.3182525\ttotal: 7.74s\tremaining: 8m 34s\n",
      "341:\tlearn: 12.3036354\ttotal: 7.76s\tremaining: 8m 34s\n",
      "342:\tlearn: 12.2918649\ttotal: 7.78s\tremaining: 8m 34s\n",
      "343:\tlearn: 12.2798361\ttotal: 7.81s\tremaining: 8m 34s\n",
      "344:\tlearn: 12.2674527\ttotal: 7.83s\tremaining: 8m 34s\n",
      "345:\tlearn: 12.2559148\ttotal: 7.85s\tremaining: 8m 34s\n",
      "346:\tlearn: 12.2394249\ttotal: 7.88s\tremaining: 8m 34s\n",
      "347:\tlearn: 12.2286730\ttotal: 7.9s\tremaining: 8m 34s\n",
      "348:\tlearn: 12.2167588\ttotal: 7.92s\tremaining: 8m 34s\n",
      "349:\tlearn: 12.2063420\ttotal: 7.94s\tremaining: 8m 33s\n",
      "350:\tlearn: 12.1898694\ttotal: 7.96s\tremaining: 8m 33s\n",
      "351:\tlearn: 12.1794721\ttotal: 7.98s\tremaining: 8m 33s\n",
      "352:\tlearn: 12.1629651\ttotal: 8s\tremaining: 8m 33s\n",
      "353:\tlearn: 12.1532608\ttotal: 8.03s\tremaining: 8m 33s\n",
      "354:\tlearn: 12.1446155\ttotal: 8.05s\tremaining: 8m 33s\n",
      "355:\tlearn: 12.1323536\ttotal: 8.06s\tremaining: 8m 33s\n",
      "356:\tlearn: 12.1217210\ttotal: 8.09s\tremaining: 8m 32s\n",
      "357:\tlearn: 12.1061249\ttotal: 8.11s\tremaining: 8m 32s\n",
      "358:\tlearn: 12.0952110\ttotal: 8.13s\tremaining: 8m 32s\n",
      "359:\tlearn: 12.0869656\ttotal: 8.15s\tremaining: 8m 32s\n",
      "360:\tlearn: 12.0745709\ttotal: 8.17s\tremaining: 8m 32s\n",
      "361:\tlearn: 12.0646000\ttotal: 8.19s\tremaining: 8m 32s\n",
      "362:\tlearn: 12.0559025\ttotal: 8.21s\tremaining: 8m 31s\n",
      "363:\tlearn: 12.0406899\ttotal: 8.23s\tremaining: 8m 31s\n",
      "364:\tlearn: 12.0286582\ttotal: 8.26s\tremaining: 8m 31s\n",
      "365:\tlearn: 12.0211739\ttotal: 8.27s\tremaining: 8m 31s\n",
      "366:\tlearn: 12.0113657\ttotal: 8.29s\tremaining: 8m 31s\n",
      "367:\tlearn: 12.0029968\ttotal: 8.31s\tremaining: 8m 31s\n",
      "368:\tlearn: 11.9934269\ttotal: 8.33s\tremaining: 8m 30s\n",
      "369:\tlearn: 11.9843474\ttotal: 8.35s\tremaining: 8m 30s\n",
      "370:\tlearn: 11.9753275\ttotal: 8.37s\tremaining: 8m 30s\n",
      "371:\tlearn: 11.9663201\ttotal: 8.39s\tremaining: 8m 30s\n",
      "372:\tlearn: 11.9565955\ttotal: 8.42s\tremaining: 8m 30s\n",
      "373:\tlearn: 11.9471277\ttotal: 8.44s\tremaining: 8m 30s\n",
      "374:\tlearn: 11.9386010\ttotal: 8.46s\tremaining: 8m 30s\n",
      "375:\tlearn: 11.9297621\ttotal: 8.48s\tremaining: 8m 30s\n",
      "376:\tlearn: 11.9214018\ttotal: 8.51s\tremaining: 8m 30s\n",
      "377:\tlearn: 11.9122395\ttotal: 8.53s\tremaining: 8m 30s\n",
      "378:\tlearn: 11.9031316\ttotal: 8.54s\tremaining: 8m 29s\n",
      "379:\tlearn: 11.8959724\ttotal: 8.56s\tremaining: 8m 29s\n",
      "380:\tlearn: 11.8879977\ttotal: 8.58s\tremaining: 8m 29s\n",
      "381:\tlearn: 11.8800338\ttotal: 8.6s\tremaining: 8m 29s\n",
      "382:\tlearn: 11.8704025\ttotal: 8.63s\tremaining: 8m 29s\n",
      "383:\tlearn: 11.8633101\ttotal: 8.65s\tremaining: 8m 29s\n",
      "384:\tlearn: 11.8554528\ttotal: 8.67s\tremaining: 8m 29s\n",
      "385:\tlearn: 11.8480305\ttotal: 8.69s\tremaining: 8m 29s\n",
      "386:\tlearn: 11.8406083\ttotal: 8.71s\tremaining: 8m 29s\n",
      "387:\tlearn: 11.8280952\ttotal: 8.73s\tremaining: 8m 28s\n",
      "388:\tlearn: 11.8165498\ttotal: 8.75s\tremaining: 8m 28s\n",
      "389:\tlearn: 11.8031795\ttotal: 8.77s\tremaining: 8m 28s\n",
      "390:\tlearn: 11.7908254\ttotal: 8.79s\tremaining: 8m 28s\n",
      "391:\tlearn: 11.7844459\ttotal: 8.81s\tremaining: 8m 28s\n",
      "392:\tlearn: 11.7770305\ttotal: 8.83s\tremaining: 8m 27s\n",
      "393:\tlearn: 11.7688126\ttotal: 8.85s\tremaining: 8m 28s\n",
      "394:\tlearn: 11.7611903\ttotal: 8.88s\tremaining: 8m 27s\n",
      "395:\tlearn: 11.7546875\ttotal: 8.89s\tremaining: 8m 27s\n",
      "396:\tlearn: 11.7440053\ttotal: 8.91s\tremaining: 8m 27s\n",
      "397:\tlearn: 11.7344685\ttotal: 8.94s\tremaining: 8m 27s\n",
      "398:\tlearn: 11.7280120\ttotal: 8.96s\tremaining: 8m 27s\n",
      "399:\tlearn: 11.7143240\ttotal: 8.97s\tremaining: 8m 27s\n",
      "400:\tlearn: 11.7056668\ttotal: 9s\tremaining: 8m 27s\n",
      "401:\tlearn: 11.7001515\ttotal: 9.02s\tremaining: 8m 26s\n",
      "402:\tlearn: 11.6939184\ttotal: 9.03s\tremaining: 8m 26s\n",
      "403:\tlearn: 11.6869006\ttotal: 9.05s\tremaining: 8m 26s\n",
      "404:\tlearn: 11.6811254\ttotal: 9.07s\tremaining: 8m 26s\n",
      "405:\tlearn: 11.6750254\ttotal: 9.09s\tremaining: 8m 25s\n",
      "406:\tlearn: 11.6683756\ttotal: 9.11s\tremaining: 8m 25s\n",
      "407:\tlearn: 11.6615811\ttotal: 9.12s\tremaining: 8m 25s\n",
      "408:\tlearn: 11.6538306\ttotal: 9.15s\tremaining: 8m 25s\n",
      "409:\tlearn: 11.6478591\ttotal: 9.16s\tremaining: 8m 25s\n",
      "410:\tlearn: 11.6398881\ttotal: 9.19s\tremaining: 8m 24s\n",
      "411:\tlearn: 11.6327860\ttotal: 9.21s\tremaining: 8m 24s\n",
      "412:\tlearn: 11.6266610\ttotal: 9.23s\tremaining: 8m 24s\n",
      "413:\tlearn: 11.6187561\ttotal: 9.25s\tremaining: 8m 24s\n",
      "414:\tlearn: 11.6140961\ttotal: 9.27s\tremaining: 8m 24s\n",
      "415:\tlearn: 11.6016910\ttotal: 9.29s\tremaining: 8m 24s\n",
      "416:\tlearn: 11.5913554\ttotal: 9.31s\tremaining: 8m 24s\n",
      "417:\tlearn: 11.5836995\ttotal: 9.33s\tremaining: 8m 24s\n",
      "418:\tlearn: 11.5773247\ttotal: 9.35s\tremaining: 8m 24s\n",
      "419:\tlearn: 11.5715148\ttotal: 9.37s\tremaining: 8m 23s\n",
      "420:\tlearn: 11.5628353\ttotal: 9.39s\tremaining: 8m 23s\n",
      "421:\tlearn: 11.5566327\ttotal: 9.41s\tremaining: 8m 23s\n",
      "422:\tlearn: 11.5505756\ttotal: 9.43s\tremaining: 8m 23s\n",
      "423:\tlearn: 11.5408908\ttotal: 9.45s\tremaining: 8m 23s\n",
      "424:\tlearn: 11.5336490\ttotal: 9.47s\tremaining: 8m 23s\n",
      "425:\tlearn: 11.5271932\ttotal: 9.49s\tremaining: 8m 22s\n",
      "426:\tlearn: 11.5209765\ttotal: 9.51s\tremaining: 8m 22s\n",
      "427:\tlearn: 11.5151671\ttotal: 9.53s\tremaining: 8m 22s\n",
      "428:\tlearn: 11.5092569\ttotal: 9.55s\tremaining: 8m 22s\n",
      "429:\tlearn: 11.5025637\ttotal: 9.57s\tremaining: 8m 22s\n",
      "430:\tlearn: 11.4967082\ttotal: 9.59s\tremaining: 8m 22s\n",
      "431:\tlearn: 11.4884160\ttotal: 9.6s\tremaining: 8m 21s\n",
      "432:\tlearn: 11.4823770\ttotal: 9.63s\tremaining: 8m 21s\n",
      "433:\tlearn: 11.4757356\ttotal: 9.65s\tremaining: 8m 21s\n",
      "434:\tlearn: 11.4683282\ttotal: 9.66s\tremaining: 8m 21s\n",
      "435:\tlearn: 11.4626280\ttotal: 9.69s\tremaining: 8m 21s\n",
      "436:\tlearn: 11.4559044\ttotal: 9.71s\tremaining: 8m 21s\n",
      "437:\tlearn: 11.4502028\ttotal: 9.73s\tremaining: 8m 21s\n",
      "438:\tlearn: 11.4426357\ttotal: 9.75s\tremaining: 8m 21s\n",
      "439:\tlearn: 11.4374488\ttotal: 9.77s\tremaining: 8m 21s\n",
      "440:\tlearn: 11.4312460\ttotal: 9.79s\tremaining: 8m 20s\n",
      "441:\tlearn: 11.4241701\ttotal: 9.81s\tremaining: 8m 20s\n",
      "442:\tlearn: 11.4192596\ttotal: 9.83s\tremaining: 8m 20s\n",
      "443:\tlearn: 11.4124519\ttotal: 9.85s\tremaining: 8m 20s\n",
      "444:\tlearn: 11.4049306\ttotal: 9.87s\tremaining: 8m 20s\n",
      "445:\tlearn: 11.3966097\ttotal: 9.89s\tremaining: 8m 20s\n",
      "446:\tlearn: 11.3899441\ttotal: 9.91s\tremaining: 8m 20s\n",
      "447:\tlearn: 11.3833483\ttotal: 9.93s\tremaining: 8m 20s\n",
      "448:\tlearn: 11.3732478\ttotal: 9.96s\tremaining: 8m 20s\n",
      "449:\tlearn: 11.3639445\ttotal: 9.98s\tremaining: 8m 20s\n",
      "450:\tlearn: 11.3538487\ttotal: 10s\tremaining: 8m 20s\n",
      "451:\tlearn: 11.3489701\ttotal: 10s\tremaining: 8m 20s\n",
      "452:\tlearn: 11.3422929\ttotal: 10s\tremaining: 8m 19s\n",
      "453:\tlearn: 11.3329380\ttotal: 10.1s\tremaining: 8m 19s\n",
      "454:\tlearn: 11.3280399\ttotal: 10.1s\tremaining: 8m 19s\n",
      "455:\tlearn: 11.3233659\ttotal: 10.1s\tremaining: 8m 19s\n",
      "456:\tlearn: 11.3180677\ttotal: 10.1s\tremaining: 8m 19s\n",
      "457:\tlearn: 11.3089767\ttotal: 10.1s\tremaining: 8m 19s\n",
      "458:\tlearn: 11.2989247\ttotal: 10.2s\tremaining: 8m 19s\n",
      "459:\tlearn: 11.2934466\ttotal: 10.2s\tremaining: 8m 18s\n",
      "460:\tlearn: 11.2869583\ttotal: 10.2s\tremaining: 8m 18s\n",
      "461:\tlearn: 11.2814232\ttotal: 10.2s\tremaining: 8m 18s\n",
      "462:\tlearn: 11.2763640\ttotal: 10.2s\tremaining: 8m 18s\n",
      "463:\tlearn: 11.2700964\ttotal: 10.3s\tremaining: 8m 18s\n",
      "464:\tlearn: 11.2652577\ttotal: 10.3s\tremaining: 8m 18s\n",
      "465:\tlearn: 11.2599693\ttotal: 10.3s\tremaining: 8m 18s\n",
      "466:\tlearn: 11.2517337\ttotal: 10.3s\tremaining: 8m 18s\n",
      "467:\tlearn: 11.2466995\ttotal: 10.3s\tremaining: 8m 18s\n",
      "468:\tlearn: 11.2368173\ttotal: 10.4s\tremaining: 8m 18s\n",
      "469:\tlearn: 11.2312858\ttotal: 10.4s\tremaining: 8m 18s\n",
      "470:\tlearn: 11.2204131\ttotal: 10.4s\tremaining: 8m 18s\n",
      "471:\tlearn: 11.2137759\ttotal: 10.4s\tremaining: 8m 18s\n",
      "472:\tlearn: 11.2055043\ttotal: 10.5s\tremaining: 8m 18s\n",
      "473:\tlearn: 11.2017441\ttotal: 10.5s\tremaining: 8m 17s\n",
      "474:\tlearn: 11.1942494\ttotal: 10.5s\tremaining: 8m 17s\n",
      "475:\tlearn: 11.1889625\ttotal: 10.5s\tremaining: 8m 17s\n",
      "476:\tlearn: 11.1843382\ttotal: 10.5s\tremaining: 8m 17s\n",
      "477:\tlearn: 11.1779038\ttotal: 10.6s\tremaining: 8m 18s\n",
      "478:\tlearn: 11.1718376\ttotal: 10.6s\tremaining: 8m 18s\n",
      "479:\tlearn: 11.1661199\ttotal: 10.6s\tremaining: 8m 17s\n",
      "480:\tlearn: 11.1613854\ttotal: 10.6s\tremaining: 8m 17s\n",
      "481:\tlearn: 11.1570616\ttotal: 10.7s\tremaining: 8m 17s\n",
      "482:\tlearn: 11.1518548\ttotal: 10.7s\tremaining: 8m 17s\n",
      "483:\tlearn: 11.1467431\ttotal: 10.7s\tremaining: 8m 17s\n",
      "484:\tlearn: 11.1424815\ttotal: 10.7s\tremaining: 8m 17s\n",
      "485:\tlearn: 11.1328917\ttotal: 10.7s\tremaining: 8m 17s\n",
      "486:\tlearn: 11.1226333\ttotal: 10.8s\tremaining: 8m 17s\n",
      "487:\tlearn: 11.1172235\ttotal: 10.8s\tremaining: 8m 16s\n",
      "488:\tlearn: 11.1120970\ttotal: 10.8s\tremaining: 8m 17s\n",
      "489:\tlearn: 11.1071258\ttotal: 10.8s\tremaining: 8m 16s\n",
      "490:\tlearn: 11.1029097\ttotal: 10.8s\tremaining: 8m 16s\n",
      "491:\tlearn: 11.0961970\ttotal: 10.9s\tremaining: 8m 16s\n",
      "492:\tlearn: 11.0916570\ttotal: 10.9s\tremaining: 8m 16s\n",
      "493:\tlearn: 11.0824743\ttotal: 10.9s\tremaining: 8m 16s\n",
      "494:\tlearn: 11.0779396\ttotal: 10.9s\tremaining: 8m 16s\n",
      "495:\tlearn: 11.0723099\ttotal: 10.9s\tremaining: 8m 16s\n",
      "496:\tlearn: 11.0634492\ttotal: 11s\tremaining: 8m 16s\n",
      "497:\tlearn: 11.0581674\ttotal: 11s\tremaining: 8m 16s\n",
      "498:\tlearn: 11.0527843\ttotal: 11s\tremaining: 8m 16s\n",
      "499:\tlearn: 11.0486819\ttotal: 11s\tremaining: 8m 15s\n",
      "500:\tlearn: 11.0452204\ttotal: 11s\tremaining: 8m 15s\n",
      "501:\tlearn: 11.0376787\ttotal: 11.1s\tremaining: 8m 15s\n",
      "502:\tlearn: 11.0319758\ttotal: 11.1s\tremaining: 8m 15s\n",
      "503:\tlearn: 11.0288061\ttotal: 11.1s\tremaining: 8m 15s\n",
      "504:\tlearn: 11.0228131\ttotal: 11.1s\tremaining: 8m 15s\n",
      "505:\tlearn: 11.0171000\ttotal: 11.2s\tremaining: 8m 15s\n",
      "506:\tlearn: 11.0105809\ttotal: 11.2s\tremaining: 8m 15s\n",
      "507:\tlearn: 11.0029180\ttotal: 11.2s\tremaining: 8m 15s\n",
      "508:\tlearn: 10.9986328\ttotal: 11.2s\tremaining: 8m 15s\n",
      "509:\tlearn: 10.9910049\ttotal: 11.2s\tremaining: 8m 15s\n",
      "510:\tlearn: 10.9857110\ttotal: 11.3s\tremaining: 8m 15s\n",
      "511:\tlearn: 10.9798149\ttotal: 11.3s\tremaining: 8m 15s\n",
      "512:\tlearn: 10.9715902\ttotal: 11.3s\tremaining: 8m 15s\n",
      "513:\tlearn: 10.9669111\ttotal: 11.3s\tremaining: 8m 15s\n",
      "514:\tlearn: 10.9596031\ttotal: 11.3s\tremaining: 8m 15s\n",
      "515:\tlearn: 10.9542993\ttotal: 11.4s\tremaining: 8m 14s\n",
      "516:\tlearn: 10.9504908\ttotal: 11.4s\tremaining: 8m 14s\n",
      "517:\tlearn: 10.9460244\ttotal: 11.4s\tremaining: 8m 14s\n",
      "518:\tlearn: 10.9405437\ttotal: 11.4s\tremaining: 8m 14s\n",
      "519:\tlearn: 10.9325487\ttotal: 11.4s\tremaining: 8m 14s\n",
      "520:\tlearn: 10.9278082\ttotal: 11.5s\tremaining: 8m 14s\n",
      "521:\tlearn: 10.9219102\ttotal: 11.5s\tremaining: 8m 14s\n",
      "522:\tlearn: 10.9183731\ttotal: 11.5s\tremaining: 8m 14s\n",
      "523:\tlearn: 10.9138609\ttotal: 11.5s\tremaining: 8m 14s\n",
      "524:\tlearn: 10.9099939\ttotal: 11.5s\tremaining: 8m 14s\n",
      "525:\tlearn: 10.9050066\ttotal: 11.6s\tremaining: 8m 14s\n",
      "526:\tlearn: 10.9000376\ttotal: 11.6s\tremaining: 8m 14s\n",
      "527:\tlearn: 10.8958422\ttotal: 11.6s\tremaining: 8m 13s\n",
      "528:\tlearn: 10.8903845\ttotal: 11.6s\tremaining: 8m 13s\n",
      "529:\tlearn: 10.8832041\ttotal: 11.6s\tremaining: 8m 13s\n",
      "530:\tlearn: 10.8780813\ttotal: 11.7s\tremaining: 8m 13s\n",
      "531:\tlearn: 10.8736354\ttotal: 11.7s\tremaining: 8m 13s\n",
      "532:\tlearn: 10.8693489\ttotal: 11.7s\tremaining: 8m 13s\n",
      "533:\tlearn: 10.8605901\ttotal: 11.7s\tremaining: 8m 13s\n",
      "534:\tlearn: 10.8557209\ttotal: 11.8s\tremaining: 8m 13s\n",
      "535:\tlearn: 10.8467877\ttotal: 11.8s\tremaining: 8m 13s\n",
      "536:\tlearn: 10.8411777\ttotal: 11.8s\tremaining: 8m 13s\n",
      "537:\tlearn: 10.8354326\ttotal: 11.8s\tremaining: 8m 13s\n",
      "538:\tlearn: 10.8296302\ttotal: 11.8s\tremaining: 8m 13s\n",
      "539:\tlearn: 10.8245926\ttotal: 11.9s\tremaining: 8m 13s\n",
      "540:\tlearn: 10.8205713\ttotal: 11.9s\tremaining: 8m 13s\n",
      "541:\tlearn: 10.8151076\ttotal: 11.9s\tremaining: 8m 13s\n",
      "542:\tlearn: 10.8104786\ttotal: 11.9s\tremaining: 8m 13s\n",
      "543:\tlearn: 10.8063623\ttotal: 11.9s\tremaining: 8m 13s\n",
      "544:\tlearn: 10.8014056\ttotal: 12s\tremaining: 8m 13s\n",
      "545:\tlearn: 10.7962253\ttotal: 12s\tremaining: 8m 13s\n",
      "546:\tlearn: 10.7930760\ttotal: 12s\tremaining: 8m 13s\n",
      "547:\tlearn: 10.7890102\ttotal: 12s\tremaining: 8m 12s\n",
      "548:\tlearn: 10.7837488\ttotal: 12.1s\tremaining: 8m 12s\n",
      "549:\tlearn: 10.7787860\ttotal: 12.1s\tremaining: 8m 12s\n",
      "550:\tlearn: 10.7743509\ttotal: 12.1s\tremaining: 8m 12s\n",
      "551:\tlearn: 10.7703267\ttotal: 12.1s\tremaining: 8m 12s\n",
      "552:\tlearn: 10.7661542\ttotal: 12.1s\tremaining: 8m 12s\n",
      "553:\tlearn: 10.7606169\ttotal: 12.2s\tremaining: 8m 12s\n",
      "554:\tlearn: 10.7572275\ttotal: 12.2s\tremaining: 8m 12s\n",
      "555:\tlearn: 10.7530555\ttotal: 12.2s\tremaining: 8m 12s\n",
      "556:\tlearn: 10.7470868\ttotal: 12.2s\tremaining: 8m 12s\n",
      "557:\tlearn: 10.7425179\ttotal: 12.2s\tremaining: 8m 12s\n",
      "558:\tlearn: 10.7385893\ttotal: 12.3s\tremaining: 8m 12s\n",
      "559:\tlearn: 10.7334228\ttotal: 12.3s\tremaining: 8m 12s\n",
      "560:\tlearn: 10.7262830\ttotal: 12.3s\tremaining: 8m 12s\n",
      "561:\tlearn: 10.7209445\ttotal: 12.3s\tremaining: 8m 12s\n",
      "562:\tlearn: 10.7156979\ttotal: 12.3s\tremaining: 8m 11s\n",
      "563:\tlearn: 10.7098612\ttotal: 12.4s\tremaining: 8m 12s\n",
      "564:\tlearn: 10.7044856\ttotal: 12.4s\tremaining: 8m 11s\n",
      "565:\tlearn: 10.7005995\ttotal: 12.4s\tremaining: 8m 11s\n",
      "566:\tlearn: 10.6954843\ttotal: 12.4s\tremaining: 8m 11s\n",
      "567:\tlearn: 10.6906589\ttotal: 12.5s\tremaining: 8m 11s\n",
      "568:\tlearn: 10.6871041\ttotal: 12.5s\tremaining: 8m 11s\n",
      "569:\tlearn: 10.6843079\ttotal: 12.5s\tremaining: 8m 11s\n",
      "570:\tlearn: 10.6805819\ttotal: 12.5s\tremaining: 8m 11s\n",
      "571:\tlearn: 10.6766753\ttotal: 12.5s\tremaining: 8m 11s\n",
      "572:\tlearn: 10.6732789\ttotal: 12.5s\tremaining: 8m 11s\n",
      "573:\tlearn: 10.6691764\ttotal: 12.6s\tremaining: 8m 10s\n",
      "574:\tlearn: 10.6623291\ttotal: 12.6s\tremaining: 8m 10s\n",
      "575:\tlearn: 10.6586582\ttotal: 12.6s\tremaining: 8m 10s\n",
      "576:\tlearn: 10.6548841\ttotal: 12.6s\tremaining: 8m 10s\n",
      "577:\tlearn: 10.6510065\ttotal: 12.6s\tremaining: 8m 10s\n",
      "578:\tlearn: 10.6471125\ttotal: 12.7s\tremaining: 8m 10s\n",
      "579:\tlearn: 10.6428280\ttotal: 12.7s\tremaining: 8m 10s\n",
      "580:\tlearn: 10.6382790\ttotal: 12.7s\tremaining: 8m 10s\n",
      "581:\tlearn: 10.6345165\ttotal: 12.7s\tremaining: 8m 10s\n",
      "582:\tlearn: 10.6284947\ttotal: 12.7s\tremaining: 8m 10s\n",
      "583:\tlearn: 10.6245184\ttotal: 12.8s\tremaining: 8m 9s\n",
      "584:\tlearn: 10.6201662\ttotal: 12.8s\tremaining: 8m 9s\n",
      "585:\tlearn: 10.6162011\ttotal: 12.8s\tremaining: 8m 9s\n",
      "586:\tlearn: 10.6093106\ttotal: 12.8s\tremaining: 8m 9s\n",
      "587:\tlearn: 10.6023578\ttotal: 12.8s\tremaining: 8m 9s\n",
      "588:\tlearn: 10.5987294\ttotal: 12.9s\tremaining: 8m 9s\n",
      "589:\tlearn: 10.5923552\ttotal: 12.9s\tremaining: 8m 9s\n",
      "590:\tlearn: 10.5871088\ttotal: 12.9s\tremaining: 8m 9s\n",
      "591:\tlearn: 10.5833867\ttotal: 12.9s\tremaining: 8m 9s\n",
      "592:\tlearn: 10.5791422\ttotal: 12.9s\tremaining: 8m 9s\n",
      "593:\tlearn: 10.5741420\ttotal: 13s\tremaining: 8m 9s\n",
      "594:\tlearn: 10.5703441\ttotal: 13s\tremaining: 8m 8s\n",
      "595:\tlearn: 10.5658067\ttotal: 13s\tremaining: 8m 8s\n",
      "596:\tlearn: 10.5621635\ttotal: 13s\tremaining: 8m 8s\n",
      "597:\tlearn: 10.5577380\ttotal: 13s\tremaining: 8m 8s\n",
      "598:\tlearn: 10.5536505\ttotal: 13.1s\tremaining: 8m 8s\n",
      "599:\tlearn: 10.5496862\ttotal: 13.1s\tremaining: 8m 8s\n",
      "600:\tlearn: 10.5457012\ttotal: 13.1s\tremaining: 8m 8s\n",
      "601:\tlearn: 10.5422891\ttotal: 13.1s\tremaining: 8m 8s\n",
      "602:\tlearn: 10.5389496\ttotal: 13.2s\tremaining: 8m 8s\n",
      "603:\tlearn: 10.5364170\ttotal: 13.2s\tremaining: 8m 8s\n",
      "604:\tlearn: 10.5325995\ttotal: 13.2s\tremaining: 8m 8s\n",
      "605:\tlearn: 10.5297408\ttotal: 13.2s\tremaining: 8m 8s\n",
      "606:\tlearn: 10.5252843\ttotal: 13.2s\tremaining: 8m 8s\n",
      "607:\tlearn: 10.5224606\ttotal: 13.2s\tremaining: 8m 7s\n",
      "608:\tlearn: 10.5197125\ttotal: 13.3s\tremaining: 8m 7s\n",
      "609:\tlearn: 10.5158253\ttotal: 13.3s\tremaining: 8m 7s\n",
      "610:\tlearn: 10.5107240\ttotal: 13.3s\tremaining: 8m 7s\n",
      "611:\tlearn: 10.5056174\ttotal: 13.3s\tremaining: 8m 7s\n",
      "612:\tlearn: 10.5002386\ttotal: 13.4s\tremaining: 8m 7s\n",
      "613:\tlearn: 10.4964033\ttotal: 13.4s\tremaining: 8m 7s\n",
      "614:\tlearn: 10.4926410\ttotal: 13.4s\tremaining: 8m 7s\n",
      "615:\tlearn: 10.4885363\ttotal: 13.4s\tremaining: 8m 7s\n",
      "616:\tlearn: 10.4846126\ttotal: 13.4s\tremaining: 8m 7s\n",
      "617:\tlearn: 10.4801907\ttotal: 13.4s\tremaining: 8m 7s\n",
      "618:\tlearn: 10.4747475\ttotal: 13.5s\tremaining: 8m 7s\n",
      "619:\tlearn: 10.4694860\ttotal: 13.5s\tremaining: 8m 7s\n",
      "620:\tlearn: 10.4646448\ttotal: 13.5s\tremaining: 8m 7s\n",
      "621:\tlearn: 10.4577058\ttotal: 13.5s\tremaining: 8m 7s\n",
      "622:\tlearn: 10.4546147\ttotal: 13.6s\tremaining: 8m 6s\n",
      "623:\tlearn: 10.4500452\ttotal: 13.6s\tremaining: 8m 7s\n",
      "624:\tlearn: 10.4428354\ttotal: 13.6s\tremaining: 8m 6s\n",
      "625:\tlearn: 10.4383892\ttotal: 13.6s\tremaining: 8m 6s\n",
      "626:\tlearn: 10.4352120\ttotal: 13.6s\tremaining: 8m 6s\n",
      "627:\tlearn: 10.4301055\ttotal: 13.7s\tremaining: 8m 6s\n",
      "628:\tlearn: 10.4260331\ttotal: 13.7s\tremaining: 8m 6s\n",
      "629:\tlearn: 10.4209562\ttotal: 13.7s\tremaining: 8m 6s\n",
      "630:\tlearn: 10.4164373\ttotal: 13.7s\tremaining: 8m 6s\n",
      "631:\tlearn: 10.4133064\ttotal: 13.7s\tremaining: 8m 6s\n",
      "632:\tlearn: 10.4087403\ttotal: 13.8s\tremaining: 8m 6s\n",
      "633:\tlearn: 10.4051252\ttotal: 13.8s\tremaining: 8m 6s\n",
      "634:\tlearn: 10.4014344\ttotal: 13.8s\tremaining: 8m 6s\n",
      "635:\tlearn: 10.3969919\ttotal: 13.8s\tremaining: 8m 6s\n",
      "636:\tlearn: 10.3922066\ttotal: 13.9s\tremaining: 8m 6s\n",
      "637:\tlearn: 10.3884500\ttotal: 13.9s\tremaining: 8m 6s\n",
      "638:\tlearn: 10.3851990\ttotal: 13.9s\tremaining: 8m 6s\n",
      "639:\tlearn: 10.3813593\ttotal: 13.9s\tremaining: 8m 6s\n",
      "640:\tlearn: 10.3774105\ttotal: 13.9s\tremaining: 8m 6s\n",
      "641:\tlearn: 10.3742690\ttotal: 14s\tremaining: 8m 6s\n",
      "642:\tlearn: 10.3705035\ttotal: 14s\tremaining: 8m 5s\n",
      "643:\tlearn: 10.3670032\ttotal: 14s\tremaining: 8m 5s\n",
      "644:\tlearn: 10.3624410\ttotal: 14s\tremaining: 8m 5s\n",
      "645:\tlearn: 10.3580605\ttotal: 14s\tremaining: 8m 5s\n",
      "646:\tlearn: 10.3544870\ttotal: 14.1s\tremaining: 8m 5s\n",
      "647:\tlearn: 10.3503527\ttotal: 14.1s\tremaining: 8m 5s\n",
      "648:\tlearn: 10.3478982\ttotal: 14.1s\tremaining: 8m 5s\n",
      "649:\tlearn: 10.3444057\ttotal: 14.1s\tremaining: 8m 5s\n",
      "650:\tlearn: 10.3413513\ttotal: 14.1s\tremaining: 8m 5s\n",
      "651:\tlearn: 10.3376832\ttotal: 14.2s\tremaining: 8m 5s\n",
      "652:\tlearn: 10.3328981\ttotal: 14.2s\tremaining: 8m 5s\n",
      "653:\tlearn: 10.3282564\ttotal: 14.2s\tremaining: 8m 5s\n",
      "654:\tlearn: 10.3252808\ttotal: 14.2s\tremaining: 8m 5s\n",
      "655:\tlearn: 10.3216515\ttotal: 14.2s\tremaining: 8m 4s\n",
      "656:\tlearn: 10.3175383\ttotal: 14.3s\tremaining: 8m 4s\n",
      "657:\tlearn: 10.3144146\ttotal: 14.3s\tremaining: 8m 4s\n",
      "658:\tlearn: 10.3098098\ttotal: 14.3s\tremaining: 8m 4s\n",
      "659:\tlearn: 10.3064513\ttotal: 14.3s\tremaining: 8m 4s\n",
      "660:\tlearn: 10.3025319\ttotal: 14.3s\tremaining: 8m 4s\n",
      "661:\tlearn: 10.2990886\ttotal: 14.4s\tremaining: 8m 4s\n",
      "662:\tlearn: 10.2958903\ttotal: 14.4s\tremaining: 8m 4s\n",
      "663:\tlearn: 10.2921478\ttotal: 14.4s\tremaining: 8m 4s\n",
      "664:\tlearn: 10.2874859\ttotal: 14.4s\tremaining: 8m 4s\n",
      "665:\tlearn: 10.2832346\ttotal: 14.4s\tremaining: 8m 4s\n",
      "666:\tlearn: 10.2800466\ttotal: 14.5s\tremaining: 8m 4s\n",
      "667:\tlearn: 10.2761574\ttotal: 14.5s\tremaining: 8m 4s\n",
      "668:\tlearn: 10.2713513\ttotal: 14.5s\tremaining: 8m 4s\n",
      "669:\tlearn: 10.2675455\ttotal: 14.5s\tremaining: 8m 3s\n",
      "670:\tlearn: 10.2634353\ttotal: 14.5s\tremaining: 8m 3s\n",
      "671:\tlearn: 10.2592755\ttotal: 14.6s\tremaining: 8m 3s\n",
      "672:\tlearn: 10.2548777\ttotal: 14.6s\tremaining: 8m 3s\n",
      "673:\tlearn: 10.2507009\ttotal: 14.6s\tremaining: 8m 3s\n",
      "674:\tlearn: 10.2465983\ttotal: 14.6s\tremaining: 8m 3s\n",
      "675:\tlearn: 10.2438924\ttotal: 14.6s\tremaining: 8m 3s\n",
      "676:\tlearn: 10.2395823\ttotal: 14.7s\tremaining: 8m 3s\n",
      "677:\tlearn: 10.2350614\ttotal: 14.7s\tremaining: 8m 3s\n",
      "678:\tlearn: 10.2310425\ttotal: 14.7s\tremaining: 8m 3s\n",
      "679:\tlearn: 10.2255373\ttotal: 14.7s\tremaining: 8m 3s\n",
      "680:\tlearn: 10.2230040\ttotal: 14.8s\tremaining: 8m 3s\n",
      "681:\tlearn: 10.2200497\ttotal: 14.8s\tremaining: 8m 3s\n",
      "682:\tlearn: 10.2148871\ttotal: 14.8s\tremaining: 8m 3s\n",
      "683:\tlearn: 10.2100914\ttotal: 14.8s\tremaining: 8m 3s\n",
      "684:\tlearn: 10.2077288\ttotal: 14.8s\tremaining: 8m 3s\n",
      "685:\tlearn: 10.2035748\ttotal: 14.9s\tremaining: 8m 3s\n",
      "686:\tlearn: 10.1977658\ttotal: 14.9s\tremaining: 8m 3s\n",
      "687:\tlearn: 10.1947619\ttotal: 14.9s\tremaining: 8m 3s\n",
      "688:\tlearn: 10.1907368\ttotal: 14.9s\tremaining: 8m 3s\n",
      "689:\tlearn: 10.1876725\ttotal: 14.9s\tremaining: 8m 3s\n",
      "690:\tlearn: 10.1847691\ttotal: 15s\tremaining: 8m 2s\n",
      "691:\tlearn: 10.1799697\ttotal: 15s\tremaining: 8m 2s\n",
      "692:\tlearn: 10.1771501\ttotal: 15s\tremaining: 8m 2s\n",
      "693:\tlearn: 10.1740064\ttotal: 15s\tremaining: 8m 2s\n",
      "694:\tlearn: 10.1693920\ttotal: 15s\tremaining: 8m 2s\n",
      "695:\tlearn: 10.1655605\ttotal: 15.1s\tremaining: 8m 2s\n",
      "696:\tlearn: 10.1612009\ttotal: 15.1s\tremaining: 8m 2s\n",
      "697:\tlearn: 10.1561788\ttotal: 15.1s\tremaining: 8m 2s\n",
      "698:\tlearn: 10.1525007\ttotal: 15.1s\tremaining: 8m 2s\n",
      "699:\tlearn: 10.1484699\ttotal: 15.2s\tremaining: 8m 2s\n",
      "700:\tlearn: 10.1444073\ttotal: 15.2s\tremaining: 8m 2s\n",
      "701:\tlearn: 10.1407494\ttotal: 15.2s\tremaining: 8m 2s\n",
      "702:\tlearn: 10.1370403\ttotal: 15.2s\tremaining: 8m 2s\n",
      "703:\tlearn: 10.1326910\ttotal: 15.2s\tremaining: 8m 2s\n",
      "704:\tlearn: 10.1300634\ttotal: 15.3s\tremaining: 8m 2s\n",
      "705:\tlearn: 10.1257115\ttotal: 15.3s\tremaining: 8m 2s\n",
      "706:\tlearn: 10.1208372\ttotal: 15.3s\tremaining: 8m 2s\n",
      "707:\tlearn: 10.1182957\ttotal: 15.3s\tremaining: 8m 2s\n",
      "708:\tlearn: 10.1149636\ttotal: 15.3s\tremaining: 8m 2s\n",
      "709:\tlearn: 10.1112342\ttotal: 15.4s\tremaining: 8m 2s\n",
      "710:\tlearn: 10.1070309\ttotal: 15.4s\tremaining: 8m 2s\n",
      "711:\tlearn: 10.1043331\ttotal: 15.4s\tremaining: 8m 2s\n",
      "712:\tlearn: 10.1012813\ttotal: 15.4s\tremaining: 8m 1s\n",
      "713:\tlearn: 10.0970717\ttotal: 15.4s\tremaining: 8m 2s\n",
      "714:\tlearn: 10.0938939\ttotal: 15.5s\tremaining: 8m 2s\n",
      "715:\tlearn: 10.0906216\ttotal: 15.5s\tremaining: 8m 1s\n",
      "716:\tlearn: 10.0878509\ttotal: 15.5s\tremaining: 8m 1s\n",
      "717:\tlearn: 10.0845550\ttotal: 15.5s\tremaining: 8m 1s\n",
      "718:\tlearn: 10.0822139\ttotal: 15.5s\tremaining: 8m 1s\n",
      "719:\tlearn: 10.0788743\ttotal: 15.6s\tremaining: 8m 1s\n",
      "720:\tlearn: 10.0762869\ttotal: 15.6s\tremaining: 8m 1s\n",
      "721:\tlearn: 10.0724533\ttotal: 15.6s\tremaining: 8m 1s\n",
      "722:\tlearn: 10.0687437\ttotal: 15.6s\tremaining: 8m 1s\n",
      "723:\tlearn: 10.0648275\ttotal: 15.6s\tremaining: 8m 1s\n",
      "724:\tlearn: 10.0590256\ttotal: 15.7s\tremaining: 8m 1s\n",
      "725:\tlearn: 10.0565796\ttotal: 15.7s\tremaining: 8m 1s\n",
      "726:\tlearn: 10.0535983\ttotal: 15.7s\tremaining: 8m 1s\n",
      "727:\tlearn: 10.0507005\ttotal: 15.7s\tremaining: 8m 1s\n",
      "728:\tlearn: 10.0466831\ttotal: 15.7s\tremaining: 8m 1s\n",
      "729:\tlearn: 10.0424601\ttotal: 15.8s\tremaining: 8m 1s\n",
      "730:\tlearn: 10.0386490\ttotal: 15.8s\tremaining: 8m 1s\n",
      "731:\tlearn: 10.0358818\ttotal: 15.8s\tremaining: 8m 1s\n",
      "732:\tlearn: 10.0334934\ttotal: 15.8s\tremaining: 8m\n",
      "733:\tlearn: 10.0289452\ttotal: 15.9s\tremaining: 8m 1s\n",
      "734:\tlearn: 10.0263476\ttotal: 15.9s\tremaining: 8m\n",
      "735:\tlearn: 10.0236551\ttotal: 15.9s\tremaining: 8m\n",
      "736:\tlearn: 10.0200162\ttotal: 15.9s\tremaining: 8m\n",
      "737:\tlearn: 10.0160753\ttotal: 15.9s\tremaining: 8m\n",
      "738:\tlearn: 10.0122846\ttotal: 16s\tremaining: 8m\n",
      "739:\tlearn: 10.0091280\ttotal: 16s\tremaining: 8m\n",
      "740:\tlearn: 10.0045383\ttotal: 16s\tremaining: 8m\n",
      "741:\tlearn: 10.0014538\ttotal: 16s\tremaining: 8m\n",
      "742:\tlearn: 9.9989892\ttotal: 16s\tremaining: 8m\n",
      "743:\tlearn: 9.9947790\ttotal: 16.1s\tremaining: 8m\n",
      "744:\tlearn: 9.9903217\ttotal: 16.1s\tremaining: 8m\n",
      "745:\tlearn: 9.9874667\ttotal: 16.1s\tremaining: 8m\n",
      "746:\tlearn: 9.9843725\ttotal: 16.1s\tremaining: 8m\n",
      "747:\tlearn: 9.9809660\ttotal: 16.1s\tremaining: 8m\n",
      "748:\tlearn: 9.9783342\ttotal: 16.2s\tremaining: 7m 59s\n",
      "749:\tlearn: 9.9746576\ttotal: 16.2s\tremaining: 7m 59s\n",
      "750:\tlearn: 9.9699505\ttotal: 16.2s\tremaining: 7m 59s\n",
      "751:\tlearn: 9.9670692\ttotal: 16.2s\tremaining: 7m 59s\n",
      "752:\tlearn: 9.9638545\ttotal: 16.2s\tremaining: 7m 59s\n",
      "753:\tlearn: 9.9610621\ttotal: 16.3s\tremaining: 7m 59s\n",
      "754:\tlearn: 9.9562093\ttotal: 16.3s\tremaining: 7m 59s\n",
      "755:\tlearn: 9.9533981\ttotal: 16.3s\tremaining: 7m 59s\n",
      "756:\tlearn: 9.9494751\ttotal: 16.3s\tremaining: 7m 59s\n",
      "757:\tlearn: 9.9453472\ttotal: 16.3s\tremaining: 7m 59s\n",
      "758:\tlearn: 9.9424327\ttotal: 16.4s\tremaining: 7m 59s\n",
      "759:\tlearn: 9.9383655\ttotal: 16.4s\tremaining: 7m 59s\n",
      "760:\tlearn: 9.9348848\ttotal: 16.4s\tremaining: 7m 59s\n",
      "761:\tlearn: 9.9314368\ttotal: 16.4s\tremaining: 7m 59s\n",
      "762:\tlearn: 9.9286924\ttotal: 16.4s\tremaining: 7m 59s\n",
      "763:\tlearn: 9.9253347\ttotal: 16.5s\tremaining: 7m 58s\n",
      "764:\tlearn: 9.9213070\ttotal: 16.5s\tremaining: 7m 58s\n",
      "765:\tlearn: 9.9188184\ttotal: 16.5s\tremaining: 7m 58s\n",
      "766:\tlearn: 9.9161064\ttotal: 16.5s\tremaining: 7m 58s\n",
      "767:\tlearn: 9.9125992\ttotal: 16.5s\tremaining: 7m 58s\n",
      "768:\tlearn: 9.9092461\ttotal: 16.6s\tremaining: 7m 58s\n",
      "769:\tlearn: 9.9065612\ttotal: 16.6s\tremaining: 7m 58s\n",
      "770:\tlearn: 9.9026399\ttotal: 16.6s\tremaining: 7m 58s\n",
      "771:\tlearn: 9.8984560\ttotal: 16.6s\tremaining: 7m 58s\n",
      "772:\tlearn: 9.8952159\ttotal: 16.6s\tremaining: 7m 58s\n",
      "773:\tlearn: 9.8918699\ttotal: 16.7s\tremaining: 7m 58s\n",
      "774:\tlearn: 9.8892372\ttotal: 16.7s\tremaining: 7m 58s\n",
      "775:\tlearn: 9.8849995\ttotal: 16.7s\tremaining: 7m 58s\n",
      "776:\tlearn: 9.8826687\ttotal: 16.7s\tremaining: 7m 58s\n",
      "777:\tlearn: 9.8777480\ttotal: 16.8s\tremaining: 7m 58s\n",
      "778:\tlearn: 9.8735738\ttotal: 16.8s\tremaining: 7m 58s\n",
      "779:\tlearn: 9.8709322\ttotal: 16.8s\tremaining: 7m 58s\n",
      "780:\tlearn: 9.8670263\ttotal: 16.8s\tremaining: 7m 58s\n",
      "781:\tlearn: 9.8624574\ttotal: 16.8s\tremaining: 7m 58s\n",
      "782:\tlearn: 9.8592173\ttotal: 16.9s\tremaining: 7m 58s\n",
      "783:\tlearn: 9.8564357\ttotal: 16.9s\tremaining: 7m 58s\n",
      "784:\tlearn: 9.8532824\ttotal: 16.9s\tremaining: 7m 58s\n",
      "785:\tlearn: 9.8492637\ttotal: 16.9s\tremaining: 7m 58s\n",
      "786:\tlearn: 9.8457966\ttotal: 16.9s\tremaining: 7m 58s\n",
      "787:\tlearn: 9.8420519\ttotal: 17s\tremaining: 7m 58s\n",
      "788:\tlearn: 9.8394856\ttotal: 17s\tremaining: 7m 57s\n",
      "789:\tlearn: 9.8349221\ttotal: 17s\tremaining: 7m 57s\n",
      "790:\tlearn: 9.8303277\ttotal: 17s\tremaining: 7m 58s\n",
      "791:\tlearn: 9.8273495\ttotal: 17s\tremaining: 7m 57s\n",
      "792:\tlearn: 9.8247889\ttotal: 17.1s\tremaining: 7m 57s\n",
      "793:\tlearn: 9.8222925\ttotal: 17.1s\tremaining: 7m 57s\n",
      "794:\tlearn: 9.8194018\ttotal: 17.1s\tremaining: 7m 57s\n",
      "795:\tlearn: 9.8172027\ttotal: 17.1s\tremaining: 7m 57s\n",
      "796:\tlearn: 9.8144379\ttotal: 17.1s\tremaining: 7m 57s\n",
      "797:\tlearn: 9.8093900\ttotal: 17.2s\tremaining: 7m 57s\n",
      "798:\tlearn: 9.8076774\ttotal: 17.2s\tremaining: 7m 57s\n",
      "799:\tlearn: 9.8045939\ttotal: 17.2s\tremaining: 7m 57s\n",
      "800:\tlearn: 9.8004440\ttotal: 17.2s\tremaining: 7m 57s\n",
      "801:\tlearn: 9.7959289\ttotal: 17.2s\tremaining: 7m 57s\n",
      "802:\tlearn: 9.7912572\ttotal: 17.3s\tremaining: 7m 57s\n",
      "803:\tlearn: 9.7890124\ttotal: 17.3s\tremaining: 7m 57s\n",
      "804:\tlearn: 9.7847047\ttotal: 17.3s\tremaining: 7m 57s\n",
      "805:\tlearn: 9.7811314\ttotal: 17.3s\tremaining: 7m 57s\n",
      "806:\tlearn: 9.7767619\ttotal: 17.4s\tremaining: 7m 57s\n",
      "807:\tlearn: 9.7735596\ttotal: 17.4s\tremaining: 7m 57s\n",
      "808:\tlearn: 9.7711035\ttotal: 17.4s\tremaining: 7m 57s\n",
      "809:\tlearn: 9.7686254\ttotal: 17.4s\tremaining: 7m 57s\n",
      "810:\tlearn: 9.7641700\ttotal: 17.4s\tremaining: 7m 57s\n",
      "811:\tlearn: 9.7618862\ttotal: 17.5s\tremaining: 7m 57s\n",
      "812:\tlearn: 9.7591927\ttotal: 17.5s\tremaining: 7m 56s\n",
      "813:\tlearn: 9.7568461\ttotal: 17.5s\tremaining: 7m 56s\n",
      "814:\tlearn: 9.7534101\ttotal: 17.5s\tremaining: 7m 56s\n",
      "815:\tlearn: 9.7495271\ttotal: 17.5s\tremaining: 7m 56s\n",
      "816:\tlearn: 9.7453850\ttotal: 17.6s\tremaining: 7m 56s\n",
      "817:\tlearn: 9.7425945\ttotal: 17.6s\tremaining: 7m 56s\n",
      "818:\tlearn: 9.7387883\ttotal: 17.6s\tremaining: 7m 56s\n",
      "819:\tlearn: 9.7363059\ttotal: 17.6s\tremaining: 7m 56s\n",
      "820:\tlearn: 9.7333352\ttotal: 17.6s\tremaining: 7m 56s\n",
      "821:\tlearn: 9.7304030\ttotal: 17.7s\tremaining: 7m 56s\n",
      "822:\tlearn: 9.7282560\ttotal: 17.7s\tremaining: 7m 56s\n",
      "823:\tlearn: 9.7260459\ttotal: 17.7s\tremaining: 7m 56s\n",
      "824:\tlearn: 9.7230574\ttotal: 17.7s\tremaining: 7m 56s\n",
      "825:\tlearn: 9.7205082\ttotal: 17.7s\tremaining: 7m 56s\n",
      "826:\tlearn: 9.7163846\ttotal: 17.8s\tremaining: 7m 56s\n",
      "827:\tlearn: 9.7141250\ttotal: 17.8s\tremaining: 7m 56s\n",
      "828:\tlearn: 9.7119549\ttotal: 17.8s\tremaining: 7m 56s\n",
      "829:\tlearn: 9.7096310\ttotal: 17.8s\tremaining: 7m 56s\n",
      "830:\tlearn: 9.7063863\ttotal: 17.8s\tremaining: 7m 56s\n",
      "831:\tlearn: 9.7031190\ttotal: 17.9s\tremaining: 7m 55s\n",
      "832:\tlearn: 9.7009837\ttotal: 17.9s\tremaining: 7m 55s\n",
      "833:\tlearn: 9.6977667\ttotal: 17.9s\tremaining: 7m 55s\n",
      "834:\tlearn: 9.6937532\ttotal: 17.9s\tremaining: 7m 55s\n",
      "835:\tlearn: 9.6903959\ttotal: 17.9s\tremaining: 7m 55s\n",
      "836:\tlearn: 9.6864932\ttotal: 18s\tremaining: 7m 55s\n",
      "837:\tlearn: 9.6841637\ttotal: 18s\tremaining: 7m 55s\n",
      "838:\tlearn: 9.6804508\ttotal: 18s\tremaining: 7m 55s\n",
      "839:\tlearn: 9.6768090\ttotal: 18s\tremaining: 7m 55s\n",
      "840:\tlearn: 9.6735306\ttotal: 18.1s\tremaining: 7m 55s\n",
      "841:\tlearn: 9.6698181\ttotal: 18.1s\tremaining: 7m 55s\n",
      "842:\tlearn: 9.6670586\ttotal: 18.1s\tremaining: 7m 55s\n",
      "843:\tlearn: 9.6643204\ttotal: 18.1s\tremaining: 7m 55s\n",
      "844:\tlearn: 9.6612725\ttotal: 18.1s\tremaining: 7m 55s\n",
      "845:\tlearn: 9.6578746\ttotal: 18.2s\tremaining: 7m 55s\n",
      "846:\tlearn: 9.6543428\ttotal: 18.2s\tremaining: 7m 55s\n",
      "847:\tlearn: 9.6522986\ttotal: 18.2s\tremaining: 7m 55s\n",
      "848:\tlearn: 9.6485923\ttotal: 18.2s\tremaining: 7m 55s\n",
      "849:\tlearn: 9.6460628\ttotal: 18.2s\tremaining: 7m 55s\n",
      "850:\tlearn: 9.6429366\ttotal: 18.3s\tremaining: 7m 55s\n",
      "851:\tlearn: 9.6384286\ttotal: 18.3s\tremaining: 7m 55s\n",
      "852:\tlearn: 9.6343512\ttotal: 18.3s\tremaining: 7m 55s\n",
      "853:\tlearn: 9.6313288\ttotal: 18.3s\tremaining: 7m 55s\n",
      "854:\tlearn: 9.6289114\ttotal: 18.3s\tremaining: 7m 55s\n",
      "855:\tlearn: 9.6255837\ttotal: 18.4s\tremaining: 7m 55s\n",
      "856:\tlearn: 9.6226059\ttotal: 18.4s\tremaining: 7m 55s\n",
      "857:\tlearn: 9.6202513\ttotal: 18.4s\tremaining: 7m 55s\n",
      "858:\tlearn: 9.6171852\ttotal: 18.4s\tremaining: 7m 54s\n",
      "859:\tlearn: 9.6141386\ttotal: 18.4s\tremaining: 7m 54s\n",
      "860:\tlearn: 9.6121993\ttotal: 18.5s\tremaining: 7m 54s\n",
      "861:\tlearn: 9.6099721\ttotal: 18.5s\tremaining: 7m 54s\n",
      "862:\tlearn: 9.6069641\ttotal: 18.5s\tremaining: 7m 54s\n",
      "863:\tlearn: 9.6039025\ttotal: 18.5s\tremaining: 7m 54s\n",
      "864:\tlearn: 9.6003503\ttotal: 18.5s\tremaining: 7m 54s\n",
      "865:\tlearn: 9.5961562\ttotal: 18.6s\tremaining: 7m 54s\n",
      "866:\tlearn: 9.5940595\ttotal: 18.6s\tremaining: 7m 54s\n",
      "867:\tlearn: 9.5914100\ttotal: 18.6s\tremaining: 7m 54s\n",
      "868:\tlearn: 9.5874381\ttotal: 18.6s\tremaining: 7m 54s\n",
      "869:\tlearn: 9.5847198\ttotal: 18.7s\tremaining: 7m 54s\n",
      "870:\tlearn: 9.5808147\ttotal: 18.7s\tremaining: 7m 54s\n",
      "871:\tlearn: 9.5781569\ttotal: 18.7s\tremaining: 7m 54s\n",
      "872:\tlearn: 9.5756274\ttotal: 18.7s\tremaining: 7m 54s\n",
      "873:\tlearn: 9.5720502\ttotal: 18.7s\tremaining: 7m 54s\n",
      "874:\tlearn: 9.5697504\ttotal: 18.8s\tremaining: 7m 54s\n",
      "875:\tlearn: 9.5658692\ttotal: 18.8s\tremaining: 7m 54s\n",
      "876:\tlearn: 9.5634996\ttotal: 18.8s\tremaining: 7m 54s\n",
      "877:\tlearn: 9.5608834\ttotal: 18.8s\tremaining: 7m 54s\n",
      "878:\tlearn: 9.5580411\ttotal: 18.8s\tremaining: 7m 54s\n",
      "879:\tlearn: 9.5543533\ttotal: 18.9s\tremaining: 7m 54s\n",
      "880:\tlearn: 9.5513591\ttotal: 18.9s\tremaining: 7m 54s\n",
      "881:\tlearn: 9.5491337\ttotal: 18.9s\tremaining: 7m 54s\n",
      "882:\tlearn: 9.5454164\ttotal: 18.9s\tremaining: 7m 54s\n",
      "883:\tlearn: 9.5433925\ttotal: 19s\tremaining: 7m 54s\n",
      "884:\tlearn: 9.5409671\ttotal: 19s\tremaining: 7m 54s\n",
      "885:\tlearn: 9.5374994\ttotal: 19s\tremaining: 7m 54s\n",
      "886:\tlearn: 9.5336293\ttotal: 19s\tremaining: 7m 54s\n",
      "887:\tlearn: 9.5316462\ttotal: 19s\tremaining: 7m 53s\n",
      "888:\tlearn: 9.5286158\ttotal: 19.1s\tremaining: 7m 54s\n",
      "889:\tlearn: 9.5257661\ttotal: 19.1s\tremaining: 7m 53s\n",
      "890:\tlearn: 9.5224206\ttotal: 19.1s\tremaining: 7m 53s\n",
      "891:\tlearn: 9.5197643\ttotal: 19.1s\tremaining: 7m 53s\n",
      "892:\tlearn: 9.5168880\ttotal: 19.1s\tremaining: 7m 53s\n",
      "893:\tlearn: 9.5137807\ttotal: 19.2s\tremaining: 7m 53s\n",
      "894:\tlearn: 9.5115986\ttotal: 19.2s\tremaining: 7m 53s\n",
      "895:\tlearn: 9.5081394\ttotal: 19.2s\tremaining: 7m 53s\n",
      "896:\tlearn: 9.5041416\ttotal: 19.2s\tremaining: 7m 53s\n",
      "897:\tlearn: 9.5022299\ttotal: 19.2s\tremaining: 7m 53s\n",
      "898:\tlearn: 9.4994878\ttotal: 19.3s\tremaining: 7m 53s\n",
      "899:\tlearn: 9.4964254\ttotal: 19.3s\tremaining: 7m 53s\n",
      "900:\tlearn: 9.4930377\ttotal: 19.3s\tremaining: 7m 53s\n",
      "901:\tlearn: 9.4906272\ttotal: 19.3s\tremaining: 7m 53s\n",
      "902:\tlearn: 9.4881341\ttotal: 19.3s\tremaining: 7m 53s\n",
      "903:\tlearn: 9.4850588\ttotal: 19.4s\tremaining: 7m 53s\n",
      "904:\tlearn: 9.4826524\ttotal: 19.4s\tremaining: 7m 53s\n",
      "905:\tlearn: 9.4805691\ttotal: 19.4s\tremaining: 7m 53s\n",
      "906:\tlearn: 9.4777731\ttotal: 19.4s\tremaining: 7m 53s\n",
      "907:\tlearn: 9.4749235\ttotal: 19.4s\tremaining: 7m 52s\n",
      "908:\tlearn: 9.4727983\ttotal: 19.5s\tremaining: 7m 52s\n",
      "909:\tlearn: 9.4705416\ttotal: 19.5s\tremaining: 7m 52s\n",
      "910:\tlearn: 9.4679981\ttotal: 19.5s\tremaining: 7m 52s\n",
      "911:\tlearn: 9.4640992\ttotal: 19.5s\tremaining: 7m 52s\n",
      "912:\tlearn: 9.4597245\ttotal: 19.5s\tremaining: 7m 52s\n",
      "913:\tlearn: 9.4574365\ttotal: 19.6s\tremaining: 7m 52s\n",
      "914:\tlearn: 9.4556432\ttotal: 19.6s\tremaining: 7m 52s\n",
      "915:\tlearn: 9.4528597\ttotal: 19.6s\tremaining: 7m 52s\n",
      "916:\tlearn: 9.4505584\ttotal: 19.6s\tremaining: 7m 52s\n",
      "917:\tlearn: 9.4473707\ttotal: 19.6s\tremaining: 7m 52s\n",
      "918:\tlearn: 9.4431488\ttotal: 19.7s\tremaining: 7m 52s\n",
      "919:\tlearn: 9.4396345\ttotal: 19.7s\tremaining: 7m 52s\n",
      "920:\tlearn: 9.4372951\ttotal: 19.7s\tremaining: 7m 52s\n",
      "921:\tlearn: 9.4338298\ttotal: 19.7s\tremaining: 7m 52s\n",
      "922:\tlearn: 9.4304149\ttotal: 19.7s\tremaining: 7m 52s\n",
      "923:\tlearn: 9.4280639\ttotal: 19.8s\tremaining: 7m 52s\n",
      "924:\tlearn: 9.4254279\ttotal: 19.8s\tremaining: 7m 52s\n",
      "925:\tlearn: 9.4215036\ttotal: 19.8s\tremaining: 7m 52s\n",
      "926:\tlearn: 9.4195289\ttotal: 19.8s\tremaining: 7m 52s\n",
      "927:\tlearn: 9.4162336\ttotal: 19.9s\tremaining: 7m 52s\n",
      "928:\tlearn: 9.4136953\ttotal: 19.9s\tremaining: 7m 52s\n",
      "929:\tlearn: 9.4093931\ttotal: 19.9s\tremaining: 7m 52s\n",
      "930:\tlearn: 9.4069678\ttotal: 19.9s\tremaining: 7m 52s\n",
      "931:\tlearn: 9.4049435\ttotal: 19.9s\tremaining: 7m 52s\n",
      "932:\tlearn: 9.4023072\ttotal: 20s\tremaining: 7m 52s\n",
      "933:\tlearn: 9.4000804\ttotal: 20s\tremaining: 7m 51s\n",
      "934:\tlearn: 9.3975475\ttotal: 20s\tremaining: 7m 52s\n",
      "935:\tlearn: 9.3939808\ttotal: 20s\tremaining: 7m 52s\n",
      "936:\tlearn: 9.3913036\ttotal: 20s\tremaining: 7m 51s\n",
      "937:\tlearn: 9.3878776\ttotal: 20.1s\tremaining: 7m 52s\n",
      "938:\tlearn: 9.3831790\ttotal: 20.1s\tremaining: 7m 51s\n",
      "939:\tlearn: 9.3795804\ttotal: 20.1s\tremaining: 7m 51s\n",
      "940:\tlearn: 9.3763759\ttotal: 20.1s\tremaining: 7m 51s\n",
      "941:\tlearn: 9.3740538\ttotal: 20.2s\tremaining: 7m 51s\n",
      "942:\tlearn: 9.3702388\ttotal: 20.2s\tremaining: 7m 51s\n",
      "943:\tlearn: 9.3673986\ttotal: 20.2s\tremaining: 7m 51s\n",
      "944:\tlearn: 9.3643741\ttotal: 20.2s\tremaining: 7m 51s\n",
      "945:\tlearn: 9.3627014\ttotal: 20.2s\tremaining: 7m 51s\n",
      "946:\tlearn: 9.3605955\ttotal: 20.3s\tremaining: 7m 51s\n",
      "947:\tlearn: 9.3577302\ttotal: 20.3s\tremaining: 7m 51s\n",
      "948:\tlearn: 9.3554599\ttotal: 20.3s\tremaining: 7m 51s\n",
      "949:\tlearn: 9.3526836\ttotal: 20.3s\tremaining: 7m 51s\n",
      "950:\tlearn: 9.3490228\ttotal: 20.3s\tremaining: 7m 51s\n",
      "951:\tlearn: 9.3453791\ttotal: 20.4s\tremaining: 7m 51s\n",
      "952:\tlearn: 9.3426803\ttotal: 20.4s\tremaining: 7m 51s\n",
      "953:\tlearn: 9.3392419\ttotal: 20.4s\tremaining: 7m 51s\n",
      "954:\tlearn: 9.3355810\ttotal: 20.4s\tremaining: 7m 51s\n",
      "955:\tlearn: 9.3326472\ttotal: 20.5s\tremaining: 7m 51s\n",
      "956:\tlearn: 9.3296868\ttotal: 20.5s\tremaining: 7m 51s\n",
      "957:\tlearn: 9.3277386\ttotal: 20.5s\tremaining: 7m 51s\n",
      "958:\tlearn: 9.3245455\ttotal: 20.5s\tremaining: 7m 51s\n",
      "959:\tlearn: 9.3223726\ttotal: 20.5s\tremaining: 7m 51s\n",
      "960:\tlearn: 9.3197090\ttotal: 20.6s\tremaining: 7m 51s\n",
      "961:\tlearn: 9.3174587\ttotal: 20.6s\tremaining: 7m 51s\n",
      "962:\tlearn: 9.3138113\ttotal: 20.6s\tremaining: 7m 51s\n",
      "963:\tlearn: 9.3116994\ttotal: 20.6s\tremaining: 7m 51s\n",
      "964:\tlearn: 9.3094619\ttotal: 20.7s\tremaining: 7m 51s\n",
      "965:\tlearn: 9.3075755\ttotal: 20.7s\tremaining: 7m 51s\n",
      "966:\tlearn: 9.3038869\ttotal: 20.7s\tremaining: 7m 51s\n",
      "967:\tlearn: 9.3000408\ttotal: 20.7s\tremaining: 7m 51s\n",
      "968:\tlearn: 9.2970190\ttotal: 20.8s\tremaining: 7m 51s\n",
      "969:\tlearn: 9.2935700\ttotal: 20.8s\tremaining: 7m 52s\n",
      "970:\tlearn: 9.2915423\ttotal: 20.8s\tremaining: 7m 52s\n",
      "971:\tlearn: 9.2894874\ttotal: 20.8s\tremaining: 7m 52s\n",
      "972:\tlearn: 9.2859803\ttotal: 20.9s\tremaining: 7m 52s\n",
      "973:\tlearn: 9.2825340\ttotal: 20.9s\tremaining: 7m 52s\n",
      "974:\tlearn: 9.2805293\ttotal: 20.9s\tremaining: 7m 52s\n",
      "975:\tlearn: 9.2773287\ttotal: 20.9s\tremaining: 7m 52s\n",
      "976:\tlearn: 9.2752547\ttotal: 21s\tremaining: 7m 52s\n",
      "977:\tlearn: 9.2714870\ttotal: 21s\tremaining: 7m 52s\n",
      "978:\tlearn: 9.2696023\ttotal: 21s\tremaining: 7m 52s\n",
      "979:\tlearn: 9.2678922\ttotal: 21s\tremaining: 7m 52s\n",
      "980:\tlearn: 9.2636339\ttotal: 21s\tremaining: 7m 52s\n",
      "981:\tlearn: 9.2606645\ttotal: 21.1s\tremaining: 7m 52s\n",
      "982:\tlearn: 9.2574113\ttotal: 21.1s\tremaining: 7m 52s\n",
      "983:\tlearn: 9.2552590\ttotal: 21.1s\tremaining: 7m 52s\n",
      "984:\tlearn: 9.2531252\ttotal: 21.1s\tremaining: 7m 52s\n",
      "985:\tlearn: 9.2509417\ttotal: 21.2s\tremaining: 7m 52s\n",
      "986:\tlearn: 9.2483761\ttotal: 21.2s\tremaining: 7m 52s\n",
      "987:\tlearn: 9.2463541\ttotal: 21.2s\tremaining: 7m 52s\n",
      "988:\tlearn: 9.2437419\ttotal: 21.2s\tremaining: 7m 52s\n",
      "989:\tlearn: 9.2409436\ttotal: 21.2s\tremaining: 7m 52s\n",
      "990:\tlearn: 9.2385239\ttotal: 21.3s\tremaining: 7m 52s\n",
      "991:\tlearn: 9.2362795\ttotal: 21.3s\tremaining: 7m 52s\n",
      "992:\tlearn: 9.2332460\ttotal: 21.3s\tremaining: 7m 52s\n",
      "993:\tlearn: 9.2304644\ttotal: 21.3s\tremaining: 7m 52s\n",
      "994:\tlearn: 9.2277769\ttotal: 21.4s\tremaining: 7m 52s\n",
      "995:\tlearn: 9.2243210\ttotal: 21.4s\tremaining: 7m 52s\n",
      "996:\tlearn: 9.2226967\ttotal: 21.4s\tremaining: 7m 52s\n",
      "997:\tlearn: 9.2208745\ttotal: 21.4s\tremaining: 7m 52s\n",
      "998:\tlearn: 9.2173345\ttotal: 21.4s\tremaining: 7m 52s\n",
      "999:\tlearn: 9.2142693\ttotal: 21.5s\tremaining: 7m 52s\n",
      "1000:\tlearn: 9.2120843\ttotal: 21.5s\tremaining: 7m 52s\n",
      "1001:\tlearn: 9.2092612\ttotal: 21.5s\tremaining: 7m 52s\n",
      "1002:\tlearn: 9.2068112\ttotal: 21.5s\tremaining: 7m 52s\n",
      "1003:\tlearn: 9.2033959\ttotal: 21.5s\tremaining: 7m 52s\n",
      "1004:\tlearn: 9.2002001\ttotal: 21.6s\tremaining: 7m 52s\n",
      "1005:\tlearn: 9.1973850\ttotal: 21.6s\tremaining: 7m 52s\n",
      "1006:\tlearn: 9.1938775\ttotal: 21.6s\tremaining: 7m 52s\n",
      "1007:\tlearn: 9.1914240\ttotal: 21.6s\tremaining: 7m 51s\n",
      "1008:\tlearn: 9.1885990\ttotal: 21.7s\tremaining: 7m 51s\n",
      "1009:\tlearn: 9.1842288\ttotal: 21.7s\tremaining: 7m 52s\n",
      "1010:\tlearn: 9.1814267\ttotal: 21.7s\tremaining: 7m 51s\n",
      "1011:\tlearn: 9.1783575\ttotal: 21.7s\tremaining: 7m 51s\n",
      "1012:\tlearn: 9.1767613\ttotal: 21.7s\tremaining: 7m 51s\n",
      "1013:\tlearn: 9.1742932\ttotal: 21.8s\tremaining: 7m 51s\n",
      "1014:\tlearn: 9.1717698\ttotal: 21.8s\tremaining: 7m 51s\n",
      "1015:\tlearn: 9.1683133\ttotal: 21.8s\tremaining: 7m 51s\n",
      "1016:\tlearn: 9.1663516\ttotal: 21.8s\tremaining: 7m 51s\n",
      "1017:\tlearn: 9.1629210\ttotal: 21.9s\tremaining: 7m 51s\n",
      "1018:\tlearn: 9.1601127\ttotal: 21.9s\tremaining: 7m 51s\n",
      "1019:\tlearn: 9.1583042\ttotal: 21.9s\tremaining: 7m 51s\n",
      "1020:\tlearn: 9.1563440\ttotal: 21.9s\tremaining: 7m 51s\n",
      "1021:\tlearn: 9.1542384\ttotal: 21.9s\tremaining: 7m 51s\n",
      "1022:\tlearn: 9.1523036\ttotal: 22s\tremaining: 7m 51s\n",
      "1023:\tlearn: 9.1499668\ttotal: 22s\tremaining: 7m 51s\n",
      "1024:\tlearn: 9.1478502\ttotal: 22s\tremaining: 7m 51s\n",
      "1025:\tlearn: 9.1449733\ttotal: 22s\tremaining: 7m 51s\n",
      "1026:\tlearn: 9.1425655\ttotal: 22s\tremaining: 7m 51s\n",
      "1027:\tlearn: 9.1386403\ttotal: 22.1s\tremaining: 7m 51s\n",
      "1028:\tlearn: 9.1362442\ttotal: 22.1s\tremaining: 7m 51s\n",
      "1029:\tlearn: 9.1327633\ttotal: 22.1s\tremaining: 7m 51s\n",
      "1030:\tlearn: 9.1301204\ttotal: 22.1s\tremaining: 7m 51s\n",
      "1031:\tlearn: 9.1280928\ttotal: 22.2s\tremaining: 7m 51s\n",
      "1032:\tlearn: 9.1254533\ttotal: 22.2s\tremaining: 7m 51s\n",
      "1033:\tlearn: 9.1236471\ttotal: 22.2s\tremaining: 7m 51s\n",
      "1034:\tlearn: 9.1216560\ttotal: 22.2s\tremaining: 7m 51s\n",
      "1035:\tlearn: 9.1191522\ttotal: 22.2s\tremaining: 7m 51s\n",
      "1036:\tlearn: 9.1166268\ttotal: 22.3s\tremaining: 7m 51s\n",
      "1037:\tlearn: 9.1145623\ttotal: 22.3s\tremaining: 7m 51s\n",
      "1038:\tlearn: 9.1119314\ttotal: 22.3s\tremaining: 7m 51s\n",
      "1039:\tlearn: 9.1090913\ttotal: 22.3s\tremaining: 7m 51s\n",
      "1040:\tlearn: 9.1064309\ttotal: 22.3s\tremaining: 7m 51s\n",
      "1041:\tlearn: 9.1037108\ttotal: 22.4s\tremaining: 7m 51s\n",
      "1042:\tlearn: 9.1010544\ttotal: 22.4s\tremaining: 7m 51s\n",
      "1043:\tlearn: 9.0991900\ttotal: 22.4s\tremaining: 7m 51s\n",
      "1044:\tlearn: 9.0966710\ttotal: 22.4s\tremaining: 7m 51s\n",
      "1045:\tlearn: 9.0935493\ttotal: 22.4s\tremaining: 7m 51s\n",
      "1046:\tlearn: 9.0914659\ttotal: 22.5s\tremaining: 7m 51s\n",
      "1047:\tlearn: 9.0892133\ttotal: 22.5s\tremaining: 7m 51s\n",
      "1048:\tlearn: 9.0867708\ttotal: 22.5s\tremaining: 7m 51s\n",
      "1049:\tlearn: 9.0846364\ttotal: 22.5s\tremaining: 7m 51s\n",
      "1050:\tlearn: 9.0826892\ttotal: 22.6s\tremaining: 7m 50s\n",
      "1051:\tlearn: 9.0805015\ttotal: 22.6s\tremaining: 7m 50s\n",
      "1052:\tlearn: 9.0779837\ttotal: 22.6s\tremaining: 7m 50s\n",
      "1053:\tlearn: 9.0756028\ttotal: 22.6s\tremaining: 7m 50s\n",
      "1054:\tlearn: 9.0739438\ttotal: 22.6s\tremaining: 7m 50s\n",
      "1055:\tlearn: 9.0719868\ttotal: 22.7s\tremaining: 7m 50s\n",
      "1056:\tlearn: 9.0703720\ttotal: 22.7s\tremaining: 7m 50s\n",
      "1057:\tlearn: 9.0677824\ttotal: 22.7s\tremaining: 7m 50s\n",
      "1058:\tlearn: 9.0660328\ttotal: 22.7s\tremaining: 7m 50s\n",
      "1059:\tlearn: 9.0646001\ttotal: 22.7s\tremaining: 7m 50s\n",
      "1060:\tlearn: 9.0609904\ttotal: 22.8s\tremaining: 7m 50s\n",
      "1061:\tlearn: 9.0587242\ttotal: 22.8s\tremaining: 7m 50s\n",
      "1062:\tlearn: 9.0550006\ttotal: 22.8s\tremaining: 7m 50s\n",
      "1063:\tlearn: 9.0525521\ttotal: 22.8s\tremaining: 7m 50s\n",
      "1064:\tlearn: 9.0502248\ttotal: 22.9s\tremaining: 7m 50s\n",
      "1065:\tlearn: 9.0470358\ttotal: 22.9s\tremaining: 7m 50s\n",
      "1066:\tlearn: 9.0442023\ttotal: 22.9s\tremaining: 7m 51s\n",
      "1067:\tlearn: 9.0419051\ttotal: 22.9s\tremaining: 7m 51s\n",
      "1068:\tlearn: 9.0392035\ttotal: 23s\tremaining: 7m 51s\n",
      "1069:\tlearn: 9.0368187\ttotal: 23s\tremaining: 7m 51s\n",
      "1070:\tlearn: 9.0353131\ttotal: 23s\tremaining: 7m 51s\n",
      "1071:\tlearn: 9.0337039\ttotal: 23s\tremaining: 7m 51s\n",
      "1072:\tlearn: 9.0313822\ttotal: 23s\tremaining: 7m 50s\n",
      "1073:\tlearn: 9.0295842\ttotal: 23.1s\tremaining: 7m 50s\n",
      "1074:\tlearn: 9.0260481\ttotal: 23.1s\tremaining: 7m 50s\n",
      "1075:\tlearn: 9.0238970\ttotal: 23.1s\tremaining: 7m 50s\n",
      "1076:\tlearn: 9.0217326\ttotal: 23.1s\tremaining: 7m 50s\n",
      "1077:\tlearn: 9.0190980\ttotal: 23.2s\tremaining: 7m 50s\n",
      "1078:\tlearn: 9.0169010\ttotal: 23.2s\tremaining: 7m 50s\n",
      "1079:\tlearn: 9.0145942\ttotal: 23.2s\tremaining: 7m 50s\n",
      "1080:\tlearn: 9.0117692\ttotal: 23.2s\tremaining: 7m 50s\n",
      "1081:\tlearn: 9.0089761\ttotal: 23.3s\tremaining: 7m 51s\n",
      "1082:\tlearn: 9.0072840\ttotal: 23.3s\tremaining: 7m 51s\n",
      "1083:\tlearn: 9.0050351\ttotal: 23.3s\tremaining: 7m 51s\n",
      "1084:\tlearn: 9.0032278\ttotal: 23.3s\tremaining: 7m 51s\n",
      "1085:\tlearn: 9.0008249\ttotal: 23.3s\tremaining: 7m 51s\n",
      "1086:\tlearn: 8.9986490\ttotal: 23.4s\tremaining: 7m 51s\n",
      "1087:\tlearn: 8.9958240\ttotal: 23.4s\tremaining: 7m 51s\n",
      "1088:\tlearn: 8.9934694\ttotal: 23.4s\tremaining: 7m 51s\n",
      "1089:\tlearn: 8.9914402\ttotal: 23.4s\tremaining: 7m 51s\n",
      "1090:\tlearn: 8.9887910\ttotal: 23.5s\tremaining: 7m 51s\n",
      "1091:\tlearn: 8.9866647\ttotal: 23.5s\tremaining: 7m 51s\n",
      "1092:\tlearn: 8.9841247\ttotal: 23.5s\tremaining: 7m 51s\n",
      "1093:\tlearn: 8.9810915\ttotal: 23.5s\tremaining: 7m 51s\n",
      "1094:\tlearn: 8.9793493\ttotal: 23.6s\tremaining: 7m 51s\n",
      "1095:\tlearn: 8.9778085\ttotal: 23.6s\tremaining: 7m 51s\n",
      "1096:\tlearn: 8.9757975\ttotal: 23.6s\tremaining: 7m 51s\n",
      "1097:\tlearn: 8.9734983\ttotal: 23.6s\tremaining: 7m 51s\n",
      "1098:\tlearn: 8.9711518\ttotal: 23.6s\tremaining: 7m 51s\n",
      "1099:\tlearn: 8.9690865\ttotal: 23.7s\tremaining: 7m 51s\n",
      "1100:\tlearn: 8.9665266\ttotal: 23.7s\tremaining: 7m 51s\n",
      "1101:\tlearn: 8.9644751\ttotal: 23.7s\tremaining: 7m 51s\n",
      "1102:\tlearn: 8.9625410\ttotal: 23.8s\tremaining: 7m 51s\n",
      "1103:\tlearn: 8.9604697\ttotal: 23.8s\tremaining: 7m 51s\n",
      "1104:\tlearn: 8.9588476\ttotal: 23.8s\tremaining: 7m 51s\n",
      "1105:\tlearn: 8.9572032\ttotal: 23.8s\tremaining: 7m 51s\n",
      "1106:\tlearn: 8.9549762\ttotal: 23.9s\tremaining: 7m 51s\n",
      "1107:\tlearn: 8.9528332\ttotal: 23.9s\tremaining: 7m 52s\n",
      "1108:\tlearn: 8.9511681\ttotal: 23.9s\tremaining: 7m 52s\n",
      "1109:\tlearn: 8.9483828\ttotal: 24s\tremaining: 7m 52s\n",
      "1110:\tlearn: 8.9451034\ttotal: 24s\tremaining: 7m 52s\n",
      "1111:\tlearn: 8.9426163\ttotal: 24s\tremaining: 7m 52s\n",
      "1112:\tlearn: 8.9404635\ttotal: 24.1s\tremaining: 7m 53s\n",
      "1113:\tlearn: 8.9375350\ttotal: 24.1s\tremaining: 7m 53s\n",
      "1114:\tlearn: 8.9351347\ttotal: 24.1s\tremaining: 7m 53s\n",
      "1115:\tlearn: 8.9319707\ttotal: 24.1s\tremaining: 7m 53s\n",
      "1116:\tlearn: 8.9305827\ttotal: 24.2s\tremaining: 7m 53s\n",
      "1117:\tlearn: 8.9292200\ttotal: 24.2s\tremaining: 7m 53s\n",
      "1118:\tlearn: 8.9263462\ttotal: 24.2s\tremaining: 7m 53s\n",
      "1119:\tlearn: 8.9242695\ttotal: 24.2s\tremaining: 7m 53s\n",
      "1120:\tlearn: 8.9223473\ttotal: 24.2s\tremaining: 7m 53s\n",
      "1121:\tlearn: 8.9198997\ttotal: 24.3s\tremaining: 7m 53s\n",
      "1122:\tlearn: 8.9182406\ttotal: 24.3s\tremaining: 7m 53s\n",
      "1123:\tlearn: 8.9163973\ttotal: 24.3s\tremaining: 7m 52s\n",
      "1124:\tlearn: 8.9141024\ttotal: 24.3s\tremaining: 7m 53s\n",
      "1125:\tlearn: 8.9122130\ttotal: 24.3s\tremaining: 7m 53s\n",
      "1126:\tlearn: 8.9100255\ttotal: 24.4s\tremaining: 7m 52s\n",
      "1127:\tlearn: 8.9084279\ttotal: 24.4s\tremaining: 7m 52s\n",
      "1128:\tlearn: 8.9055603\ttotal: 24.4s\tremaining: 7m 52s\n",
      "1129:\tlearn: 8.9034222\ttotal: 24.4s\tremaining: 7m 52s\n",
      "1130:\tlearn: 8.9007593\ttotal: 24.5s\tremaining: 7m 52s\n",
      "1131:\tlearn: 8.8987716\ttotal: 24.5s\tremaining: 7m 52s\n",
      "1132:\tlearn: 8.8964503\ttotal: 24.5s\tremaining: 7m 52s\n",
      "1133:\tlearn: 8.8949298\ttotal: 24.5s\tremaining: 7m 52s\n",
      "1134:\tlearn: 8.8922865\ttotal: 24.5s\tremaining: 7m 52s\n",
      "1135:\tlearn: 8.8903391\ttotal: 24.6s\tremaining: 7m 52s\n",
      "1136:\tlearn: 8.8879147\ttotal: 24.6s\tremaining: 7m 52s\n",
      "1137:\tlearn: 8.8859697\ttotal: 24.6s\tremaining: 7m 52s\n",
      "1138:\tlearn: 8.8828915\ttotal: 24.6s\tremaining: 7m 52s\n",
      "1139:\tlearn: 8.8808641\ttotal: 24.7s\tremaining: 7m 52s\n",
      "1140:\tlearn: 8.8791435\ttotal: 24.7s\tremaining: 7m 53s\n",
      "1141:\tlearn: 8.8761583\ttotal: 24.7s\tremaining: 7m 53s\n",
      "1142:\tlearn: 8.8741159\ttotal: 24.7s\tremaining: 7m 52s\n",
      "1143:\tlearn: 8.8714905\ttotal: 24.8s\tremaining: 7m 53s\n",
      "1144:\tlearn: 8.8687610\ttotal: 24.8s\tremaining: 7m 53s\n",
      "1145:\tlearn: 8.8671328\ttotal: 24.8s\tremaining: 7m 53s\n",
      "1146:\tlearn: 8.8652451\ttotal: 24.8s\tremaining: 7m 52s\n",
      "1147:\tlearn: 8.8628106\ttotal: 24.8s\tremaining: 7m 52s\n",
      "1148:\tlearn: 8.8605575\ttotal: 24.9s\tremaining: 7m 52s\n",
      "1149:\tlearn: 8.8588774\ttotal: 24.9s\tremaining: 7m 52s\n",
      "1150:\tlearn: 8.8563186\ttotal: 24.9s\tremaining: 7m 52s\n",
      "1151:\tlearn: 8.8544780\ttotal: 24.9s\tremaining: 7m 52s\n",
      "1152:\tlearn: 8.8529580\ttotal: 25s\tremaining: 7m 52s\n",
      "1153:\tlearn: 8.8503719\ttotal: 25s\tremaining: 7m 52s\n",
      "1154:\tlearn: 8.8479572\ttotal: 25s\tremaining: 7m 52s\n",
      "1155:\tlearn: 8.8444853\ttotal: 25s\tremaining: 7m 52s\n",
      "1156:\tlearn: 8.8420934\ttotal: 25s\tremaining: 7m 52s\n",
      "1157:\tlearn: 8.8404148\ttotal: 25.1s\tremaining: 7m 52s\n",
      "1158:\tlearn: 8.8381640\ttotal: 25.1s\tremaining: 7m 52s\n",
      "1159:\tlearn: 8.8358102\ttotal: 25.1s\tremaining: 7m 52s\n",
      "1160:\tlearn: 8.8338225\ttotal: 25.1s\tremaining: 7m 52s\n",
      "1161:\tlearn: 8.8315142\ttotal: 25.2s\tremaining: 7m 52s\n",
      "1162:\tlearn: 8.8287977\ttotal: 25.2s\tremaining: 7m 52s\n",
      "1163:\tlearn: 8.8262766\ttotal: 25.2s\tremaining: 7m 52s\n",
      "1164:\tlearn: 8.8241879\ttotal: 25.2s\tremaining: 7m 52s\n",
      "1165:\tlearn: 8.8213613\ttotal: 25.2s\tremaining: 7m 52s\n",
      "1166:\tlearn: 8.8192461\ttotal: 25.3s\tremaining: 7m 52s\n",
      "1167:\tlearn: 8.8170097\ttotal: 25.3s\tremaining: 7m 52s\n",
      "1168:\tlearn: 8.8146595\ttotal: 25.3s\tremaining: 7m 52s\n",
      "1169:\tlearn: 8.8126399\ttotal: 25.3s\tremaining: 7m 52s\n",
      "1170:\tlearn: 8.8096388\ttotal: 25.4s\tremaining: 7m 52s\n",
      "1171:\tlearn: 8.8066654\ttotal: 25.4s\tremaining: 7m 52s\n",
      "1172:\tlearn: 8.8037191\ttotal: 25.4s\tremaining: 7m 52s\n",
      "1173:\tlearn: 8.8013158\ttotal: 25.4s\tremaining: 7m 52s\n",
      "1174:\tlearn: 8.7991510\ttotal: 25.5s\tremaining: 7m 52s\n",
      "1175:\tlearn: 8.7967102\ttotal: 25.5s\tremaining: 7m 52s\n",
      "1176:\tlearn: 8.7942702\ttotal: 25.5s\tremaining: 7m 52s\n",
      "1177:\tlearn: 8.7924025\ttotal: 25.5s\tremaining: 7m 52s\n",
      "1178:\tlearn: 8.7901440\ttotal: 25.5s\tremaining: 7m 52s\n",
      "1179:\tlearn: 8.7879165\ttotal: 25.6s\tremaining: 7m 52s\n",
      "1180:\tlearn: 8.7859830\ttotal: 25.6s\tremaining: 7m 52s\n",
      "1181:\tlearn: 8.7839953\ttotal: 25.6s\tremaining: 7m 52s\n",
      "1182:\tlearn: 8.7815598\ttotal: 25.6s\tremaining: 7m 52s\n",
      "1183:\tlearn: 8.7789463\ttotal: 25.7s\tremaining: 7m 52s\n",
      "1184:\tlearn: 8.7772467\ttotal: 25.7s\tremaining: 7m 52s\n",
      "1185:\tlearn: 8.7755726\ttotal: 25.7s\tremaining: 7m 52s\n",
      "1186:\tlearn: 8.7723411\ttotal: 25.7s\tremaining: 7m 52s\n",
      "1187:\tlearn: 8.7705567\ttotal: 25.7s\tremaining: 7m 52s\n",
      "1188:\tlearn: 8.7686429\ttotal: 25.8s\tremaining: 7m 52s\n",
      "1189:\tlearn: 8.7663630\ttotal: 25.8s\tremaining: 7m 52s\n",
      "1190:\tlearn: 8.7643513\ttotal: 25.8s\tremaining: 7m 52s\n",
      "1191:\tlearn: 8.7612054\ttotal: 25.8s\tremaining: 7m 52s\n",
      "1192:\tlearn: 8.7594707\ttotal: 25.9s\tremaining: 7m 52s\n",
      "1193:\tlearn: 8.7574832\ttotal: 25.9s\tremaining: 7m 52s\n",
      "1194:\tlearn: 8.7554660\ttotal: 25.9s\tremaining: 7m 52s\n",
      "1195:\tlearn: 8.7530282\ttotal: 25.9s\tremaining: 7m 52s\n",
      "1196:\tlearn: 8.7510851\ttotal: 25.9s\tremaining: 7m 52s\n",
      "1197:\tlearn: 8.7498776\ttotal: 26s\tremaining: 7m 52s\n",
      "1198:\tlearn: 8.7479965\ttotal: 26s\tremaining: 7m 52s\n",
      "1199:\tlearn: 8.7453127\ttotal: 26s\tremaining: 7m 52s\n",
      "1200:\tlearn: 8.7430634\ttotal: 26s\tremaining: 7m 52s\n",
      "1201:\tlearn: 8.7417779\ttotal: 26s\tremaining: 7m 52s\n",
      "1202:\tlearn: 8.7393943\ttotal: 26.1s\tremaining: 7m 52s\n",
      "1203:\tlearn: 8.7369493\ttotal: 26.1s\tremaining: 7m 52s\n",
      "1204:\tlearn: 8.7350029\ttotal: 26.1s\tremaining: 7m 52s\n",
      "1205:\tlearn: 8.7326197\ttotal: 26.1s\tremaining: 7m 52s\n",
      "1206:\tlearn: 8.7306895\ttotal: 26.2s\tremaining: 7m 52s\n",
      "1207:\tlearn: 8.7291871\ttotal: 26.2s\tremaining: 7m 52s\n",
      "1208:\tlearn: 8.7269493\ttotal: 26.2s\tremaining: 7m 52s\n",
      "1209:\tlearn: 8.7252837\ttotal: 26.2s\tremaining: 7m 52s\n",
      "1210:\tlearn: 8.7232643\ttotal: 26.2s\tremaining: 7m 52s\n",
      "1211:\tlearn: 8.7210375\ttotal: 26.3s\tremaining: 7m 52s\n",
      "1212:\tlearn: 8.7189078\ttotal: 26.3s\tremaining: 7m 52s\n",
      "1213:\tlearn: 8.7166202\ttotal: 26.3s\tremaining: 7m 52s\n",
      "1214:\tlearn: 8.7136487\ttotal: 26.3s\tremaining: 7m 52s\n",
      "1215:\tlearn: 8.7115962\ttotal: 26.4s\tremaining: 7m 52s\n",
      "1216:\tlearn: 8.7093760\ttotal: 26.4s\tremaining: 7m 52s\n",
      "1217:\tlearn: 8.7071366\ttotal: 26.4s\tremaining: 7m 52s\n",
      "1218:\tlearn: 8.7047133\ttotal: 26.4s\tremaining: 7m 52s\n",
      "1219:\tlearn: 8.7031584\ttotal: 26.4s\tremaining: 7m 52s\n",
      "1220:\tlearn: 8.7001680\ttotal: 26.5s\tremaining: 7m 52s\n",
      "1221:\tlearn: 8.6987686\ttotal: 26.5s\tremaining: 7m 52s\n",
      "1222:\tlearn: 8.6971530\ttotal: 26.5s\tremaining: 7m 52s\n",
      "1223:\tlearn: 8.6948799\ttotal: 26.5s\tremaining: 7m 52s\n",
      "1224:\tlearn: 8.6926646\ttotal: 26.6s\tremaining: 7m 52s\n",
      "1225:\tlearn: 8.6910800\ttotal: 26.6s\tremaining: 7m 52s\n",
      "1226:\tlearn: 8.6888063\ttotal: 26.6s\tremaining: 7m 52s\n",
      "1227:\tlearn: 8.6866375\ttotal: 26.6s\tremaining: 7m 52s\n",
      "1228:\tlearn: 8.6851226\ttotal: 26.6s\tremaining: 7m 52s\n",
      "1229:\tlearn: 8.6833815\ttotal: 26.7s\tremaining: 7m 52s\n",
      "1230:\tlearn: 8.6812484\ttotal: 26.7s\tremaining: 7m 52s\n",
      "1231:\tlearn: 8.6796113\ttotal: 26.7s\tremaining: 7m 52s\n",
      "1232:\tlearn: 8.6782044\ttotal: 26.7s\tremaining: 7m 51s\n",
      "1233:\tlearn: 8.6766165\ttotal: 26.8s\tremaining: 7m 51s\n",
      "1234:\tlearn: 8.6742278\ttotal: 26.8s\tremaining: 7m 51s\n",
      "1235:\tlearn: 8.6716524\ttotal: 26.8s\tremaining: 7m 51s\n",
      "1236:\tlearn: 8.6698111\ttotal: 26.8s\tremaining: 7m 51s\n",
      "1237:\tlearn: 8.6669775\ttotal: 26.8s\tremaining: 7m 51s\n",
      "1238:\tlearn: 8.6649468\ttotal: 26.9s\tremaining: 7m 51s\n",
      "1239:\tlearn: 8.6621687\ttotal: 26.9s\tremaining: 7m 51s\n",
      "1240:\tlearn: 8.6603171\ttotal: 26.9s\tremaining: 7m 51s\n",
      "1241:\tlearn: 8.6584366\ttotal: 26.9s\tremaining: 7m 51s\n",
      "1242:\tlearn: 8.6563885\ttotal: 26.9s\tremaining: 7m 51s\n",
      "1243:\tlearn: 8.6546784\ttotal: 27s\tremaining: 7m 51s\n",
      "1244:\tlearn: 8.6529062\ttotal: 27s\tremaining: 7m 51s\n",
      "1245:\tlearn: 8.6509781\ttotal: 27s\tremaining: 7m 51s\n",
      "1246:\tlearn: 8.6492789\ttotal: 27s\tremaining: 7m 51s\n",
      "1247:\tlearn: 8.6466687\ttotal: 27.1s\tremaining: 7m 51s\n",
      "1248:\tlearn: 8.6449855\ttotal: 27.1s\tremaining: 7m 51s\n",
      "1249:\tlearn: 8.6419704\ttotal: 27.1s\tremaining: 7m 51s\n",
      "1250:\tlearn: 8.6408889\ttotal: 27.1s\tremaining: 7m 51s\n",
      "1251:\tlearn: 8.6386645\ttotal: 27.1s\tremaining: 7m 51s\n",
      "1252:\tlearn: 8.6363326\ttotal: 27.2s\tremaining: 7m 51s\n",
      "1253:\tlearn: 8.6346960\ttotal: 27.2s\tremaining: 7m 51s\n",
      "1254:\tlearn: 8.6325164\ttotal: 27.2s\tremaining: 7m 51s\n",
      "1255:\tlearn: 8.6306034\ttotal: 27.2s\tremaining: 7m 51s\n",
      "1256:\tlearn: 8.6287035\ttotal: 27.2s\tremaining: 7m 51s\n",
      "1257:\tlearn: 8.6269022\ttotal: 27.3s\tremaining: 7m 51s\n",
      "1258:\tlearn: 8.6249291\ttotal: 27.3s\tremaining: 7m 51s\n",
      "1259:\tlearn: 8.6231600\ttotal: 27.3s\tremaining: 7m 51s\n",
      "1260:\tlearn: 8.6215998\ttotal: 27.3s\tremaining: 7m 50s\n",
      "1261:\tlearn: 8.6192412\ttotal: 27.3s\tremaining: 7m 50s\n",
      "1262:\tlearn: 8.6174513\ttotal: 27.4s\tremaining: 7m 50s\n",
      "1263:\tlearn: 8.6150440\ttotal: 27.4s\tremaining: 7m 50s\n",
      "1264:\tlearn: 8.6131782\ttotal: 27.4s\tremaining: 7m 50s\n",
      "1265:\tlearn: 8.6109581\ttotal: 27.4s\tremaining: 7m 51s\n",
      "1266:\tlearn: 8.6087505\ttotal: 27.5s\tremaining: 7m 51s\n",
      "1267:\tlearn: 8.6063112\ttotal: 27.5s\tremaining: 7m 51s\n",
      "1268:\tlearn: 8.6040637\ttotal: 27.5s\tremaining: 7m 51s\n",
      "1269:\tlearn: 8.6026888\ttotal: 27.5s\tremaining: 7m 50s\n",
      "1270:\tlearn: 8.6003699\ttotal: 27.6s\tremaining: 7m 51s\n",
      "1271:\tlearn: 8.5988512\ttotal: 27.6s\tremaining: 7m 50s\n",
      "1272:\tlearn: 8.5975280\ttotal: 27.6s\tremaining: 7m 50s\n",
      "1273:\tlearn: 8.5957390\ttotal: 27.6s\tremaining: 7m 51s\n",
      "1274:\tlearn: 8.5945027\ttotal: 27.6s\tremaining: 7m 50s\n",
      "1275:\tlearn: 8.5929882\ttotal: 27.7s\tremaining: 7m 50s\n",
      "1276:\tlearn: 8.5905263\ttotal: 27.7s\tremaining: 7m 50s\n",
      "1277:\tlearn: 8.5880306\ttotal: 27.7s\tremaining: 7m 50s\n",
      "1278:\tlearn: 8.5852889\ttotal: 27.7s\tremaining: 7m 50s\n",
      "1279:\tlearn: 8.5842338\ttotal: 27.7s\tremaining: 7m 50s\n",
      "1280:\tlearn: 8.5829147\ttotal: 27.8s\tremaining: 7m 50s\n",
      "1281:\tlearn: 8.5807258\ttotal: 27.8s\tremaining: 7m 50s\n",
      "1282:\tlearn: 8.5785992\ttotal: 27.8s\tremaining: 7m 50s\n",
      "1283:\tlearn: 8.5769091\ttotal: 27.8s\tremaining: 7m 50s\n",
      "1284:\tlearn: 8.5749887\ttotal: 27.8s\tremaining: 7m 50s\n",
      "1285:\tlearn: 8.5732301\ttotal: 27.9s\tremaining: 7m 50s\n",
      "1286:\tlearn: 8.5707531\ttotal: 27.9s\tremaining: 7m 50s\n",
      "1287:\tlearn: 8.5684446\ttotal: 27.9s\tremaining: 7m 50s\n",
      "1288:\tlearn: 8.5662333\ttotal: 27.9s\tremaining: 7m 50s\n",
      "1289:\tlearn: 8.5646316\ttotal: 28s\tremaining: 7m 50s\n",
      "1290:\tlearn: 8.5627262\ttotal: 28s\tremaining: 7m 50s\n",
      "1291:\tlearn: 8.5608007\ttotal: 28s\tremaining: 7m 50s\n",
      "1292:\tlearn: 8.5596295\ttotal: 28s\tremaining: 7m 50s\n",
      "1293:\tlearn: 8.5582559\ttotal: 28s\tremaining: 7m 50s\n",
      "1294:\tlearn: 8.5562503\ttotal: 28.1s\tremaining: 7m 50s\n",
      "1295:\tlearn: 8.5545507\ttotal: 28.1s\tremaining: 7m 50s\n",
      "1296:\tlearn: 8.5528589\ttotal: 28.1s\tremaining: 7m 50s\n",
      "1297:\tlearn: 8.5510254\ttotal: 28.1s\tremaining: 7m 50s\n",
      "1298:\tlearn: 8.5489228\ttotal: 28.2s\tremaining: 7m 50s\n",
      "1299:\tlearn: 8.5471460\ttotal: 28.2s\tremaining: 7m 50s\n",
      "1300:\tlearn: 8.5455285\ttotal: 28.2s\tremaining: 7m 50s\n",
      "1301:\tlearn: 8.5431429\ttotal: 28.2s\tremaining: 7m 50s\n",
      "1302:\tlearn: 8.5410191\ttotal: 28.2s\tremaining: 7m 50s\n",
      "1303:\tlearn: 8.5385944\ttotal: 28.3s\tremaining: 7m 50s\n",
      "1304:\tlearn: 8.5373376\ttotal: 28.3s\tremaining: 7m 50s\n",
      "1305:\tlearn: 8.5354674\ttotal: 28.3s\tremaining: 7m 50s\n",
      "1306:\tlearn: 8.5331320\ttotal: 28.3s\tremaining: 7m 50s\n",
      "1307:\tlearn: 8.5311753\ttotal: 28.4s\tremaining: 7m 50s\n",
      "1308:\tlearn: 8.5288549\ttotal: 28.4s\tremaining: 7m 50s\n",
      "1309:\tlearn: 8.5274544\ttotal: 28.4s\tremaining: 7m 50s\n",
      "1310:\tlearn: 8.5258008\ttotal: 28.4s\tremaining: 7m 50s\n",
      "1311:\tlearn: 8.5238300\ttotal: 28.4s\tremaining: 7m 50s\n",
      "1312:\tlearn: 8.5208499\ttotal: 28.5s\tremaining: 7m 50s\n",
      "1313:\tlearn: 8.5189842\ttotal: 28.5s\tremaining: 7m 50s\n",
      "1314:\tlearn: 8.5172429\ttotal: 28.5s\tremaining: 7m 50s\n",
      "1315:\tlearn: 8.5154735\ttotal: 28.5s\tremaining: 7m 50s\n",
      "1316:\tlearn: 8.5136882\ttotal: 28.6s\tremaining: 7m 50s\n",
      "1317:\tlearn: 8.5116039\ttotal: 28.6s\tremaining: 7m 50s\n",
      "1318:\tlearn: 8.5103100\ttotal: 28.6s\tremaining: 7m 50s\n",
      "1319:\tlearn: 8.5080667\ttotal: 28.6s\tremaining: 7m 50s\n",
      "1320:\tlearn: 8.5061684\ttotal: 28.6s\tremaining: 7m 49s\n",
      "1321:\tlearn: 8.5044927\ttotal: 28.7s\tremaining: 7m 50s\n",
      "1322:\tlearn: 8.5027369\ttotal: 28.7s\tremaining: 7m 50s\n",
      "1323:\tlearn: 8.5012114\ttotal: 28.7s\tremaining: 7m 50s\n",
      "1324:\tlearn: 8.4991849\ttotal: 28.7s\tremaining: 7m 50s\n",
      "1325:\tlearn: 8.4969053\ttotal: 28.8s\tremaining: 7m 50s\n",
      "1326:\tlearn: 8.4954443\ttotal: 28.8s\tremaining: 7m 50s\n",
      "1327:\tlearn: 8.4939081\ttotal: 28.8s\tremaining: 7m 50s\n",
      "1328:\tlearn: 8.4913898\ttotal: 28.8s\tremaining: 7m 50s\n",
      "1329:\tlearn: 8.4897128\ttotal: 28.9s\tremaining: 7m 50s\n",
      "1330:\tlearn: 8.4879641\ttotal: 28.9s\tremaining: 7m 50s\n",
      "1331:\tlearn: 8.4854939\ttotal: 28.9s\tremaining: 7m 50s\n",
      "1332:\tlearn: 8.4827346\ttotal: 28.9s\tremaining: 7m 50s\n",
      "1333:\tlearn: 8.4814586\ttotal: 28.9s\tremaining: 7m 50s\n",
      "1334:\tlearn: 8.4787303\ttotal: 29s\tremaining: 7m 50s\n",
      "1335:\tlearn: 8.4762586\ttotal: 29s\tremaining: 7m 50s\n",
      "1336:\tlearn: 8.4748885\ttotal: 29s\tremaining: 7m 50s\n",
      "1337:\tlearn: 8.4727814\ttotal: 29s\tremaining: 7m 50s\n",
      "1338:\tlearn: 8.4713418\ttotal: 29.1s\tremaining: 7m 50s\n",
      "1339:\tlearn: 8.4692289\ttotal: 29.1s\tremaining: 7m 49s\n",
      "1340:\tlearn: 8.4671383\ttotal: 29.1s\tremaining: 7m 49s\n",
      "1341:\tlearn: 8.4650724\ttotal: 29.1s\tremaining: 7m 50s\n",
      "1342:\tlearn: 8.4638831\ttotal: 29.1s\tremaining: 7m 49s\n",
      "1343:\tlearn: 8.4620167\ttotal: 29.2s\tremaining: 7m 49s\n",
      "1344:\tlearn: 8.4605477\ttotal: 29.2s\tremaining: 7m 49s\n",
      "1345:\tlearn: 8.4584651\ttotal: 29.2s\tremaining: 7m 49s\n",
      "1346:\tlearn: 8.4563787\ttotal: 29.2s\tremaining: 7m 49s\n",
      "1347:\tlearn: 8.4547148\ttotal: 29.3s\tremaining: 7m 49s\n",
      "1348:\tlearn: 8.4521815\ttotal: 29.3s\tremaining: 7m 49s\n",
      "1349:\tlearn: 8.4506273\ttotal: 29.3s\tremaining: 7m 49s\n",
      "1350:\tlearn: 8.4486224\ttotal: 29.3s\tremaining: 7m 49s\n",
      "1351:\tlearn: 8.4464337\ttotal: 29.3s\tremaining: 7m 49s\n",
      "1352:\tlearn: 8.4442047\ttotal: 29.4s\tremaining: 7m 49s\n",
      "1353:\tlearn: 8.4424253\ttotal: 29.4s\tremaining: 7m 49s\n",
      "1354:\tlearn: 8.4407725\ttotal: 29.4s\tremaining: 7m 49s\n",
      "1355:\tlearn: 8.4382060\ttotal: 29.4s\tremaining: 7m 49s\n",
      "1356:\tlearn: 8.4366757\ttotal: 29.4s\tremaining: 7m 49s\n",
      "1357:\tlearn: 8.4347624\ttotal: 29.5s\tremaining: 7m 49s\n",
      "1358:\tlearn: 8.4328671\ttotal: 29.5s\tremaining: 7m 49s\n",
      "1359:\tlearn: 8.4311667\ttotal: 29.5s\tremaining: 7m 49s\n",
      "1360:\tlearn: 8.4292728\ttotal: 29.5s\tremaining: 7m 49s\n",
      "1361:\tlearn: 8.4282439\ttotal: 29.6s\tremaining: 7m 49s\n",
      "1362:\tlearn: 8.4269463\ttotal: 29.6s\tremaining: 7m 49s\n",
      "1363:\tlearn: 8.4244893\ttotal: 29.6s\tremaining: 7m 49s\n",
      "1364:\tlearn: 8.4226792\ttotal: 29.6s\tremaining: 7m 49s\n",
      "1365:\tlearn: 8.4205217\ttotal: 29.6s\tremaining: 7m 49s\n",
      "1366:\tlearn: 8.4187600\ttotal: 29.7s\tremaining: 7m 49s\n",
      "1367:\tlearn: 8.4177733\ttotal: 29.7s\tremaining: 7m 49s\n",
      "1368:\tlearn: 8.4159987\ttotal: 29.7s\tremaining: 7m 49s\n",
      "1369:\tlearn: 8.4141319\ttotal: 29.7s\tremaining: 7m 49s\n",
      "1370:\tlearn: 8.4121737\ttotal: 29.8s\tremaining: 7m 49s\n",
      "1371:\tlearn: 8.4104495\ttotal: 29.8s\tremaining: 7m 49s\n",
      "1372:\tlearn: 8.4084396\ttotal: 29.8s\tremaining: 7m 49s\n",
      "1373:\tlearn: 8.4065047\ttotal: 29.8s\tremaining: 7m 49s\n",
      "1374:\tlearn: 8.4046792\ttotal: 29.8s\tremaining: 7m 49s\n",
      "1375:\tlearn: 8.4026030\ttotal: 29.9s\tremaining: 7m 49s\n",
      "1376:\tlearn: 8.4006250\ttotal: 29.9s\tremaining: 7m 49s\n",
      "1377:\tlearn: 8.3988679\ttotal: 29.9s\tremaining: 7m 49s\n",
      "1378:\tlearn: 8.3969406\ttotal: 29.9s\tremaining: 7m 49s\n",
      "1379:\tlearn: 8.3953384\ttotal: 30s\tremaining: 7m 49s\n",
      "1380:\tlearn: 8.3937139\ttotal: 30s\tremaining: 7m 49s\n",
      "1381:\tlearn: 8.3920585\ttotal: 30s\tremaining: 7m 49s\n",
      "1382:\tlearn: 8.3901062\ttotal: 30s\tremaining: 7m 49s\n",
      "1383:\tlearn: 8.3885150\ttotal: 30s\tremaining: 7m 49s\n",
      "1384:\tlearn: 8.3863165\ttotal: 30.1s\tremaining: 7m 49s\n",
      "1385:\tlearn: 8.3847000\ttotal: 30.1s\tremaining: 7m 49s\n",
      "1386:\tlearn: 8.3834068\ttotal: 30.1s\tremaining: 7m 49s\n",
      "1387:\tlearn: 8.3819718\ttotal: 30.1s\tremaining: 7m 49s\n",
      "1388:\tlearn: 8.3805974\ttotal: 30.1s\tremaining: 7m 49s\n",
      "1389:\tlearn: 8.3790909\ttotal: 30.2s\tremaining: 7m 49s\n",
      "1390:\tlearn: 8.3769212\ttotal: 30.2s\tremaining: 7m 49s\n",
      "1391:\tlearn: 8.3748791\ttotal: 30.2s\tremaining: 7m 49s\n",
      "1392:\tlearn: 8.3728261\ttotal: 30.3s\tremaining: 7m 49s\n",
      "1393:\tlearn: 8.3717083\ttotal: 30.3s\tremaining: 7m 49s\n",
      "1394:\tlearn: 8.3698381\ttotal: 30.3s\tremaining: 7m 49s\n",
      "1395:\tlearn: 8.3678961\ttotal: 30.3s\tremaining: 7m 49s\n",
      "1396:\tlearn: 8.3659030\ttotal: 30.3s\tremaining: 7m 49s\n",
      "1397:\tlearn: 8.3640190\ttotal: 30.4s\tremaining: 7m 49s\n",
      "1398:\tlearn: 8.3615601\ttotal: 30.4s\tremaining: 7m 49s\n",
      "1399:\tlearn: 8.3597923\ttotal: 30.4s\tremaining: 7m 49s\n",
      "1400:\tlearn: 8.3575639\ttotal: 30.4s\tremaining: 7m 49s\n",
      "1401:\tlearn: 8.3563807\ttotal: 30.5s\tremaining: 7m 49s\n",
      "1402:\tlearn: 8.3546589\ttotal: 30.5s\tremaining: 7m 49s\n",
      "1403:\tlearn: 8.3524194\ttotal: 30.5s\tremaining: 7m 49s\n",
      "1404:\tlearn: 8.3499298\ttotal: 30.5s\tremaining: 7m 49s\n",
      "1405:\tlearn: 8.3485428\ttotal: 30.5s\tremaining: 7m 49s\n",
      "1406:\tlearn: 8.3466635\ttotal: 30.6s\tremaining: 7m 49s\n",
      "1407:\tlearn: 8.3447137\ttotal: 30.6s\tremaining: 7m 49s\n",
      "1408:\tlearn: 8.3434310\ttotal: 30.6s\tremaining: 7m 49s\n",
      "1409:\tlearn: 8.3420973\ttotal: 30.6s\tremaining: 7m 48s\n",
      "1410:\tlearn: 8.3397902\ttotal: 30.7s\tremaining: 7m 49s\n",
      "1411:\tlearn: 8.3381060\ttotal: 30.7s\tremaining: 7m 49s\n",
      "1412:\tlearn: 8.3360584\ttotal: 30.7s\tremaining: 7m 49s\n",
      "1413:\tlearn: 8.3344338\ttotal: 30.7s\tremaining: 7m 49s\n",
      "1414:\tlearn: 8.3329814\ttotal: 30.8s\tremaining: 7m 49s\n",
      "1415:\tlearn: 8.3310144\ttotal: 30.8s\tremaining: 7m 49s\n",
      "1416:\tlearn: 8.3290812\ttotal: 30.8s\tremaining: 7m 49s\n",
      "1417:\tlearn: 8.3272271\ttotal: 30.8s\tremaining: 7m 49s\n",
      "1418:\tlearn: 8.3257012\ttotal: 30.8s\tremaining: 7m 48s\n",
      "1419:\tlearn: 8.3241129\ttotal: 30.9s\tremaining: 7m 48s\n",
      "1420:\tlearn: 8.3214992\ttotal: 30.9s\tremaining: 7m 48s\n",
      "1421:\tlearn: 8.3189514\ttotal: 30.9s\tremaining: 7m 48s\n",
      "1422:\tlearn: 8.3174986\ttotal: 30.9s\tremaining: 7m 48s\n",
      "1423:\tlearn: 8.3163793\ttotal: 30.9s\tremaining: 7m 48s\n",
      "1424:\tlearn: 8.3146178\ttotal: 31s\tremaining: 7m 48s\n",
      "1425:\tlearn: 8.3124266\ttotal: 31s\tremaining: 7m 48s\n",
      "1426:\tlearn: 8.3100792\ttotal: 31s\tremaining: 7m 48s\n",
      "1427:\tlearn: 8.3086142\ttotal: 31s\tremaining: 7m 48s\n",
      "1428:\tlearn: 8.3065840\ttotal: 31.1s\tremaining: 7m 48s\n",
      "1429:\tlearn: 8.3045023\ttotal: 31.1s\tremaining: 7m 48s\n",
      "1430:\tlearn: 8.3031232\ttotal: 31.1s\tremaining: 7m 48s\n",
      "1431:\tlearn: 8.3019036\ttotal: 31.1s\tremaining: 7m 48s\n",
      "1432:\tlearn: 8.3001390\ttotal: 31.1s\tremaining: 7m 48s\n",
      "1433:\tlearn: 8.2978815\ttotal: 31.2s\tremaining: 7m 48s\n",
      "1434:\tlearn: 8.2957056\ttotal: 31.2s\tremaining: 7m 48s\n",
      "1435:\tlearn: 8.2930957\ttotal: 31.2s\tremaining: 7m 48s\n",
      "1436:\tlearn: 8.2914102\ttotal: 31.2s\tremaining: 7m 48s\n",
      "1437:\tlearn: 8.2900205\ttotal: 31.3s\tremaining: 7m 48s\n",
      "1438:\tlearn: 8.2881737\ttotal: 31.3s\tremaining: 7m 48s\n",
      "1439:\tlearn: 8.2865826\ttotal: 31.3s\tremaining: 7m 48s\n",
      "1440:\tlearn: 8.2850090\ttotal: 31.3s\tremaining: 7m 48s\n",
      "1441:\tlearn: 8.2836068\ttotal: 31.4s\tremaining: 7m 48s\n",
      "1442:\tlearn: 8.2824581\ttotal: 31.4s\tremaining: 7m 48s\n",
      "1443:\tlearn: 8.2815148\ttotal: 31.4s\tremaining: 7m 48s\n",
      "1444:\tlearn: 8.2797258\ttotal: 31.4s\tremaining: 7m 48s\n",
      "1445:\tlearn: 8.2781722\ttotal: 31.4s\tremaining: 7m 48s\n",
      "1446:\tlearn: 8.2765710\ttotal: 31.4s\tremaining: 7m 48s\n",
      "1447:\tlearn: 8.2748983\ttotal: 31.5s\tremaining: 7m 48s\n",
      "1448:\tlearn: 8.2730870\ttotal: 31.5s\tremaining: 7m 48s\n",
      "1449:\tlearn: 8.2711068\ttotal: 31.5s\tremaining: 7m 48s\n",
      "1450:\tlearn: 8.2695279\ttotal: 31.5s\tremaining: 7m 48s\n",
      "1451:\tlearn: 8.2673864\ttotal: 31.6s\tremaining: 7m 48s\n",
      "1452:\tlearn: 8.2653521\ttotal: 31.6s\tremaining: 7m 48s\n",
      "1453:\tlearn: 8.2638165\ttotal: 31.6s\tremaining: 7m 48s\n",
      "1454:\tlearn: 8.2626842\ttotal: 31.6s\tremaining: 7m 48s\n",
      "1455:\tlearn: 8.2614498\ttotal: 31.6s\tremaining: 7m 48s\n",
      "1456:\tlearn: 8.2594005\ttotal: 31.7s\tremaining: 7m 48s\n",
      "1457:\tlearn: 8.2577319\ttotal: 31.7s\tremaining: 7m 48s\n",
      "1458:\tlearn: 8.2552379\ttotal: 31.7s\tremaining: 7m 48s\n",
      "1459:\tlearn: 8.2537831\ttotal: 31.7s\tremaining: 7m 48s\n",
      "1460:\tlearn: 8.2512609\ttotal: 31.8s\tremaining: 7m 48s\n",
      "1461:\tlearn: 8.2495907\ttotal: 31.8s\tremaining: 7m 48s\n",
      "1462:\tlearn: 8.2470227\ttotal: 31.8s\tremaining: 7m 48s\n",
      "1463:\tlearn: 8.2447320\ttotal: 31.8s\tremaining: 7m 48s\n",
      "1464:\tlearn: 8.2426309\ttotal: 31.8s\tremaining: 7m 48s\n",
      "1465:\tlearn: 8.2412591\ttotal: 31.9s\tremaining: 7m 47s\n",
      "1466:\tlearn: 8.2387123\ttotal: 31.9s\tremaining: 7m 48s\n",
      "1467:\tlearn: 8.2370895\ttotal: 31.9s\tremaining: 7m 47s\n",
      "1468:\tlearn: 8.2356114\ttotal: 31.9s\tremaining: 7m 47s\n",
      "1469:\tlearn: 8.2340235\ttotal: 31.9s\tremaining: 7m 47s\n",
      "1470:\tlearn: 8.2323420\ttotal: 32s\tremaining: 7m 47s\n",
      "1471:\tlearn: 8.2305379\ttotal: 32s\tremaining: 7m 47s\n",
      "1472:\tlearn: 8.2291581\ttotal: 32s\tremaining: 7m 47s\n",
      "1473:\tlearn: 8.2279242\ttotal: 32s\tremaining: 7m 47s\n",
      "1474:\tlearn: 8.2271579\ttotal: 32.1s\tremaining: 7m 47s\n",
      "1475:\tlearn: 8.2255111\ttotal: 32.1s\tremaining: 7m 47s\n",
      "1476:\tlearn: 8.2230008\ttotal: 32.1s\tremaining: 7m 47s\n",
      "1477:\tlearn: 8.2220084\ttotal: 32.1s\tremaining: 7m 47s\n",
      "1478:\tlearn: 8.2202073\ttotal: 32.1s\tremaining: 7m 47s\n",
      "1479:\tlearn: 8.2186854\ttotal: 32.2s\tremaining: 7m 47s\n",
      "1480:\tlearn: 8.2173474\ttotal: 32.2s\tremaining: 7m 47s\n",
      "1481:\tlearn: 8.2152715\ttotal: 32.2s\tremaining: 7m 47s\n",
      "1482:\tlearn: 8.2134661\ttotal: 32.2s\tremaining: 7m 47s\n",
      "1483:\tlearn: 8.2116413\ttotal: 32.2s\tremaining: 7m 47s\n",
      "1484:\tlearn: 8.2101170\ttotal: 32.3s\tremaining: 7m 47s\n",
      "1485:\tlearn: 8.2091216\ttotal: 32.3s\tremaining: 7m 47s\n",
      "1486:\tlearn: 8.2073289\ttotal: 32.3s\tremaining: 7m 47s\n",
      "1487:\tlearn: 8.2059921\ttotal: 32.3s\tremaining: 7m 47s\n",
      "1488:\tlearn: 8.2051173\ttotal: 32.3s\tremaining: 7m 47s\n",
      "1489:\tlearn: 8.2037215\ttotal: 32.4s\tremaining: 7m 47s\n",
      "1490:\tlearn: 8.2019043\ttotal: 32.4s\tremaining: 7m 47s\n",
      "1491:\tlearn: 8.2004494\ttotal: 32.4s\tremaining: 7m 47s\n",
      "1492:\tlearn: 8.1982320\ttotal: 32.4s\tremaining: 7m 47s\n",
      "1493:\tlearn: 8.1967249\ttotal: 32.4s\tremaining: 7m 47s\n",
      "1494:\tlearn: 8.1948113\ttotal: 32.5s\tremaining: 7m 47s\n",
      "1495:\tlearn: 8.1923731\ttotal: 32.5s\tremaining: 7m 47s\n",
      "1496:\tlearn: 8.1907668\ttotal: 32.5s\tremaining: 7m 47s\n",
      "1497:\tlearn: 8.1884357\ttotal: 32.5s\tremaining: 7m 47s\n",
      "1498:\tlearn: 8.1867297\ttotal: 32.6s\tremaining: 7m 47s\n",
      "1499:\tlearn: 8.1850503\ttotal: 32.6s\tremaining: 7m 47s\n",
      "1500:\tlearn: 8.1833378\ttotal: 32.6s\tremaining: 7m 47s\n",
      "1501:\tlearn: 8.1821084\ttotal: 32.6s\tremaining: 7m 47s\n",
      "1502:\tlearn: 8.1805705\ttotal: 32.7s\tremaining: 7m 47s\n",
      "1503:\tlearn: 8.1790633\ttotal: 32.7s\tremaining: 7m 47s\n",
      "1504:\tlearn: 8.1768093\ttotal: 32.7s\tremaining: 7m 47s\n",
      "1505:\tlearn: 8.1749314\ttotal: 32.7s\tremaining: 7m 47s\n",
      "1506:\tlearn: 8.1734797\ttotal: 32.7s\tremaining: 7m 47s\n",
      "1507:\tlearn: 8.1722247\ttotal: 32.8s\tremaining: 7m 47s\n",
      "1508:\tlearn: 8.1704727\ttotal: 32.8s\tremaining: 7m 47s\n",
      "1509:\tlearn: 8.1687880\ttotal: 32.8s\tremaining: 7m 47s\n",
      "1510:\tlearn: 8.1673767\ttotal: 32.8s\tremaining: 7m 47s\n",
      "1511:\tlearn: 8.1658910\ttotal: 32.9s\tremaining: 7m 47s\n",
      "1512:\tlearn: 8.1635175\ttotal: 32.9s\tremaining: 7m 47s\n",
      "1513:\tlearn: 8.1623507\ttotal: 32.9s\tremaining: 7m 47s\n",
      "1514:\tlearn: 8.1606631\ttotal: 32.9s\tremaining: 7m 47s\n",
      "1515:\tlearn: 8.1591736\ttotal: 33s\tremaining: 7m 47s\n",
      "1516:\tlearn: 8.1577283\ttotal: 33s\tremaining: 7m 46s\n",
      "1517:\tlearn: 8.1565795\ttotal: 33s\tremaining: 7m 46s\n",
      "1518:\tlearn: 8.1553176\ttotal: 33s\tremaining: 7m 46s\n",
      "1519:\tlearn: 8.1540730\ttotal: 33s\tremaining: 7m 46s\n",
      "1520:\tlearn: 8.1512533\ttotal: 33.1s\tremaining: 7m 46s\n",
      "1521:\tlearn: 8.1495254\ttotal: 33.1s\tremaining: 7m 46s\n",
      "1522:\tlearn: 8.1478192\ttotal: 33.1s\tremaining: 7m 46s\n",
      "1523:\tlearn: 8.1464442\ttotal: 33.1s\tremaining: 7m 46s\n",
      "1524:\tlearn: 8.1446109\ttotal: 33.1s\tremaining: 7m 46s\n",
      "1525:\tlearn: 8.1433950\ttotal: 33.2s\tremaining: 7m 46s\n",
      "1526:\tlearn: 8.1423776\ttotal: 33.2s\tremaining: 7m 46s\n",
      "1527:\tlearn: 8.1407306\ttotal: 33.2s\tremaining: 7m 46s\n",
      "1528:\tlearn: 8.1392812\ttotal: 33.2s\tremaining: 7m 46s\n",
      "1529:\tlearn: 8.1369571\ttotal: 33.3s\tremaining: 7m 46s\n",
      "1530:\tlearn: 8.1351916\ttotal: 33.3s\tremaining: 7m 46s\n",
      "1531:\tlearn: 8.1333580\ttotal: 33.3s\tremaining: 7m 46s\n",
      "1532:\tlearn: 8.1321459\ttotal: 33.3s\tremaining: 7m 46s\n",
      "1533:\tlearn: 8.1303760\ttotal: 33.3s\tremaining: 7m 46s\n",
      "1534:\tlearn: 8.1291516\ttotal: 33.4s\tremaining: 7m 46s\n",
      "1535:\tlearn: 8.1279610\ttotal: 33.4s\tremaining: 7m 46s\n",
      "1536:\tlearn: 8.1269996\ttotal: 33.4s\tremaining: 7m 46s\n",
      "1537:\tlearn: 8.1255990\ttotal: 33.4s\tremaining: 7m 46s\n",
      "1538:\tlearn: 8.1238052\ttotal: 33.4s\tremaining: 7m 46s\n",
      "1539:\tlearn: 8.1229849\ttotal: 33.5s\tremaining: 7m 46s\n",
      "1540:\tlearn: 8.1206382\ttotal: 33.5s\tremaining: 7m 46s\n",
      "1541:\tlearn: 8.1191187\ttotal: 33.5s\tremaining: 7m 46s\n",
      "1542:\tlearn: 8.1176950\ttotal: 33.5s\tremaining: 7m 46s\n",
      "1543:\tlearn: 8.1160281\ttotal: 33.6s\tremaining: 7m 46s\n",
      "1544:\tlearn: 8.1149973\ttotal: 33.6s\tremaining: 7m 46s\n",
      "1545:\tlearn: 8.1133078\ttotal: 33.6s\tremaining: 7m 46s\n",
      "1546:\tlearn: 8.1123280\ttotal: 33.6s\tremaining: 7m 46s\n",
      "1547:\tlearn: 8.1113821\ttotal: 33.6s\tremaining: 7m 46s\n",
      "1548:\tlearn: 8.1097233\ttotal: 33.6s\tremaining: 7m 45s\n",
      "1549:\tlearn: 8.1076874\ttotal: 33.7s\tremaining: 7m 45s\n",
      "1550:\tlearn: 8.1061494\ttotal: 33.7s\tremaining: 7m 45s\n",
      "1551:\tlearn: 8.1045525\ttotal: 33.7s\tremaining: 7m 45s\n",
      "1552:\tlearn: 8.1030181\ttotal: 33.7s\tremaining: 7m 45s\n",
      "1553:\tlearn: 8.1017144\ttotal: 33.8s\tremaining: 7m 45s\n",
      "1554:\tlearn: 8.0992998\ttotal: 33.8s\tremaining: 7m 45s\n",
      "1555:\tlearn: 8.0975068\ttotal: 33.8s\tremaining: 7m 45s\n",
      "1556:\tlearn: 8.0960870\ttotal: 33.8s\tremaining: 7m 45s\n",
      "1557:\tlearn: 8.0943184\ttotal: 33.9s\tremaining: 7m 45s\n",
      "1558:\tlearn: 8.0923495\ttotal: 33.9s\tremaining: 7m 45s\n",
      "1559:\tlearn: 8.0904932\ttotal: 33.9s\tremaining: 7m 45s\n",
      "1560:\tlearn: 8.0882414\ttotal: 33.9s\tremaining: 7m 45s\n",
      "1561:\tlearn: 8.0868537\ttotal: 33.9s\tremaining: 7m 45s\n",
      "1562:\tlearn: 8.0856079\ttotal: 34s\tremaining: 7m 45s\n",
      "1563:\tlearn: 8.0839205\ttotal: 34s\tremaining: 7m 45s\n",
      "1564:\tlearn: 8.0813690\ttotal: 34s\tremaining: 7m 45s\n",
      "1565:\tlearn: 8.0795144\ttotal: 34s\tremaining: 7m 45s\n",
      "1566:\tlearn: 8.0778873\ttotal: 34.1s\tremaining: 7m 45s\n",
      "1567:\tlearn: 8.0769880\ttotal: 34.1s\tremaining: 7m 45s\n",
      "1568:\tlearn: 8.0752141\ttotal: 34.1s\tremaining: 7m 45s\n",
      "1569:\tlearn: 8.0737331\ttotal: 34.1s\tremaining: 7m 45s\n",
      "1570:\tlearn: 8.0719409\ttotal: 34.1s\tremaining: 7m 45s\n",
      "1571:\tlearn: 8.0710726\ttotal: 34.2s\tremaining: 7m 45s\n",
      "1572:\tlearn: 8.0691646\ttotal: 34.2s\tremaining: 7m 45s\n",
      "1573:\tlearn: 8.0677583\ttotal: 34.2s\tremaining: 7m 45s\n",
      "1574:\tlearn: 8.0660501\ttotal: 34.2s\tremaining: 7m 45s\n",
      "1575:\tlearn: 8.0646430\ttotal: 34.3s\tremaining: 7m 45s\n",
      "1576:\tlearn: 8.0635715\ttotal: 34.3s\tremaining: 7m 45s\n",
      "1577:\tlearn: 8.0609670\ttotal: 34.3s\tremaining: 7m 45s\n",
      "1578:\tlearn: 8.0598202\ttotal: 34.3s\tremaining: 7m 45s\n",
      "1579:\tlearn: 8.0582300\ttotal: 34.3s\tremaining: 7m 45s\n",
      "1580:\tlearn: 8.0566287\ttotal: 34.4s\tremaining: 7m 45s\n",
      "1581:\tlearn: 8.0551530\ttotal: 34.4s\tremaining: 7m 45s\n",
      "1582:\tlearn: 8.0533340\ttotal: 34.4s\tremaining: 7m 45s\n",
      "1583:\tlearn: 8.0517203\ttotal: 34.4s\tremaining: 7m 45s\n",
      "1584:\tlearn: 8.0504475\ttotal: 34.4s\tremaining: 7m 45s\n",
      "1585:\tlearn: 8.0484837\ttotal: 34.5s\tremaining: 7m 45s\n",
      "1586:\tlearn: 8.0470362\ttotal: 34.5s\tremaining: 7m 45s\n",
      "1587:\tlearn: 8.0454744\ttotal: 34.5s\tremaining: 7m 45s\n",
      "1588:\tlearn: 8.0436915\ttotal: 34.5s\tremaining: 7m 45s\n",
      "1589:\tlearn: 8.0419022\ttotal: 34.6s\tremaining: 7m 45s\n",
      "1590:\tlearn: 8.0391752\ttotal: 34.6s\tremaining: 7m 45s\n",
      "1591:\tlearn: 8.0382836\ttotal: 34.6s\tremaining: 7m 45s\n",
      "1592:\tlearn: 8.0366940\ttotal: 34.6s\tremaining: 7m 45s\n",
      "1593:\tlearn: 8.0354379\ttotal: 34.6s\tremaining: 7m 45s\n",
      "1594:\tlearn: 8.0342128\ttotal: 34.7s\tremaining: 7m 45s\n",
      "1595:\tlearn: 8.0330551\ttotal: 34.7s\tremaining: 7m 45s\n",
      "1596:\tlearn: 8.0313615\ttotal: 34.7s\tremaining: 7m 45s\n",
      "1597:\tlearn: 8.0299791\ttotal: 34.7s\tremaining: 7m 45s\n",
      "1598:\tlearn: 8.0284936\ttotal: 34.7s\tremaining: 7m 45s\n",
      "1599:\tlearn: 8.0262234\ttotal: 34.8s\tremaining: 7m 45s\n",
      "1600:\tlearn: 8.0243668\ttotal: 34.8s\tremaining: 7m 44s\n",
      "1601:\tlearn: 8.0225853\ttotal: 34.8s\tremaining: 7m 44s\n",
      "1602:\tlearn: 8.0204994\ttotal: 34.8s\tremaining: 7m 44s\n",
      "1603:\tlearn: 8.0197361\ttotal: 34.9s\tremaining: 7m 44s\n",
      "1604:\tlearn: 8.0184392\ttotal: 34.9s\tremaining: 7m 44s\n",
      "1605:\tlearn: 8.0167956\ttotal: 34.9s\tremaining: 7m 44s\n",
      "1606:\tlearn: 8.0150994\ttotal: 34.9s\tremaining: 7m 44s\n",
      "1607:\tlearn: 8.0137698\ttotal: 34.9s\tremaining: 7m 44s\n",
      "1608:\tlearn: 8.0125778\ttotal: 35s\tremaining: 7m 44s\n",
      "1609:\tlearn: 8.0113282\ttotal: 35s\tremaining: 7m 44s\n",
      "1610:\tlearn: 8.0098445\ttotal: 35s\tremaining: 7m 44s\n",
      "1611:\tlearn: 8.0080616\ttotal: 35s\tremaining: 7m 44s\n",
      "1612:\tlearn: 8.0067243\ttotal: 35s\tremaining: 7m 44s\n",
      "1613:\tlearn: 8.0051556\ttotal: 35.1s\tremaining: 7m 44s\n",
      "1614:\tlearn: 8.0036290\ttotal: 35.1s\tremaining: 7m 44s\n",
      "1615:\tlearn: 8.0021804\ttotal: 35.1s\tremaining: 7m 44s\n",
      "1616:\tlearn: 8.0008767\ttotal: 35.1s\tremaining: 7m 44s\n",
      "1617:\tlearn: 7.9992965\ttotal: 35.1s\tremaining: 7m 44s\n",
      "1618:\tlearn: 7.9980630\ttotal: 35.2s\tremaining: 7m 44s\n",
      "1619:\tlearn: 7.9966194\ttotal: 35.2s\tremaining: 7m 44s\n",
      "1620:\tlearn: 7.9949041\ttotal: 35.2s\tremaining: 7m 44s\n",
      "1621:\tlearn: 7.9930546\ttotal: 35.2s\tremaining: 7m 44s\n",
      "1622:\tlearn: 7.9918966\ttotal: 35.3s\tremaining: 7m 44s\n",
      "1623:\tlearn: 7.9902021\ttotal: 35.3s\tremaining: 7m 44s\n",
      "1624:\tlearn: 7.9887637\ttotal: 35.3s\tremaining: 7m 44s\n",
      "1625:\tlearn: 7.9869880\ttotal: 35.3s\tremaining: 7m 44s\n",
      "1626:\tlearn: 7.9856867\ttotal: 35.3s\tremaining: 7m 44s\n",
      "1627:\tlearn: 7.9843438\ttotal: 35.4s\tremaining: 7m 44s\n",
      "1628:\tlearn: 7.9830156\ttotal: 35.4s\tremaining: 7m 44s\n",
      "1629:\tlearn: 7.9818790\ttotal: 35.4s\tremaining: 7m 44s\n",
      "1630:\tlearn: 7.9807237\ttotal: 35.4s\tremaining: 7m 44s\n",
      "1631:\tlearn: 7.9785120\ttotal: 35.4s\tremaining: 7m 44s\n",
      "1632:\tlearn: 7.9775258\ttotal: 35.5s\tremaining: 7m 43s\n",
      "1633:\tlearn: 7.9759102\ttotal: 35.5s\tremaining: 7m 43s\n",
      "1634:\tlearn: 7.9740840\ttotal: 35.5s\tremaining: 7m 43s\n",
      "1635:\tlearn: 7.9727359\ttotal: 35.5s\tremaining: 7m 43s\n",
      "1636:\tlearn: 7.9710914\ttotal: 35.5s\tremaining: 7m 43s\n",
      "1637:\tlearn: 7.9694045\ttotal: 35.6s\tremaining: 7m 43s\n",
      "1638:\tlearn: 7.9679669\ttotal: 35.6s\tremaining: 7m 43s\n",
      "1639:\tlearn: 7.9665983\ttotal: 35.6s\tremaining: 7m 43s\n",
      "1640:\tlearn: 7.9643473\ttotal: 35.6s\tremaining: 7m 43s\n",
      "1641:\tlearn: 7.9628549\ttotal: 35.6s\tremaining: 7m 43s\n",
      "1642:\tlearn: 7.9612766\ttotal: 35.7s\tremaining: 7m 43s\n",
      "1643:\tlearn: 7.9595807\ttotal: 35.7s\tremaining: 7m 43s\n",
      "1644:\tlearn: 7.9573977\ttotal: 35.7s\tremaining: 7m 43s\n",
      "1645:\tlearn: 7.9563700\ttotal: 35.7s\tremaining: 7m 43s\n",
      "1646:\tlearn: 7.9548668\ttotal: 35.8s\tremaining: 7m 43s\n",
      "1647:\tlearn: 7.9540246\ttotal: 35.8s\tremaining: 7m 43s\n",
      "1648:\tlearn: 7.9527985\ttotal: 35.8s\tremaining: 7m 43s\n",
      "1649:\tlearn: 7.9511051\ttotal: 35.8s\tremaining: 7m 43s\n",
      "1650:\tlearn: 7.9496389\ttotal: 35.8s\tremaining: 7m 43s\n",
      "1651:\tlearn: 7.9475664\ttotal: 35.9s\tremaining: 7m 43s\n",
      "1652:\tlearn: 7.9460073\ttotal: 35.9s\tremaining: 7m 43s\n",
      "1653:\tlearn: 7.9441204\ttotal: 35.9s\tremaining: 7m 43s\n",
      "1654:\tlearn: 7.9419628\ttotal: 35.9s\tremaining: 7m 43s\n",
      "1655:\tlearn: 7.9408861\ttotal: 35.9s\tremaining: 7m 43s\n",
      "1656:\tlearn: 7.9398929\ttotal: 36s\tremaining: 7m 43s\n",
      "1657:\tlearn: 7.9382650\ttotal: 36s\tremaining: 7m 43s\n",
      "1658:\tlearn: 7.9369207\ttotal: 36s\tremaining: 7m 43s\n",
      "1659:\tlearn: 7.9358205\ttotal: 36s\tremaining: 7m 43s\n",
      "1660:\tlearn: 7.9340381\ttotal: 36.1s\tremaining: 7m 43s\n",
      "1661:\tlearn: 7.9326854\ttotal: 36.1s\tremaining: 7m 43s\n",
      "1662:\tlearn: 7.9306074\ttotal: 36.1s\tremaining: 7m 43s\n",
      "1663:\tlearn: 7.9287579\ttotal: 36.1s\tremaining: 7m 43s\n",
      "1664:\tlearn: 7.9268606\ttotal: 36.2s\tremaining: 7m 43s\n",
      "1665:\tlearn: 7.9256290\ttotal: 36.2s\tremaining: 7m 43s\n",
      "1666:\tlearn: 7.9244072\ttotal: 36.2s\tremaining: 7m 43s\n",
      "1667:\tlearn: 7.9237028\ttotal: 36.2s\tremaining: 7m 43s\n",
      "1668:\tlearn: 7.9216746\ttotal: 36.2s\tremaining: 7m 43s\n",
      "1669:\tlearn: 7.9199878\ttotal: 36.3s\tremaining: 7m 43s\n",
      "1670:\tlearn: 7.9178496\ttotal: 36.3s\tremaining: 7m 43s\n",
      "1671:\tlearn: 7.9161278\ttotal: 36.3s\tremaining: 7m 43s\n",
      "1672:\tlearn: 7.9141979\ttotal: 36.3s\tremaining: 7m 43s\n",
      "1673:\tlearn: 7.9125703\ttotal: 36.4s\tremaining: 7m 43s\n",
      "1674:\tlearn: 7.9107073\ttotal: 36.4s\tremaining: 7m 43s\n",
      "1675:\tlearn: 7.9081575\ttotal: 36.4s\tremaining: 7m 43s\n",
      "1676:\tlearn: 7.9064327\ttotal: 36.4s\tremaining: 7m 43s\n",
      "1677:\tlearn: 7.9054411\ttotal: 36.4s\tremaining: 7m 43s\n",
      "1678:\tlearn: 7.9032915\ttotal: 36.5s\tremaining: 7m 43s\n",
      "1679:\tlearn: 7.9014328\ttotal: 36.5s\tremaining: 7m 43s\n",
      "1680:\tlearn: 7.8997943\ttotal: 36.5s\tremaining: 7m 43s\n",
      "1681:\tlearn: 7.8987292\ttotal: 36.5s\tremaining: 7m 43s\n",
      "1682:\tlearn: 7.8966104\ttotal: 36.6s\tremaining: 7m 43s\n",
      "1683:\tlearn: 7.8953910\ttotal: 36.6s\tremaining: 7m 43s\n",
      "1684:\tlearn: 7.8937860\ttotal: 36.6s\tremaining: 7m 43s\n",
      "1685:\tlearn: 7.8920963\ttotal: 36.6s\tremaining: 7m 43s\n",
      "1686:\tlearn: 7.8910411\ttotal: 36.6s\tremaining: 7m 42s\n",
      "1687:\tlearn: 7.8899111\ttotal: 36.7s\tremaining: 7m 42s\n",
      "1688:\tlearn: 7.8879204\ttotal: 36.7s\tremaining: 7m 42s\n",
      "1689:\tlearn: 7.8864950\ttotal: 36.7s\tremaining: 7m 42s\n",
      "1690:\tlearn: 7.8846597\ttotal: 36.7s\tremaining: 7m 42s\n",
      "1691:\tlearn: 7.8833047\ttotal: 36.8s\tremaining: 7m 42s\n",
      "1692:\tlearn: 7.8822414\ttotal: 36.8s\tremaining: 7m 42s\n",
      "1693:\tlearn: 7.8802474\ttotal: 36.8s\tremaining: 7m 42s\n",
      "1694:\tlearn: 7.8793606\ttotal: 36.8s\tremaining: 7m 42s\n",
      "1695:\tlearn: 7.8775219\ttotal: 36.8s\tremaining: 7m 42s\n",
      "1696:\tlearn: 7.8760825\ttotal: 36.9s\tremaining: 7m 42s\n",
      "1697:\tlearn: 7.8749304\ttotal: 36.9s\tremaining: 7m 42s\n",
      "1698:\tlearn: 7.8737342\ttotal: 36.9s\tremaining: 7m 42s\n",
      "1699:\tlearn: 7.8724313\ttotal: 36.9s\tremaining: 7m 42s\n",
      "1700:\tlearn: 7.8714665\ttotal: 36.9s\tremaining: 7m 42s\n",
      "1701:\tlearn: 7.8702546\ttotal: 37s\tremaining: 7m 42s\n",
      "1702:\tlearn: 7.8686549\ttotal: 37s\tremaining: 7m 42s\n",
      "1703:\tlearn: 7.8675315\ttotal: 37s\tremaining: 7m 42s\n",
      "1704:\tlearn: 7.8659435\ttotal: 37s\tremaining: 7m 42s\n",
      "1705:\tlearn: 7.8647307\ttotal: 37s\tremaining: 7m 42s\n",
      "1706:\tlearn: 7.8633120\ttotal: 37.1s\tremaining: 7m 42s\n",
      "1707:\tlearn: 7.8622207\ttotal: 37.1s\tremaining: 7m 42s\n",
      "1708:\tlearn: 7.8610347\ttotal: 37.1s\tremaining: 7m 42s\n",
      "1709:\tlearn: 7.8587567\ttotal: 37.1s\tremaining: 7m 42s\n",
      "1710:\tlearn: 7.8568646\ttotal: 37.2s\tremaining: 7m 42s\n",
      "1711:\tlearn: 7.8555223\ttotal: 37.2s\tremaining: 7m 42s\n",
      "1712:\tlearn: 7.8538369\ttotal: 37.2s\tremaining: 7m 42s\n",
      "1713:\tlearn: 7.8527612\ttotal: 37.2s\tremaining: 7m 42s\n",
      "1714:\tlearn: 7.8512975\ttotal: 37.2s\tremaining: 7m 42s\n",
      "1715:\tlearn: 7.8499912\ttotal: 37.3s\tremaining: 7m 42s\n",
      "1716:\tlearn: 7.8488920\ttotal: 37.3s\tremaining: 7m 42s\n",
      "1717:\tlearn: 7.8471222\ttotal: 37.3s\tremaining: 7m 42s\n",
      "1718:\tlearn: 7.8457656\ttotal: 37.3s\tremaining: 7m 42s\n",
      "1719:\tlearn: 7.8446526\ttotal: 37.3s\tremaining: 7m 41s\n",
      "1720:\tlearn: 7.8436609\ttotal: 37.4s\tremaining: 7m 41s\n",
      "1721:\tlearn: 7.8426638\ttotal: 37.4s\tremaining: 7m 41s\n",
      "1722:\tlearn: 7.8414440\ttotal: 37.4s\tremaining: 7m 41s\n",
      "1723:\tlearn: 7.8402617\ttotal: 37.4s\tremaining: 7m 41s\n",
      "1724:\tlearn: 7.8396564\ttotal: 37.4s\tremaining: 7m 41s\n",
      "1725:\tlearn: 7.8381276\ttotal: 37.5s\tremaining: 7m 41s\n",
      "1726:\tlearn: 7.8366923\ttotal: 37.5s\tremaining: 7m 41s\n",
      "1727:\tlearn: 7.8354520\ttotal: 37.5s\tremaining: 7m 41s\n",
      "1728:\tlearn: 7.8333621\ttotal: 37.5s\tremaining: 7m 41s\n",
      "1729:\tlearn: 7.8324341\ttotal: 37.5s\tremaining: 7m 41s\n",
      "1730:\tlearn: 7.8303250\ttotal: 37.6s\tremaining: 7m 41s\n",
      "1731:\tlearn: 7.8292082\ttotal: 37.6s\tremaining: 7m 41s\n",
      "1732:\tlearn: 7.8276894\ttotal: 37.6s\tremaining: 7m 41s\n",
      "1733:\tlearn: 7.8264363\ttotal: 37.6s\tremaining: 7m 41s\n",
      "1734:\tlearn: 7.8251656\ttotal: 37.7s\tremaining: 7m 41s\n",
      "1735:\tlearn: 7.8238653\ttotal: 37.7s\tremaining: 7m 41s\n",
      "1736:\tlearn: 7.8222587\ttotal: 37.7s\tremaining: 7m 41s\n",
      "1737:\tlearn: 7.8207555\ttotal: 37.7s\tremaining: 7m 41s\n",
      "1738:\tlearn: 7.8195499\ttotal: 37.7s\tremaining: 7m 41s\n",
      "1739:\tlearn: 7.8186179\ttotal: 37.8s\tremaining: 7m 41s\n",
      "1740:\tlearn: 7.8171532\ttotal: 37.8s\tremaining: 7m 41s\n",
      "1741:\tlearn: 7.8157529\ttotal: 37.8s\tremaining: 7m 41s\n",
      "1742:\tlearn: 7.8139121\ttotal: 37.8s\tremaining: 7m 41s\n",
      "1743:\tlearn: 7.8125686\ttotal: 37.8s\tremaining: 7m 41s\n",
      "1744:\tlearn: 7.8112633\ttotal: 37.9s\tremaining: 7m 41s\n",
      "1745:\tlearn: 7.8101538\ttotal: 37.9s\tremaining: 7m 41s\n",
      "1746:\tlearn: 7.8090007\ttotal: 37.9s\tremaining: 7m 41s\n",
      "1747:\tlearn: 7.8077482\ttotal: 37.9s\tremaining: 7m 41s\n",
      "1748:\tlearn: 7.8059996\ttotal: 38s\tremaining: 7m 41s\n",
      "1749:\tlearn: 7.8039143\ttotal: 38s\tremaining: 7m 41s\n",
      "1750:\tlearn: 7.8028186\ttotal: 38s\tremaining: 7m 41s\n",
      "1751:\tlearn: 7.8013570\ttotal: 38s\tremaining: 7m 41s\n",
      "1752:\tlearn: 7.7998136\ttotal: 38s\tremaining: 7m 41s\n",
      "1753:\tlearn: 7.7985283\ttotal: 38.1s\tremaining: 7m 40s\n",
      "1754:\tlearn: 7.7974005\ttotal: 38.1s\tremaining: 7m 40s\n",
      "1755:\tlearn: 7.7964068\ttotal: 38.1s\tremaining: 7m 40s\n",
      "1756:\tlearn: 7.7946086\ttotal: 38.1s\tremaining: 7m 40s\n",
      "1757:\tlearn: 7.7926006\ttotal: 38.1s\tremaining: 7m 40s\n",
      "1758:\tlearn: 7.7913679\ttotal: 38.2s\tremaining: 7m 40s\n",
      "1759:\tlearn: 7.7901821\ttotal: 38.2s\tremaining: 7m 40s\n",
      "1760:\tlearn: 7.7893964\ttotal: 38.2s\tremaining: 7m 40s\n",
      "1761:\tlearn: 7.7883613\ttotal: 38.2s\tremaining: 7m 40s\n",
      "1762:\tlearn: 7.7870780\ttotal: 38.2s\tremaining: 7m 40s\n",
      "1763:\tlearn: 7.7854136\ttotal: 38.3s\tremaining: 7m 40s\n",
      "1764:\tlearn: 7.7841937\ttotal: 38.3s\tremaining: 7m 40s\n",
      "1765:\tlearn: 7.7832351\ttotal: 38.3s\tremaining: 7m 40s\n",
      "1766:\tlearn: 7.7812644\ttotal: 38.3s\tremaining: 7m 40s\n",
      "1767:\tlearn: 7.7804270\ttotal: 38.3s\tremaining: 7m 40s\n",
      "1768:\tlearn: 7.7791697\ttotal: 38.4s\tremaining: 7m 40s\n",
      "1769:\tlearn: 7.7777721\ttotal: 38.4s\tremaining: 7m 40s\n",
      "1770:\tlearn: 7.7763408\ttotal: 38.4s\tremaining: 7m 40s\n",
      "1771:\tlearn: 7.7751654\ttotal: 38.4s\tremaining: 7m 40s\n",
      "1772:\tlearn: 7.7742120\ttotal: 38.4s\tremaining: 7m 40s\n",
      "1773:\tlearn: 7.7727971\ttotal: 38.5s\tremaining: 7m 40s\n",
      "1774:\tlearn: 7.7712838\ttotal: 38.5s\tremaining: 7m 40s\n",
      "1775:\tlearn: 7.7700298\ttotal: 38.5s\tremaining: 7m 40s\n",
      "1776:\tlearn: 7.7686950\ttotal: 38.5s\tremaining: 7m 40s\n",
      "1777:\tlearn: 7.7673670\ttotal: 38.6s\tremaining: 7m 40s\n",
      "1778:\tlearn: 7.7660507\ttotal: 38.6s\tremaining: 7m 40s\n",
      "1779:\tlearn: 7.7650830\ttotal: 38.6s\tremaining: 7m 40s\n",
      "1780:\tlearn: 7.7628520\ttotal: 38.6s\tremaining: 7m 40s\n",
      "1781:\tlearn: 7.7609247\ttotal: 38.6s\tremaining: 7m 40s\n",
      "1782:\tlearn: 7.7597398\ttotal: 38.7s\tremaining: 7m 40s\n",
      "1783:\tlearn: 7.7579277\ttotal: 38.7s\tremaining: 7m 40s\n",
      "1784:\tlearn: 7.7560672\ttotal: 38.7s\tremaining: 7m 40s\n",
      "1785:\tlearn: 7.7544738\ttotal: 38.7s\tremaining: 7m 40s\n",
      "1786:\tlearn: 7.7530342\ttotal: 38.8s\tremaining: 7m 39s\n",
      "1787:\tlearn: 7.7510301\ttotal: 38.8s\tremaining: 7m 39s\n",
      "1788:\tlearn: 7.7490781\ttotal: 38.8s\tremaining: 7m 39s\n",
      "1789:\tlearn: 7.7476524\ttotal: 38.8s\tremaining: 7m 39s\n",
      "1790:\tlearn: 7.7461028\ttotal: 38.8s\tremaining: 7m 39s\n",
      "1791:\tlearn: 7.7440700\ttotal: 38.9s\tremaining: 7m 39s\n",
      "1792:\tlearn: 7.7426452\ttotal: 38.9s\tremaining: 7m 39s\n",
      "1793:\tlearn: 7.7413675\ttotal: 38.9s\tremaining: 7m 39s\n",
      "1794:\tlearn: 7.7403874\ttotal: 38.9s\tremaining: 7m 39s\n",
      "1795:\tlearn: 7.7389875\ttotal: 38.9s\tremaining: 7m 39s\n",
      "1796:\tlearn: 7.7373997\ttotal: 39s\tremaining: 7m 39s\n",
      "1797:\tlearn: 7.7362105\ttotal: 39s\tremaining: 7m 39s\n",
      "1798:\tlearn: 7.7344890\ttotal: 39s\tremaining: 7m 39s\n",
      "1799:\tlearn: 7.7332837\ttotal: 39s\tremaining: 7m 39s\n",
      "1800:\tlearn: 7.7315598\ttotal: 39.1s\tremaining: 7m 39s\n",
      "1801:\tlearn: 7.7302210\ttotal: 39.1s\tremaining: 7m 39s\n",
      "1802:\tlearn: 7.7285816\ttotal: 39.1s\tremaining: 7m 39s\n",
      "1803:\tlearn: 7.7268673\ttotal: 39.1s\tremaining: 7m 39s\n",
      "1804:\tlearn: 7.7259867\ttotal: 39.1s\tremaining: 7m 39s\n",
      "1805:\tlearn: 7.7239208\ttotal: 39.2s\tremaining: 7m 39s\n",
      "1806:\tlearn: 7.7221596\ttotal: 39.2s\tremaining: 7m 39s\n",
      "1807:\tlearn: 7.7204363\ttotal: 39.2s\tremaining: 7m 39s\n",
      "1808:\tlearn: 7.7187396\ttotal: 39.2s\tremaining: 7m 39s\n",
      "1809:\tlearn: 7.7173130\ttotal: 39.3s\tremaining: 7m 39s\n",
      "1810:\tlearn: 7.7159585\ttotal: 39.3s\tremaining: 7m 39s\n",
      "1811:\tlearn: 7.7148435\ttotal: 39.3s\tremaining: 7m 39s\n",
      "1812:\tlearn: 7.7131774\ttotal: 39.3s\tremaining: 7m 39s\n",
      "1813:\tlearn: 7.7120851\ttotal: 39.3s\tremaining: 7m 39s\n",
      "1814:\tlearn: 7.7101325\ttotal: 39.4s\tremaining: 7m 39s\n",
      "1815:\tlearn: 7.7088800\ttotal: 39.4s\tremaining: 7m 39s\n",
      "1816:\tlearn: 7.7079627\ttotal: 39.4s\tremaining: 7m 39s\n",
      "1817:\tlearn: 7.7063494\ttotal: 39.4s\tremaining: 7m 39s\n",
      "1818:\tlearn: 7.7049810\ttotal: 39.4s\tremaining: 7m 39s\n",
      "1819:\tlearn: 7.7032104\ttotal: 39.5s\tremaining: 7m 39s\n",
      "1820:\tlearn: 7.7011436\ttotal: 39.5s\tremaining: 7m 39s\n",
      "1821:\tlearn: 7.6997754\ttotal: 39.5s\tremaining: 7m 39s\n",
      "1822:\tlearn: 7.6987641\ttotal: 39.5s\tremaining: 7m 39s\n",
      "1823:\tlearn: 7.6975343\ttotal: 39.6s\tremaining: 7m 39s\n",
      "1824:\tlearn: 7.6964925\ttotal: 39.6s\tremaining: 7m 39s\n",
      "1825:\tlearn: 7.6953822\ttotal: 39.6s\tremaining: 7m 39s\n",
      "1826:\tlearn: 7.6942556\ttotal: 39.6s\tremaining: 7m 39s\n",
      "1827:\tlearn: 7.6928041\ttotal: 39.6s\tremaining: 7m 39s\n",
      "1828:\tlearn: 7.6920711\ttotal: 39.7s\tremaining: 7m 39s\n",
      "1829:\tlearn: 7.6912036\ttotal: 39.7s\tremaining: 7m 38s\n",
      "1830:\tlearn: 7.6899942\ttotal: 39.7s\tremaining: 7m 38s\n",
      "1831:\tlearn: 7.6884035\ttotal: 39.7s\tremaining: 7m 38s\n",
      "1832:\tlearn: 7.6861200\ttotal: 39.7s\tremaining: 7m 38s\n",
      "1833:\tlearn: 7.6851705\ttotal: 39.8s\tremaining: 7m 38s\n",
      "1834:\tlearn: 7.6838272\ttotal: 39.8s\tremaining: 7m 38s\n",
      "1835:\tlearn: 7.6825664\ttotal: 39.8s\tremaining: 7m 38s\n",
      "1836:\tlearn: 7.6807402\ttotal: 39.8s\tremaining: 7m 38s\n",
      "1837:\tlearn: 7.6793129\ttotal: 39.8s\tremaining: 7m 38s\n",
      "1838:\tlearn: 7.6776320\ttotal: 39.9s\tremaining: 7m 38s\n",
      "1839:\tlearn: 7.6760695\ttotal: 39.9s\tremaining: 7m 38s\n",
      "1840:\tlearn: 7.6743873\ttotal: 39.9s\tremaining: 7m 38s\n",
      "1841:\tlearn: 7.6735803\ttotal: 39.9s\tremaining: 7m 38s\n",
      "1842:\tlearn: 7.6721564\ttotal: 40s\tremaining: 7m 38s\n",
      "1843:\tlearn: 7.6707159\ttotal: 40s\tremaining: 7m 38s\n",
      "1844:\tlearn: 7.6692392\ttotal: 40s\tremaining: 7m 38s\n",
      "1845:\tlearn: 7.6682664\ttotal: 40s\tremaining: 7m 38s\n",
      "1846:\tlearn: 7.6663911\ttotal: 40.1s\tremaining: 7m 38s\n",
      "1847:\tlearn: 7.6653290\ttotal: 40.1s\tremaining: 7m 38s\n",
      "1848:\tlearn: 7.6639163\ttotal: 40.1s\tremaining: 7m 38s\n",
      "1849:\tlearn: 7.6628826\ttotal: 40.1s\tremaining: 7m 38s\n",
      "1850:\tlearn: 7.6614029\ttotal: 40.1s\tremaining: 7m 38s\n",
      "1851:\tlearn: 7.6605152\ttotal: 40.2s\tremaining: 7m 38s\n",
      "1852:\tlearn: 7.6587844\ttotal: 40.2s\tremaining: 7m 38s\n",
      "1853:\tlearn: 7.6574597\ttotal: 40.2s\tremaining: 7m 38s\n",
      "1854:\tlearn: 7.6556144\ttotal: 40.2s\tremaining: 7m 38s\n",
      "1855:\tlearn: 7.6540949\ttotal: 40.3s\tremaining: 7m 38s\n",
      "1856:\tlearn: 7.6527478\ttotal: 40.3s\tremaining: 7m 38s\n",
      "1857:\tlearn: 7.6513812\ttotal: 40.3s\tremaining: 7m 38s\n",
      "1858:\tlearn: 7.6498083\ttotal: 40.3s\tremaining: 7m 38s\n",
      "1859:\tlearn: 7.6480906\ttotal: 40.4s\tremaining: 7m 38s\n",
      "1860:\tlearn: 7.6469127\ttotal: 40.4s\tremaining: 7m 38s\n",
      "1861:\tlearn: 7.6459331\ttotal: 40.4s\tremaining: 7m 38s\n",
      "1862:\tlearn: 7.6446375\ttotal: 40.4s\tremaining: 7m 38s\n",
      "1863:\tlearn: 7.6434186\ttotal: 40.4s\tremaining: 7m 38s\n",
      "1864:\tlearn: 7.6413746\ttotal: 40.5s\tremaining: 7m 38s\n",
      "1865:\tlearn: 7.6397171\ttotal: 40.5s\tremaining: 7m 38s\n",
      "1866:\tlearn: 7.6378926\ttotal: 40.5s\tremaining: 7m 38s\n",
      "1867:\tlearn: 7.6370194\ttotal: 40.5s\tremaining: 7m 38s\n",
      "1868:\tlearn: 7.6361218\ttotal: 40.5s\tremaining: 7m 38s\n",
      "1869:\tlearn: 7.6339417\ttotal: 40.6s\tremaining: 7m 38s\n",
      "1870:\tlearn: 7.6326404\ttotal: 40.6s\tremaining: 7m 38s\n",
      "1871:\tlearn: 7.6308992\ttotal: 40.6s\tremaining: 7m 38s\n",
      "1872:\tlearn: 7.6292611\ttotal: 40.6s\tremaining: 7m 38s\n",
      "1873:\tlearn: 7.6282684\ttotal: 40.7s\tremaining: 7m 38s\n",
      "1874:\tlearn: 7.6269238\ttotal: 40.7s\tremaining: 7m 38s\n",
      "1875:\tlearn: 7.6258143\ttotal: 40.7s\tremaining: 7m 38s\n",
      "1876:\tlearn: 7.6244489\ttotal: 40.7s\tremaining: 7m 38s\n",
      "1877:\tlearn: 7.6230136\ttotal: 40.8s\tremaining: 7m 38s\n",
      "1878:\tlearn: 7.6214196\ttotal: 40.8s\tremaining: 7m 38s\n",
      "1879:\tlearn: 7.6200816\ttotal: 40.8s\tremaining: 7m 38s\n",
      "1880:\tlearn: 7.6190521\ttotal: 40.8s\tremaining: 7m 38s\n",
      "1881:\tlearn: 7.6174659\ttotal: 40.8s\tremaining: 7m 38s\n",
      "1882:\tlearn: 7.6164280\ttotal: 40.9s\tremaining: 7m 38s\n",
      "1883:\tlearn: 7.6146704\ttotal: 40.9s\tremaining: 7m 38s\n",
      "1884:\tlearn: 7.6136776\ttotal: 40.9s\tremaining: 7m 38s\n",
      "1885:\tlearn: 7.6128387\ttotal: 40.9s\tremaining: 7m 38s\n",
      "1886:\tlearn: 7.6122422\ttotal: 40.9s\tremaining: 7m 38s\n",
      "1887:\tlearn: 7.6109662\ttotal: 41s\tremaining: 7m 38s\n",
      "1888:\tlearn: 7.6093910\ttotal: 41s\tremaining: 7m 38s\n",
      "1889:\tlearn: 7.6075772\ttotal: 41s\tremaining: 7m 38s\n",
      "1890:\tlearn: 7.6066476\ttotal: 41s\tremaining: 7m 38s\n",
      "1891:\tlearn: 7.6054222\ttotal: 41.1s\tremaining: 7m 38s\n",
      "1892:\tlearn: 7.6045324\ttotal: 41.1s\tremaining: 7m 38s\n",
      "1893:\tlearn: 7.6036130\ttotal: 41.1s\tremaining: 7m 37s\n",
      "1894:\tlearn: 7.6026805\ttotal: 41.1s\tremaining: 7m 37s\n",
      "1895:\tlearn: 7.6018581\ttotal: 41.1s\tremaining: 7m 37s\n",
      "1896:\tlearn: 7.6007974\ttotal: 41.2s\tremaining: 7m 37s\n",
      "1897:\tlearn: 7.5992318\ttotal: 41.2s\tremaining: 7m 37s\n",
      "1898:\tlearn: 7.5975057\ttotal: 41.2s\tremaining: 7m 37s\n",
      "1899:\tlearn: 7.5968150\ttotal: 41.2s\tremaining: 7m 37s\n",
      "1900:\tlearn: 7.5952704\ttotal: 41.2s\tremaining: 7m 37s\n",
      "1901:\tlearn: 7.5942501\ttotal: 41.3s\tremaining: 7m 37s\n",
      "1902:\tlearn: 7.5931761\ttotal: 41.3s\tremaining: 7m 37s\n",
      "1903:\tlearn: 7.5921163\ttotal: 41.3s\tremaining: 7m 37s\n",
      "1904:\tlearn: 7.5911072\ttotal: 41.3s\tremaining: 7m 37s\n",
      "1905:\tlearn: 7.5890963\ttotal: 41.3s\tremaining: 7m 37s\n",
      "1906:\tlearn: 7.5871059\ttotal: 41.4s\tremaining: 7m 37s\n",
      "1907:\tlearn: 7.5860042\ttotal: 41.4s\tremaining: 7m 37s\n",
      "1908:\tlearn: 7.5850287\ttotal: 41.4s\tremaining: 7m 37s\n",
      "1909:\tlearn: 7.5838522\ttotal: 41.4s\tremaining: 7m 37s\n",
      "1910:\tlearn: 7.5828684\ttotal: 41.4s\tremaining: 7m 37s\n",
      "1911:\tlearn: 7.5813203\ttotal: 41.5s\tremaining: 7m 37s\n",
      "1912:\tlearn: 7.5799482\ttotal: 41.5s\tremaining: 7m 37s\n",
      "1913:\tlearn: 7.5790534\ttotal: 41.5s\tremaining: 7m 37s\n",
      "1914:\tlearn: 7.5780875\ttotal: 41.5s\tremaining: 7m 37s\n",
      "1915:\tlearn: 7.5761965\ttotal: 41.6s\tremaining: 7m 37s\n",
      "1916:\tlearn: 7.5752175\ttotal: 41.6s\tremaining: 7m 37s\n",
      "1917:\tlearn: 7.5738594\ttotal: 41.6s\tremaining: 7m 37s\n",
      "1918:\tlearn: 7.5725894\ttotal: 41.6s\tremaining: 7m 37s\n",
      "1919:\tlearn: 7.5715246\ttotal: 41.6s\tremaining: 7m 37s\n",
      "1920:\tlearn: 7.5696506\ttotal: 41.7s\tremaining: 7m 37s\n",
      "1921:\tlearn: 7.5684591\ttotal: 41.7s\tremaining: 7m 37s\n",
      "1922:\tlearn: 7.5666244\ttotal: 41.7s\tremaining: 7m 37s\n",
      "1923:\tlearn: 7.5653975\ttotal: 41.7s\tremaining: 7m 37s\n",
      "1924:\tlearn: 7.5637793\ttotal: 41.8s\tremaining: 7m 37s\n",
      "1925:\tlearn: 7.5623119\ttotal: 41.8s\tremaining: 7m 37s\n",
      "1926:\tlearn: 7.5611988\ttotal: 41.8s\tremaining: 7m 37s\n",
      "1927:\tlearn: 7.5602767\ttotal: 41.8s\tremaining: 7m 37s\n",
      "1928:\tlearn: 7.5591538\ttotal: 41.8s\tremaining: 7m 37s\n",
      "1929:\tlearn: 7.5580198\ttotal: 41.9s\tremaining: 7m 37s\n",
      "1930:\tlearn: 7.5566209\ttotal: 41.9s\tremaining: 7m 37s\n",
      "1931:\tlearn: 7.5556732\ttotal: 41.9s\tremaining: 7m 37s\n",
      "1932:\tlearn: 7.5543645\ttotal: 41.9s\tremaining: 7m 37s\n",
      "1933:\tlearn: 7.5532208\ttotal: 42s\tremaining: 7m 37s\n",
      "1934:\tlearn: 7.5514246\ttotal: 42s\tremaining: 7m 37s\n",
      "1935:\tlearn: 7.5505050\ttotal: 42s\tremaining: 7m 37s\n",
      "1936:\tlearn: 7.5494747\ttotal: 42s\tremaining: 7m 37s\n",
      "1937:\tlearn: 7.5486259\ttotal: 42s\tremaining: 7m 36s\n",
      "1938:\tlearn: 7.5473982\ttotal: 42.1s\tremaining: 7m 36s\n",
      "1939:\tlearn: 7.5462338\ttotal: 42.1s\tremaining: 7m 36s\n",
      "1940:\tlearn: 7.5447668\ttotal: 42.1s\tremaining: 7m 36s\n",
      "1941:\tlearn: 7.5428950\ttotal: 42.1s\tremaining: 7m 36s\n",
      "1942:\tlearn: 7.5419877\ttotal: 42.2s\tremaining: 7m 36s\n",
      "1943:\tlearn: 7.5408672\ttotal: 42.2s\tremaining: 7m 36s\n",
      "1944:\tlearn: 7.5396068\ttotal: 42.2s\tremaining: 7m 36s\n",
      "1945:\tlearn: 7.5381330\ttotal: 42.2s\tremaining: 7m 36s\n",
      "1946:\tlearn: 7.5370491\ttotal: 42.2s\tremaining: 7m 36s\n",
      "1947:\tlearn: 7.5360025\ttotal: 42.3s\tremaining: 7m 36s\n",
      "1948:\tlearn: 7.5346930\ttotal: 42.3s\tremaining: 7m 36s\n",
      "1949:\tlearn: 7.5322455\ttotal: 42.3s\tremaining: 7m 36s\n",
      "1950:\tlearn: 7.5310500\ttotal: 42.3s\tremaining: 7m 36s\n",
      "1951:\tlearn: 7.5296285\ttotal: 42.3s\tremaining: 7m 36s\n",
      "1952:\tlearn: 7.5289590\ttotal: 42.4s\tremaining: 7m 36s\n",
      "1953:\tlearn: 7.5277074\ttotal: 42.4s\tremaining: 7m 36s\n",
      "1954:\tlearn: 7.5267439\ttotal: 42.4s\tremaining: 7m 36s\n",
      "1955:\tlearn: 7.5258772\ttotal: 42.4s\tremaining: 7m 36s\n",
      "1956:\tlearn: 7.5246245\ttotal: 42.5s\tremaining: 7m 36s\n",
      "1957:\tlearn: 7.5227486\ttotal: 42.5s\tremaining: 7m 36s\n",
      "1958:\tlearn: 7.5212718\ttotal: 42.5s\tremaining: 7m 36s\n",
      "1959:\tlearn: 7.5202652\ttotal: 42.5s\tremaining: 7m 36s\n",
      "1960:\tlearn: 7.5188213\ttotal: 42.5s\tremaining: 7m 36s\n",
      "1961:\tlearn: 7.5172474\ttotal: 42.6s\tremaining: 7m 36s\n",
      "1962:\tlearn: 7.5152871\ttotal: 42.6s\tremaining: 7m 36s\n",
      "1963:\tlearn: 7.5139098\ttotal: 42.6s\tremaining: 7m 36s\n",
      "1964:\tlearn: 7.5131923\ttotal: 42.6s\tremaining: 7m 36s\n",
      "1965:\tlearn: 7.5119738\ttotal: 42.7s\tremaining: 7m 36s\n",
      "1966:\tlearn: 7.5105581\ttotal: 42.7s\tremaining: 7m 36s\n",
      "1967:\tlearn: 7.5096943\ttotal: 42.7s\tremaining: 7m 36s\n",
      "1968:\tlearn: 7.5087469\ttotal: 42.7s\tremaining: 7m 36s\n",
      "1969:\tlearn: 7.5071764\ttotal: 42.7s\tremaining: 7m 36s\n",
      "1970:\tlearn: 7.5054471\ttotal: 42.8s\tremaining: 7m 36s\n",
      "1971:\tlearn: 7.5043931\ttotal: 42.8s\tremaining: 7m 36s\n",
      "1972:\tlearn: 7.5031243\ttotal: 42.8s\tremaining: 7m 36s\n",
      "1973:\tlearn: 7.5022164\ttotal: 42.8s\tremaining: 7m 36s\n",
      "1974:\tlearn: 7.5009203\ttotal: 42.8s\tremaining: 7m 36s\n",
      "1975:\tlearn: 7.4997809\ttotal: 42.9s\tremaining: 7m 35s\n",
      "1976:\tlearn: 7.4989052\ttotal: 42.9s\tremaining: 7m 35s\n",
      "1977:\tlearn: 7.4971663\ttotal: 42.9s\tremaining: 7m 35s\n",
      "1978:\tlearn: 7.4957404\ttotal: 42.9s\tremaining: 7m 36s\n",
      "1979:\tlearn: 7.4943575\ttotal: 42.9s\tremaining: 7m 35s\n",
      "1980:\tlearn: 7.4926249\ttotal: 43s\tremaining: 7m 35s\n",
      "1981:\tlearn: 7.4906334\ttotal: 43s\tremaining: 7m 35s\n",
      "1982:\tlearn: 7.4888416\ttotal: 43s\tremaining: 7m 36s\n",
      "1983:\tlearn: 7.4874005\ttotal: 43s\tremaining: 7m 35s\n",
      "1984:\tlearn: 7.4855796\ttotal: 43.1s\tremaining: 7m 35s\n",
      "1985:\tlearn: 7.4846356\ttotal: 43.1s\tremaining: 7m 35s\n",
      "1986:\tlearn: 7.4825849\ttotal: 43.1s\tremaining: 7m 35s\n",
      "1987:\tlearn: 7.4811745\ttotal: 43.1s\tremaining: 7m 35s\n",
      "1988:\tlearn: 7.4802809\ttotal: 43.2s\tremaining: 7m 35s\n",
      "1989:\tlearn: 7.4792655\ttotal: 43.2s\tremaining: 7m 35s\n",
      "1990:\tlearn: 7.4780031\ttotal: 43.2s\tremaining: 7m 35s\n",
      "1991:\tlearn: 7.4771614\ttotal: 43.2s\tremaining: 7m 35s\n",
      "1992:\tlearn: 7.4761607\ttotal: 43.2s\tremaining: 7m 35s\n",
      "1993:\tlearn: 7.4751330\ttotal: 43.3s\tremaining: 7m 35s\n",
      "1994:\tlearn: 7.4737033\ttotal: 43.3s\tremaining: 7m 35s\n",
      "1995:\tlearn: 7.4725341\ttotal: 43.3s\tremaining: 7m 35s\n",
      "1996:\tlearn: 7.4712771\ttotal: 43.3s\tremaining: 7m 35s\n",
      "1997:\tlearn: 7.4705336\ttotal: 43.3s\tremaining: 7m 35s\n",
      "1998:\tlearn: 7.4688556\ttotal: 43.4s\tremaining: 7m 35s\n",
      "1999:\tlearn: 7.4678611\ttotal: 43.4s\tremaining: 7m 35s\n",
      "2000:\tlearn: 7.4665642\ttotal: 43.4s\tremaining: 7m 35s\n",
      "2001:\tlearn: 7.4658551\ttotal: 43.4s\tremaining: 7m 35s\n",
      "2002:\tlearn: 7.4643807\ttotal: 43.4s\tremaining: 7m 35s\n",
      "2003:\tlearn: 7.4630448\ttotal: 43.5s\tremaining: 7m 35s\n",
      "2004:\tlearn: 7.4621077\ttotal: 43.5s\tremaining: 7m 35s\n",
      "2005:\tlearn: 7.4612876\ttotal: 43.5s\tremaining: 7m 35s\n",
      "2006:\tlearn: 7.4601030\ttotal: 43.5s\tremaining: 7m 35s\n",
      "2007:\tlearn: 7.4590796\ttotal: 43.5s\tremaining: 7m 35s\n",
      "2008:\tlearn: 7.4577312\ttotal: 43.6s\tremaining: 7m 35s\n",
      "2009:\tlearn: 7.4560936\ttotal: 43.6s\tremaining: 7m 35s\n",
      "2010:\tlearn: 7.4545062\ttotal: 43.6s\tremaining: 7m 35s\n",
      "2011:\tlearn: 7.4536725\ttotal: 43.6s\tremaining: 7m 35s\n",
      "2012:\tlearn: 7.4525675\ttotal: 43.7s\tremaining: 7m 35s\n",
      "2013:\tlearn: 7.4516321\ttotal: 43.7s\tremaining: 7m 35s\n",
      "2014:\tlearn: 7.4503274\ttotal: 43.7s\tremaining: 7m 35s\n",
      "2015:\tlearn: 7.4494706\ttotal: 43.7s\tremaining: 7m 35s\n",
      "2016:\tlearn: 7.4483642\ttotal: 43.7s\tremaining: 7m 35s\n",
      "2017:\tlearn: 7.4473328\ttotal: 43.8s\tremaining: 7m 35s\n",
      "2018:\tlearn: 7.4458783\ttotal: 43.8s\tremaining: 7m 35s\n",
      "2019:\tlearn: 7.4451185\ttotal: 43.8s\tremaining: 7m 34s\n",
      "2020:\tlearn: 7.4438775\ttotal: 43.8s\tremaining: 7m 34s\n",
      "2021:\tlearn: 7.4429757\ttotal: 43.8s\tremaining: 7m 34s\n",
      "2022:\tlearn: 7.4416046\ttotal: 43.9s\tremaining: 7m 34s\n",
      "2023:\tlearn: 7.4403154\ttotal: 43.9s\tremaining: 7m 34s\n",
      "2024:\tlearn: 7.4392363\ttotal: 43.9s\tremaining: 7m 34s\n",
      "2025:\tlearn: 7.4375509\ttotal: 43.9s\tremaining: 7m 34s\n",
      "2026:\tlearn: 7.4360760\ttotal: 44s\tremaining: 7m 34s\n",
      "2027:\tlearn: 7.4347957\ttotal: 44s\tremaining: 7m 34s\n",
      "2028:\tlearn: 7.4338776\ttotal: 44s\tremaining: 7m 34s\n",
      "2029:\tlearn: 7.4329282\ttotal: 44s\tremaining: 7m 34s\n",
      "2030:\tlearn: 7.4321603\ttotal: 44s\tremaining: 7m 34s\n",
      "2031:\tlearn: 7.4308923\ttotal: 44.1s\tremaining: 7m 34s\n",
      "2032:\tlearn: 7.4298845\ttotal: 44.1s\tremaining: 7m 34s\n",
      "2033:\tlearn: 7.4289453\ttotal: 44.1s\tremaining: 7m 34s\n",
      "2034:\tlearn: 7.4277664\ttotal: 44.1s\tremaining: 7m 34s\n",
      "2035:\tlearn: 7.4269028\ttotal: 44.1s\tremaining: 7m 34s\n",
      "2036:\tlearn: 7.4260002\ttotal: 44.2s\tremaining: 7m 34s\n",
      "2037:\tlearn: 7.4249222\ttotal: 44.2s\tremaining: 7m 34s\n",
      "2038:\tlearn: 7.4239471\ttotal: 44.2s\tremaining: 7m 34s\n",
      "2039:\tlearn: 7.4228737\ttotal: 44.2s\tremaining: 7m 34s\n",
      "2040:\tlearn: 7.4216173\ttotal: 44.2s\tremaining: 7m 34s\n",
      "2041:\tlearn: 7.4201879\ttotal: 44.3s\tremaining: 7m 34s\n",
      "2042:\tlearn: 7.4187588\ttotal: 44.3s\tremaining: 7m 34s\n",
      "2043:\tlearn: 7.4180672\ttotal: 44.3s\tremaining: 7m 34s\n",
      "2044:\tlearn: 7.4173118\ttotal: 44.3s\tremaining: 7m 34s\n",
      "2045:\tlearn: 7.4162404\ttotal: 44.3s\tremaining: 7m 34s\n",
      "2046:\tlearn: 7.4145638\ttotal: 44.4s\tremaining: 7m 34s\n",
      "2047:\tlearn: 7.4135459\ttotal: 44.4s\tremaining: 7m 34s\n",
      "2048:\tlearn: 7.4118021\ttotal: 44.4s\tremaining: 7m 34s\n",
      "2049:\tlearn: 7.4105399\ttotal: 44.4s\tremaining: 7m 34s\n",
      "2050:\tlearn: 7.4091393\ttotal: 44.5s\tremaining: 7m 34s\n",
      "2051:\tlearn: 7.4080686\ttotal: 44.5s\tremaining: 7m 33s\n",
      "2052:\tlearn: 7.4070993\ttotal: 44.5s\tremaining: 7m 33s\n",
      "2053:\tlearn: 7.4060228\ttotal: 44.5s\tremaining: 7m 33s\n",
      "2054:\tlearn: 7.4048513\ttotal: 44.5s\tremaining: 7m 33s\n",
      "2055:\tlearn: 7.4041527\ttotal: 44.6s\tremaining: 7m 33s\n",
      "2056:\tlearn: 7.4036499\ttotal: 44.6s\tremaining: 7m 33s\n",
      "2057:\tlearn: 7.4023302\ttotal: 44.6s\tremaining: 7m 33s\n",
      "2058:\tlearn: 7.4009713\ttotal: 44.6s\tremaining: 7m 33s\n",
      "2059:\tlearn: 7.4000575\ttotal: 44.6s\tremaining: 7m 33s\n",
      "2060:\tlearn: 7.3983536\ttotal: 44.7s\tremaining: 7m 33s\n",
      "2061:\tlearn: 7.3967512\ttotal: 44.7s\tremaining: 7m 33s\n",
      "2062:\tlearn: 7.3951772\ttotal: 44.7s\tremaining: 7m 33s\n",
      "2063:\tlearn: 7.3940572\ttotal: 44.7s\tremaining: 7m 33s\n",
      "2064:\tlearn: 7.3929201\ttotal: 44.8s\tremaining: 7m 33s\n",
      "2065:\tlearn: 7.3911745\ttotal: 44.8s\tremaining: 7m 33s\n",
      "2066:\tlearn: 7.3894505\ttotal: 44.8s\tremaining: 7m 33s\n",
      "2067:\tlearn: 7.3881975\ttotal: 44.8s\tremaining: 7m 33s\n",
      "2068:\tlearn: 7.3863528\ttotal: 44.8s\tremaining: 7m 33s\n",
      "2069:\tlearn: 7.3858263\ttotal: 44.9s\tremaining: 7m 33s\n",
      "2070:\tlearn: 7.3844581\ttotal: 44.9s\tremaining: 7m 33s\n",
      "2071:\tlearn: 7.3833003\ttotal: 44.9s\tremaining: 7m 33s\n",
      "2072:\tlearn: 7.3823398\ttotal: 44.9s\tremaining: 7m 33s\n",
      "2073:\tlearn: 7.3811735\ttotal: 45s\tremaining: 7m 33s\n",
      "2074:\tlearn: 7.3797519\ttotal: 45s\tremaining: 7m 33s\n",
      "2075:\tlearn: 7.3780693\ttotal: 45s\tremaining: 7m 33s\n",
      "2076:\tlearn: 7.3764864\ttotal: 45s\tremaining: 7m 33s\n",
      "2077:\tlearn: 7.3749087\ttotal: 45s\tremaining: 7m 33s\n",
      "2078:\tlearn: 7.3742322\ttotal: 45.1s\tremaining: 7m 33s\n",
      "2079:\tlearn: 7.3733362\ttotal: 45.1s\tremaining: 7m 33s\n",
      "2080:\tlearn: 7.3721461\ttotal: 45.1s\tremaining: 7m 33s\n",
      "2081:\tlearn: 7.3713922\ttotal: 45.1s\tremaining: 7m 33s\n",
      "2082:\tlearn: 7.3699993\ttotal: 45.1s\tremaining: 7m 33s\n",
      "2083:\tlearn: 7.3689455\ttotal: 45.2s\tremaining: 7m 33s\n",
      "2084:\tlearn: 7.3674332\ttotal: 45.2s\tremaining: 7m 33s\n",
      "2085:\tlearn: 7.3663627\ttotal: 45.2s\tremaining: 7m 33s\n",
      "2086:\tlearn: 7.3652480\ttotal: 45.2s\tremaining: 7m 33s\n",
      "2087:\tlearn: 7.3642793\ttotal: 45.3s\tremaining: 7m 33s\n",
      "2088:\tlearn: 7.3631727\ttotal: 45.3s\tremaining: 7m 33s\n",
      "2089:\tlearn: 7.3609638\ttotal: 45.3s\tremaining: 7m 33s\n",
      "2090:\tlearn: 7.3597290\ttotal: 45.3s\tremaining: 7m 33s\n",
      "2091:\tlearn: 7.3587133\ttotal: 45.3s\tremaining: 7m 33s\n",
      "2092:\tlearn: 7.3580080\ttotal: 45.4s\tremaining: 7m 33s\n",
      "2093:\tlearn: 7.3562481\ttotal: 45.4s\tremaining: 7m 33s\n",
      "2094:\tlearn: 7.3549289\ttotal: 45.4s\tremaining: 7m 33s\n",
      "2095:\tlearn: 7.3537560\ttotal: 45.4s\tremaining: 7m 33s\n",
      "2096:\tlearn: 7.3528803\ttotal: 45.4s\tremaining: 7m 33s\n",
      "2097:\tlearn: 7.3517920\ttotal: 45.5s\tremaining: 7m 32s\n",
      "2098:\tlearn: 7.3505645\ttotal: 45.5s\tremaining: 7m 32s\n",
      "2099:\tlearn: 7.3492688\ttotal: 45.5s\tremaining: 7m 32s\n",
      "2100:\tlearn: 7.3481844\ttotal: 45.5s\tremaining: 7m 32s\n",
      "2101:\tlearn: 7.3468235\ttotal: 45.6s\tremaining: 7m 32s\n",
      "2102:\tlearn: 7.3459439\ttotal: 45.6s\tremaining: 7m 32s\n",
      "2103:\tlearn: 7.3449141\ttotal: 45.6s\tremaining: 7m 32s\n",
      "2104:\tlearn: 7.3439647\ttotal: 45.6s\tremaining: 7m 32s\n",
      "2105:\tlearn: 7.3421256\ttotal: 45.6s\tremaining: 7m 32s\n",
      "2106:\tlearn: 7.3414143\ttotal: 45.7s\tremaining: 7m 32s\n",
      "2107:\tlearn: 7.3398640\ttotal: 45.7s\tremaining: 7m 32s\n",
      "2108:\tlearn: 7.3387316\ttotal: 45.7s\tremaining: 7m 32s\n",
      "2109:\tlearn: 7.3373308\ttotal: 45.7s\tremaining: 7m 32s\n",
      "2110:\tlearn: 7.3355711\ttotal: 45.8s\tremaining: 7m 32s\n",
      "2111:\tlearn: 7.3340390\ttotal: 45.8s\tremaining: 7m 32s\n",
      "2112:\tlearn: 7.3332384\ttotal: 45.8s\tremaining: 7m 32s\n",
      "2113:\tlearn: 7.3323159\ttotal: 45.8s\tremaining: 7m 32s\n",
      "2114:\tlearn: 7.3311621\ttotal: 45.8s\tremaining: 7m 32s\n",
      "2115:\tlearn: 7.3304740\ttotal: 45.9s\tremaining: 7m 32s\n",
      "2116:\tlearn: 7.3295725\ttotal: 45.9s\tremaining: 7m 32s\n",
      "2117:\tlearn: 7.3288170\ttotal: 45.9s\tremaining: 7m 32s\n",
      "2118:\tlearn: 7.3272106\ttotal: 45.9s\tremaining: 7m 32s\n",
      "2119:\tlearn: 7.3263907\ttotal: 45.9s\tremaining: 7m 32s\n",
      "2120:\tlearn: 7.3252401\ttotal: 46s\tremaining: 7m 32s\n",
      "2121:\tlearn: 7.3240846\ttotal: 46s\tremaining: 7m 32s\n",
      "2122:\tlearn: 7.3231574\ttotal: 46s\tremaining: 7m 32s\n",
      "2123:\tlearn: 7.3220477\ttotal: 46s\tremaining: 7m 32s\n",
      "2124:\tlearn: 7.3211039\ttotal: 46s\tremaining: 7m 32s\n",
      "2125:\tlearn: 7.3201992\ttotal: 46.1s\tremaining: 7m 32s\n",
      "2126:\tlearn: 7.3190389\ttotal: 46.1s\tremaining: 7m 32s\n",
      "2127:\tlearn: 7.3179562\ttotal: 46.1s\tremaining: 7m 32s\n",
      "2128:\tlearn: 7.3164016\ttotal: 46.1s\tremaining: 7m 32s\n",
      "2129:\tlearn: 7.3157078\ttotal: 46.2s\tremaining: 7m 32s\n",
      "2130:\tlearn: 7.3148842\ttotal: 46.2s\tremaining: 7m 32s\n",
      "2131:\tlearn: 7.3137459\ttotal: 46.2s\tremaining: 7m 32s\n",
      "2132:\tlearn: 7.3126690\ttotal: 46.2s\tremaining: 7m 32s\n",
      "2133:\tlearn: 7.3116881\ttotal: 46.2s\tremaining: 7m 32s\n",
      "2134:\tlearn: 7.3107970\ttotal: 46.2s\tremaining: 7m 31s\n",
      "2135:\tlearn: 7.3092678\ttotal: 46.3s\tremaining: 7m 31s\n",
      "2136:\tlearn: 7.3082213\ttotal: 46.3s\tremaining: 7m 31s\n",
      "2137:\tlearn: 7.3075159\ttotal: 46.3s\tremaining: 7m 31s\n",
      "2138:\tlearn: 7.3066622\ttotal: 46.3s\tremaining: 7m 31s\n",
      "2139:\tlearn: 7.3054801\ttotal: 46.4s\tremaining: 7m 31s\n",
      "2140:\tlearn: 7.3037893\ttotal: 46.4s\tremaining: 7m 31s\n",
      "2141:\tlearn: 7.3025989\ttotal: 46.4s\tremaining: 7m 31s\n",
      "2142:\tlearn: 7.3004429\ttotal: 46.4s\tremaining: 7m 31s\n",
      "2143:\tlearn: 7.2990145\ttotal: 46.4s\tremaining: 7m 31s\n",
      "2144:\tlearn: 7.2982708\ttotal: 46.5s\tremaining: 7m 31s\n",
      "2145:\tlearn: 7.2969140\ttotal: 46.5s\tremaining: 7m 31s\n",
      "2146:\tlearn: 7.2954385\ttotal: 46.5s\tremaining: 7m 31s\n",
      "2147:\tlearn: 7.2941107\ttotal: 46.5s\tremaining: 7m 31s\n",
      "2148:\tlearn: 7.2927011\ttotal: 46.6s\tremaining: 7m 31s\n",
      "2149:\tlearn: 7.2914925\ttotal: 46.6s\tremaining: 7m 31s\n",
      "2150:\tlearn: 7.2903482\ttotal: 46.6s\tremaining: 7m 31s\n",
      "2151:\tlearn: 7.2884721\ttotal: 46.6s\tremaining: 7m 31s\n",
      "2152:\tlearn: 7.2875862\ttotal: 46.7s\tremaining: 7m 31s\n",
      "2153:\tlearn: 7.2866468\ttotal: 46.7s\tremaining: 7m 31s\n",
      "2154:\tlearn: 7.2856340\ttotal: 46.7s\tremaining: 7m 31s\n",
      "2155:\tlearn: 7.2845176\ttotal: 46.7s\tremaining: 7m 31s\n",
      "2156:\tlearn: 7.2837203\ttotal: 46.8s\tremaining: 7m 31s\n",
      "2157:\tlearn: 7.2829376\ttotal: 46.8s\tremaining: 7m 31s\n",
      "2158:\tlearn: 7.2818791\ttotal: 46.8s\tremaining: 7m 31s\n",
      "2159:\tlearn: 7.2808327\ttotal: 46.8s\tremaining: 7m 31s\n",
      "2160:\tlearn: 7.2804047\ttotal: 46.8s\tremaining: 7m 31s\n",
      "2161:\tlearn: 7.2794256\ttotal: 46.9s\tremaining: 7m 31s\n",
      "2162:\tlearn: 7.2786081\ttotal: 46.9s\tremaining: 7m 31s\n",
      "2163:\tlearn: 7.2777065\ttotal: 46.9s\tremaining: 7m 31s\n",
      "2164:\tlearn: 7.2762586\ttotal: 46.9s\tremaining: 7m 31s\n",
      "2165:\tlearn: 7.2751276\ttotal: 47s\tremaining: 7m 31s\n",
      "2166:\tlearn: 7.2736034\ttotal: 47s\tremaining: 7m 31s\n",
      "2167:\tlearn: 7.2722039\ttotal: 47s\tremaining: 7m 31s\n",
      "2168:\tlearn: 7.2710047\ttotal: 47s\tremaining: 7m 31s\n",
      "2169:\tlearn: 7.2698667\ttotal: 47.1s\tremaining: 7m 31s\n",
      "2170:\tlearn: 7.2683481\ttotal: 47.1s\tremaining: 7m 31s\n",
      "2171:\tlearn: 7.2667813\ttotal: 47.1s\tremaining: 7m 31s\n",
      "2172:\tlearn: 7.2654259\ttotal: 47.1s\tremaining: 7m 31s\n",
      "2173:\tlearn: 7.2643140\ttotal: 47.2s\tremaining: 7m 31s\n",
      "2174:\tlearn: 7.2627971\ttotal: 47.2s\tremaining: 7m 31s\n",
      "2175:\tlearn: 7.2620453\ttotal: 47.2s\tremaining: 7m 31s\n",
      "2176:\tlearn: 7.2608967\ttotal: 47.2s\tremaining: 7m 31s\n",
      "2177:\tlearn: 7.2595075\ttotal: 47.3s\tremaining: 7m 31s\n",
      "2178:\tlearn: 7.2578442\ttotal: 47.3s\tremaining: 7m 31s\n",
      "2179:\tlearn: 7.2567915\ttotal: 47.3s\tremaining: 7m 31s\n",
      "2180:\tlearn: 7.2559983\ttotal: 47.3s\tremaining: 7m 31s\n",
      "2181:\tlearn: 7.2553105\ttotal: 47.3s\tremaining: 7m 31s\n",
      "2182:\tlearn: 7.2544349\ttotal: 47.4s\tremaining: 7m 31s\n",
      "2183:\tlearn: 7.2531942\ttotal: 47.4s\tremaining: 7m 31s\n",
      "2184:\tlearn: 7.2520205\ttotal: 47.4s\tremaining: 7m 31s\n",
      "2185:\tlearn: 7.2512575\ttotal: 47.4s\tremaining: 7m 31s\n",
      "2186:\tlearn: 7.2505893\ttotal: 47.4s\tremaining: 7m 31s\n",
      "2187:\tlearn: 7.2495518\ttotal: 47.5s\tremaining: 7m 31s\n",
      "2188:\tlearn: 7.2483266\ttotal: 47.5s\tremaining: 7m 31s\n",
      "2189:\tlearn: 7.2467629\ttotal: 47.5s\tremaining: 7m 31s\n",
      "2190:\tlearn: 7.2457851\ttotal: 47.5s\tremaining: 7m 31s\n",
      "2191:\tlearn: 7.2443520\ttotal: 47.5s\tremaining: 7m 31s\n",
      "2192:\tlearn: 7.2437665\ttotal: 47.6s\tremaining: 7m 31s\n",
      "2193:\tlearn: 7.2426241\ttotal: 47.6s\tremaining: 7m 31s\n",
      "2194:\tlearn: 7.2416649\ttotal: 47.6s\tremaining: 7m 31s\n",
      "2195:\tlearn: 7.2406307\ttotal: 47.6s\tremaining: 7m 31s\n",
      "2196:\tlearn: 7.2397934\ttotal: 47.7s\tremaining: 7m 31s\n",
      "2197:\tlearn: 7.2384786\ttotal: 47.7s\tremaining: 7m 31s\n",
      "2198:\tlearn: 7.2369782\ttotal: 47.7s\tremaining: 7m 31s\n",
      "2199:\tlearn: 7.2359702\ttotal: 47.7s\tremaining: 7m 31s\n",
      "2200:\tlearn: 7.2350907\ttotal: 47.7s\tremaining: 7m 31s\n",
      "2201:\tlearn: 7.2344596\ttotal: 47.8s\tremaining: 7m 31s\n",
      "2202:\tlearn: 7.2331341\ttotal: 47.8s\tremaining: 7m 31s\n",
      "2203:\tlearn: 7.2317583\ttotal: 47.8s\tremaining: 7m 31s\n",
      "2204:\tlearn: 7.2301099\ttotal: 47.8s\tremaining: 7m 31s\n",
      "2205:\tlearn: 7.2289049\ttotal: 47.9s\tremaining: 7m 31s\n",
      "2206:\tlearn: 7.2270501\ttotal: 47.9s\tremaining: 7m 31s\n",
      "2207:\tlearn: 7.2262035\ttotal: 47.9s\tremaining: 7m 31s\n",
      "2208:\tlearn: 7.2245584\ttotal: 47.9s\tremaining: 7m 30s\n",
      "2209:\tlearn: 7.2235645\ttotal: 47.9s\tremaining: 7m 31s\n",
      "2210:\tlearn: 7.2226989\ttotal: 48s\tremaining: 7m 30s\n",
      "2211:\tlearn: 7.2219242\ttotal: 48s\tremaining: 7m 30s\n",
      "2212:\tlearn: 7.2209312\ttotal: 48s\tremaining: 7m 30s\n",
      "2213:\tlearn: 7.2201717\ttotal: 48s\tremaining: 7m 30s\n",
      "2214:\tlearn: 7.2185432\ttotal: 48.1s\tremaining: 7m 30s\n",
      "2215:\tlearn: 7.2176553\ttotal: 48.1s\tremaining: 7m 30s\n",
      "2216:\tlearn: 7.2162470\ttotal: 48.1s\tremaining: 7m 30s\n",
      "2217:\tlearn: 7.2148528\ttotal: 48.1s\tremaining: 7m 30s\n",
      "2218:\tlearn: 7.2135788\ttotal: 48.1s\tremaining: 7m 30s\n",
      "2219:\tlearn: 7.2129783\ttotal: 48.2s\tremaining: 7m 30s\n",
      "2220:\tlearn: 7.2122874\ttotal: 48.2s\tremaining: 7m 30s\n",
      "2221:\tlearn: 7.2117606\ttotal: 48.2s\tremaining: 7m 30s\n",
      "2222:\tlearn: 7.2110793\ttotal: 48.2s\tremaining: 7m 30s\n",
      "2223:\tlearn: 7.2105118\ttotal: 48.2s\tremaining: 7m 30s\n",
      "2224:\tlearn: 7.2097463\ttotal: 48.3s\tremaining: 7m 30s\n",
      "2225:\tlearn: 7.2086254\ttotal: 48.3s\tremaining: 7m 30s\n",
      "2226:\tlearn: 7.2073074\ttotal: 48.3s\tremaining: 7m 30s\n",
      "2227:\tlearn: 7.2058622\ttotal: 48.3s\tremaining: 7m 30s\n",
      "2228:\tlearn: 7.2047100\ttotal: 48.3s\tremaining: 7m 30s\n",
      "2229:\tlearn: 7.2037871\ttotal: 48.4s\tremaining: 7m 30s\n",
      "2230:\tlearn: 7.2025741\ttotal: 48.4s\tremaining: 7m 30s\n",
      "2231:\tlearn: 7.2008225\ttotal: 48.4s\tremaining: 7m 30s\n",
      "2232:\tlearn: 7.1992695\ttotal: 48.4s\tremaining: 7m 30s\n",
      "2233:\tlearn: 7.1983529\ttotal: 48.5s\tremaining: 7m 30s\n",
      "2234:\tlearn: 7.1973010\ttotal: 48.5s\tremaining: 7m 30s\n",
      "2235:\tlearn: 7.1958745\ttotal: 48.5s\tremaining: 7m 30s\n",
      "2236:\tlearn: 7.1948718\ttotal: 48.5s\tremaining: 7m 30s\n",
      "2237:\tlearn: 7.1936368\ttotal: 48.6s\tremaining: 7m 30s\n",
      "2238:\tlearn: 7.1928335\ttotal: 48.6s\tremaining: 7m 30s\n",
      "2239:\tlearn: 7.1912507\ttotal: 48.6s\tremaining: 7m 30s\n",
      "2240:\tlearn: 7.1902406\ttotal: 48.6s\tremaining: 7m 30s\n",
      "2241:\tlearn: 7.1893195\ttotal: 48.6s\tremaining: 7m 30s\n",
      "2242:\tlearn: 7.1877280\ttotal: 48.7s\tremaining: 7m 30s\n",
      "2243:\tlearn: 7.1867389\ttotal: 48.7s\tremaining: 7m 30s\n",
      "2244:\tlearn: 7.1850869\ttotal: 48.7s\tremaining: 7m 30s\n",
      "2245:\tlearn: 7.1838038\ttotal: 48.7s\tremaining: 7m 30s\n",
      "2246:\tlearn: 7.1825704\ttotal: 48.8s\tremaining: 7m 30s\n",
      "2247:\tlearn: 7.1815786\ttotal: 48.8s\tremaining: 7m 30s\n",
      "2248:\tlearn: 7.1806856\ttotal: 48.8s\tremaining: 7m 30s\n",
      "2249:\tlearn: 7.1798169\ttotal: 48.8s\tremaining: 7m 30s\n",
      "2250:\tlearn: 7.1781495\ttotal: 48.8s\tremaining: 7m 30s\n",
      "2251:\tlearn: 7.1764542\ttotal: 48.9s\tremaining: 7m 30s\n",
      "2252:\tlearn: 7.1755342\ttotal: 48.9s\tremaining: 7m 30s\n",
      "2253:\tlearn: 7.1742973\ttotal: 48.9s\tremaining: 7m 30s\n",
      "2254:\tlearn: 7.1728062\ttotal: 48.9s\tremaining: 7m 30s\n",
      "2255:\tlearn: 7.1717432\ttotal: 48.9s\tremaining: 7m 30s\n",
      "2256:\tlearn: 7.1708368\ttotal: 49s\tremaining: 7m 29s\n",
      "2257:\tlearn: 7.1695200\ttotal: 49s\tremaining: 7m 30s\n",
      "2258:\tlearn: 7.1685131\ttotal: 49s\tremaining: 7m 29s\n",
      "2259:\tlearn: 7.1669438\ttotal: 49s\tremaining: 7m 29s\n",
      "2260:\tlearn: 7.1652895\ttotal: 49.1s\tremaining: 7m 29s\n",
      "2261:\tlearn: 7.1640773\ttotal: 49.1s\tremaining: 7m 29s\n",
      "2262:\tlearn: 7.1631676\ttotal: 49.1s\tremaining: 7m 29s\n",
      "2263:\tlearn: 7.1615161\ttotal: 49.1s\tremaining: 7m 29s\n",
      "2264:\tlearn: 7.1608536\ttotal: 49.1s\tremaining: 7m 29s\n",
      "2265:\tlearn: 7.1595798\ttotal: 49.2s\tremaining: 7m 29s\n",
      "2266:\tlearn: 7.1588909\ttotal: 49.2s\tremaining: 7m 29s\n",
      "2267:\tlearn: 7.1576356\ttotal: 49.2s\tremaining: 7m 29s\n",
      "2268:\tlearn: 7.1564861\ttotal: 49.2s\tremaining: 7m 29s\n",
      "2269:\tlearn: 7.1556232\ttotal: 49.3s\tremaining: 7m 29s\n",
      "2270:\tlearn: 7.1545585\ttotal: 49.3s\tremaining: 7m 29s\n",
      "2271:\tlearn: 7.1528096\ttotal: 49.3s\tremaining: 7m 29s\n",
      "2272:\tlearn: 7.1516596\ttotal: 49.3s\tremaining: 7m 29s\n",
      "2273:\tlearn: 7.1512044\ttotal: 49.3s\tremaining: 7m 29s\n",
      "2274:\tlearn: 7.1502397\ttotal: 49.4s\tremaining: 7m 29s\n",
      "2275:\tlearn: 7.1487907\ttotal: 49.4s\tremaining: 7m 29s\n",
      "2276:\tlearn: 7.1471758\ttotal: 49.4s\tremaining: 7m 29s\n",
      "2277:\tlearn: 7.1453948\ttotal: 49.4s\tremaining: 7m 29s\n",
      "2278:\tlearn: 7.1444512\ttotal: 49.4s\tremaining: 7m 29s\n",
      "2279:\tlearn: 7.1429824\ttotal: 49.5s\tremaining: 7m 29s\n",
      "2280:\tlearn: 7.1425589\ttotal: 49.5s\tremaining: 7m 29s\n",
      "2281:\tlearn: 7.1412518\ttotal: 49.5s\tremaining: 7m 29s\n",
      "2282:\tlearn: 7.1400663\ttotal: 49.5s\tremaining: 7m 29s\n",
      "2283:\tlearn: 7.1390691\ttotal: 49.5s\tremaining: 7m 29s\n",
      "2284:\tlearn: 7.1379570\ttotal: 49.6s\tremaining: 7m 29s\n",
      "2285:\tlearn: 7.1369707\ttotal: 49.6s\tremaining: 7m 29s\n",
      "2286:\tlearn: 7.1369334\ttotal: 49.6s\tremaining: 7m 29s\n",
      "2287:\tlearn: 7.1360610\ttotal: 49.6s\tremaining: 7m 29s\n",
      "2288:\tlearn: 7.1353029\ttotal: 49.6s\tremaining: 7m 29s\n",
      "2289:\tlearn: 7.1340746\ttotal: 49.7s\tremaining: 7m 29s\n",
      "2290:\tlearn: 7.1328200\ttotal: 49.7s\tremaining: 7m 29s\n",
      "2291:\tlearn: 7.1321241\ttotal: 49.7s\tremaining: 7m 29s\n",
      "2292:\tlearn: 7.1306157\ttotal: 49.7s\tremaining: 7m 29s\n",
      "2293:\tlearn: 7.1293220\ttotal: 49.8s\tremaining: 7m 29s\n",
      "2294:\tlearn: 7.1280692\ttotal: 49.8s\tremaining: 7m 29s\n",
      "2295:\tlearn: 7.1275257\ttotal: 49.8s\tremaining: 7m 29s\n",
      "2296:\tlearn: 7.1263545\ttotal: 49.8s\tremaining: 7m 29s\n",
      "2297:\tlearn: 7.1251980\ttotal: 49.8s\tremaining: 7m 29s\n",
      "2298:\tlearn: 7.1238385\ttotal: 49.9s\tremaining: 7m 29s\n",
      "2299:\tlearn: 7.1233094\ttotal: 49.9s\tremaining: 7m 28s\n",
      "2300:\tlearn: 7.1220033\ttotal: 49.9s\tremaining: 7m 29s\n",
      "2301:\tlearn: 7.1207937\ttotal: 49.9s\tremaining: 7m 28s\n",
      "2302:\tlearn: 7.1198547\ttotal: 50s\tremaining: 7m 28s\n",
      "2303:\tlearn: 7.1191138\ttotal: 50s\tremaining: 7m 28s\n",
      "2304:\tlearn: 7.1173691\ttotal: 50s\tremaining: 7m 28s\n",
      "2305:\tlearn: 7.1159947\ttotal: 50s\tremaining: 7m 28s\n",
      "2306:\tlearn: 7.1152029\ttotal: 50s\tremaining: 7m 28s\n",
      "2307:\tlearn: 7.1140800\ttotal: 50.1s\tremaining: 7m 28s\n",
      "2308:\tlearn: 7.1131835\ttotal: 50.1s\tremaining: 7m 28s\n",
      "2309:\tlearn: 7.1121669\ttotal: 50.1s\tremaining: 7m 28s\n",
      "2310:\tlearn: 7.1112856\ttotal: 50.1s\tremaining: 7m 28s\n",
      "2311:\tlearn: 7.1100990\ttotal: 50.2s\tremaining: 7m 28s\n",
      "2312:\tlearn: 7.1087528\ttotal: 50.2s\tremaining: 7m 28s\n",
      "2313:\tlearn: 7.1080750\ttotal: 50.2s\tremaining: 7m 28s\n",
      "2314:\tlearn: 7.1074378\ttotal: 50.2s\tremaining: 7m 28s\n",
      "2315:\tlearn: 7.1061963\ttotal: 50.2s\tremaining: 7m 28s\n",
      "2316:\tlearn: 7.1049161\ttotal: 50.3s\tremaining: 7m 28s\n",
      "2317:\tlearn: 7.1039288\ttotal: 50.3s\tremaining: 7m 28s\n",
      "2318:\tlearn: 7.1029945\ttotal: 50.3s\tremaining: 7m 28s\n",
      "2319:\tlearn: 7.1023741\ttotal: 50.3s\tremaining: 7m 28s\n",
      "2320:\tlearn: 7.1007970\ttotal: 50.4s\tremaining: 7m 28s\n",
      "2321:\tlearn: 7.0999616\ttotal: 50.4s\tremaining: 7m 28s\n",
      "2322:\tlearn: 7.0987134\ttotal: 50.4s\tremaining: 7m 28s\n",
      "2323:\tlearn: 7.0969354\ttotal: 50.4s\tremaining: 7m 28s\n",
      "2324:\tlearn: 7.0959085\ttotal: 50.4s\tremaining: 7m 28s\n",
      "2325:\tlearn: 7.0948456\ttotal: 50.5s\tremaining: 7m 28s\n",
      "2326:\tlearn: 7.0939687\ttotal: 50.5s\tremaining: 7m 28s\n",
      "2327:\tlearn: 7.0929038\ttotal: 50.5s\tremaining: 7m 28s\n",
      "2328:\tlearn: 7.0915304\ttotal: 50.5s\tremaining: 7m 28s\n",
      "2329:\tlearn: 7.0899024\ttotal: 50.6s\tremaining: 7m 28s\n",
      "2330:\tlearn: 7.0891333\ttotal: 50.6s\tremaining: 7m 28s\n",
      "2331:\tlearn: 7.0882539\ttotal: 50.6s\tremaining: 7m 28s\n",
      "2332:\tlearn: 7.0875771\ttotal: 50.6s\tremaining: 7m 28s\n",
      "2333:\tlearn: 7.0864501\ttotal: 50.6s\tremaining: 7m 28s\n",
      "2334:\tlearn: 7.0854811\ttotal: 50.7s\tremaining: 7m 28s\n",
      "2335:\tlearn: 7.0840319\ttotal: 50.7s\tremaining: 7m 28s\n",
      "2336:\tlearn: 7.0827153\ttotal: 50.7s\tremaining: 7m 28s\n",
      "2337:\tlearn: 7.0818444\ttotal: 50.7s\tremaining: 7m 28s\n",
      "2338:\tlearn: 7.0809978\ttotal: 50.7s\tremaining: 7m 28s\n",
      "2339:\tlearn: 7.0799439\ttotal: 50.8s\tremaining: 7m 28s\n",
      "2340:\tlearn: 7.0788862\ttotal: 50.8s\tremaining: 7m 28s\n",
      "2341:\tlearn: 7.0779347\ttotal: 50.8s\tremaining: 7m 28s\n",
      "2342:\tlearn: 7.0768448\ttotal: 50.8s\tremaining: 7m 28s\n",
      "2343:\tlearn: 7.0759431\ttotal: 50.8s\tremaining: 7m 28s\n",
      "2344:\tlearn: 7.0752128\ttotal: 50.9s\tremaining: 7m 28s\n",
      "2345:\tlearn: 7.0740281\ttotal: 50.9s\tremaining: 7m 28s\n",
      "2346:\tlearn: 7.0726253\ttotal: 50.9s\tremaining: 7m 27s\n",
      "2347:\tlearn: 7.0717050\ttotal: 50.9s\tremaining: 7m 27s\n",
      "2348:\tlearn: 7.0709300\ttotal: 50.9s\tremaining: 7m 27s\n",
      "2349:\tlearn: 7.0701547\ttotal: 51s\tremaining: 7m 27s\n",
      "2350:\tlearn: 7.0691645\ttotal: 51s\tremaining: 7m 27s\n",
      "2351:\tlearn: 7.0675048\ttotal: 51s\tremaining: 7m 27s\n",
      "2352:\tlearn: 7.0659940\ttotal: 51s\tremaining: 7m 27s\n",
      "2353:\tlearn: 7.0649324\ttotal: 51.1s\tremaining: 7m 27s\n",
      "2354:\tlearn: 7.0642809\ttotal: 51.1s\tremaining: 7m 27s\n",
      "2355:\tlearn: 7.0627577\ttotal: 51.1s\tremaining: 7m 27s\n",
      "2356:\tlearn: 7.0616783\ttotal: 51.1s\tremaining: 7m 27s\n",
      "2357:\tlearn: 7.0607441\ttotal: 51.1s\tremaining: 7m 27s\n",
      "2358:\tlearn: 7.0594488\ttotal: 51.2s\tremaining: 7m 27s\n",
      "2359:\tlearn: 7.0579742\ttotal: 51.2s\tremaining: 7m 27s\n",
      "2360:\tlearn: 7.0567762\ttotal: 51.2s\tremaining: 7m 27s\n",
      "2361:\tlearn: 7.0557102\ttotal: 51.2s\tremaining: 7m 27s\n",
      "2362:\tlearn: 7.0542764\ttotal: 51.3s\tremaining: 7m 27s\n",
      "2363:\tlearn: 7.0533122\ttotal: 51.3s\tremaining: 7m 27s\n",
      "2364:\tlearn: 7.0523554\ttotal: 51.3s\tremaining: 7m 27s\n",
      "2365:\tlearn: 7.0515716\ttotal: 51.3s\tremaining: 7m 27s\n",
      "2366:\tlearn: 7.0510834\ttotal: 51.3s\tremaining: 7m 27s\n",
      "2367:\tlearn: 7.0497042\ttotal: 51.4s\tremaining: 7m 27s\n",
      "2368:\tlearn: 7.0482810\ttotal: 51.4s\tremaining: 7m 27s\n",
      "2369:\tlearn: 7.0472105\ttotal: 51.4s\tremaining: 7m 27s\n",
      "2370:\tlearn: 7.0462062\ttotal: 51.4s\tremaining: 7m 27s\n",
      "2371:\tlearn: 7.0451462\ttotal: 51.5s\tremaining: 7m 27s\n",
      "2372:\tlearn: 7.0444351\ttotal: 51.5s\tremaining: 7m 27s\n",
      "2373:\tlearn: 7.0436790\ttotal: 51.5s\tremaining: 7m 27s\n",
      "2374:\tlearn: 7.0428722\ttotal: 51.5s\tremaining: 7m 27s\n",
      "2375:\tlearn: 7.0416739\ttotal: 51.5s\tremaining: 7m 27s\n",
      "2376:\tlearn: 7.0406625\ttotal: 51.6s\tremaining: 7m 27s\n",
      "2377:\tlearn: 7.0397632\ttotal: 51.6s\tremaining: 7m 27s\n",
      "2378:\tlearn: 7.0386994\ttotal: 51.6s\tremaining: 7m 27s\n",
      "2379:\tlearn: 7.0377647\ttotal: 51.6s\tremaining: 7m 27s\n",
      "2380:\tlearn: 7.0371310\ttotal: 51.6s\tremaining: 7m 27s\n",
      "2381:\tlearn: 7.0364783\ttotal: 51.7s\tremaining: 7m 27s\n",
      "2382:\tlearn: 7.0359424\ttotal: 51.7s\tremaining: 7m 27s\n",
      "2383:\tlearn: 7.0348812\ttotal: 51.7s\tremaining: 7m 27s\n",
      "2384:\tlearn: 7.0340058\ttotal: 51.7s\tremaining: 7m 27s\n",
      "2385:\tlearn: 7.0324196\ttotal: 51.7s\tremaining: 7m 27s\n",
      "2386:\tlearn: 7.0314430\ttotal: 51.8s\tremaining: 7m 27s\n",
      "2387:\tlearn: 7.0306725\ttotal: 51.8s\tremaining: 7m 26s\n",
      "2388:\tlearn: 7.0295540\ttotal: 51.8s\tremaining: 7m 26s\n",
      "2389:\tlearn: 7.0281277\ttotal: 51.8s\tremaining: 7m 26s\n",
      "2390:\tlearn: 7.0270454\ttotal: 51.8s\tremaining: 7m 26s\n",
      "2391:\tlearn: 7.0258911\ttotal: 51.9s\tremaining: 7m 26s\n",
      "2392:\tlearn: 7.0246581\ttotal: 51.9s\tremaining: 7m 26s\n",
      "2393:\tlearn: 7.0234067\ttotal: 51.9s\tremaining: 7m 26s\n",
      "2394:\tlearn: 7.0225563\ttotal: 51.9s\tremaining: 7m 26s\n",
      "2395:\tlearn: 7.0217524\ttotal: 52s\tremaining: 7m 26s\n",
      "2396:\tlearn: 7.0205181\ttotal: 52s\tremaining: 7m 26s\n",
      "2397:\tlearn: 7.0193861\ttotal: 52s\tremaining: 7m 26s\n",
      "2398:\tlearn: 7.0185209\ttotal: 52s\tremaining: 7m 26s\n",
      "2399:\tlearn: 7.0177301\ttotal: 52.1s\tremaining: 7m 26s\n",
      "2400:\tlearn: 7.0166681\ttotal: 52.1s\tremaining: 7m 26s\n",
      "2401:\tlearn: 7.0158993\ttotal: 52.1s\tremaining: 7m 26s\n",
      "2402:\tlearn: 7.0148939\ttotal: 52.1s\tremaining: 7m 26s\n",
      "2403:\tlearn: 7.0138900\ttotal: 52.1s\tremaining: 7m 26s\n",
      "2404:\tlearn: 7.0127644\ttotal: 52.2s\tremaining: 7m 26s\n",
      "2405:\tlearn: 7.0113194\ttotal: 52.2s\tremaining: 7m 26s\n",
      "2406:\tlearn: 7.0099738\ttotal: 52.2s\tremaining: 7m 26s\n",
      "2407:\tlearn: 7.0094176\ttotal: 52.2s\tremaining: 7m 26s\n",
      "2408:\tlearn: 7.0079263\ttotal: 52.3s\tremaining: 7m 26s\n",
      "2409:\tlearn: 7.0071217\ttotal: 52.3s\tremaining: 7m 26s\n",
      "2410:\tlearn: 7.0054207\ttotal: 52.3s\tremaining: 7m 26s\n",
      "2411:\tlearn: 7.0041652\ttotal: 52.3s\tremaining: 7m 26s\n",
      "2412:\tlearn: 7.0030512\ttotal: 52.3s\tremaining: 7m 26s\n",
      "2413:\tlearn: 7.0022843\ttotal: 52.4s\tremaining: 7m 26s\n",
      "2414:\tlearn: 7.0013705\ttotal: 52.4s\tremaining: 7m 26s\n",
      "2415:\tlearn: 7.0001060\ttotal: 52.4s\tremaining: 7m 26s\n",
      "2416:\tlearn: 6.9993017\ttotal: 52.4s\tremaining: 7m 26s\n",
      "2417:\tlearn: 6.9983361\ttotal: 52.5s\tremaining: 7m 26s\n",
      "2418:\tlearn: 6.9971585\ttotal: 52.5s\tremaining: 7m 26s\n",
      "2419:\tlearn: 6.9965404\ttotal: 52.5s\tremaining: 7m 26s\n",
      "2420:\tlearn: 6.9957819\ttotal: 52.5s\tremaining: 7m 26s\n",
      "2421:\tlearn: 6.9947773\ttotal: 52.5s\tremaining: 7m 26s\n",
      "2422:\tlearn: 6.9940377\ttotal: 52.6s\tremaining: 7m 26s\n",
      "2423:\tlearn: 6.9928466\ttotal: 52.6s\tremaining: 7m 26s\n",
      "2424:\tlearn: 6.9914477\ttotal: 52.6s\tremaining: 7m 26s\n",
      "2425:\tlearn: 6.9904232\ttotal: 52.6s\tremaining: 7m 26s\n",
      "2426:\tlearn: 6.9890862\ttotal: 52.6s\tremaining: 7m 26s\n",
      "2427:\tlearn: 6.9871185\ttotal: 52.7s\tremaining: 7m 26s\n",
      "2428:\tlearn: 6.9865290\ttotal: 52.7s\tremaining: 7m 26s\n",
      "2429:\tlearn: 6.9859900\ttotal: 52.7s\tremaining: 7m 26s\n",
      "2430:\tlearn: 6.9850727\ttotal: 52.7s\tremaining: 7m 26s\n",
      "2431:\tlearn: 6.9830951\ttotal: 52.7s\tremaining: 7m 26s\n",
      "2432:\tlearn: 6.9818060\ttotal: 52.8s\tremaining: 7m 26s\n",
      "2433:\tlearn: 6.9810148\ttotal: 52.8s\tremaining: 7m 26s\n",
      "2434:\tlearn: 6.9801586\ttotal: 52.8s\tremaining: 7m 26s\n",
      "2435:\tlearn: 6.9794434\ttotal: 52.8s\tremaining: 7m 25s\n",
      "2436:\tlearn: 6.9781070\ttotal: 52.9s\tremaining: 7m 26s\n",
      "2437:\tlearn: 6.9776441\ttotal: 52.9s\tremaining: 7m 25s\n",
      "2438:\tlearn: 6.9766366\ttotal: 52.9s\tremaining: 7m 25s\n",
      "2439:\tlearn: 6.9750636\ttotal: 52.9s\tremaining: 7m 25s\n",
      "2440:\tlearn: 6.9739852\ttotal: 52.9s\tremaining: 7m 25s\n",
      "2441:\tlearn: 6.9731657\ttotal: 53s\tremaining: 7m 25s\n",
      "2442:\tlearn: 6.9720861\ttotal: 53s\tremaining: 7m 25s\n",
      "2443:\tlearn: 6.9704681\ttotal: 53s\tremaining: 7m 25s\n",
      "2444:\tlearn: 6.9694968\ttotal: 53s\tremaining: 7m 25s\n",
      "2445:\tlearn: 6.9687569\ttotal: 53s\tremaining: 7m 25s\n",
      "2446:\tlearn: 6.9677661\ttotal: 53.1s\tremaining: 7m 25s\n",
      "2447:\tlearn: 6.9663866\ttotal: 53.1s\tremaining: 7m 25s\n",
      "2448:\tlearn: 6.9645296\ttotal: 53.1s\tremaining: 7m 25s\n",
      "2449:\tlearn: 6.9632889\ttotal: 53.1s\tremaining: 7m 25s\n",
      "2450:\tlearn: 6.9622755\ttotal: 53.2s\tremaining: 7m 25s\n",
      "2451:\tlearn: 6.9606802\ttotal: 53.2s\tremaining: 7m 25s\n",
      "2452:\tlearn: 6.9596517\ttotal: 53.2s\tremaining: 7m 25s\n",
      "2453:\tlearn: 6.9590993\ttotal: 53.2s\tremaining: 7m 25s\n",
      "2454:\tlearn: 6.9580217\ttotal: 53.3s\tremaining: 7m 25s\n",
      "2455:\tlearn: 6.9567548\ttotal: 53.3s\tremaining: 7m 25s\n",
      "2456:\tlearn: 6.9555821\ttotal: 53.3s\tremaining: 7m 25s\n",
      "2457:\tlearn: 6.9545718\ttotal: 53.3s\tremaining: 7m 25s\n",
      "2458:\tlearn: 6.9542665\ttotal: 53.3s\tremaining: 7m 25s\n",
      "2459:\tlearn: 6.9532089\ttotal: 53.4s\tremaining: 7m 25s\n",
      "2460:\tlearn: 6.9523873\ttotal: 53.4s\tremaining: 7m 25s\n",
      "2461:\tlearn: 6.9508304\ttotal: 53.4s\tremaining: 7m 25s\n",
      "2462:\tlearn: 6.9496014\ttotal: 53.4s\tremaining: 7m 25s\n",
      "2463:\tlearn: 6.9484017\ttotal: 53.4s\tremaining: 7m 25s\n",
      "2464:\tlearn: 6.9471593\ttotal: 53.5s\tremaining: 7m 25s\n",
      "2465:\tlearn: 6.9456627\ttotal: 53.5s\tremaining: 7m 25s\n",
      "2466:\tlearn: 6.9447289\ttotal: 53.5s\tremaining: 7m 25s\n",
      "2467:\tlearn: 6.9437320\ttotal: 53.5s\tremaining: 7m 25s\n",
      "2468:\tlearn: 6.9427450\ttotal: 53.6s\tremaining: 7m 25s\n",
      "2469:\tlearn: 6.9418031\ttotal: 53.6s\tremaining: 7m 25s\n",
      "2470:\tlearn: 6.9407266\ttotal: 53.6s\tremaining: 7m 25s\n",
      "2471:\tlearn: 6.9393627\ttotal: 53.6s\tremaining: 7m 25s\n",
      "2472:\tlearn: 6.9381327\ttotal: 53.6s\tremaining: 7m 25s\n",
      "2473:\tlearn: 6.9375219\ttotal: 53.7s\tremaining: 7m 25s\n",
      "2474:\tlearn: 6.9366291\ttotal: 53.7s\tremaining: 7m 25s\n",
      "2475:\tlearn: 6.9358058\ttotal: 53.7s\tremaining: 7m 25s\n",
      "2476:\tlearn: 6.9352412\ttotal: 53.7s\tremaining: 7m 25s\n",
      "2477:\tlearn: 6.9341700\ttotal: 53.7s\tremaining: 7m 25s\n",
      "2478:\tlearn: 6.9331737\ttotal: 53.8s\tremaining: 7m 25s\n",
      "2479:\tlearn: 6.9315750\ttotal: 53.8s\tremaining: 7m 25s\n",
      "2480:\tlearn: 6.9305304\ttotal: 53.8s\tremaining: 7m 25s\n",
      "2481:\tlearn: 6.9292703\ttotal: 53.8s\tremaining: 7m 25s\n",
      "2482:\tlearn: 6.9275619\ttotal: 53.9s\tremaining: 7m 25s\n",
      "2483:\tlearn: 6.9261504\ttotal: 53.9s\tremaining: 7m 24s\n",
      "2484:\tlearn: 6.9253497\ttotal: 53.9s\tremaining: 7m 24s\n",
      "2485:\tlearn: 6.9243165\ttotal: 53.9s\tremaining: 7m 24s\n",
      "2486:\tlearn: 6.9228402\ttotal: 53.9s\tremaining: 7m 24s\n",
      "2487:\tlearn: 6.9219059\ttotal: 54s\tremaining: 7m 24s\n",
      "2488:\tlearn: 6.9207156\ttotal: 54s\tremaining: 7m 24s\n",
      "2489:\tlearn: 6.9199539\ttotal: 54s\tremaining: 7m 24s\n",
      "2490:\tlearn: 6.9191896\ttotal: 54s\tremaining: 7m 24s\n",
      "2491:\tlearn: 6.9180977\ttotal: 54s\tremaining: 7m 24s\n",
      "2492:\tlearn: 6.9173327\ttotal: 54.1s\tremaining: 7m 24s\n",
      "2493:\tlearn: 6.9171077\ttotal: 54.1s\tremaining: 7m 24s\n",
      "2494:\tlearn: 6.9159743\ttotal: 54.1s\tremaining: 7m 24s\n",
      "2495:\tlearn: 6.9148668\ttotal: 54.1s\tremaining: 7m 24s\n",
      "2496:\tlearn: 6.9137741\ttotal: 54.2s\tremaining: 7m 24s\n",
      "2497:\tlearn: 6.9134736\ttotal: 54.2s\tremaining: 7m 24s\n",
      "2498:\tlearn: 6.9125032\ttotal: 54.2s\tremaining: 7m 24s\n",
      "2499:\tlearn: 6.9112021\ttotal: 54.2s\tremaining: 7m 24s\n",
      "2500:\tlearn: 6.9099205\ttotal: 54.2s\tremaining: 7m 24s\n",
      "2501:\tlearn: 6.9089671\ttotal: 54.3s\tremaining: 7m 24s\n",
      "2502:\tlearn: 6.9081139\ttotal: 54.3s\tremaining: 7m 24s\n",
      "2503:\tlearn: 6.9073856\ttotal: 54.3s\tremaining: 7m 24s\n",
      "2504:\tlearn: 6.9065104\ttotal: 54.3s\tremaining: 7m 24s\n",
      "2505:\tlearn: 6.9057089\ttotal: 54.3s\tremaining: 7m 24s\n",
      "2506:\tlearn: 6.9050113\ttotal: 54.4s\tremaining: 7m 24s\n",
      "2507:\tlearn: 6.9040246\ttotal: 54.4s\tremaining: 7m 24s\n",
      "2508:\tlearn: 6.9030370\ttotal: 54.4s\tremaining: 7m 24s\n",
      "2509:\tlearn: 6.9020690\ttotal: 54.4s\tremaining: 7m 24s\n",
      "2510:\tlearn: 6.9013598\ttotal: 54.4s\tremaining: 7m 24s\n",
      "2511:\tlearn: 6.8996494\ttotal: 54.5s\tremaining: 7m 24s\n",
      "2512:\tlearn: 6.8985850\ttotal: 54.5s\tremaining: 7m 24s\n",
      "2513:\tlearn: 6.8975400\ttotal: 54.5s\tremaining: 7m 24s\n",
      "2514:\tlearn: 6.8963053\ttotal: 54.5s\tremaining: 7m 24s\n",
      "2515:\tlearn: 6.8956053\ttotal: 54.6s\tremaining: 7m 24s\n",
      "2516:\tlearn: 6.8950290\ttotal: 54.6s\tremaining: 7m 24s\n",
      "2517:\tlearn: 6.8938757\ttotal: 54.6s\tremaining: 7m 24s\n",
      "2518:\tlearn: 6.8931093\ttotal: 54.6s\tremaining: 7m 24s\n",
      "2519:\tlearn: 6.8922755\ttotal: 54.6s\tremaining: 7m 24s\n",
      "2520:\tlearn: 6.8914802\ttotal: 54.7s\tremaining: 7m 23s\n",
      "2521:\tlearn: 6.8901707\ttotal: 54.7s\tremaining: 7m 23s\n",
      "2522:\tlearn: 6.8889955\ttotal: 54.7s\tremaining: 7m 23s\n",
      "2523:\tlearn: 6.8880279\ttotal: 54.7s\tremaining: 7m 23s\n",
      "2524:\tlearn: 6.8872135\ttotal: 54.7s\tremaining: 7m 23s\n",
      "2525:\tlearn: 6.8853991\ttotal: 54.8s\tremaining: 7m 23s\n",
      "2526:\tlearn: 6.8846845\ttotal: 54.8s\tremaining: 7m 23s\n",
      "2527:\tlearn: 6.8839305\ttotal: 54.8s\tremaining: 7m 23s\n",
      "2528:\tlearn: 6.8824790\ttotal: 54.8s\tremaining: 7m 23s\n",
      "2529:\tlearn: 6.8814149\ttotal: 54.8s\tremaining: 7m 23s\n",
      "2530:\tlearn: 6.8800948\ttotal: 54.9s\tremaining: 7m 23s\n",
      "2531:\tlearn: 6.8795429\ttotal: 54.9s\tremaining: 7m 23s\n",
      "2532:\tlearn: 6.8779658\ttotal: 54.9s\tremaining: 7m 23s\n",
      "2533:\tlearn: 6.8766334\ttotal: 54.9s\tremaining: 7m 23s\n",
      "2534:\tlearn: 6.8757881\ttotal: 54.9s\tremaining: 7m 23s\n",
      "2535:\tlearn: 6.8745950\ttotal: 55s\tremaining: 7m 23s\n",
      "2536:\tlearn: 6.8737719\ttotal: 55s\tremaining: 7m 23s\n",
      "2537:\tlearn: 6.8732065\ttotal: 55s\tremaining: 7m 23s\n",
      "2538:\tlearn: 6.8719019\ttotal: 55s\tremaining: 7m 23s\n",
      "2539:\tlearn: 6.8706195\ttotal: 55.1s\tremaining: 7m 23s\n",
      "2540:\tlearn: 6.8692814\ttotal: 55.1s\tremaining: 7m 23s\n",
      "2541:\tlearn: 6.8678660\ttotal: 55.1s\tremaining: 7m 23s\n",
      "2542:\tlearn: 6.8663391\ttotal: 55.1s\tremaining: 7m 23s\n",
      "2543:\tlearn: 6.8653857\ttotal: 55.1s\tremaining: 7m 23s\n",
      "2544:\tlearn: 6.8648430\ttotal: 55.2s\tremaining: 7m 23s\n",
      "2545:\tlearn: 6.8639325\ttotal: 55.2s\tremaining: 7m 23s\n",
      "2546:\tlearn: 6.8630772\ttotal: 55.2s\tremaining: 7m 23s\n",
      "2547:\tlearn: 6.8623929\ttotal: 55.2s\tremaining: 7m 23s\n",
      "2548:\tlearn: 6.8617290\ttotal: 55.2s\tremaining: 7m 23s\n",
      "2549:\tlearn: 6.8602608\ttotal: 55.3s\tremaining: 7m 23s\n",
      "2550:\tlearn: 6.8588562\ttotal: 55.3s\tremaining: 7m 23s\n",
      "2551:\tlearn: 6.8573019\ttotal: 55.3s\tremaining: 7m 23s\n",
      "2552:\tlearn: 6.8565210\ttotal: 55.3s\tremaining: 7m 23s\n",
      "2553:\tlearn: 6.8558171\ttotal: 55.4s\tremaining: 7m 23s\n",
      "2554:\tlearn: 6.8553083\ttotal: 55.4s\tremaining: 7m 23s\n",
      "2555:\tlearn: 6.8539139\ttotal: 55.4s\tremaining: 7m 23s\n",
      "2556:\tlearn: 6.8527284\ttotal: 55.4s\tremaining: 7m 23s\n",
      "2557:\tlearn: 6.8523313\ttotal: 55.4s\tremaining: 7m 23s\n",
      "2558:\tlearn: 6.8511300\ttotal: 55.5s\tremaining: 7m 23s\n",
      "2559:\tlearn: 6.8504983\ttotal: 55.5s\tremaining: 7m 23s\n",
      "2560:\tlearn: 6.8494695\ttotal: 55.5s\tremaining: 7m 22s\n",
      "2561:\tlearn: 6.8479844\ttotal: 55.5s\tremaining: 7m 22s\n",
      "2562:\tlearn: 6.8474671\ttotal: 55.5s\tremaining: 7m 22s\n",
      "2563:\tlearn: 6.8466153\ttotal: 55.6s\tremaining: 7m 22s\n",
      "2564:\tlearn: 6.8455509\ttotal: 55.6s\tremaining: 7m 22s\n",
      "2565:\tlearn: 6.8447322\ttotal: 55.6s\tremaining: 7m 22s\n",
      "2566:\tlearn: 6.8438435\ttotal: 55.6s\tremaining: 7m 22s\n",
      "2567:\tlearn: 6.8430914\ttotal: 55.7s\tremaining: 7m 22s\n",
      "2568:\tlearn: 6.8423639\ttotal: 55.7s\tremaining: 7m 22s\n",
      "2569:\tlearn: 6.8410784\ttotal: 55.7s\tremaining: 7m 22s\n",
      "2570:\tlearn: 6.8394912\ttotal: 55.7s\tremaining: 7m 22s\n",
      "2571:\tlearn: 6.8389425\ttotal: 55.7s\tremaining: 7m 22s\n",
      "2572:\tlearn: 6.8376611\ttotal: 55.8s\tremaining: 7m 22s\n",
      "2573:\tlearn: 6.8362448\ttotal: 55.8s\tremaining: 7m 22s\n",
      "2574:\tlearn: 6.8357423\ttotal: 55.8s\tremaining: 7m 22s\n",
      "2575:\tlearn: 6.8344500\ttotal: 55.8s\tremaining: 7m 22s\n",
      "2576:\tlearn: 6.8335807\ttotal: 55.8s\tremaining: 7m 22s\n",
      "2577:\tlearn: 6.8327601\ttotal: 55.9s\tremaining: 7m 22s\n",
      "2578:\tlearn: 6.8318019\ttotal: 55.9s\tremaining: 7m 22s\n",
      "2579:\tlearn: 6.8309057\ttotal: 55.9s\tremaining: 7m 22s\n",
      "2580:\tlearn: 6.8298069\ttotal: 55.9s\tremaining: 7m 22s\n",
      "2581:\tlearn: 6.8283713\ttotal: 56s\tremaining: 7m 22s\n",
      "2582:\tlearn: 6.8278102\ttotal: 56s\tremaining: 7m 22s\n",
      "2583:\tlearn: 6.8265097\ttotal: 56s\tremaining: 7m 22s\n",
      "2584:\tlearn: 6.8254625\ttotal: 56s\tremaining: 7m 22s\n",
      "2585:\tlearn: 6.8243801\ttotal: 56.1s\tremaining: 7m 22s\n",
      "2586:\tlearn: 6.8230706\ttotal: 56.1s\tremaining: 7m 22s\n",
      "2587:\tlearn: 6.8216441\ttotal: 56.1s\tremaining: 7m 22s\n",
      "2588:\tlearn: 6.8214665\ttotal: 56.1s\tremaining: 7m 22s\n",
      "2589:\tlearn: 6.8200216\ttotal: 56.1s\tremaining: 7m 22s\n",
      "2590:\tlearn: 6.8188321\ttotal: 56.2s\tremaining: 7m 22s\n",
      "2591:\tlearn: 6.8175173\ttotal: 56.2s\tremaining: 7m 22s\n",
      "2592:\tlearn: 6.8170426\ttotal: 56.2s\tremaining: 7m 22s\n",
      "2593:\tlearn: 6.8157970\ttotal: 56.2s\tremaining: 7m 22s\n",
      "2594:\tlearn: 6.8143879\ttotal: 56.3s\tremaining: 7m 22s\n",
      "2595:\tlearn: 6.8131508\ttotal: 56.3s\tremaining: 7m 22s\n",
      "2596:\tlearn: 6.8124890\ttotal: 56.3s\tremaining: 7m 22s\n",
      "2597:\tlearn: 6.8116259\ttotal: 56.3s\tremaining: 7m 22s\n",
      "2598:\tlearn: 6.8108668\ttotal: 56.3s\tremaining: 7m 22s\n",
      "2599:\tlearn: 6.8100246\ttotal: 56.4s\tremaining: 7m 22s\n",
      "2600:\tlearn: 6.8088236\ttotal: 56.4s\tremaining: 7m 22s\n",
      "2601:\tlearn: 6.8079286\ttotal: 56.4s\tremaining: 7m 22s\n",
      "2602:\tlearn: 6.8071063\ttotal: 56.4s\tremaining: 7m 22s\n",
      "2603:\tlearn: 6.8059139\ttotal: 56.5s\tremaining: 7m 22s\n",
      "2604:\tlearn: 6.8047824\ttotal: 56.5s\tremaining: 7m 22s\n",
      "2605:\tlearn: 6.8040536\ttotal: 56.5s\tremaining: 7m 22s\n",
      "2606:\tlearn: 6.8032601\ttotal: 56.5s\tremaining: 7m 22s\n",
      "2607:\tlearn: 6.8018718\ttotal: 56.5s\tremaining: 7m 22s\n",
      "2608:\tlearn: 6.8011137\ttotal: 56.6s\tremaining: 7m 22s\n",
      "2609:\tlearn: 6.8005219\ttotal: 56.6s\tremaining: 7m 22s\n",
      "2610:\tlearn: 6.7989421\ttotal: 56.6s\tremaining: 7m 22s\n",
      "2611:\tlearn: 6.7982343\ttotal: 56.6s\tremaining: 7m 22s\n",
      "2612:\tlearn: 6.7969244\ttotal: 56.7s\tremaining: 7m 22s\n",
      "2613:\tlearn: 6.7958395\ttotal: 56.7s\tremaining: 7m 22s\n",
      "2614:\tlearn: 6.7950297\ttotal: 56.7s\tremaining: 7m 22s\n",
      "2615:\tlearn: 6.7939337\ttotal: 56.7s\tremaining: 7m 22s\n",
      "2616:\tlearn: 6.7926365\ttotal: 56.8s\tremaining: 7m 22s\n",
      "2617:\tlearn: 6.7916910\ttotal: 56.8s\tremaining: 7m 22s\n",
      "2618:\tlearn: 6.7907607\ttotal: 56.8s\tremaining: 7m 22s\n",
      "2619:\tlearn: 6.7890152\ttotal: 56.8s\tremaining: 7m 22s\n",
      "2620:\tlearn: 6.7883047\ttotal: 56.8s\tremaining: 7m 22s\n",
      "2621:\tlearn: 6.7867736\ttotal: 56.9s\tremaining: 7m 22s\n",
      "2622:\tlearn: 6.7864564\ttotal: 56.9s\tremaining: 7m 21s\n",
      "2623:\tlearn: 6.7853871\ttotal: 56.9s\tremaining: 7m 21s\n",
      "2624:\tlearn: 6.7848037\ttotal: 56.9s\tremaining: 7m 21s\n",
      "2625:\tlearn: 6.7834708\ttotal: 57s\tremaining: 7m 21s\n",
      "2626:\tlearn: 6.7825627\ttotal: 57s\tremaining: 7m 21s\n",
      "2627:\tlearn: 6.7818553\ttotal: 57s\tremaining: 7m 21s\n",
      "2628:\tlearn: 6.7811228\ttotal: 57s\tremaining: 7m 21s\n",
      "2629:\tlearn: 6.7801217\ttotal: 57s\tremaining: 7m 21s\n",
      "2630:\tlearn: 6.7793054\ttotal: 57.1s\tremaining: 7m 21s\n",
      "2631:\tlearn: 6.7787337\ttotal: 57.1s\tremaining: 7m 21s\n",
      "2632:\tlearn: 6.7777940\ttotal: 57.1s\tremaining: 7m 21s\n",
      "2633:\tlearn: 6.7763319\ttotal: 57.1s\tremaining: 7m 21s\n",
      "2634:\tlearn: 6.7753437\ttotal: 57.2s\tremaining: 7m 21s\n",
      "2635:\tlearn: 6.7744424\ttotal: 57.2s\tremaining: 7m 21s\n",
      "2636:\tlearn: 6.7733367\ttotal: 57.2s\tremaining: 7m 21s\n",
      "2637:\tlearn: 6.7724508\ttotal: 57.2s\tremaining: 7m 21s\n",
      "2638:\tlearn: 6.7713091\ttotal: 57.3s\tremaining: 7m 21s\n",
      "2639:\tlearn: 6.7707037\ttotal: 57.3s\tremaining: 7m 21s\n",
      "2640:\tlearn: 6.7691971\ttotal: 57.3s\tremaining: 7m 21s\n",
      "2641:\tlearn: 6.7681442\ttotal: 57.3s\tremaining: 7m 21s\n",
      "2642:\tlearn: 6.7667245\ttotal: 57.3s\tremaining: 7m 21s\n",
      "2643:\tlearn: 6.7657019\ttotal: 57.4s\tremaining: 7m 21s\n",
      "2644:\tlearn: 6.7649344\ttotal: 57.4s\tremaining: 7m 21s\n",
      "2645:\tlearn: 6.7642396\ttotal: 57.4s\tremaining: 7m 21s\n",
      "2646:\tlearn: 6.7638163\ttotal: 57.4s\tremaining: 7m 21s\n",
      "2647:\tlearn: 6.7629878\ttotal: 57.4s\tremaining: 7m 21s\n",
      "2648:\tlearn: 6.7625107\ttotal: 57.5s\tremaining: 7m 21s\n",
      "2649:\tlearn: 6.7611642\ttotal: 57.5s\tremaining: 7m 21s\n",
      "2650:\tlearn: 6.7605499\ttotal: 57.5s\tremaining: 7m 21s\n",
      "2651:\tlearn: 6.7597944\ttotal: 57.5s\tremaining: 7m 21s\n",
      "2652:\tlearn: 6.7597324\ttotal: 57.5s\tremaining: 7m 21s\n",
      "2653:\tlearn: 6.7591472\ttotal: 57.6s\tremaining: 7m 21s\n",
      "2654:\tlearn: 6.7578304\ttotal: 57.6s\tremaining: 7m 21s\n",
      "2655:\tlearn: 6.7563986\ttotal: 57.6s\tremaining: 7m 21s\n",
      "2656:\tlearn: 6.7551128\ttotal: 57.6s\tremaining: 7m 21s\n",
      "2657:\tlearn: 6.7543931\ttotal: 57.7s\tremaining: 7m 21s\n",
      "2658:\tlearn: 6.7535820\ttotal: 57.7s\tremaining: 7m 21s\n",
      "2659:\tlearn: 6.7529089\ttotal: 57.7s\tremaining: 7m 21s\n",
      "2660:\tlearn: 6.7513292\ttotal: 57.7s\tremaining: 7m 21s\n",
      "2661:\tlearn: 6.7503790\ttotal: 57.8s\tremaining: 7m 21s\n",
      "2662:\tlearn: 6.7496877\ttotal: 57.8s\tremaining: 7m 21s\n",
      "2663:\tlearn: 6.7490035\ttotal: 57.8s\tremaining: 7m 21s\n",
      "2664:\tlearn: 6.7478720\ttotal: 57.8s\tremaining: 7m 21s\n",
      "2665:\tlearn: 6.7469570\ttotal: 57.8s\tremaining: 7m 21s\n",
      "2666:\tlearn: 6.7456188\ttotal: 57.9s\tremaining: 7m 21s\n",
      "2667:\tlearn: 6.7447225\ttotal: 57.9s\tremaining: 7m 21s\n",
      "2668:\tlearn: 6.7435587\ttotal: 57.9s\tremaining: 7m 21s\n",
      "2669:\tlearn: 6.7425162\ttotal: 57.9s\tremaining: 7m 21s\n",
      "2670:\tlearn: 6.7420086\ttotal: 58s\tremaining: 7m 21s\n",
      "2671:\tlearn: 6.7411349\ttotal: 58s\tremaining: 7m 21s\n",
      "2672:\tlearn: 6.7404482\ttotal: 58s\tremaining: 7m 21s\n",
      "2673:\tlearn: 6.7391184\ttotal: 58s\tremaining: 7m 21s\n",
      "2674:\tlearn: 6.7385751\ttotal: 58s\tremaining: 7m 20s\n",
      "2675:\tlearn: 6.7373664\ttotal: 58.1s\tremaining: 7m 20s\n",
      "2676:\tlearn: 6.7360626\ttotal: 58.1s\tremaining: 7m 20s\n",
      "2677:\tlearn: 6.7347956\ttotal: 58.1s\tremaining: 7m 20s\n",
      "2678:\tlearn: 6.7338987\ttotal: 58.1s\tremaining: 7m 20s\n",
      "2679:\tlearn: 6.7329761\ttotal: 58.1s\tremaining: 7m 20s\n",
      "2680:\tlearn: 6.7315278\ttotal: 58.2s\tremaining: 7m 20s\n",
      "2681:\tlearn: 6.7306302\ttotal: 58.2s\tremaining: 7m 20s\n",
      "2682:\tlearn: 6.7298114\ttotal: 58.2s\tremaining: 7m 20s\n",
      "2683:\tlearn: 6.7284710\ttotal: 58.2s\tremaining: 7m 20s\n",
      "2684:\tlearn: 6.7276454\ttotal: 58.2s\tremaining: 7m 20s\n",
      "2685:\tlearn: 6.7274335\ttotal: 58.3s\tremaining: 7m 20s\n",
      "2686:\tlearn: 6.7261253\ttotal: 58.3s\tremaining: 7m 20s\n",
      "2687:\tlearn: 6.7254615\ttotal: 58.3s\tremaining: 7m 20s\n",
      "2688:\tlearn: 6.7244730\ttotal: 58.3s\tremaining: 7m 20s\n",
      "2689:\tlearn: 6.7237547\ttotal: 58.3s\tremaining: 7m 20s\n",
      "2690:\tlearn: 6.7230569\ttotal: 58.4s\tremaining: 7m 20s\n",
      "2691:\tlearn: 6.7221625\ttotal: 58.4s\tremaining: 7m 20s\n",
      "2692:\tlearn: 6.7215660\ttotal: 58.4s\tremaining: 7m 20s\n",
      "2693:\tlearn: 6.7201946\ttotal: 58.4s\tremaining: 7m 20s\n",
      "2694:\tlearn: 6.7197953\ttotal: 58.5s\tremaining: 7m 20s\n",
      "2695:\tlearn: 6.7186788\ttotal: 58.5s\tremaining: 7m 20s\n",
      "2696:\tlearn: 6.7178820\ttotal: 58.5s\tremaining: 7m 20s\n",
      "2697:\tlearn: 6.7168506\ttotal: 58.5s\tremaining: 7m 20s\n",
      "2698:\tlearn: 6.7153788\ttotal: 58.5s\tremaining: 7m 20s\n",
      "2699:\tlearn: 6.7137458\ttotal: 58.6s\tremaining: 7m 20s\n",
      "2700:\tlearn: 6.7129218\ttotal: 58.6s\tremaining: 7m 20s\n",
      "2701:\tlearn: 6.7121785\ttotal: 58.6s\tremaining: 7m 20s\n",
      "2702:\tlearn: 6.7111109\ttotal: 58.6s\tremaining: 7m 20s\n",
      "2703:\tlearn: 6.7098977\ttotal: 58.6s\tremaining: 7m 20s\n",
      "2704:\tlearn: 6.7088822\ttotal: 58.7s\tremaining: 7m 20s\n",
      "2705:\tlearn: 6.7081671\ttotal: 58.7s\tremaining: 7m 20s\n",
      "2706:\tlearn: 6.7073251\ttotal: 58.7s\tremaining: 7m 20s\n",
      "2707:\tlearn: 6.7068775\ttotal: 58.7s\tremaining: 7m 20s\n",
      "2708:\tlearn: 6.7060384\ttotal: 58.7s\tremaining: 7m 19s\n",
      "2709:\tlearn: 6.7053890\ttotal: 58.8s\tremaining: 7m 19s\n",
      "2710:\tlearn: 6.7042782\ttotal: 58.8s\tremaining: 7m 19s\n",
      "2711:\tlearn: 6.7033116\ttotal: 58.8s\tremaining: 7m 19s\n",
      "2712:\tlearn: 6.7024231\ttotal: 58.8s\tremaining: 7m 19s\n",
      "2713:\tlearn: 6.7015769\ttotal: 58.9s\tremaining: 7m 19s\n",
      "2714:\tlearn: 6.7008809\ttotal: 58.9s\tremaining: 7m 19s\n",
      "2715:\tlearn: 6.7002752\ttotal: 58.9s\tremaining: 7m 19s\n",
      "2716:\tlearn: 6.6989465\ttotal: 58.9s\tremaining: 7m 19s\n",
      "2717:\tlearn: 6.6981395\ttotal: 58.9s\tremaining: 7m 19s\n",
      "2718:\tlearn: 6.6973928\ttotal: 59s\tremaining: 7m 19s\n",
      "2719:\tlearn: 6.6964181\ttotal: 59s\tremaining: 7m 19s\n",
      "2720:\tlearn: 6.6957695\ttotal: 59s\tremaining: 7m 19s\n",
      "2721:\tlearn: 6.6949793\ttotal: 59s\tremaining: 7m 19s\n",
      "2722:\tlearn: 6.6943131\ttotal: 59.1s\tremaining: 7m 19s\n",
      "2723:\tlearn: 6.6936607\ttotal: 59.1s\tremaining: 7m 19s\n",
      "2724:\tlearn: 6.6926236\ttotal: 59.1s\tremaining: 7m 19s\n",
      "2725:\tlearn: 6.6917318\ttotal: 59.1s\tremaining: 7m 19s\n",
      "2726:\tlearn: 6.6910465\ttotal: 59.1s\tremaining: 7m 19s\n",
      "2727:\tlearn: 6.6899843\ttotal: 59.2s\tremaining: 7m 19s\n",
      "2728:\tlearn: 6.6890855\ttotal: 59.2s\tremaining: 7m 19s\n",
      "2729:\tlearn: 6.6885568\ttotal: 59.2s\tremaining: 7m 19s\n",
      "2730:\tlearn: 6.6868781\ttotal: 59.2s\tremaining: 7m 19s\n",
      "2731:\tlearn: 6.6861609\ttotal: 59.2s\tremaining: 7m 19s\n",
      "2732:\tlearn: 6.6848970\ttotal: 59.3s\tremaining: 7m 19s\n",
      "2733:\tlearn: 6.6841077\ttotal: 59.3s\tremaining: 7m 19s\n",
      "2734:\tlearn: 6.6826458\ttotal: 59.3s\tremaining: 7m 19s\n",
      "2735:\tlearn: 6.6818077\ttotal: 59.3s\tremaining: 7m 19s\n",
      "2736:\tlearn: 6.6805743\ttotal: 59.3s\tremaining: 7m 19s\n",
      "2737:\tlearn: 6.6799457\ttotal: 59.4s\tremaining: 7m 19s\n",
      "2738:\tlearn: 6.6789009\ttotal: 59.4s\tremaining: 7m 19s\n",
      "2739:\tlearn: 6.6779209\ttotal: 59.4s\tremaining: 7m 19s\n",
      "2740:\tlearn: 6.6769109\ttotal: 59.4s\tremaining: 7m 19s\n",
      "2741:\tlearn: 6.6758730\ttotal: 59.5s\tremaining: 7m 19s\n",
      "2742:\tlearn: 6.6749031\ttotal: 59.5s\tremaining: 7m 19s\n",
      "2743:\tlearn: 6.6743352\ttotal: 59.5s\tremaining: 7m 19s\n",
      "2744:\tlearn: 6.6735979\ttotal: 59.5s\tremaining: 7m 19s\n",
      "2745:\tlearn: 6.6725053\ttotal: 59.5s\tremaining: 7m 19s\n",
      "2746:\tlearn: 6.6717033\ttotal: 59.6s\tremaining: 7m 19s\n",
      "2747:\tlearn: 6.6705072\ttotal: 59.6s\tremaining: 7m 19s\n",
      "2748:\tlearn: 6.6695705\ttotal: 59.6s\tremaining: 7m 19s\n",
      "2749:\tlearn: 6.6680004\ttotal: 59.6s\tremaining: 7m 19s\n",
      "2750:\tlearn: 6.6667800\ttotal: 59.7s\tremaining: 7m 19s\n",
      "2751:\tlearn: 6.6657730\ttotal: 59.7s\tremaining: 7m 19s\n",
      "2752:\tlearn: 6.6652753\ttotal: 59.7s\tremaining: 7m 19s\n",
      "2753:\tlearn: 6.6642518\ttotal: 59.7s\tremaining: 7m 18s\n",
      "2754:\tlearn: 6.6633191\ttotal: 59.7s\tremaining: 7m 18s\n",
      "2755:\tlearn: 6.6618508\ttotal: 59.8s\tremaining: 7m 18s\n",
      "2756:\tlearn: 6.6604164\ttotal: 59.8s\tremaining: 7m 18s\n",
      "2757:\tlearn: 6.6596058\ttotal: 59.8s\tremaining: 7m 18s\n",
      "2758:\tlearn: 6.6588804\ttotal: 59.8s\tremaining: 7m 18s\n",
      "2759:\tlearn: 6.6577401\ttotal: 59.8s\tremaining: 7m 18s\n",
      "2760:\tlearn: 6.6566163\ttotal: 59.9s\tremaining: 7m 18s\n",
      "2761:\tlearn: 6.6556210\ttotal: 59.9s\tremaining: 7m 18s\n",
      "2762:\tlearn: 6.6550695\ttotal: 59.9s\tremaining: 7m 18s\n",
      "2763:\tlearn: 6.6538294\ttotal: 59.9s\tremaining: 7m 18s\n",
      "2764:\tlearn: 6.6531560\ttotal: 60s\tremaining: 7m 18s\n",
      "2765:\tlearn: 6.6519859\ttotal: 60s\tremaining: 7m 18s\n",
      "2766:\tlearn: 6.6508589\ttotal: 1m\tremaining: 7m 18s\n",
      "2767:\tlearn: 6.6500329\ttotal: 1m\tremaining: 7m 18s\n",
      "2768:\tlearn: 6.6492673\ttotal: 1m\tremaining: 7m 18s\n",
      "2769:\tlearn: 6.6481823\ttotal: 1m\tremaining: 7m 18s\n",
      "2770:\tlearn: 6.6472078\ttotal: 1m\tremaining: 7m 18s\n",
      "2771:\tlearn: 6.6461647\ttotal: 1m\tremaining: 7m 18s\n",
      "2772:\tlearn: 6.6454205\ttotal: 1m\tremaining: 7m 18s\n",
      "2773:\tlearn: 6.6442005\ttotal: 1m\tremaining: 7m 18s\n",
      "2774:\tlearn: 6.6436872\ttotal: 1m\tremaining: 7m 18s\n",
      "2775:\tlearn: 6.6424152\ttotal: 1m\tremaining: 7m 18s\n",
      "2776:\tlearn: 6.6417720\ttotal: 1m\tremaining: 7m 18s\n",
      "2777:\tlearn: 6.6409331\ttotal: 1m\tremaining: 7m 18s\n",
      "2778:\tlearn: 6.6403632\ttotal: 1m\tremaining: 7m 18s\n",
      "2779:\tlearn: 6.6396810\ttotal: 1m\tremaining: 7m 18s\n",
      "2780:\tlearn: 6.6388191\ttotal: 1m\tremaining: 7m 18s\n",
      "2781:\tlearn: 6.6377153\ttotal: 1m\tremaining: 7m 18s\n",
      "2782:\tlearn: 6.6364938\ttotal: 1m\tremaining: 7m 18s\n",
      "2783:\tlearn: 6.6357733\ttotal: 1m\tremaining: 7m 18s\n",
      "2784:\tlearn: 6.6346455\ttotal: 1m\tremaining: 7m 18s\n",
      "2785:\tlearn: 6.6332996\ttotal: 1m\tremaining: 7m 18s\n",
      "2786:\tlearn: 6.6328314\ttotal: 1m\tremaining: 7m 18s\n",
      "2787:\tlearn: 6.6316560\ttotal: 1m\tremaining: 7m 18s\n",
      "2788:\tlearn: 6.6310527\ttotal: 1m\tremaining: 7m 18s\n",
      "2789:\tlearn: 6.6301811\ttotal: 1m\tremaining: 7m 18s\n",
      "2790:\tlearn: 6.6294076\ttotal: 1m\tremaining: 7m 18s\n",
      "2791:\tlearn: 6.6284375\ttotal: 1m\tremaining: 7m 18s\n",
      "2792:\tlearn: 6.6276530\ttotal: 1m\tremaining: 7m 18s\n",
      "2793:\tlearn: 6.6264834\ttotal: 1m\tremaining: 7m 18s\n",
      "2794:\tlearn: 6.6254421\ttotal: 1m\tremaining: 7m 18s\n",
      "2795:\tlearn: 6.6245745\ttotal: 1m\tremaining: 7m 18s\n",
      "2796:\tlearn: 6.6235893\ttotal: 1m\tremaining: 7m 18s\n",
      "2797:\tlearn: 6.6231507\ttotal: 1m\tremaining: 7m 18s\n",
      "2798:\tlearn: 6.6223157\ttotal: 1m\tremaining: 7m 18s\n",
      "2799:\tlearn: 6.6216227\ttotal: 1m\tremaining: 7m 18s\n",
      "2800:\tlearn: 6.6209198\ttotal: 1m\tremaining: 7m 17s\n",
      "2801:\tlearn: 6.6204333\ttotal: 1m\tremaining: 7m 17s\n",
      "2802:\tlearn: 6.6198844\ttotal: 1m\tremaining: 7m 17s\n",
      "2803:\tlearn: 6.6189702\ttotal: 1m\tremaining: 7m 17s\n",
      "2804:\tlearn: 6.6183079\ttotal: 1m\tremaining: 7m 17s\n",
      "2805:\tlearn: 6.6176699\ttotal: 1m\tremaining: 7m 17s\n",
      "2806:\tlearn: 6.6171368\ttotal: 1m\tremaining: 7m 17s\n",
      "2807:\tlearn: 6.6161132\ttotal: 1m\tremaining: 7m 17s\n",
      "2808:\tlearn: 6.6152568\ttotal: 1m\tremaining: 7m 17s\n",
      "2809:\tlearn: 6.6147196\ttotal: 1m\tremaining: 7m 17s\n",
      "2810:\tlearn: 6.6139637\ttotal: 1m\tremaining: 7m 17s\n",
      "2811:\tlearn: 6.6135459\ttotal: 1m\tremaining: 7m 17s\n",
      "2812:\tlearn: 6.6127170\ttotal: 1m\tremaining: 7m 17s\n",
      "2813:\tlearn: 6.6123895\ttotal: 1m\tremaining: 7m 17s\n",
      "2814:\tlearn: 6.6114339\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2815:\tlearn: 6.6103108\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2816:\tlearn: 6.6096704\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2817:\tlearn: 6.6087123\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2818:\tlearn: 6.6074230\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2819:\tlearn: 6.6066871\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2820:\tlearn: 6.6060040\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2821:\tlearn: 6.6052877\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2822:\tlearn: 6.6046116\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2823:\tlearn: 6.6040683\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2824:\tlearn: 6.6028798\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2825:\tlearn: 6.6016675\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2826:\tlearn: 6.6004388\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2827:\tlearn: 6.5994297\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2828:\tlearn: 6.5988215\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2829:\tlearn: 6.5978964\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2830:\tlearn: 6.5971928\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2831:\tlearn: 6.5959839\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2832:\tlearn: 6.5950389\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2833:\tlearn: 6.5945100\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2834:\tlearn: 6.5936467\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2835:\tlearn: 6.5929632\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2836:\tlearn: 6.5926847\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2837:\tlearn: 6.5918106\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2838:\tlearn: 6.5906065\ttotal: 1m 1s\tremaining: 7m 17s\n",
      "2839:\tlearn: 6.5899692\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2840:\tlearn: 6.5895198\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2841:\tlearn: 6.5886085\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2842:\tlearn: 6.5876080\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2843:\tlearn: 6.5864250\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2844:\tlearn: 6.5850808\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2845:\tlearn: 6.5846589\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2846:\tlearn: 6.5840401\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2847:\tlearn: 6.5828553\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2848:\tlearn: 6.5821859\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2849:\tlearn: 6.5814696\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2850:\tlearn: 6.5803547\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2851:\tlearn: 6.5797907\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2852:\tlearn: 6.5795687\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2853:\tlearn: 6.5787287\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2854:\tlearn: 6.5777855\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2855:\tlearn: 6.5773183\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2856:\tlearn: 6.5765518\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2857:\tlearn: 6.5757775\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2858:\tlearn: 6.5748922\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2859:\tlearn: 6.5736709\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2860:\tlearn: 6.5736377\ttotal: 1m 1s\tremaining: 7m 16s\n",
      "2861:\tlearn: 6.5729269\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2862:\tlearn: 6.5723866\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2863:\tlearn: 6.5714363\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2864:\tlearn: 6.5708905\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2865:\tlearn: 6.5693385\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2866:\tlearn: 6.5684843\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2867:\tlearn: 6.5677787\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2868:\tlearn: 6.5671671\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2869:\tlearn: 6.5664535\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2870:\tlearn: 6.5661406\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2871:\tlearn: 6.5656522\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2872:\tlearn: 6.5648334\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2873:\tlearn: 6.5635857\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2874:\tlearn: 6.5629783\ttotal: 1m 2s\tremaining: 7m 16s\n",
      "2875:\tlearn: 6.5625560\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2876:\tlearn: 6.5615449\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2877:\tlearn: 6.5610984\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2878:\tlearn: 6.5602322\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2879:\tlearn: 6.5594283\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2880:\tlearn: 6.5587864\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2881:\tlearn: 6.5581566\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2882:\tlearn: 6.5573905\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2883:\tlearn: 6.5564704\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2884:\tlearn: 6.5556052\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2885:\tlearn: 6.5543086\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2886:\tlearn: 6.5531687\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2887:\tlearn: 6.5521522\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2888:\tlearn: 6.5514631\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2889:\tlearn: 6.5504675\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2890:\tlearn: 6.5494370\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2891:\tlearn: 6.5483802\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2892:\tlearn: 6.5473793\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2893:\tlearn: 6.5464747\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2894:\tlearn: 6.5452605\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2895:\tlearn: 6.5444885\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2896:\tlearn: 6.5431697\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2897:\tlearn: 6.5419943\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2898:\tlearn: 6.5407062\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2899:\tlearn: 6.5398010\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2900:\tlearn: 6.5386396\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2901:\tlearn: 6.5374940\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2902:\tlearn: 6.5368607\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2903:\tlearn: 6.5362364\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2904:\tlearn: 6.5351932\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2905:\tlearn: 6.5344935\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2906:\tlearn: 6.5332743\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "2907:\tlearn: 6.5324846\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2908:\tlearn: 6.5312262\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2909:\tlearn: 6.5305351\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2910:\tlearn: 6.5298622\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2911:\tlearn: 6.5286969\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2912:\tlearn: 6.5275980\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2913:\tlearn: 6.5261150\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2914:\tlearn: 6.5253745\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2915:\tlearn: 6.5248574\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2916:\tlearn: 6.5239802\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2917:\tlearn: 6.5230523\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2918:\tlearn: 6.5222052\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2919:\tlearn: 6.5212091\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2920:\tlearn: 6.5204555\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2921:\tlearn: 6.5197288\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2922:\tlearn: 6.5187773\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2923:\tlearn: 6.5180670\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2924:\tlearn: 6.5168528\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2925:\tlearn: 6.5163554\ttotal: 1m 3s\tremaining: 7m 15s\n",
      "2926:\tlearn: 6.5155981\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2927:\tlearn: 6.5146259\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2928:\tlearn: 6.5136818\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2929:\tlearn: 6.5128614\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2930:\tlearn: 6.5115691\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2931:\tlearn: 6.5101638\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2932:\tlearn: 6.5089444\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2933:\tlearn: 6.5076551\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2934:\tlearn: 6.5068113\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2935:\tlearn: 6.5062588\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2936:\tlearn: 6.5053073\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2937:\tlearn: 6.5044340\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2938:\tlearn: 6.5044076\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2939:\tlearn: 6.5034158\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2940:\tlearn: 6.5028753\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2941:\tlearn: 6.5016745\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2942:\tlearn: 6.5016095\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2943:\tlearn: 6.5002313\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2944:\tlearn: 6.4996839\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2945:\tlearn: 6.4996182\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2946:\tlearn: 6.4984203\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2947:\tlearn: 6.4970805\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2948:\tlearn: 6.4964929\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2949:\tlearn: 6.4949921\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2950:\tlearn: 6.4949595\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2951:\tlearn: 6.4940169\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2952:\tlearn: 6.4934300\ttotal: 1m 3s\tremaining: 7m 14s\n",
      "2953:\tlearn: 6.4927582\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2954:\tlearn: 6.4922678\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2955:\tlearn: 6.4916888\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2956:\tlearn: 6.4909191\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2957:\tlearn: 6.4902958\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2958:\tlearn: 6.4893376\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2959:\tlearn: 6.4888447\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2960:\tlearn: 6.4880859\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2961:\tlearn: 6.4864953\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2962:\tlearn: 6.4851861\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2963:\tlearn: 6.4838341\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2964:\tlearn: 6.4829803\ttotal: 1m 4s\tremaining: 7m 14s\n",
      "2965:\tlearn: 6.4821068\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2966:\tlearn: 6.4809853\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2967:\tlearn: 6.4798690\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2968:\tlearn: 6.4790995\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2969:\tlearn: 6.4784359\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2970:\tlearn: 6.4774220\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2971:\tlearn: 6.4766709\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2972:\tlearn: 6.4755322\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2973:\tlearn: 6.4744921\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2974:\tlearn: 6.4734768\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2975:\tlearn: 6.4729051\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2976:\tlearn: 6.4719118\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2977:\tlearn: 6.4712303\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2978:\tlearn: 6.4706390\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2979:\tlearn: 6.4698834\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2980:\tlearn: 6.4685803\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2981:\tlearn: 6.4677917\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2982:\tlearn: 6.4668101\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2983:\tlearn: 6.4658068\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2984:\tlearn: 6.4646964\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2985:\tlearn: 6.4639160\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2986:\tlearn: 6.4627663\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2987:\tlearn: 6.4618231\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2988:\tlearn: 6.4612174\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2989:\tlearn: 6.4602430\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2990:\tlearn: 6.4595115\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2991:\tlearn: 6.4588548\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2992:\tlearn: 6.4578477\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2993:\tlearn: 6.4572047\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2994:\tlearn: 6.4560401\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2995:\tlearn: 6.4549439\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2996:\tlearn: 6.4544679\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2997:\tlearn: 6.4532512\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2998:\tlearn: 6.4523707\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "2999:\tlearn: 6.4517047\ttotal: 1m 4s\tremaining: 7m 13s\n",
      "3000:\tlearn: 6.4507902\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3001:\tlearn: 6.4499157\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3002:\tlearn: 6.4491915\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3003:\tlearn: 6.4485257\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3004:\tlearn: 6.4478595\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3005:\tlearn: 6.4473641\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3006:\tlearn: 6.4460047\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3007:\tlearn: 6.4454356\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3008:\tlearn: 6.4444783\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3009:\tlearn: 6.4434296\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3010:\tlearn: 6.4423192\ttotal: 1m 5s\tremaining: 7m 13s\n",
      "3011:\tlearn: 6.4418545\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3012:\tlearn: 6.4412749\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3013:\tlearn: 6.4406346\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3014:\tlearn: 6.4391574\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3015:\tlearn: 6.4385847\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3016:\tlearn: 6.4375508\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3017:\tlearn: 6.4366064\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3018:\tlearn: 6.4360312\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3019:\tlearn: 6.4349817\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3020:\tlearn: 6.4341181\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3021:\tlearn: 6.4331038\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3022:\tlearn: 6.4322744\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3023:\tlearn: 6.4318653\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3024:\tlearn: 6.4306269\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3025:\tlearn: 6.4294473\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3026:\tlearn: 6.4284846\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3027:\tlearn: 6.4270709\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3028:\tlearn: 6.4266326\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3029:\tlearn: 6.4254394\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3030:\tlearn: 6.4241195\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3031:\tlearn: 6.4234517\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3032:\tlearn: 6.4226007\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3033:\tlearn: 6.4219742\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3034:\tlearn: 6.4213924\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3035:\tlearn: 6.4205147\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3036:\tlearn: 6.4200048\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3037:\tlearn: 6.4192749\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3038:\tlearn: 6.4186670\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3039:\tlearn: 6.4174446\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3040:\tlearn: 6.4168831\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3041:\tlearn: 6.4165353\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3042:\tlearn: 6.4162065\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3043:\tlearn: 6.4156072\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3044:\tlearn: 6.4149532\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3045:\tlearn: 6.4139912\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3046:\tlearn: 6.4135552\ttotal: 1m 5s\tremaining: 7m 12s\n",
      "3047:\tlearn: 6.4124725\ttotal: 1m 6s\tremaining: 7m 12s\n",
      "3048:\tlearn: 6.4113636\ttotal: 1m 6s\tremaining: 7m 12s\n",
      "3049:\tlearn: 6.4105658\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3050:\tlearn: 6.4096771\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3051:\tlearn: 6.4094325\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3052:\tlearn: 6.4088048\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3053:\tlearn: 6.4080477\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3054:\tlearn: 6.4070795\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3055:\tlearn: 6.4066964\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3056:\tlearn: 6.4062255\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3057:\tlearn: 6.4048248\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3058:\tlearn: 6.4043004\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3059:\tlearn: 6.4040353\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3060:\tlearn: 6.4029957\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3061:\tlearn: 6.4017516\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3062:\tlearn: 6.4010717\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3063:\tlearn: 6.4005875\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3064:\tlearn: 6.3995895\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3065:\tlearn: 6.3988167\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3066:\tlearn: 6.3981466\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3067:\tlearn: 6.3975259\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3068:\tlearn: 6.3963034\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3069:\tlearn: 6.3949359\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3070:\tlearn: 6.3938197\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3071:\tlearn: 6.3926142\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3072:\tlearn: 6.3914165\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3073:\tlearn: 6.3905830\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3074:\tlearn: 6.3896829\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3075:\tlearn: 6.3889414\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3076:\tlearn: 6.3884234\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3077:\tlearn: 6.3874160\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3078:\tlearn: 6.3866694\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3079:\tlearn: 6.3859233\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3080:\tlearn: 6.3850587\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3081:\tlearn: 6.3840940\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3082:\tlearn: 6.3831031\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3083:\tlearn: 6.3823004\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3084:\tlearn: 6.3811740\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3085:\tlearn: 6.3805968\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3086:\tlearn: 6.3795645\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3087:\tlearn: 6.3783779\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3088:\tlearn: 6.3773716\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3089:\tlearn: 6.3765979\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3090:\tlearn: 6.3759236\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3091:\tlearn: 6.3752743\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3092:\tlearn: 6.3739435\ttotal: 1m 6s\tremaining: 7m 11s\n",
      "3093:\tlearn: 6.3730046\ttotal: 1m 7s\tremaining: 7m 11s\n",
      "3094:\tlearn: 6.3726909\ttotal: 1m 7s\tremaining: 7m 11s\n",
      "3095:\tlearn: 6.3718022\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3096:\tlearn: 6.3710757\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3097:\tlearn: 6.3706018\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3098:\tlearn: 6.3699150\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3099:\tlearn: 6.3691319\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3100:\tlearn: 6.3684189\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3101:\tlearn: 6.3675679\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3102:\tlearn: 6.3670045\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3103:\tlearn: 6.3657713\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3104:\tlearn: 6.3651130\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3105:\tlearn: 6.3643282\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3106:\tlearn: 6.3638388\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3107:\tlearn: 6.3628956\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3108:\tlearn: 6.3620872\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3109:\tlearn: 6.3616646\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3110:\tlearn: 6.3612574\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3111:\tlearn: 6.3604447\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3112:\tlearn: 6.3597046\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3113:\tlearn: 6.3591206\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3114:\tlearn: 6.3587517\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3115:\tlearn: 6.3580713\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3116:\tlearn: 6.3573874\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3117:\tlearn: 6.3567854\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3118:\tlearn: 6.3560541\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3119:\tlearn: 6.3548289\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3120:\tlearn: 6.3540261\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3121:\tlearn: 6.3533060\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3122:\tlearn: 6.3527314\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3123:\tlearn: 6.3519326\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3124:\tlearn: 6.3511893\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3125:\tlearn: 6.3502378\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3126:\tlearn: 6.3493109\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3127:\tlearn: 6.3488952\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3128:\tlearn: 6.3478211\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3129:\tlearn: 6.3471387\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3130:\tlearn: 6.3461940\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3131:\tlearn: 6.3460916\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3132:\tlearn: 6.3454813\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3133:\tlearn: 6.3450972\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3134:\tlearn: 6.3443623\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3135:\tlearn: 6.3435350\ttotal: 1m 7s\tremaining: 7m 9s\n",
      "3136:\tlearn: 6.3428745\ttotal: 1m 7s\tremaining: 7m 9s\n",
      "3137:\tlearn: 6.3421113\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3138:\tlearn: 6.3411904\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3139:\tlearn: 6.3400574\ttotal: 1m 7s\tremaining: 7m 10s\n",
      "3140:\tlearn: 6.3388321\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3141:\tlearn: 6.3379341\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3142:\tlearn: 6.3368228\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3143:\tlearn: 6.3361051\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3144:\tlearn: 6.3355481\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3145:\tlearn: 6.3347825\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3146:\tlearn: 6.3339655\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3147:\tlearn: 6.3336677\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3148:\tlearn: 6.3331667\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3149:\tlearn: 6.3321489\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3150:\tlearn: 6.3314846\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3151:\tlearn: 6.3309448\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3152:\tlearn: 6.3299851\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3153:\tlearn: 6.3285031\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3154:\tlearn: 6.3277554\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3155:\tlearn: 6.3269525\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3156:\tlearn: 6.3262015\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3157:\tlearn: 6.3252175\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3158:\tlearn: 6.3243562\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3159:\tlearn: 6.3232892\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3160:\tlearn: 6.3223711\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3161:\tlearn: 6.3215255\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3162:\tlearn: 6.3203761\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3163:\tlearn: 6.3193938\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3164:\tlearn: 6.3184695\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3165:\tlearn: 6.3178864\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3166:\tlearn: 6.3171253\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3167:\tlearn: 6.3165464\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3168:\tlearn: 6.3158946\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3169:\tlearn: 6.3149276\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3170:\tlearn: 6.3138541\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3171:\tlearn: 6.3128533\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3172:\tlearn: 6.3120194\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3173:\tlearn: 6.3116712\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3174:\tlearn: 6.3109363\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3175:\tlearn: 6.3098135\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3176:\tlearn: 6.3085849\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3177:\tlearn: 6.3077717\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3178:\tlearn: 6.3071546\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3179:\tlearn: 6.3064913\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3180:\tlearn: 6.3056522\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3181:\tlearn: 6.3046007\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3182:\tlearn: 6.3040727\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3183:\tlearn: 6.3033792\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3184:\tlearn: 6.3022725\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3185:\tlearn: 6.3013489\ttotal: 1m 8s\tremaining: 7m 9s\n",
      "3186:\tlearn: 6.3004045\ttotal: 1m 9s\tremaining: 7m 9s\n",
      "3187:\tlearn: 6.2995842\ttotal: 1m 9s\tremaining: 7m 9s\n",
      "3188:\tlearn: 6.2988291\ttotal: 1m 9s\tremaining: 7m 9s\n",
      "3189:\tlearn: 6.2982775\ttotal: 1m 9s\tremaining: 7m 9s\n",
      "3190:\tlearn: 6.2977312\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3191:\tlearn: 6.2973172\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3192:\tlearn: 6.2967451\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3193:\tlearn: 6.2962493\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3194:\tlearn: 6.2954141\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3195:\tlearn: 6.2945451\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3196:\tlearn: 6.2936036\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3197:\tlearn: 6.2924036\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3198:\tlearn: 6.2913141\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3199:\tlearn: 6.2907621\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3200:\tlearn: 6.2900656\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3201:\tlearn: 6.2890767\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3202:\tlearn: 6.2884437\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3203:\tlearn: 6.2874314\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3204:\tlearn: 6.2869539\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3205:\tlearn: 6.2862798\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3206:\tlearn: 6.2856962\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3207:\tlearn: 6.2847478\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3208:\tlearn: 6.2836902\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3209:\tlearn: 6.2828898\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3210:\tlearn: 6.2820695\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3211:\tlearn: 6.2810226\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3212:\tlearn: 6.2798539\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3213:\tlearn: 6.2791587\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3214:\tlearn: 6.2784109\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3215:\tlearn: 6.2776828\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3216:\tlearn: 6.2765183\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3217:\tlearn: 6.2758224\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3218:\tlearn: 6.2751909\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3219:\tlearn: 6.2744647\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3220:\tlearn: 6.2735382\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3221:\tlearn: 6.2727051\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3222:\tlearn: 6.2713944\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3223:\tlearn: 6.2703274\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3224:\tlearn: 6.2692617\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3225:\tlearn: 6.2683486\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3226:\tlearn: 6.2677530\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3227:\tlearn: 6.2673277\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3228:\tlearn: 6.2665886\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3229:\tlearn: 6.2656429\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3230:\tlearn: 6.2653862\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3231:\tlearn: 6.2643080\ttotal: 1m 9s\tremaining: 7m 8s\n",
      "3232:\tlearn: 6.2636517\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3233:\tlearn: 6.2627560\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3234:\tlearn: 6.2621631\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3235:\tlearn: 6.2614868\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3236:\tlearn: 6.2609428\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3237:\tlearn: 6.2597163\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3238:\tlearn: 6.2591226\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3239:\tlearn: 6.2585779\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3240:\tlearn: 6.2581731\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3241:\tlearn: 6.2576481\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3242:\tlearn: 6.2571591\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3243:\tlearn: 6.2565612\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3244:\tlearn: 6.2558586\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3245:\tlearn: 6.2551046\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3246:\tlearn: 6.2544223\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3247:\tlearn: 6.2536383\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3248:\tlearn: 6.2530049\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3249:\tlearn: 6.2523516\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3250:\tlearn: 6.2518658\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3251:\tlearn: 6.2514175\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3252:\tlearn: 6.2508111\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3253:\tlearn: 6.2501550\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3254:\tlearn: 6.2494097\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3255:\tlearn: 6.2487887\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3256:\tlearn: 6.2482998\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3257:\tlearn: 6.2479456\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3258:\tlearn: 6.2476918\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3259:\tlearn: 6.2470834\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3260:\tlearn: 6.2458366\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3261:\tlearn: 6.2450728\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3262:\tlearn: 6.2443180\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3263:\tlearn: 6.2436041\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3264:\tlearn: 6.2426564\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3265:\tlearn: 6.2416097\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3266:\tlearn: 6.2410821\ttotal: 1m 10s\tremaining: 7m 7s\n",
      "3267:\tlearn: 6.2404559\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3268:\tlearn: 6.2397900\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3269:\tlearn: 6.2391595\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3270:\tlearn: 6.2385656\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3271:\tlearn: 6.2380742\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3272:\tlearn: 6.2372272\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3273:\tlearn: 6.2363032\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3274:\tlearn: 6.2356993\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3275:\tlearn: 6.2349349\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3276:\tlearn: 6.2340945\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3277:\tlearn: 6.2334016\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3278:\tlearn: 6.2324723\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3279:\tlearn: 6.2314950\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3280:\tlearn: 6.2307884\ttotal: 1m 10s\tremaining: 7m 6s\n",
      "3281:\tlearn: 6.2297471\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3282:\tlearn: 6.2287271\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3283:\tlearn: 6.2280441\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3284:\tlearn: 6.2274120\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3285:\tlearn: 6.2268960\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3286:\tlearn: 6.2256410\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3287:\tlearn: 6.2249962\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3288:\tlearn: 6.2240954\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3289:\tlearn: 6.2237611\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3290:\tlearn: 6.2229656\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3291:\tlearn: 6.2220648\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3292:\tlearn: 6.2212794\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3293:\tlearn: 6.2205342\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3294:\tlearn: 6.2198796\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3295:\tlearn: 6.2189949\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3296:\tlearn: 6.2178036\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3297:\tlearn: 6.2168127\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3298:\tlearn: 6.2159441\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3299:\tlearn: 6.2152442\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3300:\tlearn: 6.2142400\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3301:\tlearn: 6.2134390\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3302:\tlearn: 6.2127647\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3303:\tlearn: 6.2117531\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3304:\tlearn: 6.2111298\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3305:\tlearn: 6.2103463\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3306:\tlearn: 6.2098163\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3307:\tlearn: 6.2094279\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3308:\tlearn: 6.2089741\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3309:\tlearn: 6.2080337\ttotal: 1m 11s\tremaining: 7m 6s\n",
      "3310:\tlearn: 6.2075651\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3311:\tlearn: 6.2063059\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3312:\tlearn: 6.2057053\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3313:\tlearn: 6.2048630\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3314:\tlearn: 6.2040180\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3315:\tlearn: 6.2028441\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3316:\tlearn: 6.2026709\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3317:\tlearn: 6.2019473\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3318:\tlearn: 6.2014781\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3319:\tlearn: 6.2008989\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3320:\tlearn: 6.1998830\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3321:\tlearn: 6.1991538\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3322:\tlearn: 6.1983309\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3323:\tlearn: 6.1976841\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3324:\tlearn: 6.1966004\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3325:\tlearn: 6.1959816\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3326:\tlearn: 6.1951983\ttotal: 1m 11s\tremaining: 7m 5s\n",
      "3327:\tlearn: 6.1946443\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3328:\tlearn: 6.1934510\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3329:\tlearn: 6.1928847\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3330:\tlearn: 6.1922909\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3331:\tlearn: 6.1911103\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3332:\tlearn: 6.1905724\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3333:\tlearn: 6.1898472\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3334:\tlearn: 6.1895043\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3335:\tlearn: 6.1889165\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3336:\tlearn: 6.1882452\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3337:\tlearn: 6.1877398\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3338:\tlearn: 6.1869447\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3339:\tlearn: 6.1861582\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3340:\tlearn: 6.1856321\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3341:\tlearn: 6.1849278\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3342:\tlearn: 6.1842070\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3343:\tlearn: 6.1838130\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3344:\tlearn: 6.1827157\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3345:\tlearn: 6.1826932\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3346:\tlearn: 6.1819324\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3347:\tlearn: 6.1813099\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3348:\tlearn: 6.1807192\ttotal: 1m 12s\tremaining: 7m 5s\n",
      "3349:\tlearn: 6.1803362\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3350:\tlearn: 6.1798419\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3351:\tlearn: 6.1791179\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3352:\tlearn: 6.1787853\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3353:\tlearn: 6.1778116\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3354:\tlearn: 6.1770217\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3355:\tlearn: 6.1763770\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3356:\tlearn: 6.1753381\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3357:\tlearn: 6.1743412\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3358:\tlearn: 6.1734443\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3359:\tlearn: 6.1720882\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3360:\tlearn: 6.1713097\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3361:\tlearn: 6.1704039\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3362:\tlearn: 6.1698933\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3363:\tlearn: 6.1691349\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3364:\tlearn: 6.1681245\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3365:\tlearn: 6.1671845\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3366:\tlearn: 6.1663762\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3367:\tlearn: 6.1655344\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3368:\tlearn: 6.1651367\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3369:\tlearn: 6.1644118\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3370:\tlearn: 6.1634845\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3371:\tlearn: 6.1625816\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3372:\tlearn: 6.1619421\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3373:\tlearn: 6.1613303\ttotal: 1m 12s\tremaining: 7m 4s\n",
      "3374:\tlearn: 6.1605484\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3375:\tlearn: 6.1601382\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3376:\tlearn: 6.1596594\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3377:\tlearn: 6.1591312\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3378:\tlearn: 6.1582180\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3379:\tlearn: 6.1572957\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3380:\tlearn: 6.1568458\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3381:\tlearn: 6.1559176\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3382:\tlearn: 6.1552333\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3383:\tlearn: 6.1541346\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3384:\tlearn: 6.1538994\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3385:\tlearn: 6.1533954\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3386:\tlearn: 6.1527153\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3387:\tlearn: 6.1522320\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3388:\tlearn: 6.1511222\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3389:\tlearn: 6.1503385\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3390:\tlearn: 6.1492732\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3391:\tlearn: 6.1487190\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3392:\tlearn: 6.1478559\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3393:\tlearn: 6.1474432\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3394:\tlearn: 6.1464516\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3395:\tlearn: 6.1459993\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3396:\tlearn: 6.1452134\ttotal: 1m 13s\tremaining: 7m 4s\n",
      "3397:\tlearn: 6.1445625\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3398:\tlearn: 6.1439589\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3399:\tlearn: 6.1433707\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3400:\tlearn: 6.1426250\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3401:\tlearn: 6.1413885\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3402:\tlearn: 6.1402727\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3403:\tlearn: 6.1397013\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3404:\tlearn: 6.1389472\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3405:\tlearn: 6.1378652\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3406:\tlearn: 6.1369982\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3407:\tlearn: 6.1360742\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3408:\tlearn: 6.1350394\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3409:\tlearn: 6.1343954\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3410:\tlearn: 6.1336819\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3411:\tlearn: 6.1331361\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3412:\tlearn: 6.1325769\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3413:\tlearn: 6.1316660\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3414:\tlearn: 6.1306562\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3415:\tlearn: 6.1298822\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3416:\tlearn: 6.1292100\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3417:\tlearn: 6.1287394\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3418:\tlearn: 6.1277181\ttotal: 1m 13s\tremaining: 7m 3s\n",
      "3419:\tlearn: 6.1269264\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3420:\tlearn: 6.1263853\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3421:\tlearn: 6.1253626\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3422:\tlearn: 6.1246154\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3423:\tlearn: 6.1240744\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3424:\tlearn: 6.1231371\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3425:\tlearn: 6.1227316\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3426:\tlearn: 6.1217906\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3427:\tlearn: 6.1212666\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3428:\tlearn: 6.1201902\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3429:\tlearn: 6.1201623\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3430:\tlearn: 6.1195016\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3431:\tlearn: 6.1186647\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3432:\tlearn: 6.1176889\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3433:\tlearn: 6.1170714\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3434:\tlearn: 6.1160251\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3435:\tlearn: 6.1148404\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3436:\tlearn: 6.1141637\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3437:\tlearn: 6.1135139\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3438:\tlearn: 6.1130631\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3439:\tlearn: 6.1119575\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3440:\tlearn: 6.1110023\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3441:\tlearn: 6.1102862\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3442:\tlearn: 6.1097264\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3443:\tlearn: 6.1092600\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3444:\tlearn: 6.1087704\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3445:\tlearn: 6.1084369\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3446:\tlearn: 6.1076223\ttotal: 1m 14s\tremaining: 7m 3s\n",
      "3447:\tlearn: 6.1069961\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3448:\tlearn: 6.1060715\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3449:\tlearn: 6.1054281\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3450:\tlearn: 6.1046942\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3451:\tlearn: 6.1041548\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3452:\tlearn: 6.1038869\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3453:\tlearn: 6.1032424\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3454:\tlearn: 6.1027737\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3455:\tlearn: 6.1022248\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3456:\tlearn: 6.1010889\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3457:\tlearn: 6.1005074\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3458:\tlearn: 6.0999565\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3459:\tlearn: 6.0990055\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3460:\tlearn: 6.0984785\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3461:\tlearn: 6.0974320\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3462:\tlearn: 6.0966239\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3463:\tlearn: 6.0957471\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3464:\tlearn: 6.0947851\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3465:\tlearn: 6.0940176\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3466:\tlearn: 6.0936806\ttotal: 1m 14s\tremaining: 7m 2s\n",
      "3467:\tlearn: 6.0928647\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3468:\tlearn: 6.0921137\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3469:\tlearn: 6.0915456\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3470:\tlearn: 6.0912201\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3471:\tlearn: 6.0908550\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3472:\tlearn: 6.0900967\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3473:\tlearn: 6.0891152\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3474:\tlearn: 6.0881134\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3475:\tlearn: 6.0872422\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3476:\tlearn: 6.0864980\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3477:\tlearn: 6.0860580\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3478:\tlearn: 6.0860120\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3479:\tlearn: 6.0852640\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3480:\tlearn: 6.0847108\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3481:\tlearn: 6.0838559\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3482:\tlearn: 6.0833912\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3483:\tlearn: 6.0827027\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3484:\tlearn: 6.0818661\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3485:\tlearn: 6.0813642\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3486:\tlearn: 6.0807373\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3487:\tlearn: 6.0797594\ttotal: 1m 15s\tremaining: 7m 2s\n",
      "3488:\tlearn: 6.0791424\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3489:\tlearn: 6.0791208\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3490:\tlearn: 6.0780902\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3491:\tlearn: 6.0778724\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3492:\tlearn: 6.0768678\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3493:\tlearn: 6.0760147\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3494:\tlearn: 6.0749030\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3495:\tlearn: 6.0740191\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3496:\tlearn: 6.0730628\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3497:\tlearn: 6.0726051\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3498:\tlearn: 6.0719657\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3499:\tlearn: 6.0716243\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3500:\tlearn: 6.0705748\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3501:\tlearn: 6.0695867\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3502:\tlearn: 6.0690630\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3503:\tlearn: 6.0680641\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3504:\tlearn: 6.0673103\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3505:\tlearn: 6.0663220\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3506:\tlearn: 6.0661443\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3507:\tlearn: 6.0650470\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3508:\tlearn: 6.0642162\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3509:\tlearn: 6.0636462\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3510:\tlearn: 6.0628982\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3511:\tlearn: 6.0623001\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3512:\tlearn: 6.0612565\ttotal: 1m 15s\tremaining: 7m 1s\n",
      "3513:\tlearn: 6.0606466\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3514:\tlearn: 6.0594354\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3515:\tlearn: 6.0588013\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3516:\tlearn: 6.0582737\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3517:\tlearn: 6.0579527\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3518:\tlearn: 6.0570733\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3519:\tlearn: 6.0557840\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3520:\tlearn: 6.0550625\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3521:\tlearn: 6.0547658\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3522:\tlearn: 6.0533882\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3523:\tlearn: 6.0527600\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3524:\tlearn: 6.0521195\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3525:\tlearn: 6.0513521\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3526:\tlearn: 6.0510341\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3527:\tlearn: 6.0503316\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3528:\tlearn: 6.0491287\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3529:\tlearn: 6.0485034\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3530:\tlearn: 6.0479368\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3531:\tlearn: 6.0470598\ttotal: 1m 16s\tremaining: 7m 1s\n",
      "3532:\tlearn: 6.0465958\ttotal: 1m 16s\tremaining: 7m\n",
      "3533:\tlearn: 6.0456704\ttotal: 1m 16s\tremaining: 7m\n",
      "3534:\tlearn: 6.0449597\ttotal: 1m 16s\tremaining: 7m\n",
      "3535:\tlearn: 6.0442027\ttotal: 1m 16s\tremaining: 7m\n",
      "3536:\tlearn: 6.0435735\ttotal: 1m 16s\tremaining: 7m\n",
      "3537:\tlearn: 6.0428252\ttotal: 1m 16s\tremaining: 7m\n",
      "3538:\tlearn: 6.0423744\ttotal: 1m 16s\tremaining: 7m\n",
      "3539:\tlearn: 6.0418671\ttotal: 1m 16s\tremaining: 7m\n",
      "3540:\tlearn: 6.0408886\ttotal: 1m 16s\tremaining: 7m\n",
      "3541:\tlearn: 6.0397839\ttotal: 1m 16s\tremaining: 7m\n",
      "3542:\tlearn: 6.0393057\ttotal: 1m 16s\tremaining: 7m\n",
      "3543:\tlearn: 6.0387943\ttotal: 1m 16s\tremaining: 7m\n",
      "3544:\tlearn: 6.0383827\ttotal: 1m 16s\tremaining: 7m\n",
      "3545:\tlearn: 6.0377869\ttotal: 1m 16s\tremaining: 7m\n",
      "3546:\tlearn: 6.0372255\ttotal: 1m 16s\tremaining: 7m\n",
      "3547:\tlearn: 6.0364352\ttotal: 1m 16s\tremaining: 7m\n",
      "3548:\tlearn: 6.0359530\ttotal: 1m 16s\tremaining: 7m\n",
      "3549:\tlearn: 6.0350710\ttotal: 1m 16s\tremaining: 7m\n",
      "3550:\tlearn: 6.0344307\ttotal: 1m 16s\tremaining: 7m\n",
      "3551:\tlearn: 6.0336627\ttotal: 1m 16s\tremaining: 7m\n",
      "3552:\tlearn: 6.0330416\ttotal: 1m 16s\tremaining: 7m\n",
      "3553:\tlearn: 6.0324229\ttotal: 1m 16s\tremaining: 7m\n",
      "3554:\tlearn: 6.0319301\ttotal: 1m 16s\tremaining: 7m\n",
      "3555:\tlearn: 6.0312711\ttotal: 1m 16s\tremaining: 7m\n",
      "3556:\tlearn: 6.0306428\ttotal: 1m 16s\tremaining: 7m\n",
      "3557:\tlearn: 6.0297690\ttotal: 1m 16s\tremaining: 7m\n",
      "3558:\tlearn: 6.0291321\ttotal: 1m 16s\tremaining: 7m\n",
      "3559:\tlearn: 6.0285302\ttotal: 1m 16s\tremaining: 7m\n",
      "3560:\tlearn: 6.0280242\ttotal: 1m 16s\tremaining: 7m\n",
      "3561:\tlearn: 6.0270346\ttotal: 1m 17s\tremaining: 7m\n",
      "3562:\tlearn: 6.0260904\ttotal: 1m 17s\tremaining: 7m\n",
      "3563:\tlearn: 6.0255093\ttotal: 1m 17s\tremaining: 7m\n",
      "3564:\tlearn: 6.0249813\ttotal: 1m 17s\tremaining: 7m\n",
      "3565:\tlearn: 6.0240428\ttotal: 1m 17s\tremaining: 7m\n",
      "3566:\tlearn: 6.0235339\ttotal: 1m 17s\tremaining: 7m\n",
      "3567:\tlearn: 6.0226709\ttotal: 1m 17s\tremaining: 7m\n",
      "3568:\tlearn: 6.0219053\ttotal: 1m 17s\tremaining: 7m\n",
      "3569:\tlearn: 6.0212100\ttotal: 1m 17s\tremaining: 7m\n",
      "3570:\tlearn: 6.0207877\ttotal: 1m 17s\tremaining: 7m\n",
      "3571:\tlearn: 6.0198912\ttotal: 1m 17s\tremaining: 7m\n",
      "3572:\tlearn: 6.0194065\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3573:\tlearn: 6.0190811\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3574:\tlearn: 6.0183204\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3575:\tlearn: 6.0177307\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3576:\tlearn: 6.0170714\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3577:\tlearn: 6.0161436\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3578:\tlearn: 6.0155501\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3579:\tlearn: 6.0145534\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3580:\tlearn: 6.0137942\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3581:\tlearn: 6.0132382\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3582:\tlearn: 6.0122728\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3583:\tlearn: 6.0112907\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3584:\tlearn: 6.0101719\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3585:\tlearn: 6.0094770\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3586:\tlearn: 6.0085140\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3587:\tlearn: 6.0077717\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3588:\tlearn: 6.0071061\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3589:\tlearn: 6.0065672\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3590:\tlearn: 6.0056691\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3591:\tlearn: 6.0049688\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3592:\tlearn: 6.0045117\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3593:\tlearn: 6.0036463\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3594:\tlearn: 6.0026737\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3595:\tlearn: 6.0017859\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3596:\tlearn: 6.0011686\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3597:\tlearn: 6.0002389\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3598:\tlearn: 5.9997312\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3599:\tlearn: 5.9986031\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3600:\tlearn: 5.9978234\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3601:\tlearn: 5.9969004\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3602:\tlearn: 5.9958725\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3603:\tlearn: 5.9952649\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3604:\tlearn: 5.9943024\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3605:\tlearn: 5.9936122\ttotal: 1m 17s\tremaining: 6m 59s\n",
      "3606:\tlearn: 5.9929761\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3607:\tlearn: 5.9921495\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3608:\tlearn: 5.9917255\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3609:\tlearn: 5.9910894\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3610:\tlearn: 5.9900887\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3611:\tlearn: 5.9889489\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3612:\tlearn: 5.9881713\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3613:\tlearn: 5.9872838\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3614:\tlearn: 5.9864183\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3615:\tlearn: 5.9855451\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3616:\tlearn: 5.9851451\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3617:\tlearn: 5.9839843\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3618:\tlearn: 5.9830708\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3619:\tlearn: 5.9821246\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3620:\tlearn: 5.9816468\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3621:\tlearn: 5.9810526\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3622:\tlearn: 5.9803125\ttotal: 1m 18s\tremaining: 6m 59s\n",
      "3623:\tlearn: 5.9798407\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3624:\tlearn: 5.9794295\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3625:\tlearn: 5.9784965\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3626:\tlearn: 5.9779815\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3627:\tlearn: 5.9774080\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3628:\tlearn: 5.9768281\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3629:\tlearn: 5.9757226\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3630:\tlearn: 5.9748987\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3631:\tlearn: 5.9742290\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3632:\tlearn: 5.9730128\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3633:\tlearn: 5.9723294\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3634:\tlearn: 5.9715763\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3635:\tlearn: 5.9709179\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3636:\tlearn: 5.9703448\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3637:\tlearn: 5.9694701\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3638:\tlearn: 5.9689679\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3639:\tlearn: 5.9681798\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3640:\tlearn: 5.9674880\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3641:\tlearn: 5.9669125\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3642:\tlearn: 5.9665229\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3643:\tlearn: 5.9654284\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3644:\tlearn: 5.9646900\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3645:\tlearn: 5.9639149\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3646:\tlearn: 5.9632050\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3647:\tlearn: 5.9626191\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3648:\tlearn: 5.9619410\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3649:\tlearn: 5.9609076\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3650:\tlearn: 5.9602516\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3651:\tlearn: 5.9596753\ttotal: 1m 18s\tremaining: 6m 58s\n",
      "3652:\tlearn: 5.9585860\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3653:\tlearn: 5.9576808\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3654:\tlearn: 5.9571618\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3655:\tlearn: 5.9563387\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3656:\tlearn: 5.9558629\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3657:\tlearn: 5.9550531\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3658:\tlearn: 5.9543562\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3659:\tlearn: 5.9537942\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3660:\tlearn: 5.9531819\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3661:\tlearn: 5.9528482\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3662:\tlearn: 5.9523634\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3663:\tlearn: 5.9516435\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3664:\tlearn: 5.9511972\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3665:\tlearn: 5.9506207\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3666:\tlearn: 5.9499032\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3667:\tlearn: 5.9493058\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3668:\tlearn: 5.9483995\ttotal: 1m 19s\tremaining: 6m 58s\n",
      "3669:\tlearn: 5.9479209\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3670:\tlearn: 5.9472580\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3671:\tlearn: 5.9467809\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3672:\tlearn: 5.9460098\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3673:\tlearn: 5.9454907\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3674:\tlearn: 5.9450162\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3675:\tlearn: 5.9445431\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3676:\tlearn: 5.9438404\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3677:\tlearn: 5.9430896\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3678:\tlearn: 5.9420357\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3679:\tlearn: 5.9413965\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3680:\tlearn: 5.9409875\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3681:\tlearn: 5.9407676\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3682:\tlearn: 5.9397143\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3683:\tlearn: 5.9391099\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3684:\tlearn: 5.9383655\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3685:\tlearn: 5.9379707\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3686:\tlearn: 5.9371082\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3687:\tlearn: 5.9364170\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3688:\tlearn: 5.9357900\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3689:\tlearn: 5.9351410\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3690:\tlearn: 5.9347021\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3691:\tlearn: 5.9342599\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3692:\tlearn: 5.9334949\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3693:\tlearn: 5.9327999\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3694:\tlearn: 5.9321107\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3695:\tlearn: 5.9316868\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3696:\tlearn: 5.9311408\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3697:\tlearn: 5.9305157\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3698:\tlearn: 5.9297490\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3699:\tlearn: 5.9292074\ttotal: 1m 19s\tremaining: 6m 57s\n",
      "3700:\tlearn: 5.9288400\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3701:\tlearn: 5.9280837\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3702:\tlearn: 5.9275887\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3703:\tlearn: 5.9269257\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3704:\tlearn: 5.9263620\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3705:\tlearn: 5.9255164\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3706:\tlearn: 5.9249768\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3707:\tlearn: 5.9243733\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3708:\tlearn: 5.9235124\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3709:\tlearn: 5.9229889\ttotal: 1m 20s\tremaining: 6m 57s\n",
      "3710:\tlearn: 5.9223857\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3711:\tlearn: 5.9219467\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3712:\tlearn: 5.9211531\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3713:\tlearn: 5.9201114\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3714:\tlearn: 5.9196467\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3715:\tlearn: 5.9186864\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3716:\tlearn: 5.9186655\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3717:\tlearn: 5.9180495\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3718:\tlearn: 5.9173922\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3719:\tlearn: 5.9166390\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3720:\tlearn: 5.9158309\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3721:\tlearn: 5.9151908\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3722:\tlearn: 5.9142861\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3723:\tlearn: 5.9137044\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3724:\tlearn: 5.9126796\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3725:\tlearn: 5.9117942\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3726:\tlearn: 5.9109075\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3727:\tlearn: 5.9100834\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3728:\tlearn: 5.9097137\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3729:\tlearn: 5.9090470\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3730:\tlearn: 5.9085426\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3731:\tlearn: 5.9080040\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3732:\tlearn: 5.9071250\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3733:\tlearn: 5.9064623\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3734:\tlearn: 5.9058434\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3735:\tlearn: 5.9053421\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3736:\tlearn: 5.9047685\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3737:\tlearn: 5.9042920\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3738:\tlearn: 5.9034830\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3739:\tlearn: 5.9030119\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3740:\tlearn: 5.9026254\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3741:\tlearn: 5.9017544\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3742:\tlearn: 5.9007620\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3743:\tlearn: 5.9000420\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3744:\tlearn: 5.8997403\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3745:\tlearn: 5.8990629\ttotal: 1m 20s\tremaining: 6m 56s\n",
      "3746:\tlearn: 5.8986974\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3747:\tlearn: 5.8977037\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3748:\tlearn: 5.8971484\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3749:\tlearn: 5.8965554\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3750:\tlearn: 5.8957673\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3751:\tlearn: 5.8951810\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3752:\tlearn: 5.8944484\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3753:\tlearn: 5.8937749\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3754:\tlearn: 5.8930164\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3755:\tlearn: 5.8920757\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3756:\tlearn: 5.8915602\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3757:\tlearn: 5.8909115\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3758:\tlearn: 5.8900545\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3759:\tlearn: 5.8895810\ttotal: 1m 21s\tremaining: 6m 56s\n",
      "3760:\tlearn: 5.8892349\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3761:\tlearn: 5.8887515\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3762:\tlearn: 5.8879607\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3763:\tlearn: 5.8874693\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3764:\tlearn: 5.8869277\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3765:\tlearn: 5.8860210\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3766:\tlearn: 5.8856007\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3767:\tlearn: 5.8852322\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3768:\tlearn: 5.8846556\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3769:\tlearn: 5.8839655\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3770:\tlearn: 5.8829805\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3771:\tlearn: 5.8826478\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3772:\tlearn: 5.8822727\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3773:\tlearn: 5.8818523\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3774:\tlearn: 5.8812113\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3775:\tlearn: 5.8807567\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3776:\tlearn: 5.8803536\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3777:\tlearn: 5.8793478\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3778:\tlearn: 5.8788921\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3779:\tlearn: 5.8781227\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3780:\tlearn: 5.8776949\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3781:\tlearn: 5.8769764\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3782:\tlearn: 5.8763127\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3783:\tlearn: 5.8752254\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3784:\tlearn: 5.8751925\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3785:\tlearn: 5.8745634\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3786:\tlearn: 5.8736263\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3787:\tlearn: 5.8732616\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3788:\tlearn: 5.8726463\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3789:\tlearn: 5.8719025\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3790:\tlearn: 5.8711151\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3791:\tlearn: 5.8706335\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3792:\tlearn: 5.8702554\ttotal: 1m 21s\tremaining: 6m 55s\n",
      "3793:\tlearn: 5.8697298\ttotal: 1m 22s\tremaining: 6m 55s\n",
      "3794:\tlearn: 5.8692601\ttotal: 1m 22s\tremaining: 6m 55s\n",
      "3795:\tlearn: 5.8681901\ttotal: 1m 22s\tremaining: 6m 55s\n",
      "3796:\tlearn: 5.8675088\ttotal: 1m 22s\tremaining: 6m 55s\n",
      "3797:\tlearn: 5.8664861\ttotal: 1m 22s\tremaining: 6m 55s\n",
      "3798:\tlearn: 5.8657879\ttotal: 1m 22s\tremaining: 6m 55s\n",
      "3799:\tlearn: 5.8650007\ttotal: 1m 22s\tremaining: 6m 55s\n",
      "3800:\tlearn: 5.8643830\ttotal: 1m 22s\tremaining: 6m 55s\n",
      "3801:\tlearn: 5.8634432\ttotal: 1m 22s\tremaining: 6m 55s\n",
      "3802:\tlearn: 5.8629920\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3803:\tlearn: 5.8624421\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3804:\tlearn: 5.8614232\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3805:\tlearn: 5.8607387\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3806:\tlearn: 5.8604113\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3807:\tlearn: 5.8596009\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3808:\tlearn: 5.8588605\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3809:\tlearn: 5.8582107\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3810:\tlearn: 5.8575732\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3811:\tlearn: 5.8569204\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3812:\tlearn: 5.8559348\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3813:\tlearn: 5.8547805\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3814:\tlearn: 5.8542438\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3815:\tlearn: 5.8539497\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3816:\tlearn: 5.8528144\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3817:\tlearn: 5.8520304\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3818:\tlearn: 5.8509295\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3819:\tlearn: 5.8504484\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3820:\tlearn: 5.8496904\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3821:\tlearn: 5.8492367\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3822:\tlearn: 5.8487760\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3823:\tlearn: 5.8484444\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3824:\tlearn: 5.8474640\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3825:\tlearn: 5.8465254\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3826:\tlearn: 5.8458494\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3827:\tlearn: 5.8450567\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3828:\tlearn: 5.8442681\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3829:\tlearn: 5.8437105\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3830:\tlearn: 5.8427975\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3831:\tlearn: 5.8422395\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3832:\tlearn: 5.8416084\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3833:\tlearn: 5.8410021\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3834:\tlearn: 5.8403599\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3835:\tlearn: 5.8395126\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3836:\tlearn: 5.8388962\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3837:\tlearn: 5.8385243\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3838:\tlearn: 5.8378567\ttotal: 1m 22s\tremaining: 6m 54s\n",
      "3839:\tlearn: 5.8370470\ttotal: 1m 23s\tremaining: 6m 54s\n",
      "3840:\tlearn: 5.8362899\ttotal: 1m 23s\tremaining: 6m 54s\n",
      "3841:\tlearn: 5.8354937\ttotal: 1m 23s\tremaining: 6m 54s\n",
      "3842:\tlearn: 5.8349142\ttotal: 1m 23s\tremaining: 6m 54s\n",
      "3843:\tlearn: 5.8341414\ttotal: 1m 23s\tremaining: 6m 54s\n",
      "3844:\tlearn: 5.8337026\ttotal: 1m 23s\tremaining: 6m 54s\n",
      "3845:\tlearn: 5.8330122\ttotal: 1m 23s\tremaining: 6m 54s\n",
      "3846:\tlearn: 5.8325424\ttotal: 1m 23s\tremaining: 6m 54s\n",
      "3847:\tlearn: 5.8319727\ttotal: 1m 23s\tremaining: 6m 54s\n",
      "3848:\tlearn: 5.8315126\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3849:\tlearn: 5.8311914\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3850:\tlearn: 5.8305624\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3851:\tlearn: 5.8300032\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3852:\tlearn: 5.8295930\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3853:\tlearn: 5.8291500\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3854:\tlearn: 5.8281738\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3855:\tlearn: 5.8277623\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3856:\tlearn: 5.8273020\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3857:\tlearn: 5.8270581\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3858:\tlearn: 5.8266484\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3859:\tlearn: 5.8259483\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3860:\tlearn: 5.8248408\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3861:\tlearn: 5.8242998\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3862:\tlearn: 5.8235815\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3863:\tlearn: 5.8228570\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3864:\tlearn: 5.8222507\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3865:\tlearn: 5.8213428\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3866:\tlearn: 5.8211834\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3867:\tlearn: 5.8204081\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3868:\tlearn: 5.8198020\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3869:\tlearn: 5.8191494\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3870:\tlearn: 5.8185172\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3871:\tlearn: 5.8181481\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3872:\tlearn: 5.8177717\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3873:\tlearn: 5.8175703\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3874:\tlearn: 5.8169680\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3875:\tlearn: 5.8163022\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3876:\tlearn: 5.8155092\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3877:\tlearn: 5.8146464\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3878:\tlearn: 5.8141363\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3879:\tlearn: 5.8135484\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3880:\tlearn: 5.8130772\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3881:\tlearn: 5.8120624\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3882:\tlearn: 5.8117482\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3883:\tlearn: 5.8110152\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3884:\tlearn: 5.8106814\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3885:\tlearn: 5.8099387\ttotal: 1m 23s\tremaining: 6m 53s\n",
      "3886:\tlearn: 5.8095563\ttotal: 1m 24s\tremaining: 6m 53s\n",
      "3887:\tlearn: 5.8088386\ttotal: 1m 24s\tremaining: 6m 53s\n",
      "3888:\tlearn: 5.8083125\ttotal: 1m 24s\tremaining: 6m 53s\n",
      "3889:\tlearn: 5.8078261\ttotal: 1m 24s\tremaining: 6m 53s\n",
      "3890:\tlearn: 5.8069082\ttotal: 1m 24s\tremaining: 6m 53s\n",
      "3891:\tlearn: 5.8061564\ttotal: 1m 24s\tremaining: 6m 53s\n",
      "3892:\tlearn: 5.8053546\ttotal: 1m 24s\tremaining: 6m 53s\n",
      "3893:\tlearn: 5.8050443\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3894:\tlearn: 5.8043892\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3895:\tlearn: 5.8037924\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3896:\tlearn: 5.8028820\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3897:\tlearn: 5.8025070\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3898:\tlearn: 5.8018963\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3899:\tlearn: 5.8014011\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3900:\tlearn: 5.8004800\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3901:\tlearn: 5.7999144\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3902:\tlearn: 5.7993848\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3903:\tlearn: 5.7986432\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3904:\tlearn: 5.7980356\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3905:\tlearn: 5.7974901\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3906:\tlearn: 5.7968448\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3907:\tlearn: 5.7959813\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3908:\tlearn: 5.7950879\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3909:\tlearn: 5.7946514\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3910:\tlearn: 5.7942180\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3911:\tlearn: 5.7938841\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3912:\tlearn: 5.7931006\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3913:\tlearn: 5.7924656\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3914:\tlearn: 5.7917231\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3915:\tlearn: 5.7910832\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3916:\tlearn: 5.7903914\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3917:\tlearn: 5.7894821\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3918:\tlearn: 5.7890550\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3919:\tlearn: 5.7882609\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3920:\tlearn: 5.7878171\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3921:\tlearn: 5.7876443\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3922:\tlearn: 5.7864952\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3923:\tlearn: 5.7860686\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3924:\tlearn: 5.7859469\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3925:\tlearn: 5.7849850\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3926:\tlearn: 5.7844038\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3927:\tlearn: 5.7836137\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3928:\tlearn: 5.7827930\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3929:\tlearn: 5.7819409\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3930:\tlearn: 5.7810640\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3931:\tlearn: 5.7807156\ttotal: 1m 24s\tremaining: 6m 52s\n",
      "3932:\tlearn: 5.7800979\ttotal: 1m 25s\tremaining: 6m 52s\n",
      "3933:\tlearn: 5.7794219\ttotal: 1m 25s\tremaining: 6m 52s\n",
      "3934:\tlearn: 5.7788883\ttotal: 1m 25s\tremaining: 6m 52s\n",
      "3935:\tlearn: 5.7779037\ttotal: 1m 25s\tremaining: 6m 52s\n",
      "3936:\tlearn: 5.7772694\ttotal: 1m 25s\tremaining: 6m 52s\n",
      "3937:\tlearn: 5.7764651\ttotal: 1m 25s\tremaining: 6m 52s\n",
      "3938:\tlearn: 5.7754117\ttotal: 1m 25s\tremaining: 6m 52s\n",
      "3939:\tlearn: 5.7745383\ttotal: 1m 25s\tremaining: 6m 52s\n",
      "3940:\tlearn: 5.7745187\ttotal: 1m 25s\tremaining: 6m 52s\n",
      "3941:\tlearn: 5.7731533\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3942:\tlearn: 5.7725449\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3943:\tlearn: 5.7716118\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3944:\tlearn: 5.7711120\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3945:\tlearn: 5.7708133\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3946:\tlearn: 5.7699642\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3947:\tlearn: 5.7695473\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3948:\tlearn: 5.7690153\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3949:\tlearn: 5.7684520\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3950:\tlearn: 5.7676018\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3951:\tlearn: 5.7667669\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3952:\tlearn: 5.7661450\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3953:\tlearn: 5.7656557\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3954:\tlearn: 5.7650463\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3955:\tlearn: 5.7645385\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3956:\tlearn: 5.7641445\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3957:\tlearn: 5.7635021\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3958:\tlearn: 5.7627535\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3959:\tlearn: 5.7620832\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3960:\tlearn: 5.7614592\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3961:\tlearn: 5.7608135\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3962:\tlearn: 5.7604151\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3963:\tlearn: 5.7598970\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3964:\tlearn: 5.7595706\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3965:\tlearn: 5.7591214\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3966:\tlearn: 5.7589259\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3967:\tlearn: 5.7584109\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3968:\tlearn: 5.7577416\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3969:\tlearn: 5.7573432\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3970:\tlearn: 5.7567188\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3971:\tlearn: 5.7557324\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3972:\tlearn: 5.7551788\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3973:\tlearn: 5.7546376\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3974:\tlearn: 5.7538461\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3975:\tlearn: 5.7532627\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3976:\tlearn: 5.7523211\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3977:\tlearn: 5.7520357\ttotal: 1m 25s\tremaining: 6m 51s\n",
      "3978:\tlearn: 5.7513290\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3979:\tlearn: 5.7505499\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3980:\tlearn: 5.7499047\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3981:\tlearn: 5.7490580\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3982:\tlearn: 5.7487791\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3983:\tlearn: 5.7481862\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3984:\tlearn: 5.7472657\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3985:\tlearn: 5.7468283\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3986:\tlearn: 5.7458233\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3987:\tlearn: 5.7450963\ttotal: 1m 26s\tremaining: 6m 51s\n",
      "3988:\tlearn: 5.7442824\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3989:\tlearn: 5.7434131\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3990:\tlearn: 5.7429916\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3991:\tlearn: 5.7421914\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3992:\tlearn: 5.7417378\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3993:\tlearn: 5.7411397\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3994:\tlearn: 5.7407689\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3995:\tlearn: 5.7402310\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3996:\tlearn: 5.7397211\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3997:\tlearn: 5.7392531\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3998:\tlearn: 5.7383882\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "3999:\tlearn: 5.7378599\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4000:\tlearn: 5.7374218\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4001:\tlearn: 5.7369106\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4002:\tlearn: 5.7360807\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4003:\tlearn: 5.7354569\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4004:\tlearn: 5.7349565\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4005:\tlearn: 5.7344026\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4006:\tlearn: 5.7337279\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4007:\tlearn: 5.7331175\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4008:\tlearn: 5.7327370\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4009:\tlearn: 5.7319688\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4010:\tlearn: 5.7316155\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4011:\tlearn: 5.7311672\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4012:\tlearn: 5.7303294\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4013:\tlearn: 5.7298464\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4014:\tlearn: 5.7296197\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4015:\tlearn: 5.7288847\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4016:\tlearn: 5.7281973\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4017:\tlearn: 5.7273664\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4018:\tlearn: 5.7270504\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4019:\tlearn: 5.7265697\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4020:\tlearn: 5.7261134\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4021:\tlearn: 5.7254456\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4022:\tlearn: 5.7245380\ttotal: 1m 26s\tremaining: 6m 50s\n",
      "4023:\tlearn: 5.7240403\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4024:\tlearn: 5.7235460\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4025:\tlearn: 5.7231426\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4026:\tlearn: 5.7225728\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4027:\tlearn: 5.7222140\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4028:\tlearn: 5.7217894\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4029:\tlearn: 5.7212741\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4030:\tlearn: 5.7208350\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4031:\tlearn: 5.7204138\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4032:\tlearn: 5.7197782\ttotal: 1m 27s\tremaining: 6m 50s\n",
      "4033:\tlearn: 5.7192419\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4034:\tlearn: 5.7187039\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4035:\tlearn: 5.7182260\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4036:\tlearn: 5.7176069\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4037:\tlearn: 5.7168213\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4038:\tlearn: 5.7164496\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4039:\tlearn: 5.7161181\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4040:\tlearn: 5.7156387\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4041:\tlearn: 5.7150545\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4042:\tlearn: 5.7143422\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4043:\tlearn: 5.7134804\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4044:\tlearn: 5.7125133\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4045:\tlearn: 5.7121679\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4046:\tlearn: 5.7112808\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4047:\tlearn: 5.7110008\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4048:\tlearn: 5.7107120\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4049:\tlearn: 5.7101233\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4050:\tlearn: 5.7092997\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4051:\tlearn: 5.7087677\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4052:\tlearn: 5.7079736\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4053:\tlearn: 5.7074916\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4054:\tlearn: 5.7069364\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4055:\tlearn: 5.7061562\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4056:\tlearn: 5.7055452\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4057:\tlearn: 5.7055225\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4058:\tlearn: 5.7048676\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4059:\tlearn: 5.7042424\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4060:\tlearn: 5.7036835\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4061:\tlearn: 5.7029283\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4062:\tlearn: 5.7023797\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4063:\tlearn: 5.7018840\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4064:\tlearn: 5.7011616\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4065:\tlearn: 5.7007420\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4066:\tlearn: 5.7004121\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4067:\tlearn: 5.6998422\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4068:\tlearn: 5.6993601\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4069:\tlearn: 5.6986419\ttotal: 1m 27s\tremaining: 6m 49s\n",
      "4070:\tlearn: 5.6979963\ttotal: 1m 28s\tremaining: 6m 49s\n",
      "4071:\tlearn: 5.6975068\ttotal: 1m 28s\tremaining: 6m 49s\n",
      "4072:\tlearn: 5.6968612\ttotal: 1m 28s\tremaining: 6m 49s\n",
      "4073:\tlearn: 5.6964863\ttotal: 1m 28s\tremaining: 6m 49s\n",
      "4074:\tlearn: 5.6959574\ttotal: 1m 28s\tremaining: 6m 49s\n",
      "4075:\tlearn: 5.6950697\ttotal: 1m 28s\tremaining: 6m 49s\n",
      "4076:\tlearn: 5.6942586\ttotal: 1m 28s\tremaining: 6m 49s\n",
      "4077:\tlearn: 5.6935512\ttotal: 1m 28s\tremaining: 6m 49s\n",
      "4078:\tlearn: 5.6932144\ttotal: 1m 28s\tremaining: 6m 49s\n",
      "4079:\tlearn: 5.6927478\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4080:\tlearn: 5.6924871\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4081:\tlearn: 5.6917086\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4082:\tlearn: 5.6911509\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4083:\tlearn: 5.6907500\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4084:\tlearn: 5.6903227\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4085:\tlearn: 5.6898891\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4086:\tlearn: 5.6889901\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4087:\tlearn: 5.6886014\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4088:\tlearn: 5.6881035\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4089:\tlearn: 5.6877650\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4090:\tlearn: 5.6874831\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4091:\tlearn: 5.6870405\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4092:\tlearn: 5.6865214\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4093:\tlearn: 5.6862852\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4094:\tlearn: 5.6856518\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4095:\tlearn: 5.6851139\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4096:\tlearn: 5.6847130\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4097:\tlearn: 5.6842548\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4098:\tlearn: 5.6835993\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4099:\tlearn: 5.6829801\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4100:\tlearn: 5.6827137\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4101:\tlearn: 5.6819313\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4102:\tlearn: 5.6807163\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4103:\tlearn: 5.6800265\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4104:\tlearn: 5.6795355\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4105:\tlearn: 5.6787852\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4106:\tlearn: 5.6783497\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4107:\tlearn: 5.6777127\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4108:\tlearn: 5.6774518\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4109:\tlearn: 5.6769231\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4110:\tlearn: 5.6761780\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4111:\tlearn: 5.6754695\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4112:\tlearn: 5.6749831\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4113:\tlearn: 5.6746409\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4114:\tlearn: 5.6740516\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4115:\tlearn: 5.6733566\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4116:\tlearn: 5.6728325\ttotal: 1m 28s\tremaining: 6m 48s\n",
      "4117:\tlearn: 5.6722646\ttotal: 1m 29s\tremaining: 6m 48s\n",
      "4118:\tlearn: 5.6714180\ttotal: 1m 29s\tremaining: 6m 48s\n",
      "4119:\tlearn: 5.6705377\ttotal: 1m 29s\tremaining: 6m 48s\n",
      "4120:\tlearn: 5.6701931\ttotal: 1m 29s\tremaining: 6m 48s\n",
      "4121:\tlearn: 5.6698114\ttotal: 1m 29s\tremaining: 6m 48s\n",
      "4122:\tlearn: 5.6691561\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4123:\tlearn: 5.6687285\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4124:\tlearn: 5.6683064\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4125:\tlearn: 5.6675465\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4126:\tlearn: 5.6673606\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4127:\tlearn: 5.6667090\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4128:\tlearn: 5.6659297\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4129:\tlearn: 5.6656369\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4130:\tlearn: 5.6648971\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4131:\tlearn: 5.6643558\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4132:\tlearn: 5.6638508\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4133:\tlearn: 5.6638301\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4134:\tlearn: 5.6630389\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4135:\tlearn: 5.6625495\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4136:\tlearn: 5.6619293\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4137:\tlearn: 5.6614987\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4138:\tlearn: 5.6609090\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4139:\tlearn: 5.6601953\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4140:\tlearn: 5.6599510\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4141:\tlearn: 5.6596383\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4142:\tlearn: 5.6590323\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4143:\tlearn: 5.6585653\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4144:\tlearn: 5.6578538\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4145:\tlearn: 5.6572479\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4146:\tlearn: 5.6567471\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4147:\tlearn: 5.6565068\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4148:\tlearn: 5.6554581\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4149:\tlearn: 5.6549771\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4150:\tlearn: 5.6544430\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4151:\tlearn: 5.6534176\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4152:\tlearn: 5.6528506\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4153:\tlearn: 5.6523672\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4154:\tlearn: 5.6519392\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4155:\tlearn: 5.6512935\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4156:\tlearn: 5.6508250\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4157:\tlearn: 5.6503387\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4158:\tlearn: 5.6499436\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4159:\tlearn: 5.6493918\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4160:\tlearn: 5.6487614\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4161:\tlearn: 5.6483993\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4162:\tlearn: 5.6479201\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4163:\tlearn: 5.6472423\ttotal: 1m 29s\tremaining: 6m 47s\n",
      "4164:\tlearn: 5.6464502\ttotal: 1m 30s\tremaining: 6m 47s\n",
      "4165:\tlearn: 5.6459964\ttotal: 1m 30s\tremaining: 6m 47s\n",
      "4166:\tlearn: 5.6456344\ttotal: 1m 30s\tremaining: 6m 47s\n",
      "4167:\tlearn: 5.6450066\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4168:\tlearn: 5.6442939\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4169:\tlearn: 5.6437216\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4170:\tlearn: 5.6429228\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4171:\tlearn: 5.6422405\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4172:\tlearn: 5.6416948\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4173:\tlearn: 5.6412080\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4174:\tlearn: 5.6406036\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4175:\tlearn: 5.6398920\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4176:\tlearn: 5.6391138\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4177:\tlearn: 5.6381276\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4178:\tlearn: 5.6377885\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4179:\tlearn: 5.6371810\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4180:\tlearn: 5.6364939\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4181:\tlearn: 5.6362366\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4182:\tlearn: 5.6356183\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4183:\tlearn: 5.6352430\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4184:\tlearn: 5.6345070\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4185:\tlearn: 5.6336645\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4186:\tlearn: 5.6330361\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4187:\tlearn: 5.6325094\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4188:\tlearn: 5.6321143\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4189:\tlearn: 5.6318492\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4190:\tlearn: 5.6311996\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4191:\tlearn: 5.6307565\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4192:\tlearn: 5.6303329\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4193:\tlearn: 5.6298207\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4194:\tlearn: 5.6292246\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4195:\tlearn: 5.6289076\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4196:\tlearn: 5.6281450\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4197:\tlearn: 5.6273172\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4198:\tlearn: 5.6264644\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4199:\tlearn: 5.6257811\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4200:\tlearn: 5.6251431\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4201:\tlearn: 5.6246821\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4202:\tlearn: 5.6242071\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4203:\tlearn: 5.6234456\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4204:\tlearn: 5.6229567\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4205:\tlearn: 5.6223527\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4206:\tlearn: 5.6217904\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4207:\tlearn: 5.6213029\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4208:\tlearn: 5.6209739\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4209:\tlearn: 5.6204916\ttotal: 1m 30s\tremaining: 6m 46s\n",
      "4210:\tlearn: 5.6200089\ttotal: 1m 31s\tremaining: 6m 46s\n",
      "4211:\tlearn: 5.6192579\ttotal: 1m 31s\tremaining: 6m 46s\n",
      "4212:\tlearn: 5.6189023\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4213:\tlearn: 5.6181095\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4214:\tlearn: 5.6175176\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4215:\tlearn: 5.6170952\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4216:\tlearn: 5.6163412\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4217:\tlearn: 5.6155874\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4218:\tlearn: 5.6149897\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4219:\tlearn: 5.6146488\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4220:\tlearn: 5.6142925\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4221:\tlearn: 5.6139708\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4222:\tlearn: 5.6131791\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4223:\tlearn: 5.6122372\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4224:\tlearn: 5.6118927\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4225:\tlearn: 5.6113870\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4226:\tlearn: 5.6107976\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4227:\tlearn: 5.6100698\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4228:\tlearn: 5.6095395\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4229:\tlearn: 5.6088935\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4230:\tlearn: 5.6082416\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4231:\tlearn: 5.6078242\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4232:\tlearn: 5.6073584\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4233:\tlearn: 5.6071241\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4234:\tlearn: 5.6063906\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4235:\tlearn: 5.6059499\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4236:\tlearn: 5.6056105\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4237:\tlearn: 5.6051898\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4238:\tlearn: 5.6045905\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4239:\tlearn: 5.6038618\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4240:\tlearn: 5.6036186\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4241:\tlearn: 5.6031545\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4242:\tlearn: 5.6027199\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4243:\tlearn: 5.6023758\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4244:\tlearn: 5.6016937\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4245:\tlearn: 5.6010244\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4246:\tlearn: 5.6002587\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4247:\tlearn: 5.5999810\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4248:\tlearn: 5.5990066\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4249:\tlearn: 5.5986484\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4250:\tlearn: 5.5981030\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4251:\tlearn: 5.5976445\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4252:\tlearn: 5.5974859\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4253:\tlearn: 5.5969722\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "4254:\tlearn: 5.5966414\ttotal: 1m 31s\tremaining: 6m 44s\n",
      "4255:\tlearn: 5.5959519\ttotal: 1m 31s\tremaining: 6m 44s\n",
      "4256:\tlearn: 5.5952861\ttotal: 1m 31s\tremaining: 6m 44s\n",
      "4257:\tlearn: 5.5947480\ttotal: 1m 31s\tremaining: 6m 44s\n",
      "4258:\tlearn: 5.5940933\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4259:\tlearn: 5.5937458\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4260:\tlearn: 5.5934805\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4261:\tlearn: 5.5928882\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4262:\tlearn: 5.5924334\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4263:\tlearn: 5.5920484\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4264:\tlearn: 5.5910815\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4265:\tlearn: 5.5907917\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4266:\tlearn: 5.5904155\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4267:\tlearn: 5.5899624\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4268:\tlearn: 5.5896711\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4269:\tlearn: 5.5891727\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4270:\tlearn: 5.5887493\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4271:\tlearn: 5.5881376\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4272:\tlearn: 5.5877842\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4273:\tlearn: 5.5871226\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4274:\tlearn: 5.5863877\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4275:\tlearn: 5.5860227\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4276:\tlearn: 5.5856075\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4277:\tlearn: 5.5850274\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4278:\tlearn: 5.5843682\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4279:\tlearn: 5.5836261\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4280:\tlearn: 5.5832526\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4281:\tlearn: 5.5825865\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4282:\tlearn: 5.5822745\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4283:\tlearn: 5.5818173\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4284:\tlearn: 5.5812714\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4285:\tlearn: 5.5801380\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4286:\tlearn: 5.5796084\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4287:\tlearn: 5.5791331\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4288:\tlearn: 5.5785322\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4289:\tlearn: 5.5779875\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4290:\tlearn: 5.5776392\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4291:\tlearn: 5.5771412\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4292:\tlearn: 5.5767293\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4293:\tlearn: 5.5762477\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4294:\tlearn: 5.5756392\ttotal: 1m 32s\tremaining: 6m 44s\n",
      "4295:\tlearn: 5.5752050\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4296:\tlearn: 5.5747584\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4297:\tlearn: 5.5742507\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4298:\tlearn: 5.5740595\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4299:\tlearn: 5.5736265\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4300:\tlearn: 5.5726141\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4301:\tlearn: 5.5725338\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4302:\tlearn: 5.5718532\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4303:\tlearn: 5.5715233\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4304:\tlearn: 5.5711846\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "4305:\tlearn: 5.5703918\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4306:\tlearn: 5.5695186\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4307:\tlearn: 5.5688265\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4308:\tlearn: 5.5682382\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4309:\tlearn: 5.5675273\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4310:\tlearn: 5.5672839\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4311:\tlearn: 5.5668284\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4312:\tlearn: 5.5663477\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4313:\tlearn: 5.5657274\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4314:\tlearn: 5.5651496\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4315:\tlearn: 5.5647486\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4316:\tlearn: 5.5638650\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4317:\tlearn: 5.5632259\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4318:\tlearn: 5.5628819\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4319:\tlearn: 5.5624414\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4320:\tlearn: 5.5620314\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4321:\tlearn: 5.5616630\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4322:\tlearn: 5.5608523\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4323:\tlearn: 5.5602003\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4324:\tlearn: 5.5596644\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4325:\tlearn: 5.5593121\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4326:\tlearn: 5.5584584\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4327:\tlearn: 5.5579573\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4328:\tlearn: 5.5571781\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4329:\tlearn: 5.5563488\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4330:\tlearn: 5.5559256\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4331:\tlearn: 5.5554499\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4332:\tlearn: 5.5548768\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4333:\tlearn: 5.5544629\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4334:\tlearn: 5.5539222\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4335:\tlearn: 5.5535254\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4336:\tlearn: 5.5529906\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4337:\tlearn: 5.5524992\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4338:\tlearn: 5.5519067\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4339:\tlearn: 5.5513085\ttotal: 1m 33s\tremaining: 6m 43s\n",
      "4340:\tlearn: 5.5506975\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4341:\tlearn: 5.5501427\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4342:\tlearn: 5.5496410\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4343:\tlearn: 5.5491311\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4344:\tlearn: 5.5484211\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4345:\tlearn: 5.5478225\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4346:\tlearn: 5.5471428\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4347:\tlearn: 5.5466060\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4348:\tlearn: 5.5462822\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4349:\tlearn: 5.5458112\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4350:\tlearn: 5.5454698\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4351:\tlearn: 5.5453703\ttotal: 1m 33s\tremaining: 6m 42s\n",
      "4352:\tlearn: 5.5448288\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4353:\tlearn: 5.5444714\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4354:\tlearn: 5.5437901\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4355:\tlearn: 5.5431288\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4356:\tlearn: 5.5424508\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4357:\tlearn: 5.5417462\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4358:\tlearn: 5.5411258\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4359:\tlearn: 5.5402365\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4360:\tlearn: 5.5395961\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4361:\tlearn: 5.5389979\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4362:\tlearn: 5.5385144\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4363:\tlearn: 5.5381705\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4364:\tlearn: 5.5373158\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4365:\tlearn: 5.5366444\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4366:\tlearn: 5.5362060\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4367:\tlearn: 5.5354882\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4368:\tlearn: 5.5352550\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4369:\tlearn: 5.5348152\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4370:\tlearn: 5.5343147\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4371:\tlearn: 5.5336960\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4372:\tlearn: 5.5332880\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4373:\tlearn: 5.5327737\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4374:\tlearn: 5.5323394\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4375:\tlearn: 5.5316437\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4376:\tlearn: 5.5311454\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4377:\tlearn: 5.5303047\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4378:\tlearn: 5.5298351\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4379:\tlearn: 5.5290407\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4380:\tlearn: 5.5284050\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4381:\tlearn: 5.5278641\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4382:\tlearn: 5.5275974\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4383:\tlearn: 5.5272906\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4384:\tlearn: 5.5267518\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4385:\tlearn: 5.5261882\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4386:\tlearn: 5.5255706\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4387:\tlearn: 5.5248780\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4388:\tlearn: 5.5244481\ttotal: 1m 34s\tremaining: 6m 42s\n",
      "4389:\tlearn: 5.5240842\ttotal: 1m 34s\tremaining: 6m 41s\n",
      "4390:\tlearn: 5.5232305\ttotal: 1m 34s\tremaining: 6m 41s\n",
      "4391:\tlearn: 5.5227645\ttotal: 1m 34s\tremaining: 6m 41s\n",
      "4392:\tlearn: 5.5224940\ttotal: 1m 34s\tremaining: 6m 41s\n",
      "4393:\tlearn: 5.5217245\ttotal: 1m 34s\tremaining: 6m 41s\n",
      "4394:\tlearn: 5.5211144\ttotal: 1m 34s\tremaining: 6m 41s\n",
      "4395:\tlearn: 5.5206535\ttotal: 1m 34s\tremaining: 6m 41s\n",
      "4396:\tlearn: 5.5199794\ttotal: 1m 34s\tremaining: 6m 41s\n",
      "4397:\tlearn: 5.5192199\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4398:\tlearn: 5.5186532\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4399:\tlearn: 5.5181923\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4400:\tlearn: 5.5172214\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4401:\tlearn: 5.5167410\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4402:\tlearn: 5.5160427\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4403:\tlearn: 5.5151342\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4404:\tlearn: 5.5145391\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4405:\tlearn: 5.5137648\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4406:\tlearn: 5.5132021\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4407:\tlearn: 5.5127775\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4408:\tlearn: 5.5122889\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4409:\tlearn: 5.5118909\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4410:\tlearn: 5.5113987\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4411:\tlearn: 5.5108033\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4412:\tlearn: 5.5100422\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4413:\tlearn: 5.5097856\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4414:\tlearn: 5.5090401\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4415:\tlearn: 5.5088373\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4416:\tlearn: 5.5081719\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4417:\tlearn: 5.5074007\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4418:\tlearn: 5.5067684\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4419:\tlearn: 5.5061059\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4420:\tlearn: 5.5054426\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4421:\tlearn: 5.5048771\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4422:\tlearn: 5.5041546\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4423:\tlearn: 5.5039068\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4424:\tlearn: 5.5034557\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4425:\tlearn: 5.5027853\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4426:\tlearn: 5.5023948\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4427:\tlearn: 5.5018310\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4428:\tlearn: 5.5012027\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4429:\tlearn: 5.5004114\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4430:\tlearn: 5.5000825\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4431:\tlearn: 5.4995275\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4432:\tlearn: 5.4990995\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4433:\tlearn: 5.4985939\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4434:\tlearn: 5.4981118\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4435:\tlearn: 5.4975611\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4436:\tlearn: 5.4971432\ttotal: 1m 35s\tremaining: 6m 41s\n",
      "4437:\tlearn: 5.4966325\ttotal: 1m 35s\tremaining: 6m 40s\n",
      "4438:\tlearn: 5.4957677\ttotal: 1m 35s\tremaining: 6m 40s\n",
      "4439:\tlearn: 5.4950419\ttotal: 1m 35s\tremaining: 6m 40s\n",
      "4440:\tlearn: 5.4943683\ttotal: 1m 35s\tremaining: 6m 40s\n",
      "4441:\tlearn: 5.4940174\ttotal: 1m 35s\tremaining: 6m 40s\n",
      "4442:\tlearn: 5.4936599\ttotal: 1m 35s\tremaining: 6m 40s\n",
      "4443:\tlearn: 5.4929812\ttotal: 1m 35s\tremaining: 6m 40s\n",
      "4444:\tlearn: 5.4921813\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4445:\tlearn: 5.4916703\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4446:\tlearn: 5.4912899\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4447:\tlearn: 5.4906328\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4448:\tlearn: 5.4903351\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4449:\tlearn: 5.4897676\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4450:\tlearn: 5.4890481\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4451:\tlearn: 5.4883789\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4452:\tlearn: 5.4876096\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4453:\tlearn: 5.4866963\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4454:\tlearn: 5.4862423\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4455:\tlearn: 5.4854918\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4456:\tlearn: 5.4846598\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4457:\tlearn: 5.4841707\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4458:\tlearn: 5.4835746\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4459:\tlearn: 5.4832746\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4460:\tlearn: 5.4831831\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4461:\tlearn: 5.4828018\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4462:\tlearn: 5.4823310\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4463:\tlearn: 5.4817447\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4464:\tlearn: 5.4809666\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4465:\tlearn: 5.4804098\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4466:\tlearn: 5.4798995\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4467:\tlearn: 5.4792845\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4468:\tlearn: 5.4784034\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4469:\tlearn: 5.4775529\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4470:\tlearn: 5.4769634\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4471:\tlearn: 5.4765409\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4472:\tlearn: 5.4760081\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4473:\tlearn: 5.4752595\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4474:\tlearn: 5.4748955\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4475:\tlearn: 5.4742977\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4476:\tlearn: 5.4738678\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4477:\tlearn: 5.4730768\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4478:\tlearn: 5.4724389\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4479:\tlearn: 5.4718042\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4480:\tlearn: 5.4712730\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4481:\tlearn: 5.4712531\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4482:\tlearn: 5.4707888\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4483:\tlearn: 5.4699566\ttotal: 1m 36s\tremaining: 6m 40s\n",
      "4484:\tlearn: 5.4694607\ttotal: 1m 36s\tremaining: 6m 39s\n",
      "4485:\tlearn: 5.4690018\ttotal: 1m 36s\tremaining: 6m 39s\n",
      "4486:\tlearn: 5.4684828\ttotal: 1m 36s\tremaining: 6m 39s\n",
      "4487:\tlearn: 5.4678861\ttotal: 1m 36s\tremaining: 6m 39s\n",
      "4488:\tlearn: 5.4670618\ttotal: 1m 36s\tremaining: 6m 39s\n",
      "4489:\tlearn: 5.4665216\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4490:\tlearn: 5.4657516\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4491:\tlearn: 5.4654501\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4492:\tlearn: 5.4648282\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4493:\tlearn: 5.4643282\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4494:\tlearn: 5.4632969\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4495:\tlearn: 5.4629280\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4496:\tlearn: 5.4622946\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4497:\tlearn: 5.4618315\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4498:\tlearn: 5.4611864\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4499:\tlearn: 5.4607289\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4500:\tlearn: 5.4604259\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4501:\tlearn: 5.4604061\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4502:\tlearn: 5.4597162\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4503:\tlearn: 5.4592584\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4504:\tlearn: 5.4590043\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4505:\tlearn: 5.4586851\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4506:\tlearn: 5.4584473\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4507:\tlearn: 5.4579062\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4508:\tlearn: 5.4574193\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4509:\tlearn: 5.4568329\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4510:\tlearn: 5.4563947\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4511:\tlearn: 5.4560000\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4512:\tlearn: 5.4556488\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4513:\tlearn: 5.4551463\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4514:\tlearn: 5.4545974\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4515:\tlearn: 5.4542302\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4516:\tlearn: 5.4536644\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4517:\tlearn: 5.4530195\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4518:\tlearn: 5.4524073\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4519:\tlearn: 5.4519718\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4520:\tlearn: 5.4515222\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4521:\tlearn: 5.4510044\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4522:\tlearn: 5.4506021\ttotal: 1m 37s\tremaining: 6m 39s\n",
      "4523:\tlearn: 5.4502957\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4524:\tlearn: 5.4498651\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4525:\tlearn: 5.4492801\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4526:\tlearn: 5.4487922\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4527:\tlearn: 5.4479113\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4528:\tlearn: 5.4472005\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4529:\tlearn: 5.4466899\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4530:\tlearn: 5.4462625\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4531:\tlearn: 5.4456422\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4532:\tlearn: 5.4450972\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4533:\tlearn: 5.4447639\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4534:\tlearn: 5.4441827\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4535:\tlearn: 5.4436255\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4536:\tlearn: 5.4432375\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4537:\tlearn: 5.4427753\ttotal: 1m 37s\tremaining: 6m 38s\n",
      "4538:\tlearn: 5.4422690\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4539:\tlearn: 5.4415510\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4540:\tlearn: 5.4410080\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4541:\tlearn: 5.4402496\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4542:\tlearn: 5.4398617\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4543:\tlearn: 5.4394607\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4544:\tlearn: 5.4389352\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4545:\tlearn: 5.4384703\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4546:\tlearn: 5.4380121\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4547:\tlearn: 5.4376754\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4548:\tlearn: 5.4373470\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4549:\tlearn: 5.4369384\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4550:\tlearn: 5.4362124\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4551:\tlearn: 5.4355199\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4552:\tlearn: 5.4352268\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4553:\tlearn: 5.4346958\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4554:\tlearn: 5.4339188\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4555:\tlearn: 5.4338972\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4556:\tlearn: 5.4335513\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4557:\tlearn: 5.4330403\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4558:\tlearn: 5.4329546\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4559:\tlearn: 5.4322899\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4560:\tlearn: 5.4316799\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4561:\tlearn: 5.4310376\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4562:\tlearn: 5.4304393\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4563:\tlearn: 5.4300338\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4564:\tlearn: 5.4295588\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4565:\tlearn: 5.4291767\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4566:\tlearn: 5.4287241\ttotal: 1m 38s\tremaining: 6m 38s\n",
      "4567:\tlearn: 5.4283750\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4568:\tlearn: 5.4277510\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4569:\tlearn: 5.4270044\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4570:\tlearn: 5.4261930\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4571:\tlearn: 5.4256714\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4572:\tlearn: 5.4252772\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4573:\tlearn: 5.4245688\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4574:\tlearn: 5.4238499\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4575:\tlearn: 5.4232536\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4576:\tlearn: 5.4228080\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4577:\tlearn: 5.4224232\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4578:\tlearn: 5.4220997\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4579:\tlearn: 5.4218748\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4580:\tlearn: 5.4215913\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4581:\tlearn: 5.4212784\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4582:\tlearn: 5.4206845\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4583:\tlearn: 5.4202148\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4584:\tlearn: 5.4199111\ttotal: 1m 38s\tremaining: 6m 37s\n",
      "4585:\tlearn: 5.4196007\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4586:\tlearn: 5.4190270\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4587:\tlearn: 5.4185742\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4588:\tlearn: 5.4179194\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4589:\tlearn: 5.4173557\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4590:\tlearn: 5.4170775\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4591:\tlearn: 5.4162764\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4592:\tlearn: 5.4159043\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4593:\tlearn: 5.4154929\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4594:\tlearn: 5.4150927\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4595:\tlearn: 5.4147165\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4596:\tlearn: 5.4138240\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4597:\tlearn: 5.4132338\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4598:\tlearn: 5.4128339\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4599:\tlearn: 5.4123111\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4600:\tlearn: 5.4114822\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4601:\tlearn: 5.4109289\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4602:\tlearn: 5.4103184\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4603:\tlearn: 5.4097135\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4604:\tlearn: 5.4094094\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4605:\tlearn: 5.4092561\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4606:\tlearn: 5.4087017\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4607:\tlearn: 5.4083771\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4608:\tlearn: 5.4077611\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4609:\tlearn: 5.4074404\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4610:\tlearn: 5.4068557\ttotal: 1m 39s\tremaining: 6m 37s\n",
      "4611:\tlearn: 5.4061564\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4612:\tlearn: 5.4058349\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4613:\tlearn: 5.4051370\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4614:\tlearn: 5.4049224\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4615:\tlearn: 5.4041709\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4616:\tlearn: 5.4038983\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4617:\tlearn: 5.4033638\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4618:\tlearn: 5.4032683\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4619:\tlearn: 5.4027294\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4620:\tlearn: 5.4023585\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4621:\tlearn: 5.4018910\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4622:\tlearn: 5.4015421\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4623:\tlearn: 5.4012983\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4624:\tlearn: 5.4006796\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4625:\tlearn: 5.4001809\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4626:\tlearn: 5.3999515\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4627:\tlearn: 5.3995397\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4628:\tlearn: 5.3990735\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4629:\tlearn: 5.3985146\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4630:\tlearn: 5.3980885\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4631:\tlearn: 5.3975652\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4632:\tlearn: 5.3971903\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4633:\tlearn: 5.3966830\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4634:\tlearn: 5.3958945\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4635:\tlearn: 5.3954570\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4636:\tlearn: 5.3949215\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4637:\tlearn: 5.3940531\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4638:\tlearn: 5.3935793\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4639:\tlearn: 5.3931052\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4640:\tlearn: 5.3922600\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4641:\tlearn: 5.3913470\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4642:\tlearn: 5.3905983\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4643:\tlearn: 5.3899513\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4644:\tlearn: 5.3892206\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4645:\tlearn: 5.3885109\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4646:\tlearn: 5.3878226\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4647:\tlearn: 5.3872237\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4648:\tlearn: 5.3864362\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4649:\tlearn: 5.3859717\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4650:\tlearn: 5.3852950\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4651:\tlearn: 5.3846613\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4652:\tlearn: 5.3840570\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4653:\tlearn: 5.3836699\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4654:\tlearn: 5.3831683\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4655:\tlearn: 5.3828838\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4656:\tlearn: 5.3821117\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4657:\tlearn: 5.3818877\ttotal: 1m 40s\tremaining: 6m 36s\n",
      "4658:\tlearn: 5.3815023\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4659:\tlearn: 5.3807225\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4660:\tlearn: 5.3802451\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4661:\tlearn: 5.3797608\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4662:\tlearn: 5.3791633\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4663:\tlearn: 5.3788101\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4664:\tlearn: 5.3778933\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4665:\tlearn: 5.3773683\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4666:\tlearn: 5.3768007\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4667:\tlearn: 5.3763439\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4668:\tlearn: 5.3759527\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4669:\tlearn: 5.3753751\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4670:\tlearn: 5.3747858\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4671:\tlearn: 5.3744675\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4672:\tlearn: 5.3741203\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4673:\tlearn: 5.3735031\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4674:\tlearn: 5.3727152\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4675:\tlearn: 5.3722874\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4676:\tlearn: 5.3714900\ttotal: 1m 40s\tremaining: 6m 35s\n",
      "4677:\tlearn: 5.3711501\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4678:\tlearn: 5.3706802\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4679:\tlearn: 5.3702974\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4680:\tlearn: 5.3699124\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4681:\tlearn: 5.3693358\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4682:\tlearn: 5.3689850\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4683:\tlearn: 5.3685582\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4684:\tlearn: 5.3683235\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4685:\tlearn: 5.3676638\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4686:\tlearn: 5.3673348\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4687:\tlearn: 5.3670763\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4688:\tlearn: 5.3663874\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4689:\tlearn: 5.3659085\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4690:\tlearn: 5.3654718\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4691:\tlearn: 5.3649697\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4692:\tlearn: 5.3643503\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4693:\tlearn: 5.3639539\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4694:\tlearn: 5.3632513\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4695:\tlearn: 5.3625632\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4696:\tlearn: 5.3619771\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4697:\tlearn: 5.3615363\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4698:\tlearn: 5.3610636\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4699:\tlearn: 5.3602705\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4700:\tlearn: 5.3598387\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4701:\tlearn: 5.3595940\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4702:\tlearn: 5.3589682\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4703:\tlearn: 5.3581551\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4704:\tlearn: 5.3577915\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4705:\tlearn: 5.3572554\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4706:\tlearn: 5.3564171\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4707:\tlearn: 5.3559151\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4708:\tlearn: 5.3554706\ttotal: 1m 41s\tremaining: 6m 35s\n",
      "4709:\tlearn: 5.3549843\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4710:\tlearn: 5.3546475\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4711:\tlearn: 5.3544001\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4712:\tlearn: 5.3540305\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4713:\tlearn: 5.3536917\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4714:\tlearn: 5.3531170\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4715:\tlearn: 5.3526106\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4716:\tlearn: 5.3522686\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4717:\tlearn: 5.3518707\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4718:\tlearn: 5.3514621\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4719:\tlearn: 5.3508697\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4720:\tlearn: 5.3504988\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4721:\tlearn: 5.3501677\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4722:\tlearn: 5.3494406\ttotal: 1m 41s\tremaining: 6m 34s\n",
      "4723:\tlearn: 5.3489343\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4724:\tlearn: 5.3479328\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4725:\tlearn: 5.3475632\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4726:\tlearn: 5.3467473\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4727:\tlearn: 5.3461876\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4728:\tlearn: 5.3457736\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4729:\tlearn: 5.3453320\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4730:\tlearn: 5.3446675\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4731:\tlearn: 5.3443743\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4732:\tlearn: 5.3434944\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4733:\tlearn: 5.3430291\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4734:\tlearn: 5.3425715\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4735:\tlearn: 5.3422399\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4736:\tlearn: 5.3414103\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4737:\tlearn: 5.3406930\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4738:\tlearn: 5.3401118\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4739:\tlearn: 5.3396941\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4740:\tlearn: 5.3391392\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4741:\tlearn: 5.3385919\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4742:\tlearn: 5.3376784\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4743:\tlearn: 5.3372698\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4744:\tlearn: 5.3370434\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4745:\tlearn: 5.3363572\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4746:\tlearn: 5.3360307\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4747:\tlearn: 5.3356775\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4748:\tlearn: 5.3351850\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4749:\tlearn: 5.3346821\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4750:\tlearn: 5.3343879\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4751:\tlearn: 5.3338343\ttotal: 1m 42s\tremaining: 6m 34s\n",
      "4752:\tlearn: 5.3336061\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4753:\tlearn: 5.3335878\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4754:\tlearn: 5.3334246\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4755:\tlearn: 5.3326307\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4756:\tlearn: 5.3322705\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4757:\tlearn: 5.3317095\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4758:\tlearn: 5.3314245\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4759:\tlearn: 5.3308906\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4760:\tlearn: 5.3306639\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4761:\tlearn: 5.3304179\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4762:\tlearn: 5.3299341\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4763:\tlearn: 5.3291956\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4764:\tlearn: 5.3287084\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4765:\tlearn: 5.3281190\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4766:\tlearn: 5.3274180\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4767:\tlearn: 5.3267066\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4768:\tlearn: 5.3262040\ttotal: 1m 42s\tremaining: 6m 33s\n",
      "4769:\tlearn: 5.3254523\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4770:\tlearn: 5.3251214\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4771:\tlearn: 5.3246950\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4772:\tlearn: 5.3239491\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4773:\tlearn: 5.3234108\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4774:\tlearn: 5.3229955\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4775:\tlearn: 5.3223058\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4776:\tlearn: 5.3219184\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4777:\tlearn: 5.3218567\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4778:\tlearn: 5.3214906\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4779:\tlearn: 5.3209432\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4780:\tlearn: 5.3205175\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4781:\tlearn: 5.3200253\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4782:\tlearn: 5.3190027\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4783:\tlearn: 5.3184219\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4784:\tlearn: 5.3179443\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4785:\tlearn: 5.3173627\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4786:\tlearn: 5.3165274\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4787:\tlearn: 5.3158902\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4788:\tlearn: 5.3153626\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4789:\tlearn: 5.3150879\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4790:\tlearn: 5.3147547\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4791:\tlearn: 5.3143021\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4792:\tlearn: 5.3138817\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4793:\tlearn: 5.3133446\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4794:\tlearn: 5.3130163\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4795:\tlearn: 5.3126726\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4796:\tlearn: 5.3124692\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4797:\tlearn: 5.3122443\ttotal: 1m 43s\tremaining: 6m 33s\n",
      "4798:\tlearn: 5.3116907\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4799:\tlearn: 5.3110768\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4800:\tlearn: 5.3106568\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4801:\tlearn: 5.3103788\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4802:\tlearn: 5.3098172\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4803:\tlearn: 5.3093164\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4804:\tlearn: 5.3086719\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4805:\tlearn: 5.3082550\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4806:\tlearn: 5.3077701\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4807:\tlearn: 5.3070454\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4808:\tlearn: 5.3065724\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4809:\tlearn: 5.3060630\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4810:\tlearn: 5.3056432\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4811:\tlearn: 5.3048773\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4812:\tlearn: 5.3045044\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4813:\tlearn: 5.3041601\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4814:\tlearn: 5.3036739\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4815:\tlearn: 5.3032774\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "4816:\tlearn: 5.3027448\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4817:\tlearn: 5.3022068\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4818:\tlearn: 5.3018698\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4819:\tlearn: 5.3016575\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4820:\tlearn: 5.3012041\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4821:\tlearn: 5.3006280\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4822:\tlearn: 5.3003184\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4823:\tlearn: 5.2996788\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4824:\tlearn: 5.2991645\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4825:\tlearn: 5.2988320\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4826:\tlearn: 5.2988138\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4827:\tlearn: 5.2984849\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4828:\tlearn: 5.2979669\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4829:\tlearn: 5.2975954\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4830:\tlearn: 5.2968046\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4831:\tlearn: 5.2963590\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4832:\tlearn: 5.2958475\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4833:\tlearn: 5.2957044\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4834:\tlearn: 5.2950150\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4835:\tlearn: 5.2945298\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4836:\tlearn: 5.2939975\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4837:\tlearn: 5.2934048\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4838:\tlearn: 5.2929229\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4839:\tlearn: 5.2922356\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4840:\tlearn: 5.2917746\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4841:\tlearn: 5.2909141\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4842:\tlearn: 5.2903756\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4843:\tlearn: 5.2900990\ttotal: 1m 44s\tremaining: 6m 32s\n",
      "4844:\tlearn: 5.2898236\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4845:\tlearn: 5.2888774\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4846:\tlearn: 5.2881802\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4847:\tlearn: 5.2876475\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4848:\tlearn: 5.2870862\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4849:\tlearn: 5.2865980\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4850:\tlearn: 5.2858814\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4851:\tlearn: 5.2852555\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4852:\tlearn: 5.2846246\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4853:\tlearn: 5.2841753\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4854:\tlearn: 5.2838057\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4855:\tlearn: 5.2833724\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4856:\tlearn: 5.2830398\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4857:\tlearn: 5.2827379\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4858:\tlearn: 5.2825137\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4859:\tlearn: 5.2821134\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4860:\tlearn: 5.2817164\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4861:\tlearn: 5.2812371\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "4862:\tlearn: 5.2806804\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4863:\tlearn: 5.2803156\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4864:\tlearn: 5.2797680\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4865:\tlearn: 5.2793497\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4866:\tlearn: 5.2790390\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4867:\tlearn: 5.2787829\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4868:\tlearn: 5.2776817\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4869:\tlearn: 5.2769313\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4870:\tlearn: 5.2760918\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4871:\tlearn: 5.2759194\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4872:\tlearn: 5.2755329\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4873:\tlearn: 5.2752846\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4874:\tlearn: 5.2747449\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4875:\tlearn: 5.2743627\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4876:\tlearn: 5.2735702\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4877:\tlearn: 5.2733397\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4878:\tlearn: 5.2727735\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4879:\tlearn: 5.2723383\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4880:\tlearn: 5.2718875\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4881:\tlearn: 5.2712195\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4882:\tlearn: 5.2709674\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4883:\tlearn: 5.2707121\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4884:\tlearn: 5.2706782\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4885:\tlearn: 5.2701351\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4886:\tlearn: 5.2697482\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4887:\tlearn: 5.2690324\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4888:\tlearn: 5.2683463\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4889:\tlearn: 5.2677917\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4890:\tlearn: 5.2673367\ttotal: 1m 45s\tremaining: 6m 31s\n",
      "4891:\tlearn: 5.2671563\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4892:\tlearn: 5.2667289\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4893:\tlearn: 5.2657989\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4894:\tlearn: 5.2654058\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4895:\tlearn: 5.2649996\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4896:\tlearn: 5.2646271\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4897:\tlearn: 5.2643311\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4898:\tlearn: 5.2635701\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4899:\tlearn: 5.2630996\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4900:\tlearn: 5.2625816\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4901:\tlearn: 5.2621250\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4902:\tlearn: 5.2618032\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4903:\tlearn: 5.2613721\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4904:\tlearn: 5.2607604\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4905:\tlearn: 5.2605228\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4906:\tlearn: 5.2598597\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4907:\tlearn: 5.2591558\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4908:\tlearn: 5.2584656\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "4909:\tlearn: 5.2577879\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4910:\tlearn: 5.2573828\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4911:\tlearn: 5.2568192\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4912:\tlearn: 5.2563287\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4913:\tlearn: 5.2556919\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4914:\tlearn: 5.2551077\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4915:\tlearn: 5.2544416\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4916:\tlearn: 5.2536341\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4917:\tlearn: 5.2530689\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4918:\tlearn: 5.2526490\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4919:\tlearn: 5.2524912\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4920:\tlearn: 5.2520211\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4921:\tlearn: 5.2514289\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4922:\tlearn: 5.2510481\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4923:\tlearn: 5.2503216\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4924:\tlearn: 5.2498460\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4925:\tlearn: 5.2494707\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4926:\tlearn: 5.2487311\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4927:\tlearn: 5.2484336\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4928:\tlearn: 5.2476532\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4929:\tlearn: 5.2473941\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4930:\tlearn: 5.2469108\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4931:\tlearn: 5.2463305\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4932:\tlearn: 5.2458967\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4933:\tlearn: 5.2453566\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4934:\tlearn: 5.2448912\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4935:\tlearn: 5.2443466\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4936:\tlearn: 5.2438537\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4937:\tlearn: 5.2433140\ttotal: 1m 46s\tremaining: 6m 30s\n",
      "4938:\tlearn: 5.2428976\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4939:\tlearn: 5.2421592\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4940:\tlearn: 5.2416859\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4941:\tlearn: 5.2412588\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4942:\tlearn: 5.2406710\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4943:\tlearn: 5.2402095\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4944:\tlearn: 5.2396576\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4945:\tlearn: 5.2394052\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4946:\tlearn: 5.2386644\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4947:\tlearn: 5.2381727\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4948:\tlearn: 5.2376688\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4949:\tlearn: 5.2370843\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4950:\tlearn: 5.2365523\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4951:\tlearn: 5.2359250\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4952:\tlearn: 5.2358577\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4953:\tlearn: 5.2349775\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4954:\tlearn: 5.2346467\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "4955:\tlearn: 5.2343854\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4956:\tlearn: 5.2339370\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4957:\tlearn: 5.2336620\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4958:\tlearn: 5.2330928\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4959:\tlearn: 5.2325995\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4960:\tlearn: 5.2320829\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4961:\tlearn: 5.2316322\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4962:\tlearn: 5.2311268\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4963:\tlearn: 5.2308025\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4964:\tlearn: 5.2302508\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4965:\tlearn: 5.2295377\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4966:\tlearn: 5.2290047\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4967:\tlearn: 5.2287151\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4968:\tlearn: 5.2284365\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4969:\tlearn: 5.2278145\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4970:\tlearn: 5.2272926\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4971:\tlearn: 5.2269825\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4972:\tlearn: 5.2263315\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4973:\tlearn: 5.2259100\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4974:\tlearn: 5.2257487\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4975:\tlearn: 5.2254644\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4976:\tlearn: 5.2251995\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4977:\tlearn: 5.2242259\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4978:\tlearn: 5.2234663\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4979:\tlearn: 5.2231335\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4980:\tlearn: 5.2225501\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4981:\tlearn: 5.2219279\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4982:\tlearn: 5.2213491\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4983:\tlearn: 5.2211018\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4984:\tlearn: 5.2208657\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4985:\tlearn: 5.2205330\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4986:\tlearn: 5.2202257\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4987:\tlearn: 5.2196862\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4988:\tlearn: 5.2189595\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4989:\tlearn: 5.2185923\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "4990:\tlearn: 5.2182900\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "4991:\tlearn: 5.2176562\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "4992:\tlearn: 5.2173118\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "4993:\tlearn: 5.2172936\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "4994:\tlearn: 5.2170248\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "4995:\tlearn: 5.2163149\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "4996:\tlearn: 5.2160084\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "4997:\tlearn: 5.2156236\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "4998:\tlearn: 5.2150852\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "4999:\tlearn: 5.2145342\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "5000:\tlearn: 5.2144967\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5001:\tlearn: 5.2138737\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5002:\tlearn: 5.2136601\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5003:\tlearn: 5.2132195\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5004:\tlearn: 5.2127487\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5005:\tlearn: 5.2123360\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5006:\tlearn: 5.2122122\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5007:\tlearn: 5.2117365\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5008:\tlearn: 5.2110899\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5009:\tlearn: 5.2105264\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5010:\tlearn: 5.2099886\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5011:\tlearn: 5.2094262\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5012:\tlearn: 5.2087365\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5013:\tlearn: 5.2079918\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5014:\tlearn: 5.2075777\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5015:\tlearn: 5.2069243\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5016:\tlearn: 5.2064901\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5017:\tlearn: 5.2061153\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5018:\tlearn: 5.2060949\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5019:\tlearn: 5.2055959\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5020:\tlearn: 5.2049702\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5021:\tlearn: 5.2046046\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5022:\tlearn: 5.2041958\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5023:\tlearn: 5.2038725\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5024:\tlearn: 5.2035628\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5025:\tlearn: 5.2029449\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5026:\tlearn: 5.2024090\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5027:\tlearn: 5.2018105\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5028:\tlearn: 5.2013813\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5029:\tlearn: 5.2009564\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5030:\tlearn: 5.2003107\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5031:\tlearn: 5.1998480\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5032:\tlearn: 5.1994307\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5033:\tlearn: 5.1986214\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5034:\tlearn: 5.1981369\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5035:\tlearn: 5.1975455\ttotal: 1m 48s\tremaining: 6m 28s\n",
      "5036:\tlearn: 5.1971929\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5037:\tlearn: 5.1968015\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5038:\tlearn: 5.1963766\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5039:\tlearn: 5.1957555\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5040:\tlearn: 5.1953702\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5041:\tlearn: 5.1950456\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5042:\tlearn: 5.1946860\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5043:\tlearn: 5.1944288\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5044:\tlearn: 5.1938005\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5045:\tlearn: 5.1933736\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "5046:\tlearn: 5.1927559\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5047:\tlearn: 5.1922073\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5048:\tlearn: 5.1917960\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5049:\tlearn: 5.1913703\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5050:\tlearn: 5.1909726\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5051:\tlearn: 5.1906957\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5052:\tlearn: 5.1900878\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5053:\tlearn: 5.1895057\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5054:\tlearn: 5.1891682\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5055:\tlearn: 5.1884077\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5056:\tlearn: 5.1880036\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5057:\tlearn: 5.1872569\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5058:\tlearn: 5.1865950\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5059:\tlearn: 5.1857932\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5060:\tlearn: 5.1854782\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5061:\tlearn: 5.1851609\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5062:\tlearn: 5.1848568\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5063:\tlearn: 5.1842478\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5064:\tlearn: 5.1835087\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5065:\tlearn: 5.1830749\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5066:\tlearn: 5.1827298\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5067:\tlearn: 5.1820657\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5068:\tlearn: 5.1818186\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5069:\tlearn: 5.1814637\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5070:\tlearn: 5.1807280\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5071:\tlearn: 5.1804092\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5072:\tlearn: 5.1798957\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5073:\tlearn: 5.1797115\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5074:\tlearn: 5.1792318\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5075:\tlearn: 5.1787827\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5076:\tlearn: 5.1784519\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5077:\tlearn: 5.1777342\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5078:\tlearn: 5.1772521\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5079:\tlearn: 5.1768249\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5080:\tlearn: 5.1761849\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "5081:\tlearn: 5.1758393\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5082:\tlearn: 5.1753969\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5083:\tlearn: 5.1747178\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5084:\tlearn: 5.1745311\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5085:\tlearn: 5.1742735\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5086:\tlearn: 5.1736682\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5087:\tlearn: 5.1732575\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5088:\tlearn: 5.1729853\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5089:\tlearn: 5.1726299\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5090:\tlearn: 5.1722281\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5091:\tlearn: 5.1718010\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5092:\tlearn: 5.1715298\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "5093:\tlearn: 5.1711147\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5094:\tlearn: 5.1702547\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5095:\tlearn: 5.1698802\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5096:\tlearn: 5.1692570\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5097:\tlearn: 5.1688480\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5098:\tlearn: 5.1683503\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5099:\tlearn: 5.1679102\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5100:\tlearn: 5.1678618\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5101:\tlearn: 5.1675354\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5102:\tlearn: 5.1670408\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5103:\tlearn: 5.1665067\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5104:\tlearn: 5.1660692\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5105:\tlearn: 5.1655229\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5106:\tlearn: 5.1651973\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5107:\tlearn: 5.1645763\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5108:\tlearn: 5.1638845\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5109:\tlearn: 5.1634669\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5110:\tlearn: 5.1628460\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5111:\tlearn: 5.1626012\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5112:\tlearn: 5.1621594\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5113:\tlearn: 5.1614298\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5114:\tlearn: 5.1609817\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5115:\tlearn: 5.1603622\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5116:\tlearn: 5.1597866\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5117:\tlearn: 5.1592665\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5118:\tlearn: 5.1589240\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5119:\tlearn: 5.1586081\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5120:\tlearn: 5.1581100\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5121:\tlearn: 5.1578588\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5122:\tlearn: 5.1571904\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5123:\tlearn: 5.1570045\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5124:\tlearn: 5.1563632\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5125:\tlearn: 5.1560268\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5126:\tlearn: 5.1554243\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5127:\tlearn: 5.1549259\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5128:\tlearn: 5.1543603\ttotal: 1m 50s\tremaining: 6m 26s\n",
      "5129:\tlearn: 5.1538495\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5130:\tlearn: 5.1533509\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5131:\tlearn: 5.1529984\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5132:\tlearn: 5.1525776\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5133:\tlearn: 5.1524941\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5134:\tlearn: 5.1518909\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5135:\tlearn: 5.1512816\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5136:\tlearn: 5.1505734\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5137:\tlearn: 5.1501354\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5138:\tlearn: 5.1493666\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "5139:\tlearn: 5.1488390\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5140:\tlearn: 5.1482133\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5141:\tlearn: 5.1480242\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5142:\tlearn: 5.1475792\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5143:\tlearn: 5.1469687\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5144:\tlearn: 5.1465935\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5145:\tlearn: 5.1462398\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5146:\tlearn: 5.1458162\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5147:\tlearn: 5.1453103\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5148:\tlearn: 5.1447253\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5149:\tlearn: 5.1439596\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5150:\tlearn: 5.1436372\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5151:\tlearn: 5.1433256\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5152:\tlearn: 5.1429839\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5153:\tlearn: 5.1425071\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5154:\tlearn: 5.1421592\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5155:\tlearn: 5.1415797\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5156:\tlearn: 5.1412597\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5157:\tlearn: 5.1407887\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5158:\tlearn: 5.1402300\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5159:\tlearn: 5.1399155\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5160:\tlearn: 5.1392735\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5161:\tlearn: 5.1389726\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5162:\tlearn: 5.1384660\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5163:\tlearn: 5.1380857\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5164:\tlearn: 5.1374588\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5165:\tlearn: 5.1370547\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5166:\tlearn: 5.1366480\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5167:\tlearn: 5.1361225\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5168:\tlearn: 5.1358070\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5169:\tlearn: 5.1354881\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5170:\tlearn: 5.1349773\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5171:\tlearn: 5.1345654\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5172:\tlearn: 5.1338294\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5173:\tlearn: 5.1332031\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "5174:\tlearn: 5.1327598\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5175:\tlearn: 5.1321376\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5176:\tlearn: 5.1315019\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5177:\tlearn: 5.1309026\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5178:\tlearn: 5.1304383\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5179:\tlearn: 5.1299079\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5180:\tlearn: 5.1293735\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5181:\tlearn: 5.1287619\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5182:\tlearn: 5.1280574\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5183:\tlearn: 5.1277319\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5184:\tlearn: 5.1273505\ttotal: 1m 51s\tremaining: 6m 24s\n",
      "5185:\tlearn: 5.1267430\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5186:\tlearn: 5.1262392\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5187:\tlearn: 5.1256659\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5188:\tlearn: 5.1251890\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5189:\tlearn: 5.1247133\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5190:\tlearn: 5.1244587\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5191:\tlearn: 5.1242562\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5192:\tlearn: 5.1238210\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5193:\tlearn: 5.1236583\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5194:\tlearn: 5.1230199\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5195:\tlearn: 5.1225737\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5196:\tlearn: 5.1221001\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5197:\tlearn: 5.1217871\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5198:\tlearn: 5.1215183\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5199:\tlearn: 5.1210465\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5200:\tlearn: 5.1208273\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5201:\tlearn: 5.1205228\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5202:\tlearn: 5.1200823\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5203:\tlearn: 5.1195942\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5204:\tlearn: 5.1190159\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5205:\tlearn: 5.1183155\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5206:\tlearn: 5.1180472\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5207:\tlearn: 5.1173826\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5208:\tlearn: 5.1169667\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5209:\tlearn: 5.1165202\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5210:\tlearn: 5.1160039\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5211:\tlearn: 5.1155292\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5212:\tlearn: 5.1148202\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5213:\tlearn: 5.1142966\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5214:\tlearn: 5.1136213\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5215:\tlearn: 5.1130135\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5216:\tlearn: 5.1127410\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5217:\tlearn: 5.1122751\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5218:\tlearn: 5.1119429\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5219:\tlearn: 5.1113336\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5220:\tlearn: 5.1106746\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5221:\tlearn: 5.1102170\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5222:\tlearn: 5.1097083\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "5223:\tlearn: 5.1094438\ttotal: 1m 52s\tremaining: 6m 23s\n",
      "5224:\tlearn: 5.1089882\ttotal: 1m 52s\tremaining: 6m 23s\n",
      "5225:\tlearn: 5.1084428\ttotal: 1m 52s\tremaining: 6m 23s\n",
      "5226:\tlearn: 5.1078937\ttotal: 1m 52s\tremaining: 6m 23s\n",
      "5227:\tlearn: 5.1078750\ttotal: 1m 52s\tremaining: 6m 23s\n",
      "5228:\tlearn: 5.1075096\ttotal: 1m 52s\tremaining: 6m 23s\n",
      "5229:\tlearn: 5.1072880\ttotal: 1m 52s\tremaining: 6m 23s\n",
      "5230:\tlearn: 5.1068264\ttotal: 1m 52s\tremaining: 6m 23s\n",
      "5231:\tlearn: 5.1062423\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5232:\tlearn: 5.1059229\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5233:\tlearn: 5.1051994\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5234:\tlearn: 5.1046198\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5235:\tlearn: 5.1041887\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5236:\tlearn: 5.1040054\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5237:\tlearn: 5.1037729\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5238:\tlearn: 5.1034722\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5239:\tlearn: 5.1031900\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5240:\tlearn: 5.1028636\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5241:\tlearn: 5.1022466\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5242:\tlearn: 5.1020701\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5243:\tlearn: 5.1018234\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5244:\tlearn: 5.1014679\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5245:\tlearn: 5.1010404\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5246:\tlearn: 5.1004711\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5247:\tlearn: 5.0997837\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5248:\tlearn: 5.0994606\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5249:\tlearn: 5.0991245\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5250:\tlearn: 5.0986870\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5251:\tlearn: 5.0981783\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5252:\tlearn: 5.0981596\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5253:\tlearn: 5.0976896\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5254:\tlearn: 5.0973341\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5255:\tlearn: 5.0970126\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5256:\tlearn: 5.0966320\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5257:\tlearn: 5.0961373\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5258:\tlearn: 5.0958013\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5259:\tlearn: 5.0952590\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5260:\tlearn: 5.0949188\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5261:\tlearn: 5.0946096\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5262:\tlearn: 5.0941330\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5263:\tlearn: 5.0936178\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5264:\tlearn: 5.0933838\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "5265:\tlearn: 5.0929817\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5266:\tlearn: 5.0926541\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5267:\tlearn: 5.0923252\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5268:\tlearn: 5.0919035\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5269:\tlearn: 5.0915203\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5270:\tlearn: 5.0912009\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5271:\tlearn: 5.0908390\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5272:\tlearn: 5.0903965\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5273:\tlearn: 5.0901275\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5274:\tlearn: 5.0897154\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5275:\tlearn: 5.0891753\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5276:\tlearn: 5.0888382\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5277:\tlearn: 5.0885284\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5278:\tlearn: 5.0881454\ttotal: 1m 53s\tremaining: 6m 22s\n",
      "5279:\tlearn: 5.0881236\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5280:\tlearn: 5.0874469\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5281:\tlearn: 5.0867166\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5282:\tlearn: 5.0863255\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5283:\tlearn: 5.0860596\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5284:\tlearn: 5.0857520\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5285:\tlearn: 5.0852113\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5286:\tlearn: 5.0844747\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5287:\tlearn: 5.0839059\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5288:\tlearn: 5.0832015\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5289:\tlearn: 5.0824467\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5290:\tlearn: 5.0821007\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5291:\tlearn: 5.0816903\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5292:\tlearn: 5.0816750\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5293:\tlearn: 5.0811486\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5294:\tlearn: 5.0805765\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5295:\tlearn: 5.0804342\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5296:\tlearn: 5.0801201\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5297:\tlearn: 5.0795469\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5298:\tlearn: 5.0789790\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5299:\tlearn: 5.0785730\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5300:\tlearn: 5.0781052\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5301:\tlearn: 5.0774270\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5302:\tlearn: 5.0772414\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5303:\tlearn: 5.0768609\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5304:\tlearn: 5.0764139\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5305:\tlearn: 5.0759666\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5306:\tlearn: 5.0755190\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5307:\tlearn: 5.0749506\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "5308:\tlearn: 5.0744318\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5309:\tlearn: 5.0739714\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5310:\tlearn: 5.0737235\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5311:\tlearn: 5.0731190\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5312:\tlearn: 5.0723200\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5313:\tlearn: 5.0717626\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5314:\tlearn: 5.0712789\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5315:\tlearn: 5.0709379\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5316:\tlearn: 5.0706327\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5317:\tlearn: 5.0700193\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5318:\tlearn: 5.0697146\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5319:\tlearn: 5.0693459\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5320:\tlearn: 5.0688389\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5321:\tlearn: 5.0688227\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5322:\tlearn: 5.0684402\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5323:\tlearn: 5.0680977\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5324:\tlearn: 5.0676430\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5325:\tlearn: 5.0672602\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "5326:\tlearn: 5.0663779\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5327:\tlearn: 5.0658299\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5328:\tlearn: 5.0652651\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5329:\tlearn: 5.0647253\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5330:\tlearn: 5.0643230\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5331:\tlearn: 5.0638735\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5332:\tlearn: 5.0634079\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5333:\tlearn: 5.0629489\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5334:\tlearn: 5.0627000\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5335:\tlearn: 5.0626838\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5336:\tlearn: 5.0619917\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5337:\tlearn: 5.0616646\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5338:\tlearn: 5.0612457\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5339:\tlearn: 5.0607635\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5340:\tlearn: 5.0603068\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5341:\tlearn: 5.0598895\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5342:\tlearn: 5.0595304\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5343:\tlearn: 5.0589820\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5344:\tlearn: 5.0584657\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5345:\tlearn: 5.0582664\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5346:\tlearn: 5.0576741\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5347:\tlearn: 5.0571131\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5348:\tlearn: 5.0568523\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5349:\tlearn: 5.0564592\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5350:\tlearn: 5.0560000\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5351:\tlearn: 5.0556482\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "5352:\tlearn: 5.0553614\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5353:\tlearn: 5.0549576\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5354:\tlearn: 5.0544466\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5355:\tlearn: 5.0538274\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5356:\tlearn: 5.0534684\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5357:\tlearn: 5.0530160\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5358:\tlearn: 5.0526616\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5359:\tlearn: 5.0524019\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5360:\tlearn: 5.0519383\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5361:\tlearn: 5.0515840\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5362:\tlearn: 5.0511017\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5363:\tlearn: 5.0507559\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5364:\tlearn: 5.0503912\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5365:\tlearn: 5.0498130\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5366:\tlearn: 5.0493151\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5367:\tlearn: 5.0489194\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5368:\tlearn: 5.0486337\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5369:\tlearn: 5.0483651\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5370:\tlearn: 5.0475941\ttotal: 1m 55s\tremaining: 6m 20s\n",
      "5371:\tlearn: 5.0471747\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5372:\tlearn: 5.0468048\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5373:\tlearn: 5.0464208\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5374:\tlearn: 5.0456188\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5375:\tlearn: 5.0450533\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5376:\tlearn: 5.0447188\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5377:\tlearn: 5.0447036\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5378:\tlearn: 5.0443518\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5379:\tlearn: 5.0438445\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5380:\tlearn: 5.0434132\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5381:\tlearn: 5.0430980\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5382:\tlearn: 5.0429421\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5383:\tlearn: 5.0427384\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5384:\tlearn: 5.0421438\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5385:\tlearn: 5.0418501\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5386:\tlearn: 5.0414018\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5387:\tlearn: 5.0408501\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5388:\tlearn: 5.0405543\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5389:\tlearn: 5.0397622\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5390:\tlearn: 5.0394867\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5391:\tlearn: 5.0391881\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5392:\tlearn: 5.0387079\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5393:\tlearn: 5.0383120\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5394:\tlearn: 5.0379520\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5395:\tlearn: 5.0373747\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5396:\tlearn: 5.0369956\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5397:\tlearn: 5.0363284\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5398:\tlearn: 5.0356090\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5399:\tlearn: 5.0353017\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5400:\tlearn: 5.0346846\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5401:\tlearn: 5.0341426\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "5402:\tlearn: 5.0337289\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5403:\tlearn: 5.0332934\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5404:\tlearn: 5.0328939\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5405:\tlearn: 5.0325296\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5406:\tlearn: 5.0321395\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5407:\tlearn: 5.0316526\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5408:\tlearn: 5.0309818\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5409:\tlearn: 5.0307683\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5410:\tlearn: 5.0307533\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5411:\tlearn: 5.0305703\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5412:\tlearn: 5.0305559\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5413:\tlearn: 5.0303276\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5414:\tlearn: 5.0300343\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5415:\tlearn: 5.0296076\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5416:\tlearn: 5.0291292\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5417:\tlearn: 5.0285224\ttotal: 1m 56s\tremaining: 6m 19s\n",
      "5418:\tlearn: 5.0280743\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5419:\tlearn: 5.0272764\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5420:\tlearn: 5.0268702\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5421:\tlearn: 5.0265205\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5422:\tlearn: 5.0263434\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5423:\tlearn: 5.0258432\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5424:\tlearn: 5.0253159\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5425:\tlearn: 5.0253018\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5426:\tlearn: 5.0251657\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5427:\tlearn: 5.0249014\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5428:\tlearn: 5.0244532\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5429:\tlearn: 5.0241560\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5430:\tlearn: 5.0236696\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5431:\tlearn: 5.0235431\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5432:\tlearn: 5.0231977\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5433:\tlearn: 5.0229414\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5434:\tlearn: 5.0226075\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5435:\tlearn: 5.0222039\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5436:\tlearn: 5.0217554\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5437:\tlearn: 5.0211024\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5438:\tlearn: 5.0205470\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5439:\tlearn: 5.0201300\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5440:\tlearn: 5.0196147\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5441:\tlearn: 5.0193272\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5442:\tlearn: 5.0186910\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5443:\tlearn: 5.0181452\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5444:\tlearn: 5.0174989\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5445:\tlearn: 5.0171957\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5446:\tlearn: 5.0167923\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5447:\tlearn: 5.0165206\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5448:\tlearn: 5.0160076\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5449:\tlearn: 5.0159736\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5450:\tlearn: 5.0153926\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5451:\tlearn: 5.0149846\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "5452:\tlearn: 5.0146623\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5453:\tlearn: 5.0144209\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5454:\tlearn: 5.0140010\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5455:\tlearn: 5.0136921\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5456:\tlearn: 5.0132349\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5457:\tlearn: 5.0128041\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5458:\tlearn: 5.0124263\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5459:\tlearn: 5.0118033\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5460:\tlearn: 5.0112308\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5461:\tlearn: 5.0104649\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5462:\tlearn: 5.0100625\ttotal: 1m 57s\tremaining: 6m 18s\n",
      "5463:\tlearn: 5.0095267\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5464:\tlearn: 5.0089266\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5465:\tlearn: 5.0085714\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5466:\tlearn: 5.0083098\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5467:\tlearn: 5.0080221\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5468:\tlearn: 5.0072949\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5469:\tlearn: 5.0068369\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5470:\tlearn: 5.0064546\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5471:\tlearn: 5.0062027\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5472:\tlearn: 5.0057282\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5473:\tlearn: 5.0053161\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5474:\tlearn: 5.0046746\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5475:\tlearn: 5.0044666\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5476:\tlearn: 5.0041490\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5477:\tlearn: 5.0036006\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5478:\tlearn: 5.0028726\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5479:\tlearn: 5.0025379\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5480:\tlearn: 5.0019197\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5481:\tlearn: 5.0012700\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5482:\tlearn: 5.0008302\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5483:\tlearn: 5.0002275\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5484:\tlearn: 4.9996785\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5485:\tlearn: 4.9990767\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5486:\tlearn: 4.9985642\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5487:\tlearn: 4.9982079\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5488:\tlearn: 4.9980228\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5489:\tlearn: 4.9977642\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5490:\tlearn: 4.9972234\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5491:\tlearn: 4.9966410\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5492:\tlearn: 4.9963751\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5493:\tlearn: 4.9959678\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5494:\tlearn: 4.9955495\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5495:\tlearn: 4.9952654\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5496:\tlearn: 4.9950898\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5497:\tlearn: 4.9948252\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5498:\tlearn: 4.9945124\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "5499:\tlearn: 4.9938547\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5500:\tlearn: 4.9934527\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5501:\tlearn: 4.9930789\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5502:\tlearn: 4.9923777\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5503:\tlearn: 4.9918193\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5504:\tlearn: 4.9914613\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5505:\tlearn: 4.9909983\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5506:\tlearn: 4.9901984\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5507:\tlearn: 4.9899490\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5508:\tlearn: 4.9895990\ttotal: 1m 58s\tremaining: 6m 17s\n",
      "5509:\tlearn: 4.9893631\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5510:\tlearn: 4.9889638\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5511:\tlearn: 4.9884998\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5512:\tlearn: 4.9880912\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5513:\tlearn: 4.9877547\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5514:\tlearn: 4.9873510\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5515:\tlearn: 4.9869128\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5516:\tlearn: 4.9864969\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5517:\tlearn: 4.9861425\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5518:\tlearn: 4.9858191\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5519:\tlearn: 4.9853293\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5520:\tlearn: 4.9848730\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5521:\tlearn: 4.9844212\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5522:\tlearn: 4.9840517\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5523:\tlearn: 4.9835625\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5524:\tlearn: 4.9830735\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5525:\tlearn: 4.9826425\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5526:\tlearn: 4.9818519\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5527:\tlearn: 4.9814356\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5528:\tlearn: 4.9809096\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5529:\tlearn: 4.9807166\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5530:\tlearn: 4.9803947\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5531:\tlearn: 4.9801085\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5532:\tlearn: 4.9795018\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5533:\tlearn: 4.9791204\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5534:\tlearn: 4.9786940\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5535:\tlearn: 4.9783295\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5536:\tlearn: 4.9779121\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5537:\tlearn: 4.9774964\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5538:\tlearn: 4.9770133\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5539:\tlearn: 4.9763581\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5540:\tlearn: 4.9760453\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5541:\tlearn: 4.9753126\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5542:\tlearn: 4.9750647\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5543:\tlearn: 4.9747890\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5544:\tlearn: 4.9744752\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5545:\tlearn: 4.9741545\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "5546:\tlearn: 4.9741390\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "5547:\tlearn: 4.9737522\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "5548:\tlearn: 4.9734269\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "5549:\tlearn: 4.9730530\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "5550:\tlearn: 4.9728911\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "5551:\tlearn: 4.9724941\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "5552:\tlearn: 4.9719494\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "5553:\tlearn: 4.9715720\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "5554:\tlearn: 4.9708996\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "5555:\tlearn: 4.9703571\ttotal: 2m\tremaining: 6m 16s\n",
      "5556:\tlearn: 4.9698256\ttotal: 2m\tremaining: 6m 16s\n",
      "5557:\tlearn: 4.9692244\ttotal: 2m\tremaining: 6m 16s\n",
      "5558:\tlearn: 4.9688122\ttotal: 2m\tremaining: 6m 16s\n",
      "5559:\tlearn: 4.9687093\ttotal: 2m\tremaining: 6m 16s\n",
      "5560:\tlearn: 4.9681505\ttotal: 2m\tremaining: 6m 16s\n",
      "5561:\tlearn: 4.9679929\ttotal: 2m\tremaining: 6m 16s\n",
      "5562:\tlearn: 4.9675976\ttotal: 2m\tremaining: 6m 16s\n",
      "5563:\tlearn: 4.9670074\ttotal: 2m\tremaining: 6m 16s\n",
      "5564:\tlearn: 4.9665130\ttotal: 2m\tremaining: 6m 16s\n",
      "5565:\tlearn: 4.9662399\ttotal: 2m\tremaining: 6m 16s\n",
      "5566:\tlearn: 4.9658379\ttotal: 2m\tremaining: 6m 16s\n",
      "5567:\tlearn: 4.9656038\ttotal: 2m\tremaining: 6m 16s\n",
      "5568:\tlearn: 4.9649929\ttotal: 2m\tremaining: 6m 16s\n",
      "5569:\tlearn: 4.9644872\ttotal: 2m\tremaining: 6m 16s\n",
      "5570:\tlearn: 4.9641393\ttotal: 2m\tremaining: 6m 16s\n",
      "5571:\tlearn: 4.9634633\ttotal: 2m\tremaining: 6m 16s\n",
      "5572:\tlearn: 4.9630372\ttotal: 2m\tremaining: 6m 16s\n",
      "5573:\tlearn: 4.9627876\ttotal: 2m\tremaining: 6m 16s\n",
      "5574:\tlearn: 4.9622579\ttotal: 2m\tremaining: 6m 16s\n",
      "5575:\tlearn: 4.9617406\ttotal: 2m\tremaining: 6m 16s\n",
      "5576:\tlearn: 4.9616752\ttotal: 2m\tremaining: 6m 16s\n",
      "5577:\tlearn: 4.9613012\ttotal: 2m\tremaining: 6m 16s\n",
      "5578:\tlearn: 4.9606752\ttotal: 2m\tremaining: 6m 16s\n",
      "5579:\tlearn: 4.9599485\ttotal: 2m\tremaining: 6m 16s\n",
      "5580:\tlearn: 4.9596050\ttotal: 2m\tremaining: 6m 16s\n",
      "5581:\tlearn: 4.9590379\ttotal: 2m\tremaining: 6m 16s\n",
      "5582:\tlearn: 4.9584862\ttotal: 2m\tremaining: 6m 16s\n",
      "5583:\tlearn: 4.9580175\ttotal: 2m\tremaining: 6m 16s\n",
      "5584:\tlearn: 4.9574961\ttotal: 2m\tremaining: 6m 16s\n",
      "5585:\tlearn: 4.9570534\ttotal: 2m\tremaining: 6m 16s\n",
      "5586:\tlearn: 4.9565597\ttotal: 2m\tremaining: 6m 16s\n",
      "5587:\tlearn: 4.9558799\ttotal: 2m\tremaining: 6m 16s\n",
      "5588:\tlearn: 4.9558667\ttotal: 2m\tremaining: 6m 16s\n",
      "5589:\tlearn: 4.9553011\ttotal: 2m\tremaining: 6m 16s\n",
      "5590:\tlearn: 4.9550194\ttotal: 2m\tremaining: 6m 16s\n",
      "5591:\tlearn: 4.9544449\ttotal: 2m\tremaining: 6m 16s\n",
      "5592:\tlearn: 4.9541615\ttotal: 2m\tremaining: 6m 15s\n",
      "5593:\tlearn: 4.9538457\ttotal: 2m\tremaining: 6m 15s\n",
      "5594:\tlearn: 4.9537993\ttotal: 2m\tremaining: 6m 15s\n",
      "5595:\tlearn: 4.9534146\ttotal: 2m\tremaining: 6m 15s\n",
      "5596:\tlearn: 4.9529508\ttotal: 2m\tremaining: 6m 15s\n",
      "5597:\tlearn: 4.9525751\ttotal: 2m\tremaining: 6m 15s\n",
      "5598:\tlearn: 4.9520863\ttotal: 2m\tremaining: 6m 15s\n",
      "5599:\tlearn: 4.9514519\ttotal: 2m\tremaining: 6m 15s\n",
      "5600:\tlearn: 4.9507942\ttotal: 2m\tremaining: 6m 15s\n",
      "5601:\tlearn: 4.9504621\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5602:\tlearn: 4.9502490\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5603:\tlearn: 4.9495807\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5604:\tlearn: 4.9494355\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5605:\tlearn: 4.9488446\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5606:\tlearn: 4.9488283\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5607:\tlearn: 4.9484435\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5608:\tlearn: 4.9481956\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5609:\tlearn: 4.9475663\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5610:\tlearn: 4.9473191\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5611:\tlearn: 4.9470852\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5612:\tlearn: 4.9464576\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5613:\tlearn: 4.9461175\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5614:\tlearn: 4.9454787\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5615:\tlearn: 4.9450304\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5616:\tlearn: 4.9445628\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5617:\tlearn: 4.9443490\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5618:\tlearn: 4.9439502\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5619:\tlearn: 4.9436836\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5620:\tlearn: 4.9435010\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5621:\tlearn: 4.9434874\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5622:\tlearn: 4.9428649\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5623:\tlearn: 4.9423085\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5624:\tlearn: 4.9419705\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5625:\tlearn: 4.9416220\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5626:\tlearn: 4.9408469\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5627:\tlearn: 4.9405637\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5628:\tlearn: 4.9400716\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5629:\tlearn: 4.9393495\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5630:\tlearn: 4.9387681\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5631:\tlearn: 4.9385912\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5632:\tlearn: 4.9383746\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5633:\tlearn: 4.9380190\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5634:\tlearn: 4.9375616\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5635:\tlearn: 4.9373048\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "5636:\tlearn: 4.9369755\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5637:\tlearn: 4.9364972\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5638:\tlearn: 4.9362750\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5639:\tlearn: 4.9359839\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5640:\tlearn: 4.9357498\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5641:\tlearn: 4.9353137\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5642:\tlearn: 4.9348277\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5643:\tlearn: 4.9341869\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5644:\tlearn: 4.9341719\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5645:\tlearn: 4.9334378\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5646:\tlearn: 4.9332723\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5647:\tlearn: 4.9327703\ttotal: 2m 1s\tremaining: 6m 14s\n",
      "5648:\tlearn: 4.9325383\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5649:\tlearn: 4.9322304\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5650:\tlearn: 4.9318710\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5651:\tlearn: 4.9316628\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5652:\tlearn: 4.9313930\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5653:\tlearn: 4.9311922\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5654:\tlearn: 4.9309758\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5655:\tlearn: 4.9308433\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5656:\tlearn: 4.9302443\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5657:\tlearn: 4.9298537\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5658:\tlearn: 4.9296419\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5659:\tlearn: 4.9292054\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5660:\tlearn: 4.9287937\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5661:\tlearn: 4.9284627\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5662:\tlearn: 4.9278414\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5663:\tlearn: 4.9275472\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5664:\tlearn: 4.9271325\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5665:\tlearn: 4.9265352\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5666:\tlearn: 4.9263000\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5667:\tlearn: 4.9260182\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5668:\tlearn: 4.9253497\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5669:\tlearn: 4.9251233\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5670:\tlearn: 4.9246690\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5671:\tlearn: 4.9243442\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5672:\tlearn: 4.9237142\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5673:\tlearn: 4.9233688\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5674:\tlearn: 4.9230007\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5675:\tlearn: 4.9226625\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5676:\tlearn: 4.9222020\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5677:\tlearn: 4.9218148\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5678:\tlearn: 4.9213329\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5679:\tlearn: 4.9209620\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5680:\tlearn: 4.9206230\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5681:\tlearn: 4.9199634\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5682:\tlearn: 4.9197794\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "5683:\tlearn: 4.9197635\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5684:\tlearn: 4.9192674\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5685:\tlearn: 4.9188457\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5686:\tlearn: 4.9183844\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5687:\tlearn: 4.9180026\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5688:\tlearn: 4.9176390\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5689:\tlearn: 4.9173448\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5690:\tlearn: 4.9170711\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5691:\tlearn: 4.9170580\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5692:\tlearn: 4.9167326\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5693:\tlearn: 4.9161952\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5694:\tlearn: 4.9157713\ttotal: 2m 2s\tremaining: 6m 13s\n",
      "5695:\tlearn: 4.9154537\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5696:\tlearn: 4.9150079\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5697:\tlearn: 4.9143705\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5698:\tlearn: 4.9140251\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5699:\tlearn: 4.9135944\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5700:\tlearn: 4.9131047\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5701:\tlearn: 4.9127602\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5702:\tlearn: 4.9122062\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5703:\tlearn: 4.9116269\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5704:\tlearn: 4.9113893\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5705:\tlearn: 4.9108053\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5706:\tlearn: 4.9102777\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5707:\tlearn: 4.9097786\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5708:\tlearn: 4.9094742\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5709:\tlearn: 4.9093837\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5710:\tlearn: 4.9089006\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5711:\tlearn: 4.9082704\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5712:\tlearn: 4.9079411\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5713:\tlearn: 4.9077639\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5714:\tlearn: 4.9073304\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5715:\tlearn: 4.9069122\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5716:\tlearn: 4.9066589\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5717:\tlearn: 4.9066466\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5718:\tlearn: 4.9061000\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5719:\tlearn: 4.9055541\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5720:\tlearn: 4.9049265\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5721:\tlearn: 4.9042359\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5722:\tlearn: 4.9039261\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5723:\tlearn: 4.9034726\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5724:\tlearn: 4.9031108\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5725:\tlearn: 4.9030973\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "5726:\tlearn: 4.9029723\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5727:\tlearn: 4.9026172\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5728:\tlearn: 4.9021797\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5729:\tlearn: 4.9017023\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5730:\tlearn: 4.9013378\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5731:\tlearn: 4.9008045\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5732:\tlearn: 4.9004506\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5733:\tlearn: 4.9001738\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5734:\tlearn: 4.8999278\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5735:\tlearn: 4.8994851\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5736:\tlearn: 4.8992199\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5737:\tlearn: 4.8988172\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5738:\tlearn: 4.8983472\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5739:\tlearn: 4.8977171\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5740:\tlearn: 4.8971607\ttotal: 2m 3s\tremaining: 6m 12s\n",
      "5741:\tlearn: 4.8966097\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5742:\tlearn: 4.8963551\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5743:\tlearn: 4.8960525\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5744:\tlearn: 4.8956602\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5745:\tlearn: 4.8952178\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5746:\tlearn: 4.8949618\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5747:\tlearn: 4.8946374\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5748:\tlearn: 4.8941921\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5749:\tlearn: 4.8940935\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5750:\tlearn: 4.8934977\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5751:\tlearn: 4.8931874\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5752:\tlearn: 4.8927258\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5753:\tlearn: 4.8923191\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5754:\tlearn: 4.8919741\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5755:\tlearn: 4.8917298\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5756:\tlearn: 4.8913307\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5757:\tlearn: 4.8913039\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5758:\tlearn: 4.8910382\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5759:\tlearn: 4.8906161\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5760:\tlearn: 4.8901699\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5761:\tlearn: 4.8897883\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5762:\tlearn: 4.8894361\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5763:\tlearn: 4.8892421\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5764:\tlearn: 4.8887691\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5765:\tlearn: 4.8886259\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5766:\tlearn: 4.8880210\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5767:\tlearn: 4.8874938\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5768:\tlearn: 4.8869831\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5769:\tlearn: 4.8866010\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5770:\tlearn: 4.8862166\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5771:\tlearn: 4.8858328\ttotal: 2m 4s\tremaining: 6m 12s\n",
      "5772:\tlearn: 4.8854642\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5773:\tlearn: 4.8848348\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5774:\tlearn: 4.8843034\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5775:\tlearn: 4.8838143\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5776:\tlearn: 4.8834690\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5777:\tlearn: 4.8830913\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5778:\tlearn: 4.8829045\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5779:\tlearn: 4.8826487\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5780:\tlearn: 4.8824136\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5781:\tlearn: 4.8823979\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5782:\tlearn: 4.8817324\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5783:\tlearn: 4.8811210\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5784:\tlearn: 4.8807757\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5785:\tlearn: 4.8804295\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5786:\tlearn: 4.8799980\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5787:\tlearn: 4.8796582\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5788:\tlearn: 4.8790889\ttotal: 2m 4s\tremaining: 6m 11s\n",
      "5789:\tlearn: 4.8787834\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5790:\tlearn: 4.8784039\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5791:\tlearn: 4.8777185\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5792:\tlearn: 4.8773475\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5793:\tlearn: 4.8769158\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5794:\tlearn: 4.8769021\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5795:\tlearn: 4.8764706\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5796:\tlearn: 4.8757805\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5797:\tlearn: 4.8753868\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5798:\tlearn: 4.8747873\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5799:\tlearn: 4.8742142\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5800:\tlearn: 4.8739571\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5801:\tlearn: 4.8736813\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5802:\tlearn: 4.8736680\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5803:\tlearn: 4.8733057\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5804:\tlearn: 4.8731310\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5805:\tlearn: 4.8726532\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5806:\tlearn: 4.8722519\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5807:\tlearn: 4.8722337\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5808:\tlearn: 4.8719291\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5809:\tlearn: 4.8715942\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5810:\tlearn: 4.8711101\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5811:\tlearn: 4.8705476\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5812:\tlearn: 4.8701409\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5813:\tlearn: 4.8697116\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5814:\tlearn: 4.8694238\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "5815:\tlearn: 4.8688113\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5816:\tlearn: 4.8684710\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5817:\tlearn: 4.8678924\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5818:\tlearn: 4.8673819\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5819:\tlearn: 4.8669209\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5820:\tlearn: 4.8664522\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5821:\tlearn: 4.8658182\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5822:\tlearn: 4.8652445\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5823:\tlearn: 4.8649132\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5824:\tlearn: 4.8644476\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5825:\tlearn: 4.8641648\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5826:\tlearn: 4.8637686\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5827:\tlearn: 4.8633052\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5828:\tlearn: 4.8628616\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5829:\tlearn: 4.8624040\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5830:\tlearn: 4.8620629\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5831:\tlearn: 4.8616047\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5832:\tlearn: 4.8610966\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5833:\tlearn: 4.8603670\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5834:\tlearn: 4.8600963\ttotal: 2m 5s\tremaining: 6m 10s\n",
      "5835:\tlearn: 4.8594996\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5836:\tlearn: 4.8591479\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5837:\tlearn: 4.8582674\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5838:\tlearn: 4.8578099\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5839:\tlearn: 4.8572564\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5840:\tlearn: 4.8567339\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5841:\tlearn: 4.8563801\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5842:\tlearn: 4.8561589\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5843:\tlearn: 4.8558531\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5844:\tlearn: 4.8553800\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5845:\tlearn: 4.8548036\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5846:\tlearn: 4.8545923\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5847:\tlearn: 4.8543771\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5848:\tlearn: 4.8540621\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5849:\tlearn: 4.8537762\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5850:\tlearn: 4.8531672\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5851:\tlearn: 4.8525701\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5852:\tlearn: 4.8523505\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5853:\tlearn: 4.8518203\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5854:\tlearn: 4.8515397\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5855:\tlearn: 4.8513964\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5856:\tlearn: 4.8508685\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5857:\tlearn: 4.8506040\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5858:\tlearn: 4.8502226\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5859:\tlearn: 4.8498238\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5860:\tlearn: 4.8494418\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5861:\tlearn: 4.8493819\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5862:\tlearn: 4.8493079\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5863:\tlearn: 4.8488896\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5864:\tlearn: 4.8484394\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "5865:\tlearn: 4.8480433\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5866:\tlearn: 4.8475359\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5867:\tlearn: 4.8472810\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5868:\tlearn: 4.8470347\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5869:\tlearn: 4.8466069\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5870:\tlearn: 4.8461843\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5871:\tlearn: 4.8459065\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5872:\tlearn: 4.8455256\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5873:\tlearn: 4.8451286\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5874:\tlearn: 4.8449165\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5875:\tlearn: 4.8447365\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5876:\tlearn: 4.8442551\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5877:\tlearn: 4.8439987\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5878:\tlearn: 4.8436649\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5879:\tlearn: 4.8431848\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5880:\tlearn: 4.8429411\ttotal: 2m 6s\tremaining: 6m 9s\n",
      "5881:\tlearn: 4.8426173\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5882:\tlearn: 4.8422035\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5883:\tlearn: 4.8417858\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5884:\tlearn: 4.8415330\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5885:\tlearn: 4.8410801\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5886:\tlearn: 4.8407526\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5887:\tlearn: 4.8401738\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5888:\tlearn: 4.8398632\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5889:\tlearn: 4.8396557\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5890:\tlearn: 4.8389357\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5891:\tlearn: 4.8387528\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5892:\tlearn: 4.8383949\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5893:\tlearn: 4.8378589\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5894:\tlearn: 4.8372331\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5895:\tlearn: 4.8369157\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5896:\tlearn: 4.8367547\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5897:\tlearn: 4.8362764\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5898:\tlearn: 4.8359948\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5899:\tlearn: 4.8354361\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5900:\tlearn: 4.8350861\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5901:\tlearn: 4.8347930\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5902:\tlearn: 4.8345351\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5903:\tlearn: 4.8342448\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5904:\tlearn: 4.8338272\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5905:\tlearn: 4.8334771\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5906:\tlearn: 4.8332527\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5907:\tlearn: 4.8329111\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5908:\tlearn: 4.8325797\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5909:\tlearn: 4.8322789\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5910:\tlearn: 4.8319876\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5911:\tlearn: 4.8317800\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5912:\tlearn: 4.8313217\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5913:\tlearn: 4.8305519\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5914:\tlearn: 4.8299316\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "5915:\tlearn: 4.8295405\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5916:\tlearn: 4.8291597\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5917:\tlearn: 4.8287783\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5918:\tlearn: 4.8285295\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5919:\tlearn: 4.8279248\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5920:\tlearn: 4.8274621\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5921:\tlearn: 4.8271612\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5922:\tlearn: 4.8266140\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5923:\tlearn: 4.8261424\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5924:\tlearn: 4.8254672\ttotal: 2m 7s\tremaining: 6m 8s\n",
      "5925:\tlearn: 4.8251963\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5926:\tlearn: 4.8246290\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5927:\tlearn: 4.8241550\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5928:\tlearn: 4.8236349\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5929:\tlearn: 4.8234091\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5930:\tlearn: 4.8231732\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5931:\tlearn: 4.8227611\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5932:\tlearn: 4.8224842\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5933:\tlearn: 4.8219442\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5934:\tlearn: 4.8215812\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5935:\tlearn: 4.8213599\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5936:\tlearn: 4.8209122\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5937:\tlearn: 4.8205564\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5938:\tlearn: 4.8201594\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5939:\tlearn: 4.8194945\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5940:\tlearn: 4.8192818\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5941:\tlearn: 4.8190289\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5942:\tlearn: 4.8187900\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5943:\tlearn: 4.8182918\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5944:\tlearn: 4.8179383\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5945:\tlearn: 4.8176282\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5946:\tlearn: 4.8170678\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5947:\tlearn: 4.8168371\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5948:\tlearn: 4.8164292\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5949:\tlearn: 4.8157166\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5950:\tlearn: 4.8153261\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5951:\tlearn: 4.8149923\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5952:\tlearn: 4.8147941\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5953:\tlearn: 4.8143671\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5954:\tlearn: 4.8139943\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5955:\tlearn: 4.8138117\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5956:\tlearn: 4.8136605\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5957:\tlearn: 4.8132555\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5958:\tlearn: 4.8128638\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5959:\tlearn: 4.8127902\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5960:\tlearn: 4.8127771\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5961:\tlearn: 4.8123066\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5962:\tlearn: 4.8119318\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5963:\tlearn: 4.8114364\ttotal: 2m 8s\tremaining: 6m 8s\n",
      "5964:\tlearn: 4.8110610\ttotal: 2m 8s\tremaining: 6m 7s\n",
      "5965:\tlearn: 4.8108424\ttotal: 2m 8s\tremaining: 6m 7s\n",
      "5966:\tlearn: 4.8103800\ttotal: 2m 8s\tremaining: 6m 7s\n",
      "5967:\tlearn: 4.8099893\ttotal: 2m 8s\tremaining: 6m 7s\n",
      "5968:\tlearn: 4.8096075\ttotal: 2m 8s\tremaining: 6m 7s\n",
      "5969:\tlearn: 4.8093742\ttotal: 2m 8s\tremaining: 6m 7s\n",
      "5970:\tlearn: 4.8090380\ttotal: 2m 8s\tremaining: 6m 7s\n",
      "5971:\tlearn: 4.8087746\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5972:\tlearn: 4.8084985\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5973:\tlearn: 4.8079222\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5974:\tlearn: 4.8076013\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5975:\tlearn: 4.8072064\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5976:\tlearn: 4.8067782\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5977:\tlearn: 4.8065024\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5978:\tlearn: 4.8062405\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5979:\tlearn: 4.8060923\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5980:\tlearn: 4.8056400\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5981:\tlearn: 4.8051727\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5982:\tlearn: 4.8049488\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5983:\tlearn: 4.8046424\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5984:\tlearn: 4.8039715\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5985:\tlearn: 4.8035635\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5986:\tlearn: 4.8031920\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5987:\tlearn: 4.8030003\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5988:\tlearn: 4.8028180\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5989:\tlearn: 4.8024360\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5990:\tlearn: 4.8020665\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5991:\tlearn: 4.8016612\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5992:\tlearn: 4.8010902\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5993:\tlearn: 4.8008129\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5994:\tlearn: 4.8003176\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5995:\tlearn: 4.7999176\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5996:\tlearn: 4.7994266\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5997:\tlearn: 4.7991532\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5998:\tlearn: 4.7985476\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "5999:\tlearn: 4.7979995\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6000:\tlearn: 4.7977488\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6001:\tlearn: 4.7974864\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6002:\tlearn: 4.7969687\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6003:\tlearn: 4.7964079\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6004:\tlearn: 4.7959637\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6005:\tlearn: 4.7955977\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6006:\tlearn: 4.7950429\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6007:\tlearn: 4.7947356\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6008:\tlearn: 4.7942416\ttotal: 2m 9s\tremaining: 6m 7s\n",
      "6009:\tlearn: 4.7937359\ttotal: 2m 9s\tremaining: 6m 6s\n",
      "6010:\tlearn: 4.7933723\ttotal: 2m 9s\tremaining: 6m 6s\n",
      "6011:\tlearn: 4.7928735\ttotal: 2m 9s\tremaining: 6m 6s\n",
      "6012:\tlearn: 4.7925022\ttotal: 2m 9s\tremaining: 6m 6s\n",
      "6013:\tlearn: 4.7919667\ttotal: 2m 9s\tremaining: 6m 6s\n",
      "6014:\tlearn: 4.7917315\ttotal: 2m 9s\tremaining: 6m 6s\n",
      "6015:\tlearn: 4.7913304\ttotal: 2m 9s\tremaining: 6m 6s\n",
      "6016:\tlearn: 4.7908434\ttotal: 2m 9s\tremaining: 6m 6s\n",
      "6017:\tlearn: 4.7904001\ttotal: 2m 9s\tremaining: 6m 6s\n",
      "6018:\tlearn: 4.7901514\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6019:\tlearn: 4.7899463\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6020:\tlearn: 4.7894879\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6021:\tlearn: 4.7891142\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6022:\tlearn: 4.7887688\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6023:\tlearn: 4.7882667\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6024:\tlearn: 4.7882532\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6025:\tlearn: 4.7877835\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6026:\tlearn: 4.7873541\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6027:\tlearn: 4.7870420\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6028:\tlearn: 4.7865081\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6029:\tlearn: 4.7861499\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6030:\tlearn: 4.7858336\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6031:\tlearn: 4.7852258\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6032:\tlearn: 4.7848336\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6033:\tlearn: 4.7845118\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6034:\tlearn: 4.7841623\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6035:\tlearn: 4.7835947\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6036:\tlearn: 4.7832780\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6037:\tlearn: 4.7828646\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6038:\tlearn: 4.7823724\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6039:\tlearn: 4.7821078\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6040:\tlearn: 4.7818433\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6041:\tlearn: 4.7813348\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6042:\tlearn: 4.7813235\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6043:\tlearn: 4.7807184\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6044:\tlearn: 4.7803945\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6045:\tlearn: 4.7800670\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6046:\tlearn: 4.7800537\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6047:\tlearn: 4.7793829\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6048:\tlearn: 4.7790861\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6049:\tlearn: 4.7788441\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6050:\tlearn: 4.7784843\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6051:\tlearn: 4.7781773\ttotal: 2m 10s\tremaining: 6m 6s\n",
      "6052:\tlearn: 4.7779059\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6053:\tlearn: 4.7775597\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6054:\tlearn: 4.7772049\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6055:\tlearn: 4.7769011\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6056:\tlearn: 4.7766896\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6057:\tlearn: 4.7762622\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6058:\tlearn: 4.7757462\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6059:\tlearn: 4.7751099\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6060:\tlearn: 4.7746351\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6061:\tlearn: 4.7742809\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6062:\tlearn: 4.7738289\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6063:\tlearn: 4.7737003\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6064:\tlearn: 4.7731194\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6065:\tlearn: 4.7728968\ttotal: 2m 10s\tremaining: 6m 5s\n",
      "6066:\tlearn: 4.7722292\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6067:\tlearn: 4.7717973\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6068:\tlearn: 4.7714020\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6069:\tlearn: 4.7709480\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6070:\tlearn: 4.7703454\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6071:\tlearn: 4.7699360\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6072:\tlearn: 4.7695893\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6073:\tlearn: 4.7690946\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6074:\tlearn: 4.7688789\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6075:\tlearn: 4.7684980\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6076:\tlearn: 4.7681536\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6077:\tlearn: 4.7675486\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6078:\tlearn: 4.7671562\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6079:\tlearn: 4.7667214\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6080:\tlearn: 4.7662364\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6081:\tlearn: 4.7659453\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6082:\tlearn: 4.7655060\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6083:\tlearn: 4.7651494\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6084:\tlearn: 4.7649148\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6085:\tlearn: 4.7646113\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6086:\tlearn: 4.7641624\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6087:\tlearn: 4.7638944\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6088:\tlearn: 4.7634690\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6089:\tlearn: 4.7634566\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6090:\tlearn: 4.7632762\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6091:\tlearn: 4.7631944\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6092:\tlearn: 4.7630208\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6093:\tlearn: 4.7629049\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6094:\tlearn: 4.7626337\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6095:\tlearn: 4.7622724\ttotal: 2m 11s\tremaining: 6m 5s\n",
      "6096:\tlearn: 4.7620652\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6097:\tlearn: 4.7615969\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6098:\tlearn: 4.7612852\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6099:\tlearn: 4.7608378\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6100:\tlearn: 4.7602407\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6101:\tlearn: 4.7597896\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6102:\tlearn: 4.7592463\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6103:\tlearn: 4.7589496\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6104:\tlearn: 4.7586561\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6105:\tlearn: 4.7584570\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6106:\tlearn: 4.7579985\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6107:\tlearn: 4.7577175\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6108:\tlearn: 4.7572429\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6109:\tlearn: 4.7567346\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6110:\tlearn: 4.7563642\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6111:\tlearn: 4.7561215\ttotal: 2m 11s\tremaining: 6m 4s\n",
      "6112:\tlearn: 4.7556648\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6113:\tlearn: 4.7553430\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6114:\tlearn: 4.7548278\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6115:\tlearn: 4.7544200\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6116:\tlearn: 4.7540002\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6117:\tlearn: 4.7535933\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6118:\tlearn: 4.7532118\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6119:\tlearn: 4.7526823\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6120:\tlearn: 4.7520703\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6121:\tlearn: 4.7517475\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6122:\tlearn: 4.7512019\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6123:\tlearn: 4.7508454\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6124:\tlearn: 4.7501580\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6125:\tlearn: 4.7501457\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6126:\tlearn: 4.7497217\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6127:\tlearn: 4.7492055\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6128:\tlearn: 4.7485291\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6129:\tlearn: 4.7481436\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6130:\tlearn: 4.7479842\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6131:\tlearn: 4.7475539\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6132:\tlearn: 4.7474850\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6133:\tlearn: 4.7470393\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6134:\tlearn: 4.7466667\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6135:\tlearn: 4.7462305\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6136:\tlearn: 4.7458162\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6137:\tlearn: 4.7455174\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6138:\tlearn: 4.7449768\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6139:\tlearn: 4.7447126\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6140:\tlearn: 4.7442108\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6141:\tlearn: 4.7439251\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6142:\tlearn: 4.7436037\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6143:\tlearn: 4.7432913\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6144:\tlearn: 4.7429833\ttotal: 2m 12s\tremaining: 6m 4s\n",
      "6145:\tlearn: 4.7428443\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6146:\tlearn: 4.7425831\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6147:\tlearn: 4.7422181\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6148:\tlearn: 4.7420310\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6149:\tlearn: 4.7414524\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6150:\tlearn: 4.7408494\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6151:\tlearn: 4.7404424\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6152:\tlearn: 4.7403387\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6153:\tlearn: 4.7398905\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6154:\tlearn: 4.7396779\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6155:\tlearn: 4.7393940\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6156:\tlearn: 4.7393660\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6157:\tlearn: 4.7390796\ttotal: 2m 12s\tremaining: 6m 3s\n",
      "6158:\tlearn: 4.7385090\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6159:\tlearn: 4.7379958\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6160:\tlearn: 4.7376876\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6161:\tlearn: 4.7374263\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6162:\tlearn: 4.7368313\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6163:\tlearn: 4.7367556\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6164:\tlearn: 4.7361358\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6165:\tlearn: 4.7357408\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6166:\tlearn: 4.7354066\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6167:\tlearn: 4.7350213\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6168:\tlearn: 4.7345219\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6169:\tlearn: 4.7339995\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6170:\tlearn: 4.7336558\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6171:\tlearn: 4.7334548\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6172:\tlearn: 4.7331307\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6173:\tlearn: 4.7325808\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6174:\tlearn: 4.7323893\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6175:\tlearn: 4.7320365\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6176:\tlearn: 4.7315420\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6177:\tlearn: 4.7311634\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6178:\tlearn: 4.7307831\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6179:\tlearn: 4.7304078\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6180:\tlearn: 4.7300658\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6181:\tlearn: 4.7298579\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6182:\tlearn: 4.7295332\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6183:\tlearn: 4.7291487\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6184:\tlearn: 4.7286191\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6185:\tlearn: 4.7284305\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6186:\tlearn: 4.7281103\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6187:\tlearn: 4.7278117\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6188:\tlearn: 4.7274920\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6189:\tlearn: 4.7268441\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6190:\tlearn: 4.7264911\ttotal: 2m 13s\tremaining: 6m 3s\n",
      "6191:\tlearn: 4.7260327\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6192:\tlearn: 4.7255211\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6193:\tlearn: 4.7253147\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6194:\tlearn: 4.7250161\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6195:\tlearn: 4.7243712\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6196:\tlearn: 4.7240857\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6197:\tlearn: 4.7236121\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6198:\tlearn: 4.7235579\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6199:\tlearn: 4.7234882\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6200:\tlearn: 4.7231006\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6201:\tlearn: 4.7228878\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6202:\tlearn: 4.7222955\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6203:\tlearn: 4.7218804\ttotal: 2m 13s\tremaining: 6m 2s\n",
      "6204:\tlearn: 4.7214044\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6205:\tlearn: 4.7210011\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6206:\tlearn: 4.7205717\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6207:\tlearn: 4.7199715\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6208:\tlearn: 4.7194784\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6209:\tlearn: 4.7191176\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6210:\tlearn: 4.7186730\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6211:\tlearn: 4.7185263\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6212:\tlearn: 4.7181376\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6213:\tlearn: 4.7177711\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6214:\tlearn: 4.7176725\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6215:\tlearn: 4.7171815\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6216:\tlearn: 4.7167214\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6217:\tlearn: 4.7163098\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6218:\tlearn: 4.7160724\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6219:\tlearn: 4.7154718\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6220:\tlearn: 4.7153098\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6221:\tlearn: 4.7151016\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6222:\tlearn: 4.7148383\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6223:\tlearn: 4.7144269\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6224:\tlearn: 4.7141065\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6225:\tlearn: 4.7135420\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6226:\tlearn: 4.7131294\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6227:\tlearn: 4.7127447\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6228:\tlearn: 4.7123205\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6229:\tlearn: 4.7118283\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6230:\tlearn: 4.7116484\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6231:\tlearn: 4.7112418\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6232:\tlearn: 4.7110203\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6233:\tlearn: 4.7105691\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6234:\tlearn: 4.7102449\ttotal: 2m 14s\tremaining: 6m 2s\n",
      "6235:\tlearn: 4.7102308\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6236:\tlearn: 4.7099618\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6237:\tlearn: 4.7094456\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6238:\tlearn: 4.7091558\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6239:\tlearn: 4.7090646\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6240:\tlearn: 4.7088082\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6241:\tlearn: 4.7083587\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6242:\tlearn: 4.7080877\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6243:\tlearn: 4.7076911\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6244:\tlearn: 4.7073001\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6245:\tlearn: 4.7067950\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6246:\tlearn: 4.7062935\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6247:\tlearn: 4.7061794\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6248:\tlearn: 4.7056665\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6249:\tlearn: 4.7053183\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6250:\tlearn: 4.7047993\ttotal: 2m 14s\tremaining: 6m 1s\n",
      "6251:\tlearn: 4.7045788\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6252:\tlearn: 4.7040752\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6253:\tlearn: 4.7035397\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6254:\tlearn: 4.7031996\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6255:\tlearn: 4.7028503\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6256:\tlearn: 4.7025223\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6257:\tlearn: 4.7021472\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6258:\tlearn: 4.7018027\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6259:\tlearn: 4.7011842\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6260:\tlearn: 4.7008479\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6261:\tlearn: 4.7005772\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6262:\tlearn: 4.7002353\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6263:\tlearn: 4.7000690\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6264:\tlearn: 4.6994248\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6265:\tlearn: 4.6988382\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6266:\tlearn: 4.6985018\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6267:\tlearn: 4.6979575\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6268:\tlearn: 4.6975384\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6269:\tlearn: 4.6969055\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6270:\tlearn: 4.6966357\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6271:\tlearn: 4.6962113\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6272:\tlearn: 4.6958054\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6273:\tlearn: 4.6955459\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6274:\tlearn: 4.6952692\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6275:\tlearn: 4.6947673\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6276:\tlearn: 4.6943852\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6277:\tlearn: 4.6940861\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6278:\tlearn: 4.6936865\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6279:\tlearn: 4.6930941\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6280:\tlearn: 4.6927890\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6281:\tlearn: 4.6923771\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6282:\tlearn: 4.6920560\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6283:\tlearn: 4.6916883\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6284:\tlearn: 4.6911778\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6285:\tlearn: 4.6905183\ttotal: 2m 15s\tremaining: 6m 1s\n",
      "6286:\tlearn: 4.6905061\ttotal: 2m 15s\tremaining: 6m\n",
      "6287:\tlearn: 4.6903280\ttotal: 2m 15s\tremaining: 6m\n",
      "6288:\tlearn: 4.6896701\ttotal: 2m 15s\tremaining: 6m\n",
      "6289:\tlearn: 4.6892158\ttotal: 2m 15s\tremaining: 6m\n",
      "6290:\tlearn: 4.6887063\ttotal: 2m 15s\tremaining: 6m\n",
      "6291:\tlearn: 4.6883059\ttotal: 2m 15s\tremaining: 6m\n",
      "6292:\tlearn: 4.6879813\ttotal: 2m 15s\tremaining: 6m\n",
      "6293:\tlearn: 4.6876465\ttotal: 2m 15s\tremaining: 6m\n",
      "6294:\tlearn: 4.6872123\ttotal: 2m 15s\tremaining: 6m\n",
      "6295:\tlearn: 4.6869332\ttotal: 2m 15s\tremaining: 6m\n",
      "6296:\tlearn: 4.6866659\ttotal: 2m 16s\tremaining: 6m\n",
      "6297:\tlearn: 4.6861081\ttotal: 2m 16s\tremaining: 6m\n",
      "6298:\tlearn: 4.6859424\ttotal: 2m 16s\tremaining: 6m\n",
      "6299:\tlearn: 4.6856662\ttotal: 2m 16s\tremaining: 6m\n",
      "6300:\tlearn: 4.6853209\ttotal: 2m 16s\tremaining: 6m\n",
      "6301:\tlearn: 4.6848426\ttotal: 2m 16s\tremaining: 6m\n",
      "6302:\tlearn: 4.6846889\ttotal: 2m 16s\tremaining: 6m\n",
      "6303:\tlearn: 4.6844022\ttotal: 2m 16s\tremaining: 6m\n",
      "6304:\tlearn: 4.6840146\ttotal: 2m 16s\tremaining: 6m\n",
      "6305:\tlearn: 4.6833904\ttotal: 2m 16s\tremaining: 6m\n",
      "6306:\tlearn: 4.6831052\ttotal: 2m 16s\tremaining: 6m\n",
      "6307:\tlearn: 4.6826421\ttotal: 2m 16s\tremaining: 6m\n",
      "6308:\tlearn: 4.6822733\ttotal: 2m 16s\tremaining: 6m\n",
      "6309:\tlearn: 4.6822093\ttotal: 2m 16s\tremaining: 6m\n",
      "6310:\tlearn: 4.6818399\ttotal: 2m 16s\tremaining: 6m\n",
      "6311:\tlearn: 4.6814397\ttotal: 2m 16s\tremaining: 6m\n",
      "6312:\tlearn: 4.6811013\ttotal: 2m 16s\tremaining: 6m\n",
      "6313:\tlearn: 4.6806494\ttotal: 2m 16s\tremaining: 6m\n",
      "6314:\tlearn: 4.6803289\ttotal: 2m 16s\tremaining: 6m\n",
      "6315:\tlearn: 4.6800138\ttotal: 2m 16s\tremaining: 6m\n",
      "6316:\tlearn: 4.6797114\ttotal: 2m 16s\tremaining: 6m\n",
      "6317:\tlearn: 4.6791673\ttotal: 2m 16s\tremaining: 6m\n",
      "6318:\tlearn: 4.6786105\ttotal: 2m 16s\tremaining: 6m\n",
      "6319:\tlearn: 4.6780959\ttotal: 2m 16s\tremaining: 6m\n",
      "6320:\tlearn: 4.6777777\ttotal: 2m 16s\tremaining: 6m\n",
      "6321:\tlearn: 4.6774656\ttotal: 2m 16s\tremaining: 6m\n",
      "6322:\tlearn: 4.6770956\ttotal: 2m 16s\tremaining: 6m\n",
      "6323:\tlearn: 4.6768558\ttotal: 2m 16s\tremaining: 6m\n",
      "6324:\tlearn: 4.6765752\ttotal: 2m 16s\tremaining: 6m\n",
      "6325:\tlearn: 4.6759890\ttotal: 2m 16s\tremaining: 6m\n",
      "6326:\tlearn: 4.6758617\ttotal: 2m 16s\tremaining: 6m\n",
      "6327:\tlearn: 4.6754423\ttotal: 2m 16s\tremaining: 6m\n",
      "6328:\tlearn: 4.6751750\ttotal: 2m 16s\tremaining: 6m\n",
      "6329:\tlearn: 4.6748403\ttotal: 2m 16s\tremaining: 6m\n",
      "6330:\tlearn: 4.6748229\ttotal: 2m 16s\tremaining: 6m\n",
      "6331:\tlearn: 4.6745263\ttotal: 2m 16s\tremaining: 6m\n",
      "6332:\tlearn: 4.6742623\ttotal: 2m 16s\tremaining: 6m\n",
      "6333:\tlearn: 4.6739541\ttotal: 2m 16s\tremaining: 5m 59s\n",
      "6334:\tlearn: 4.6734849\ttotal: 2m 16s\tremaining: 5m 59s\n",
      "6335:\tlearn: 4.6732780\ttotal: 2m 16s\tremaining: 5m 59s\n",
      "6336:\tlearn: 4.6730806\ttotal: 2m 16s\tremaining: 5m 59s\n",
      "6337:\tlearn: 4.6726919\ttotal: 2m 16s\tremaining: 5m 59s\n",
      "6338:\tlearn: 4.6718479\ttotal: 2m 16s\tremaining: 5m 59s\n",
      "6339:\tlearn: 4.6712424\ttotal: 2m 16s\tremaining: 5m 59s\n",
      "6340:\tlearn: 4.6707121\ttotal: 2m 16s\tremaining: 5m 59s\n",
      "6341:\tlearn: 4.6702954\ttotal: 2m 16s\tremaining: 5m 59s\n",
      "6342:\tlearn: 4.6699077\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6343:\tlearn: 4.6691580\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6344:\tlearn: 4.6687797\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6345:\tlearn: 4.6684125\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6346:\tlearn: 4.6682101\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6347:\tlearn: 4.6678028\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6348:\tlearn: 4.6676747\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6349:\tlearn: 4.6673066\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6350:\tlearn: 4.6668682\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6351:\tlearn: 4.6666848\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6352:\tlearn: 4.6662689\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6353:\tlearn: 4.6662433\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6354:\tlearn: 4.6658198\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6355:\tlearn: 4.6652827\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6356:\tlearn: 4.6650408\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6357:\tlearn: 4.6647104\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6358:\tlearn: 4.6642695\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6359:\tlearn: 4.6639480\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6360:\tlearn: 4.6636942\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6361:\tlearn: 4.6632739\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6362:\tlearn: 4.6629449\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6363:\tlearn: 4.6627061\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6364:\tlearn: 4.6622966\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6365:\tlearn: 4.6618970\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6366:\tlearn: 4.6613030\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6367:\tlearn: 4.6607364\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6368:\tlearn: 4.6604245\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6369:\tlearn: 4.6598985\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6370:\tlearn: 4.6593604\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6371:\tlearn: 4.6591034\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6372:\tlearn: 4.6587303\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6373:\tlearn: 4.6585332\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6374:\tlearn: 4.6582845\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6375:\tlearn: 4.6577917\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6376:\tlearn: 4.6574920\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6377:\tlearn: 4.6573468\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6378:\tlearn: 4.6570597\ttotal: 2m 17s\tremaining: 5m 59s\n",
      "6379:\tlearn: 4.6570464\ttotal: 2m 17s\tremaining: 5m 58s\n",
      "6380:\tlearn: 4.6567105\ttotal: 2m 17s\tremaining: 5m 58s\n",
      "6381:\tlearn: 4.6561995\ttotal: 2m 17s\tremaining: 5m 58s\n",
      "6382:\tlearn: 4.6560060\ttotal: 2m 17s\tremaining: 5m 58s\n",
      "6383:\tlearn: 4.6556202\ttotal: 2m 17s\tremaining: 5m 58s\n",
      "6384:\tlearn: 4.6552645\ttotal: 2m 17s\tremaining: 5m 58s\n",
      "6385:\tlearn: 4.6549846\ttotal: 2m 17s\tremaining: 5m 58s\n",
      "6386:\tlearn: 4.6544306\ttotal: 2m 17s\tremaining: 5m 58s\n",
      "6387:\tlearn: 4.6540409\ttotal: 2m 17s\tremaining: 5m 58s\n",
      "6388:\tlearn: 4.6536986\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6389:\tlearn: 4.6534634\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6390:\tlearn: 4.6534481\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6391:\tlearn: 4.6531120\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6392:\tlearn: 4.6527232\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6393:\tlearn: 4.6523146\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6394:\tlearn: 4.6519733\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6395:\tlearn: 4.6517400\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6396:\tlearn: 4.6516109\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6397:\tlearn: 4.6515338\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6398:\tlearn: 4.6511688\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6399:\tlearn: 4.6507426\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6400:\tlearn: 4.6503035\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6401:\tlearn: 4.6497526\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6402:\tlearn: 4.6491633\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6403:\tlearn: 4.6489363\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6404:\tlearn: 4.6485496\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6405:\tlearn: 4.6481707\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6406:\tlearn: 4.6477913\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6407:\tlearn: 4.6472294\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6408:\tlearn: 4.6467291\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6409:\tlearn: 4.6461482\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6410:\tlearn: 4.6457609\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6411:\tlearn: 4.6453829\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6412:\tlearn: 4.6450587\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6413:\tlearn: 4.6446166\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6414:\tlearn: 4.6442989\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6415:\tlearn: 4.6439174\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6416:\tlearn: 4.6434428\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6417:\tlearn: 4.6431784\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6418:\tlearn: 4.6429114\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6419:\tlearn: 4.6426198\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6420:\tlearn: 4.6422255\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6421:\tlearn: 4.6417429\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6422:\tlearn: 4.6412778\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6423:\tlearn: 4.6408232\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6424:\tlearn: 4.6403116\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6425:\tlearn: 4.6397411\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6426:\tlearn: 4.6393864\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6427:\tlearn: 4.6393748\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6428:\tlearn: 4.6389727\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6429:\tlearn: 4.6385782\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6430:\tlearn: 4.6381504\ttotal: 2m 18s\tremaining: 5m 58s\n",
      "6431:\tlearn: 4.6379217\ttotal: 2m 18s\tremaining: 5m 57s\n",
      "6432:\tlearn: 4.6377041\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6433:\tlearn: 4.6372678\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6434:\tlearn: 4.6369649\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6435:\tlearn: 4.6365605\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6436:\tlearn: 4.6359389\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6437:\tlearn: 4.6357469\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6438:\tlearn: 4.6353718\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6439:\tlearn: 4.6352215\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6440:\tlearn: 4.6348905\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6441:\tlearn: 4.6346248\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6442:\tlearn: 4.6342238\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6443:\tlearn: 4.6338249\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6444:\tlearn: 4.6335391\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6445:\tlearn: 4.6331252\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6446:\tlearn: 4.6328653\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6447:\tlearn: 4.6325921\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6448:\tlearn: 4.6323531\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6449:\tlearn: 4.6319164\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6450:\tlearn: 4.6315896\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6451:\tlearn: 4.6313302\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6452:\tlearn: 4.6309407\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6453:\tlearn: 4.6306876\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6454:\tlearn: 4.6301992\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6455:\tlearn: 4.6300134\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6456:\tlearn: 4.6296389\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6457:\tlearn: 4.6293878\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6458:\tlearn: 4.6290087\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6459:\tlearn: 4.6286370\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6460:\tlearn: 4.6284218\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6461:\tlearn: 4.6282100\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6462:\tlearn: 4.6276353\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6463:\tlearn: 4.6274579\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6464:\tlearn: 4.6273812\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6465:\tlearn: 4.6270710\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6466:\tlearn: 4.6268217\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6467:\tlearn: 4.6264919\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6468:\tlearn: 4.6258804\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6469:\tlearn: 4.6253003\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6470:\tlearn: 4.6250810\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6471:\tlearn: 4.6246860\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6472:\tlearn: 4.6243282\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6473:\tlearn: 4.6238577\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6474:\tlearn: 4.6235416\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6475:\tlearn: 4.6231060\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6476:\tlearn: 4.6226318\ttotal: 2m 19s\tremaining: 5m 57s\n",
      "6477:\tlearn: 4.6221213\ttotal: 2m 19s\tremaining: 5m 56s\n",
      "6478:\tlearn: 4.6216980\ttotal: 2m 19s\tremaining: 5m 56s\n",
      "6479:\tlearn: 4.6211502\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6480:\tlearn: 4.6208152\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6481:\tlearn: 4.6205315\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6482:\tlearn: 4.6199404\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6483:\tlearn: 4.6196336\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6484:\tlearn: 4.6190075\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6485:\tlearn: 4.6184141\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6486:\tlearn: 4.6181712\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6487:\tlearn: 4.6178942\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6488:\tlearn: 4.6173461\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6489:\tlearn: 4.6170085\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6490:\tlearn: 4.6167867\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6491:\tlearn: 4.6164371\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6492:\tlearn: 4.6159556\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6493:\tlearn: 4.6155105\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6494:\tlearn: 4.6149322\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6495:\tlearn: 4.6145987\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6496:\tlearn: 4.6142810\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6497:\tlearn: 4.6138863\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6498:\tlearn: 4.6135616\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6499:\tlearn: 4.6132776\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6500:\tlearn: 4.6127878\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6501:\tlearn: 4.6123807\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6502:\tlearn: 4.6119664\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6503:\tlearn: 4.6114320\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6504:\tlearn: 4.6110174\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6505:\tlearn: 4.6108154\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6506:\tlearn: 4.6104507\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6507:\tlearn: 4.6102207\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6508:\tlearn: 4.6099443\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6509:\tlearn: 4.6096581\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6510:\tlearn: 4.6091764\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6511:\tlearn: 4.6087957\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6512:\tlearn: 4.6084668\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6513:\tlearn: 4.6080344\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6514:\tlearn: 4.6080244\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6515:\tlearn: 4.6077233\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6516:\tlearn: 4.6073035\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6517:\tlearn: 4.6069635\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6518:\tlearn: 4.6066976\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6519:\tlearn: 4.6061884\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6520:\tlearn: 4.6057996\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6521:\tlearn: 4.6055800\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6522:\tlearn: 4.6052533\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6523:\tlearn: 4.6048135\ttotal: 2m 20s\tremaining: 5m 56s\n",
      "6524:\tlearn: 4.6042522\ttotal: 2m 21s\tremaining: 5m 56s\n",
      "6525:\tlearn: 4.6037957\ttotal: 2m 21s\tremaining: 5m 56s\n",
      "6526:\tlearn: 4.6036533\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6527:\tlearn: 4.6034431\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6528:\tlearn: 4.6030433\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6529:\tlearn: 4.6024430\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6530:\tlearn: 4.6018338\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6531:\tlearn: 4.6015705\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6532:\tlearn: 4.6013863\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6533:\tlearn: 4.6010447\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6534:\tlearn: 4.6004949\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6535:\tlearn: 4.5997789\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6536:\tlearn: 4.5993484\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6537:\tlearn: 4.5990035\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6538:\tlearn: 4.5985550\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6539:\tlearn: 4.5982512\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6540:\tlearn: 4.5979834\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6541:\tlearn: 4.5977872\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6542:\tlearn: 4.5975549\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6543:\tlearn: 4.5970720\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6544:\tlearn: 4.5965758\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6545:\tlearn: 4.5964115\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6546:\tlearn: 4.5958588\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6547:\tlearn: 4.5956589\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6548:\tlearn: 4.5953773\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6549:\tlearn: 4.5949982\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6550:\tlearn: 4.5945583\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6551:\tlearn: 4.5944232\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6552:\tlearn: 4.5940642\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6553:\tlearn: 4.5937403\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6554:\tlearn: 4.5933422\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6555:\tlearn: 4.5930625\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6556:\tlearn: 4.5927765\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6557:\tlearn: 4.5925644\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6558:\tlearn: 4.5924568\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6559:\tlearn: 4.5922808\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6560:\tlearn: 4.5919887\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6561:\tlearn: 4.5916996\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6562:\tlearn: 4.5914976\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6563:\tlearn: 4.5910972\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6564:\tlearn: 4.5910342\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6565:\tlearn: 4.5906218\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6566:\tlearn: 4.5903035\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6567:\tlearn: 4.5897453\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6568:\tlearn: 4.5895907\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6569:\tlearn: 4.5891876\ttotal: 2m 21s\tremaining: 5m 55s\n",
      "6570:\tlearn: 4.5888950\ttotal: 2m 21s\tremaining: 5m 54s\n",
      "6571:\tlearn: 4.5885716\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6572:\tlearn: 4.5882226\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6573:\tlearn: 4.5880383\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6574:\tlearn: 4.5878003\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6575:\tlearn: 4.5876173\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6576:\tlearn: 4.5872178\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6577:\tlearn: 4.5869354\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6578:\tlearn: 4.5865771\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6579:\tlearn: 4.5862148\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6580:\tlearn: 4.5861723\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6581:\tlearn: 4.5857860\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6582:\tlearn: 4.5855340\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6583:\tlearn: 4.5851624\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6584:\tlearn: 4.5848563\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6585:\tlearn: 4.5844374\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6586:\tlearn: 4.5840839\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6587:\tlearn: 4.5837681\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6588:\tlearn: 4.5834292\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6589:\tlearn: 4.5830060\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6590:\tlearn: 4.5827553\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6591:\tlearn: 4.5826250\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6592:\tlearn: 4.5823668\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6593:\tlearn: 4.5820418\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6594:\tlearn: 4.5817141\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6595:\tlearn: 4.5813795\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6596:\tlearn: 4.5810060\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6597:\tlearn: 4.5807009\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6598:\tlearn: 4.5803708\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6599:\tlearn: 4.5800201\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6600:\tlearn: 4.5797504\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6601:\tlearn: 4.5792268\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6602:\tlearn: 4.5789018\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6603:\tlearn: 4.5786853\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6604:\tlearn: 4.5785710\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6605:\tlearn: 4.5782925\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6606:\tlearn: 4.5778627\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6607:\tlearn: 4.5775481\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6608:\tlearn: 4.5772595\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6609:\tlearn: 4.5766329\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6610:\tlearn: 4.5763275\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6611:\tlearn: 4.5761947\ttotal: 2m 22s\tremaining: 5m 54s\n",
      "6612:\tlearn: 4.5759277\ttotal: 2m 22s\tremaining: 5m 53s\n",
      "6613:\tlearn: 4.5755132\ttotal: 2m 22s\tremaining: 5m 53s\n",
      "6614:\tlearn: 4.5752472\ttotal: 2m 22s\tremaining: 5m 53s\n",
      "6615:\tlearn: 4.5746728\ttotal: 2m 22s\tremaining: 5m 53s\n",
      "6616:\tlearn: 4.5744552\ttotal: 2m 22s\tremaining: 5m 53s\n",
      "6617:\tlearn: 4.5741335\ttotal: 2m 22s\tremaining: 5m 53s\n",
      "6618:\tlearn: 4.5737041\ttotal: 2m 22s\tremaining: 5m 53s\n",
      "6619:\tlearn: 4.5733880\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6620:\tlearn: 4.5727851\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6621:\tlearn: 4.5723764\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6622:\tlearn: 4.5720872\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6623:\tlearn: 4.5718432\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6624:\tlearn: 4.5713747\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6625:\tlearn: 4.5710318\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6626:\tlearn: 4.5707788\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6627:\tlearn: 4.5703743\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6628:\tlearn: 4.5698635\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6629:\tlearn: 4.5695762\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6630:\tlearn: 4.5691635\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6631:\tlearn: 4.5688139\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6632:\tlearn: 4.5684793\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6633:\tlearn: 4.5680193\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6634:\tlearn: 4.5676644\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6635:\tlearn: 4.5674736\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6636:\tlearn: 4.5672416\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6637:\tlearn: 4.5669906\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6638:\tlearn: 4.5666093\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6639:\tlearn: 4.5663550\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6640:\tlearn: 4.5660352\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6641:\tlearn: 4.5657852\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6642:\tlearn: 4.5654783\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6643:\tlearn: 4.5653610\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6644:\tlearn: 4.5650758\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6645:\tlearn: 4.5645726\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6646:\tlearn: 4.5643150\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6647:\tlearn: 4.5640217\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6648:\tlearn: 4.5636722\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6649:\tlearn: 4.5632036\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6650:\tlearn: 4.5627797\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6651:\tlearn: 4.5624292\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6652:\tlearn: 4.5620608\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6653:\tlearn: 4.5617680\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6654:\tlearn: 4.5612815\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6655:\tlearn: 4.5607295\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6656:\tlearn: 4.5602114\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6657:\tlearn: 4.5598399\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6658:\tlearn: 4.5596668\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6659:\tlearn: 4.5591149\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6660:\tlearn: 4.5591044\ttotal: 2m 23s\tremaining: 5m 53s\n",
      "6661:\tlearn: 4.5586865\ttotal: 2m 23s\tremaining: 5m 52s\n",
      "6662:\tlearn: 4.5582785\ttotal: 2m 23s\tremaining: 5m 52s\n",
      "6663:\tlearn: 4.5582687\ttotal: 2m 23s\tremaining: 5m 52s\n",
      "6664:\tlearn: 4.5578923\ttotal: 2m 23s\tremaining: 5m 52s\n",
      "6665:\tlearn: 4.5576652\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6666:\tlearn: 4.5575117\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6667:\tlearn: 4.5570889\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6668:\tlearn: 4.5565952\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6669:\tlearn: 4.5562628\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6670:\tlearn: 4.5560502\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6671:\tlearn: 4.5555662\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6672:\tlearn: 4.5552644\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6673:\tlearn: 4.5547705\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6674:\tlearn: 4.5545030\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6675:\tlearn: 4.5540786\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6676:\tlearn: 4.5536960\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6677:\tlearn: 4.5533446\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6678:\tlearn: 4.5529043\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6679:\tlearn: 4.5526942\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6680:\tlearn: 4.5525040\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6681:\tlearn: 4.5522777\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6682:\tlearn: 4.5519527\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6683:\tlearn: 4.5516126\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6684:\tlearn: 4.5512691\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6685:\tlearn: 4.5508254\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6686:\tlearn: 4.5503524\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6687:\tlearn: 4.5501200\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6688:\tlearn: 4.5499036\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6689:\tlearn: 4.5495619\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6690:\tlearn: 4.5490702\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6691:\tlearn: 4.5487586\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6692:\tlearn: 4.5483843\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6693:\tlearn: 4.5480406\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6694:\tlearn: 4.5474892\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6695:\tlearn: 4.5471676\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6696:\tlearn: 4.5468398\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6697:\tlearn: 4.5466370\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6698:\tlearn: 4.5463681\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6699:\tlearn: 4.5459904\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6700:\tlearn: 4.5456561\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6701:\tlearn: 4.5455328\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6702:\tlearn: 4.5453428\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6703:\tlearn: 4.5450310\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6704:\tlearn: 4.5447256\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6705:\tlearn: 4.5444984\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6706:\tlearn: 4.5441796\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6707:\tlearn: 4.5439945\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6708:\tlearn: 4.5436201\ttotal: 2m 24s\tremaining: 5m 52s\n",
      "6709:\tlearn: 4.5432745\ttotal: 2m 25s\tremaining: 5m 52s\n",
      "6710:\tlearn: 4.5430636\ttotal: 2m 25s\tremaining: 5m 52s\n",
      "6711:\tlearn: 4.5428662\ttotal: 2m 25s\tremaining: 5m 52s\n",
      "6712:\tlearn: 4.5425162\ttotal: 2m 25s\tremaining: 5m 52s\n",
      "6713:\tlearn: 4.5419536\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6714:\tlearn: 4.5415111\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6715:\tlearn: 4.5410082\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6716:\tlearn: 4.5406543\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6717:\tlearn: 4.5403414\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6718:\tlearn: 4.5400708\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6719:\tlearn: 4.5396050\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6720:\tlearn: 4.5393886\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6721:\tlearn: 4.5390067\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6722:\tlearn: 4.5387961\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6723:\tlearn: 4.5385805\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6724:\tlearn: 4.5381885\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6725:\tlearn: 4.5377554\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6726:\tlearn: 4.5373364\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6727:\tlearn: 4.5370333\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6728:\tlearn: 4.5367448\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6729:\tlearn: 4.5363358\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6730:\tlearn: 4.5360495\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6731:\tlearn: 4.5357238\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6732:\tlearn: 4.5353241\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6733:\tlearn: 4.5351863\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6734:\tlearn: 4.5348413\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6735:\tlearn: 4.5344370\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6736:\tlearn: 4.5341146\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6737:\tlearn: 4.5337683\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6738:\tlearn: 4.5334136\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6739:\tlearn: 4.5331169\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6740:\tlearn: 4.5327293\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6741:\tlearn: 4.5322088\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6742:\tlearn: 4.5318720\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6743:\tlearn: 4.5317696\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6744:\tlearn: 4.5315511\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6745:\tlearn: 4.5313057\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6746:\tlearn: 4.5310829\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6747:\tlearn: 4.5308961\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6748:\tlearn: 4.5305349\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6749:\tlearn: 4.5300354\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6750:\tlearn: 4.5296030\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6751:\tlearn: 4.5292890\ttotal: 2m 25s\tremaining: 5m 51s\n",
      "6752:\tlearn: 4.5289693\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6753:\tlearn: 4.5287330\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6754:\tlearn: 4.5283200\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6755:\tlearn: 4.5279631\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6756:\tlearn: 4.5279545\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6757:\tlearn: 4.5273750\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6758:\tlearn: 4.5269449\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6759:\tlearn: 4.5267923\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6760:\tlearn: 4.5265731\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6761:\tlearn: 4.5259871\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6762:\tlearn: 4.5256268\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6763:\tlearn: 4.5253624\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6764:\tlearn: 4.5248628\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6765:\tlearn: 4.5245219\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "6766:\tlearn: 4.5240547\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6767:\tlearn: 4.5236857\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6768:\tlearn: 4.5233949\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6769:\tlearn: 4.5232191\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6770:\tlearn: 4.5227670\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6771:\tlearn: 4.5225129\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6772:\tlearn: 4.5221279\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6773:\tlearn: 4.5219390\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6774:\tlearn: 4.5216561\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6775:\tlearn: 4.5215670\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6776:\tlearn: 4.5211738\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6777:\tlearn: 4.5207328\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6778:\tlearn: 4.5204210\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6779:\tlearn: 4.5200152\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6780:\tlearn: 4.5196168\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6781:\tlearn: 4.5194996\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6782:\tlearn: 4.5193240\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6783:\tlearn: 4.5190813\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6784:\tlearn: 4.5188281\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6785:\tlearn: 4.5185430\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6786:\tlearn: 4.5180666\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6787:\tlearn: 4.5175373\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6788:\tlearn: 4.5175270\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6789:\tlearn: 4.5171410\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6790:\tlearn: 4.5169442\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6791:\tlearn: 4.5166515\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6792:\tlearn: 4.5162887\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6793:\tlearn: 4.5159876\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6794:\tlearn: 4.5156547\ttotal: 2m 26s\tremaining: 5m 50s\n",
      "6795:\tlearn: 4.5153418\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6796:\tlearn: 4.5148003\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6797:\tlearn: 4.5145070\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6798:\tlearn: 4.5139709\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6799:\tlearn: 4.5137890\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6800:\tlearn: 4.5135147\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6801:\tlearn: 4.5132621\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6802:\tlearn: 4.5127382\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6803:\tlearn: 4.5122943\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6804:\tlearn: 4.5118665\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6805:\tlearn: 4.5114255\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6806:\tlearn: 4.5110336\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6807:\tlearn: 4.5106738\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6808:\tlearn: 4.5103109\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6809:\tlearn: 4.5099826\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6810:\tlearn: 4.5094569\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6811:\tlearn: 4.5092075\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6812:\tlearn: 4.5089985\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6813:\tlearn: 4.5087243\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6814:\tlearn: 4.5083390\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6815:\tlearn: 4.5078443\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6816:\tlearn: 4.5075808\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6817:\tlearn: 4.5073129\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6818:\tlearn: 4.5070384\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6819:\tlearn: 4.5066996\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6820:\tlearn: 4.5064872\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6821:\tlearn: 4.5061605\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6822:\tlearn: 4.5059833\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6823:\tlearn: 4.5057165\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6824:\tlearn: 4.5055907\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6825:\tlearn: 4.5054101\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6826:\tlearn: 4.5051125\ttotal: 2m 27s\tremaining: 5m 50s\n",
      "6827:\tlearn: 4.5049568\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6828:\tlearn: 4.5045878\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6829:\tlearn: 4.5041638\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6830:\tlearn: 4.5037602\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6831:\tlearn: 4.5033358\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6832:\tlearn: 4.5030709\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6833:\tlearn: 4.5024281\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6834:\tlearn: 4.5019822\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6835:\tlearn: 4.5016842\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6836:\tlearn: 4.5012758\ttotal: 2m 27s\tremaining: 5m 49s\n",
      "6837:\tlearn: 4.5008586\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6838:\tlearn: 4.5005955\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6839:\tlearn: 4.5003345\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6840:\tlearn: 4.5003237\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6841:\tlearn: 4.4997884\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6842:\tlearn: 4.4993615\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6843:\tlearn: 4.4991558\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6844:\tlearn: 4.4986186\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6845:\tlearn: 4.4982492\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6846:\tlearn: 4.4978924\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6847:\tlearn: 4.4976021\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6848:\tlearn: 4.4972252\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6849:\tlearn: 4.4968882\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6850:\tlearn: 4.4963415\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6851:\tlearn: 4.4960320\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6852:\tlearn: 4.4956000\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6853:\tlearn: 4.4954191\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6854:\tlearn: 4.4952562\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6855:\tlearn: 4.4951775\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6856:\tlearn: 4.4948096\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6857:\tlearn: 4.4944270\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6858:\tlearn: 4.4938860\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6859:\tlearn: 4.4935585\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6860:\tlearn: 4.4932460\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6861:\tlearn: 4.4928316\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6862:\tlearn: 4.4925844\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6863:\tlearn: 4.4923188\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6864:\tlearn: 4.4918746\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6865:\tlearn: 4.4915731\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6866:\tlearn: 4.4911596\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6867:\tlearn: 4.4907858\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6868:\tlearn: 4.4904716\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6869:\tlearn: 4.4901585\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6870:\tlearn: 4.4898614\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6871:\tlearn: 4.4895120\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6872:\tlearn: 4.4890147\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6873:\tlearn: 4.4887226\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6874:\tlearn: 4.4884533\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6875:\tlearn: 4.4879177\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6876:\tlearn: 4.4877246\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6877:\tlearn: 4.4872045\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6878:\tlearn: 4.4868484\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6879:\tlearn: 4.4866784\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "6880:\tlearn: 4.4864903\ttotal: 2m 29s\tremaining: 5m 49s\n",
      "6881:\tlearn: 4.4861259\ttotal: 2m 29s\tremaining: 5m 49s\n",
      "6882:\tlearn: 4.4857737\ttotal: 2m 29s\tremaining: 5m 49s\n",
      "6883:\tlearn: 4.4854658\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6884:\tlearn: 4.4851377\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6885:\tlearn: 4.4847976\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6886:\tlearn: 4.4846037\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6887:\tlearn: 4.4841400\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6888:\tlearn: 4.4838469\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6889:\tlearn: 4.4833086\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6890:\tlearn: 4.4829764\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6891:\tlearn: 4.4826318\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6892:\tlearn: 4.4824619\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6893:\tlearn: 4.4821278\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6894:\tlearn: 4.4817863\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6895:\tlearn: 4.4814548\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6896:\tlearn: 4.4811628\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6897:\tlearn: 4.4809308\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6898:\tlearn: 4.4807150\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6899:\tlearn: 4.4804262\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6900:\tlearn: 4.4799824\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6901:\tlearn: 4.4797244\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6902:\tlearn: 4.4793700\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6903:\tlearn: 4.4791372\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6904:\tlearn: 4.4788134\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6905:\tlearn: 4.4785117\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6906:\tlearn: 4.4779532\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6907:\tlearn: 4.4776094\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6908:\tlearn: 4.4774517\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6909:\tlearn: 4.4770030\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6910:\tlearn: 4.4769930\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6911:\tlearn: 4.4764782\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6912:\tlearn: 4.4760708\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6913:\tlearn: 4.4757856\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6914:\tlearn: 4.4754856\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6915:\tlearn: 4.4752723\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6916:\tlearn: 4.4746362\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6917:\tlearn: 4.4745335\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6918:\tlearn: 4.4743018\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6919:\tlearn: 4.4737928\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6920:\tlearn: 4.4734610\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6921:\tlearn: 4.4728745\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6922:\tlearn: 4.4725025\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "6923:\tlearn: 4.4719379\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6924:\tlearn: 4.4718034\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6925:\tlearn: 4.4714260\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6926:\tlearn: 4.4709386\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6927:\tlearn: 4.4705596\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6928:\tlearn: 4.4702708\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6929:\tlearn: 4.4700086\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6930:\tlearn: 4.4695964\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6931:\tlearn: 4.4692730\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6932:\tlearn: 4.4689740\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6933:\tlearn: 4.4686469\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6934:\tlearn: 4.4682708\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6935:\tlearn: 4.4679037\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6936:\tlearn: 4.4676837\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "6937:\tlearn: 4.4672760\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6938:\tlearn: 4.4669100\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6939:\tlearn: 4.4666048\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6940:\tlearn: 4.4662872\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6941:\tlearn: 4.4660527\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6942:\tlearn: 4.4657620\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6943:\tlearn: 4.4655956\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6944:\tlearn: 4.4653125\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6945:\tlearn: 4.4651232\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6946:\tlearn: 4.4648788\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6947:\tlearn: 4.4645561\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6948:\tlearn: 4.4642605\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6949:\tlearn: 4.4639366\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6950:\tlearn: 4.4634543\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6951:\tlearn: 4.4631734\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6952:\tlearn: 4.4627330\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6953:\tlearn: 4.4624499\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6954:\tlearn: 4.4622566\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6955:\tlearn: 4.4619642\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6956:\tlearn: 4.4615830\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6957:\tlearn: 4.4612197\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6958:\tlearn: 4.4609702\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6959:\tlearn: 4.4606805\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6960:\tlearn: 4.4602252\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6961:\tlearn: 4.4599808\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6962:\tlearn: 4.4596782\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6963:\tlearn: 4.4593321\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6964:\tlearn: 4.4591084\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6965:\tlearn: 4.4588054\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6966:\tlearn: 4.4584850\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6967:\tlearn: 4.4582039\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6968:\tlearn: 4.4579807\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6969:\tlearn: 4.4576624\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "6970:\tlearn: 4.4573488\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6971:\tlearn: 4.4569731\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6972:\tlearn: 4.4569634\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6973:\tlearn: 4.4567393\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6974:\tlearn: 4.4565353\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6975:\tlearn: 4.4562198\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6976:\tlearn: 4.4560040\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6977:\tlearn: 4.4556019\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6978:\tlearn: 4.4553540\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6979:\tlearn: 4.4550407\ttotal: 2m 31s\tremaining: 5m 47s\n",
      "6980:\tlearn: 4.4547922\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6981:\tlearn: 4.4544383\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6982:\tlearn: 4.4541138\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6983:\tlearn: 4.4539112\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6984:\tlearn: 4.4536716\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6985:\tlearn: 4.4533682\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6986:\tlearn: 4.4530254\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6987:\tlearn: 4.4526973\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6988:\tlearn: 4.4522385\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6989:\tlearn: 4.4517524\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6990:\tlearn: 4.4515010\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6991:\tlearn: 4.4512958\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6992:\tlearn: 4.4510609\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6993:\tlearn: 4.4508974\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6994:\tlearn: 4.4506348\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6995:\tlearn: 4.4504742\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6996:\tlearn: 4.4501353\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6997:\tlearn: 4.4500212\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6998:\tlearn: 4.4495379\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "6999:\tlearn: 4.4491871\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7000:\tlearn: 4.4486816\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7001:\tlearn: 4.4484249\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7002:\tlearn: 4.4480817\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7003:\tlearn: 4.4478058\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7004:\tlearn: 4.4474679\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7005:\tlearn: 4.4469091\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7006:\tlearn: 4.4466924\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7007:\tlearn: 4.4464877\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7008:\tlearn: 4.4461342\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7009:\tlearn: 4.4458434\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7010:\tlearn: 4.4456029\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7011:\tlearn: 4.4452577\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7012:\tlearn: 4.4447189\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7013:\tlearn: 4.4445969\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7014:\tlearn: 4.4444671\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7015:\tlearn: 4.4441260\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7016:\tlearn: 4.4439532\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7017:\tlearn: 4.4435508\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "7018:\tlearn: 4.4430857\ttotal: 2m 32s\tremaining: 5m 46s\n",
      "7019:\tlearn: 4.4428621\ttotal: 2m 32s\tremaining: 5m 46s\n",
      "7020:\tlearn: 4.4425052\ttotal: 2m 32s\tremaining: 5m 46s\n",
      "7021:\tlearn: 4.4422250\ttotal: 2m 32s\tremaining: 5m 46s\n",
      "7022:\tlearn: 4.4418996\ttotal: 2m 32s\tremaining: 5m 46s\n",
      "7023:\tlearn: 4.4415165\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7024:\tlearn: 4.4412229\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7025:\tlearn: 4.4408838\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7026:\tlearn: 4.4407088\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7027:\tlearn: 4.4402424\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7028:\tlearn: 4.4399001\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7029:\tlearn: 4.4395310\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7030:\tlearn: 4.4390453\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7031:\tlearn: 4.4386276\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7032:\tlearn: 4.4380703\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7033:\tlearn: 4.4377384\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7034:\tlearn: 4.4371592\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7035:\tlearn: 4.4368807\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7036:\tlearn: 4.4364823\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7037:\tlearn: 4.4361763\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7038:\tlearn: 4.4359650\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7039:\tlearn: 4.4355138\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7040:\tlearn: 4.4352164\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7041:\tlearn: 4.4352071\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7042:\tlearn: 4.4350306\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7043:\tlearn: 4.4347668\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7044:\tlearn: 4.4344202\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7045:\tlearn: 4.4341172\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7046:\tlearn: 4.4336429\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7047:\tlearn: 4.4332381\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7048:\tlearn: 4.4328885\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7049:\tlearn: 4.4326464\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7050:\tlearn: 4.4320212\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7051:\tlearn: 4.4317362\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7052:\tlearn: 4.4311765\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7053:\tlearn: 4.4308102\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7054:\tlearn: 4.4302932\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7055:\tlearn: 4.4301210\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7056:\tlearn: 4.4297213\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7057:\tlearn: 4.4293154\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7058:\tlearn: 4.4289305\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7059:\tlearn: 4.4288550\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7060:\tlearn: 4.4286524\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7061:\tlearn: 4.4284807\ttotal: 2m 32s\tremaining: 5m 45s\n",
      "7062:\tlearn: 4.4281475\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7063:\tlearn: 4.4276468\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7064:\tlearn: 4.4273837\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7065:\tlearn: 4.4268735\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7066:\tlearn: 4.4266433\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7067:\tlearn: 4.4262685\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7068:\tlearn: 4.4260246\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7069:\tlearn: 4.4257458\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7070:\tlearn: 4.4254425\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7071:\tlearn: 4.4253341\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7072:\tlearn: 4.4249649\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7073:\tlearn: 4.4248041\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "7074:\tlearn: 4.4245128\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7075:\tlearn: 4.4243296\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7076:\tlearn: 4.4239584\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7077:\tlearn: 4.4236051\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7078:\tlearn: 4.4233549\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7079:\tlearn: 4.4229291\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7080:\tlearn: 4.4224205\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7081:\tlearn: 4.4224102\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7082:\tlearn: 4.4221140\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7083:\tlearn: 4.4219962\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7084:\tlearn: 4.4218293\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7085:\tlearn: 4.4218170\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7086:\tlearn: 4.4214008\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7087:\tlearn: 4.4208946\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7088:\tlearn: 4.4205193\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7089:\tlearn: 4.4200995\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7090:\tlearn: 4.4196512\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7091:\tlearn: 4.4192388\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7092:\tlearn: 4.4190310\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7093:\tlearn: 4.4187720\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7094:\tlearn: 4.4182520\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7095:\tlearn: 4.4178372\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7096:\tlearn: 4.4173414\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7097:\tlearn: 4.4170504\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7098:\tlearn: 4.4167165\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7099:\tlearn: 4.4163671\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7100:\tlearn: 4.4159468\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7101:\tlearn: 4.4153428\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7102:\tlearn: 4.4149548\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7103:\tlearn: 4.4148035\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7104:\tlearn: 4.4144406\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "7105:\tlearn: 4.4141527\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7106:\tlearn: 4.4137133\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7107:\tlearn: 4.4134922\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7108:\tlearn: 4.4131407\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7109:\tlearn: 4.4127526\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7110:\tlearn: 4.4125304\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7111:\tlearn: 4.4121193\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7112:\tlearn: 4.4118394\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7113:\tlearn: 4.4114806\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7114:\tlearn: 4.4111549\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7115:\tlearn: 4.4107569\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7116:\tlearn: 4.4104294\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7117:\tlearn: 4.4100919\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7118:\tlearn: 4.4096982\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7119:\tlearn: 4.4094050\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7120:\tlearn: 4.4091653\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7121:\tlearn: 4.4088245\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7122:\tlearn: 4.4086796\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7123:\tlearn: 4.4083645\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7124:\tlearn: 4.4081000\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7125:\tlearn: 4.4078420\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7126:\tlearn: 4.4074544\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7127:\tlearn: 4.4072861\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7128:\tlearn: 4.4067571\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "7129:\tlearn: 4.4065373\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7130:\tlearn: 4.4061505\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7131:\tlearn: 4.4057923\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7132:\tlearn: 4.4055954\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7133:\tlearn: 4.4052723\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7134:\tlearn: 4.4048752\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7135:\tlearn: 4.4046043\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7136:\tlearn: 4.4041534\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7137:\tlearn: 4.4041423\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7138:\tlearn: 4.4038147\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7139:\tlearn: 4.4033479\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7140:\tlearn: 4.4028128\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7141:\tlearn: 4.4026335\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7142:\tlearn: 4.4023966\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7143:\tlearn: 4.4020104\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7144:\tlearn: 4.4017029\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7145:\tlearn: 4.4013099\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7146:\tlearn: 4.4010166\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7147:\tlearn: 4.4005692\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7148:\tlearn: 4.4003339\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "7149:\tlearn: 4.3999608\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7150:\tlearn: 4.3995225\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7151:\tlearn: 4.3993369\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7152:\tlearn: 4.3989759\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7153:\tlearn: 4.3986500\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7154:\tlearn: 4.3983892\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7155:\tlearn: 4.3980582\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7156:\tlearn: 4.3977288\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7157:\tlearn: 4.3974338\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7158:\tlearn: 4.3972652\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7159:\tlearn: 4.3970854\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7160:\tlearn: 4.3966532\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7161:\tlearn: 4.3966064\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7162:\tlearn: 4.3964101\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7163:\tlearn: 4.3962322\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7164:\tlearn: 4.3957635\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7165:\tlearn: 4.3956103\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7166:\tlearn: 4.3954149\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7167:\tlearn: 4.3950277\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7168:\tlearn: 4.3946013\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7169:\tlearn: 4.3941908\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7170:\tlearn: 4.3938852\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7171:\tlearn: 4.3935937\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7172:\tlearn: 4.3933523\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7173:\tlearn: 4.3929389\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7174:\tlearn: 4.3925355\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7175:\tlearn: 4.3921847\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7176:\tlearn: 4.3916994\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7177:\tlearn: 4.3914246\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7178:\tlearn: 4.3910561\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7179:\tlearn: 4.3907606\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7180:\tlearn: 4.3906061\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7181:\tlearn: 4.3902981\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7182:\tlearn: 4.3900223\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "7183:\tlearn: 4.3897699\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7184:\tlearn: 4.3893256\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7185:\tlearn: 4.3893147\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7186:\tlearn: 4.3891155\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7187:\tlearn: 4.3888212\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7188:\tlearn: 4.3886150\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7189:\tlearn: 4.3881689\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7190:\tlearn: 4.3879277\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7191:\tlearn: 4.3875828\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7192:\tlearn: 4.3872090\ttotal: 2m 35s\tremaining: 5m 42s\n",
      "7193:\tlearn: 4.3868934\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7194:\tlearn: 4.3866162\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7195:\tlearn: 4.3861448\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7196:\tlearn: 4.3857072\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7197:\tlearn: 4.3853339\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7198:\tlearn: 4.3849010\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7199:\tlearn: 4.3845056\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7200:\tlearn: 4.3842355\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7201:\tlearn: 4.3838961\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7202:\tlearn: 4.3836691\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7203:\tlearn: 4.3833118\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7204:\tlearn: 4.3829971\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7205:\tlearn: 4.3826491\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7206:\tlearn: 4.3824877\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7207:\tlearn: 4.3821356\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7208:\tlearn: 4.3817502\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7209:\tlearn: 4.3814453\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7210:\tlearn: 4.3808416\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7211:\tlearn: 4.3805970\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7212:\tlearn: 4.3802922\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7213:\tlearn: 4.3798957\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7214:\tlearn: 4.3798838\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7215:\tlearn: 4.3796162\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7216:\tlearn: 4.3793969\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7217:\tlearn: 4.3792692\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7218:\tlearn: 4.3787409\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7219:\tlearn: 4.3785156\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7220:\tlearn: 4.3781450\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7221:\tlearn: 4.3779805\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7222:\tlearn: 4.3777295\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7223:\tlearn: 4.3774121\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7224:\tlearn: 4.3771239\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7225:\tlearn: 4.3766183\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7226:\tlearn: 4.3762608\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7227:\tlearn: 4.3760431\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7228:\tlearn: 4.3756689\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7229:\tlearn: 4.3753247\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7230:\tlearn: 4.3751768\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7231:\tlearn: 4.3749377\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7232:\tlearn: 4.3748542\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7233:\tlearn: 4.3745271\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "7234:\tlearn: 4.3743091\ttotal: 2m 36s\tremaining: 5m 41s\n",
      "7235:\tlearn: 4.3741814\ttotal: 2m 36s\tremaining: 5m 41s\n",
      "7236:\tlearn: 4.3740788\ttotal: 2m 36s\tremaining: 5m 41s\n",
      "7237:\tlearn: 4.3736666\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7238:\tlearn: 4.3733577\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7239:\tlearn: 4.3731040\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7240:\tlearn: 4.3726042\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7241:\tlearn: 4.3721463\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7242:\tlearn: 4.3718901\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7243:\tlearn: 4.3715455\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7244:\tlearn: 4.3711949\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7245:\tlearn: 4.3708351\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7246:\tlearn: 4.3706254\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7247:\tlearn: 4.3704168\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7248:\tlearn: 4.3698941\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7249:\tlearn: 4.3692902\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7250:\tlearn: 4.3689104\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7251:\tlearn: 4.3682384\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7252:\tlearn: 4.3677716\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7253:\tlearn: 4.3674035\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7254:\tlearn: 4.3668618\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7255:\tlearn: 4.3664570\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7256:\tlearn: 4.3663276\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7257:\tlearn: 4.3660130\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7258:\tlearn: 4.3655321\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7259:\tlearn: 4.3653203\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7260:\tlearn: 4.3649768\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7261:\tlearn: 4.3645966\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7262:\tlearn: 4.3641838\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7263:\tlearn: 4.3638922\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7264:\tlearn: 4.3635671\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7265:\tlearn: 4.3633744\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7266:\tlearn: 4.3627072\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7267:\tlearn: 4.3625123\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7268:\tlearn: 4.3621092\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7269:\tlearn: 4.3618406\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7270:\tlearn: 4.3615619\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7271:\tlearn: 4.3614012\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7272:\tlearn: 4.3611653\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7273:\tlearn: 4.3607347\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7274:\tlearn: 4.3603674\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7275:\tlearn: 4.3601041\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7276:\tlearn: 4.3597543\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7277:\tlearn: 4.3595371\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7278:\tlearn: 4.3592558\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "7279:\tlearn: 4.3587119\ttotal: 2m 38s\tremaining: 5m 41s\n",
      "7280:\tlearn: 4.3584947\ttotal: 2m 38s\tremaining: 5m 41s\n",
      "7281:\tlearn: 4.3581991\ttotal: 2m 38s\tremaining: 5m 41s\n",
      "7282:\tlearn: 4.3577187\ttotal: 2m 38s\tremaining: 5m 41s\n",
      "7283:\tlearn: 4.3575109\ttotal: 2m 38s\tremaining: 5m 41s\n",
      "7284:\tlearn: 4.3573210\ttotal: 2m 38s\tremaining: 5m 41s\n",
      "7285:\tlearn: 4.3570978\ttotal: 2m 38s\tremaining: 5m 41s\n",
      "7286:\tlearn: 4.3569675\ttotal: 2m 38s\tremaining: 5m 41s\n",
      "7287:\tlearn: 4.3565577\ttotal: 2m 38s\tremaining: 5m 41s\n",
      "7288:\tlearn: 4.3561092\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7289:\tlearn: 4.3558952\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7290:\tlearn: 4.3555218\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7291:\tlearn: 4.3552047\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7292:\tlearn: 4.3548152\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7293:\tlearn: 4.3541687\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7294:\tlearn: 4.3537236\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7295:\tlearn: 4.3532372\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7296:\tlearn: 4.3530276\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7297:\tlearn: 4.3526899\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7298:\tlearn: 4.3523140\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7299:\tlearn: 4.3520323\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7300:\tlearn: 4.3518278\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7301:\tlearn: 4.3515915\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7302:\tlearn: 4.3511606\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7303:\tlearn: 4.3506758\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7304:\tlearn: 4.3503394\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7305:\tlearn: 4.3500109\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7306:\tlearn: 4.3497290\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7307:\tlearn: 4.3492127\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7308:\tlearn: 4.3489606\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7309:\tlearn: 4.3485448\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7310:\tlearn: 4.3481602\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7311:\tlearn: 4.3477842\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7312:\tlearn: 4.3475766\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7313:\tlearn: 4.3472157\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7314:\tlearn: 4.3468436\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7315:\tlearn: 4.3464448\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7316:\tlearn: 4.3459879\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7317:\tlearn: 4.3457458\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7318:\tlearn: 4.3454886\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7319:\tlearn: 4.3452316\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7320:\tlearn: 4.3447883\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7321:\tlearn: 4.3445610\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7322:\tlearn: 4.3442291\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7323:\tlearn: 4.3437522\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "7324:\tlearn: 4.3435056\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7325:\tlearn: 4.3432916\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7326:\tlearn: 4.3429476\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7327:\tlearn: 4.3426464\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7328:\tlearn: 4.3423687\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7329:\tlearn: 4.3423578\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7330:\tlearn: 4.3419715\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7331:\tlearn: 4.3415775\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7332:\tlearn: 4.3410691\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7333:\tlearn: 4.3407418\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7334:\tlearn: 4.3404750\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7335:\tlearn: 4.3401516\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "7336:\tlearn: 4.3397704\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7337:\tlearn: 4.3394028\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7338:\tlearn: 4.3392992\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7339:\tlearn: 4.3392837\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7340:\tlearn: 4.3388545\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7341:\tlearn: 4.3387227\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7342:\tlearn: 4.3387133\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7343:\tlearn: 4.3384149\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7344:\tlearn: 4.3380649\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7345:\tlearn: 4.3376665\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7346:\tlearn: 4.3373524\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7347:\tlearn: 4.3368857\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7348:\tlearn: 4.3365921\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7349:\tlearn: 4.3359079\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7350:\tlearn: 4.3357356\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7351:\tlearn: 4.3353320\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7352:\tlearn: 4.3350416\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7353:\tlearn: 4.3347902\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7354:\tlearn: 4.3344824\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7355:\tlearn: 4.3340793\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7356:\tlearn: 4.3338433\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7357:\tlearn: 4.3335392\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7358:\tlearn: 4.3333024\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7359:\tlearn: 4.3332070\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7360:\tlearn: 4.3327916\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7361:\tlearn: 4.3325875\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7362:\tlearn: 4.3323516\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7363:\tlearn: 4.3321100\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7364:\tlearn: 4.3319064\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7365:\tlearn: 4.3316188\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7366:\tlearn: 4.3313187\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7367:\tlearn: 4.3309441\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7368:\tlearn: 4.3305996\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7369:\tlearn: 4.3303300\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7370:\tlearn: 4.3300433\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "7371:\tlearn: 4.3297202\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7372:\tlearn: 4.3292338\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7373:\tlearn: 4.3287954\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7374:\tlearn: 4.3284075\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7375:\tlearn: 4.3283231\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7376:\tlearn: 4.3278438\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7377:\tlearn: 4.3275483\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7378:\tlearn: 4.3274744\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7379:\tlearn: 4.3272271\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7380:\tlearn: 4.3267796\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7381:\tlearn: 4.3263326\ttotal: 2m 40s\tremaining: 5m 39s\n",
      "7382:\tlearn: 4.3261158\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7383:\tlearn: 4.3257175\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7384:\tlearn: 4.3255072\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7385:\tlearn: 4.3251778\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7386:\tlearn: 4.3249315\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7387:\tlearn: 4.3247416\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7388:\tlearn: 4.3244705\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7389:\tlearn: 4.3240505\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7390:\tlearn: 4.3235335\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7391:\tlearn: 4.3230924\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7392:\tlearn: 4.3227795\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7393:\tlearn: 4.3222576\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7394:\tlearn: 4.3217483\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7395:\tlearn: 4.3212748\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7396:\tlearn: 4.3212654\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7397:\tlearn: 4.3209961\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7398:\tlearn: 4.3208128\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7399:\tlearn: 4.3204225\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7400:\tlearn: 4.3200306\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7401:\tlearn: 4.3197408\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7402:\tlearn: 4.3193799\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7403:\tlearn: 4.3189979\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7404:\tlearn: 4.3185249\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7405:\tlearn: 4.3183538\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7406:\tlearn: 4.3180451\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7407:\tlearn: 4.3178084\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7408:\tlearn: 4.3173856\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7409:\tlearn: 4.3169497\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7410:\tlearn: 4.3167318\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7411:\tlearn: 4.3163042\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7412:\tlearn: 4.3161521\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7413:\tlearn: 4.3157958\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7414:\tlearn: 4.3154715\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7415:\tlearn: 4.3150245\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "7416:\tlearn: 4.3145695\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7417:\tlearn: 4.3143848\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7418:\tlearn: 4.3141609\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7419:\tlearn: 4.3138845\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7420:\tlearn: 4.3137091\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7421:\tlearn: 4.3134272\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7422:\tlearn: 4.3129312\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7423:\tlearn: 4.3128357\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7424:\tlearn: 4.3124925\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7425:\tlearn: 4.3120532\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7426:\tlearn: 4.3116878\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7427:\tlearn: 4.3114238\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7428:\tlearn: 4.3112025\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7429:\tlearn: 4.3108550\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7430:\tlearn: 4.3105292\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7431:\tlearn: 4.3102622\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7432:\tlearn: 4.3098801\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7433:\tlearn: 4.3095389\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7434:\tlearn: 4.3091439\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7435:\tlearn: 4.3087782\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7436:\tlearn: 4.3082612\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7437:\tlearn: 4.3080974\ttotal: 2m 41s\tremaining: 5m 38s\n",
      "7438:\tlearn: 4.3078466\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7439:\tlearn: 4.3076344\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7440:\tlearn: 4.3072393\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7441:\tlearn: 4.3066353\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7442:\tlearn: 4.3059785\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7443:\tlearn: 4.3056349\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7444:\tlearn: 4.3053241\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7445:\tlearn: 4.3050205\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7446:\tlearn: 4.3050119\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7447:\tlearn: 4.3044776\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7448:\tlearn: 4.3042304\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7449:\tlearn: 4.3039255\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7450:\tlearn: 4.3038230\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7451:\tlearn: 4.3035306\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7452:\tlearn: 4.3032275\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7453:\tlearn: 4.3030041\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7454:\tlearn: 4.3027995\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7455:\tlearn: 4.3027925\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7456:\tlearn: 4.3024250\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "7457:\tlearn: 4.3021909\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7458:\tlearn: 4.3020498\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7459:\tlearn: 4.3017431\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7460:\tlearn: 4.3013765\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7461:\tlearn: 4.3010032\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7462:\tlearn: 4.3006566\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7463:\tlearn: 4.3006219\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7464:\tlearn: 4.3002669\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7465:\tlearn: 4.3000543\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7466:\tlearn: 4.2997347\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7467:\tlearn: 4.2994177\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7468:\tlearn: 4.2991027\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7469:\tlearn: 4.2987509\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7470:\tlearn: 4.2985177\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7471:\tlearn: 4.2981418\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7472:\tlearn: 4.2979852\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7473:\tlearn: 4.2975210\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7474:\tlearn: 4.2968450\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7475:\tlearn: 4.2965898\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7476:\tlearn: 4.2964411\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7477:\tlearn: 4.2962270\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7478:\tlearn: 4.2958977\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7479:\tlearn: 4.2955600\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7480:\tlearn: 4.2953953\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7481:\tlearn: 4.2950392\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7482:\tlearn: 4.2948024\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7483:\tlearn: 4.2945026\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7484:\tlearn: 4.2941735\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7485:\tlearn: 4.2940146\ttotal: 2m 42s\tremaining: 5m 37s\n",
      "7486:\tlearn: 4.2937645\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7487:\tlearn: 4.2931750\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7488:\tlearn: 4.2929697\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7489:\tlearn: 4.2928561\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7490:\tlearn: 4.2922917\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7491:\tlearn: 4.2919724\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7492:\tlearn: 4.2917140\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7493:\tlearn: 4.2914331\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7494:\tlearn: 4.2911119\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7495:\tlearn: 4.2909493\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7496:\tlearn: 4.2905954\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7497:\tlearn: 4.2902344\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7498:\tlearn: 4.2898740\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7499:\tlearn: 4.2896821\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7500:\tlearn: 4.2894141\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7501:\tlearn: 4.2891793\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "7502:\tlearn: 4.2888174\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7503:\tlearn: 4.2885148\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7504:\tlearn: 4.2883379\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7505:\tlearn: 4.2881616\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7506:\tlearn: 4.2878872\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7507:\tlearn: 4.2875963\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7508:\tlearn: 4.2872887\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7509:\tlearn: 4.2870839\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7510:\tlearn: 4.2866987\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7511:\tlearn: 4.2861634\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7512:\tlearn: 4.2859175\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7513:\tlearn: 4.2856665\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7514:\tlearn: 4.2854164\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7515:\tlearn: 4.2851301\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7516:\tlearn: 4.2846769\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7517:\tlearn: 4.2843923\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7518:\tlearn: 4.2841628\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7519:\tlearn: 4.2836903\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7520:\tlearn: 4.2834123\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7521:\tlearn: 4.2830532\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7522:\tlearn: 4.2826306\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7523:\tlearn: 4.2822741\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7524:\tlearn: 4.2818444\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7525:\tlearn: 4.2817649\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7526:\tlearn: 4.2814830\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7527:\tlearn: 4.2813415\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7528:\tlearn: 4.2810930\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7529:\tlearn: 4.2808474\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7530:\tlearn: 4.2803478\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7531:\tlearn: 4.2800140\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7532:\tlearn: 4.2797774\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7533:\tlearn: 4.2794950\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7534:\tlearn: 4.2792087\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7535:\tlearn: 4.2787172\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7536:\tlearn: 4.2784726\ttotal: 2m 43s\tremaining: 5m 36s\n",
      "7537:\tlearn: 4.2779971\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7538:\tlearn: 4.2778914\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7539:\tlearn: 4.2774816\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7540:\tlearn: 4.2772574\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7541:\tlearn: 4.2771578\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7542:\tlearn: 4.2766864\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7543:\tlearn: 4.2764044\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7544:\tlearn: 4.2762077\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7545:\tlearn: 4.2758471\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7546:\tlearn: 4.2755386\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7547:\tlearn: 4.2753511\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7548:\tlearn: 4.2749378\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7549:\tlearn: 4.2747200\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7550:\tlearn: 4.2740466\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7551:\tlearn: 4.2737240\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7552:\tlearn: 4.2734770\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7553:\tlearn: 4.2732894\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7554:\tlearn: 4.2730488\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7555:\tlearn: 4.2730370\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7556:\tlearn: 4.2727362\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7557:\tlearn: 4.2725488\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7558:\tlearn: 4.2722500\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7559:\tlearn: 4.2720164\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7560:\tlearn: 4.2716864\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7561:\tlearn: 4.2714781\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7562:\tlearn: 4.2710615\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7563:\tlearn: 4.2708773\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7564:\tlearn: 4.2705726\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7565:\tlearn: 4.2702668\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7566:\tlearn: 4.2699249\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7567:\tlearn: 4.2697261\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7568:\tlearn: 4.2693551\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7569:\tlearn: 4.2690578\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7570:\tlearn: 4.2685775\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7571:\tlearn: 4.2683425\ttotal: 2m 44s\tremaining: 5m 36s\n",
      "7572:\tlearn: 4.2679852\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7573:\tlearn: 4.2675985\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7574:\tlearn: 4.2674894\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7575:\tlearn: 4.2671797\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7576:\tlearn: 4.2668763\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7577:\tlearn: 4.2667168\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7578:\tlearn: 4.2665108\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7579:\tlearn: 4.2662656\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7580:\tlearn: 4.2659393\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7581:\tlearn: 4.2655459\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7582:\tlearn: 4.2652158\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7583:\tlearn: 4.2647926\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "7584:\tlearn: 4.2646691\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7585:\tlearn: 4.2643920\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7586:\tlearn: 4.2641883\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7587:\tlearn: 4.2638805\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7588:\tlearn: 4.2633498\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7589:\tlearn: 4.2629193\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7590:\tlearn: 4.2624996\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7591:\tlearn: 4.2623181\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7592:\tlearn: 4.2622093\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7593:\tlearn: 4.2620041\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7594:\tlearn: 4.2618147\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7595:\tlearn: 4.2614810\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7596:\tlearn: 4.2612961\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7597:\tlearn: 4.2609717\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7598:\tlearn: 4.2607524\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7599:\tlearn: 4.2603493\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7600:\tlearn: 4.2600536\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7601:\tlearn: 4.2597092\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7602:\tlearn: 4.2592674\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7603:\tlearn: 4.2588412\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7604:\tlearn: 4.2585227\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7605:\tlearn: 4.2581954\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7606:\tlearn: 4.2579444\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7607:\tlearn: 4.2577007\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7608:\tlearn: 4.2575340\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7609:\tlearn: 4.2572531\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7610:\tlearn: 4.2569856\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7611:\tlearn: 4.2567179\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7612:\tlearn: 4.2564907\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7613:\tlearn: 4.2562069\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7614:\tlearn: 4.2559604\ttotal: 2m 45s\tremaining: 5m 35s\n",
      "7615:\tlearn: 4.2557014\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7616:\tlearn: 4.2554682\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7617:\tlearn: 4.2552013\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7618:\tlearn: 4.2548179\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7619:\tlearn: 4.2547556\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7620:\tlearn: 4.2544252\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7621:\tlearn: 4.2541153\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7622:\tlearn: 4.2539345\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7623:\tlearn: 4.2536197\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7624:\tlearn: 4.2533091\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7625:\tlearn: 4.2530794\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7626:\tlearn: 4.2526578\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7627:\tlearn: 4.2524799\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7628:\tlearn: 4.2524706\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7629:\tlearn: 4.2521388\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7630:\tlearn: 4.2516895\ttotal: 2m 46s\tremaining: 5m 35s\n",
      "7631:\tlearn: 4.2514233\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7632:\tlearn: 4.2510688\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7633:\tlearn: 4.2510459\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7634:\tlearn: 4.2507331\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7635:\tlearn: 4.2503237\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7636:\tlearn: 4.2500686\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7637:\tlearn: 4.2496825\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7638:\tlearn: 4.2494113\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7639:\tlearn: 4.2492082\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7640:\tlearn: 4.2488524\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7641:\tlearn: 4.2485710\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7642:\tlearn: 4.2481303\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7643:\tlearn: 4.2478628\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7644:\tlearn: 4.2475792\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7645:\tlearn: 4.2471609\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7646:\tlearn: 4.2467017\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7647:\tlearn: 4.2464757\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7648:\tlearn: 4.2461477\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7649:\tlearn: 4.2458380\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7650:\tlearn: 4.2455193\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7651:\tlearn: 4.2452689\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7652:\tlearn: 4.2451438\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7653:\tlearn: 4.2448242\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7654:\tlearn: 4.2445462\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7655:\tlearn: 4.2441885\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7656:\tlearn: 4.2440150\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7657:\tlearn: 4.2436272\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7658:\tlearn: 4.2433029\ttotal: 2m 46s\tremaining: 5m 34s\n",
      "7659:\tlearn: 4.2430624\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7660:\tlearn: 4.2428334\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7661:\tlearn: 4.2423904\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7662:\tlearn: 4.2421219\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7663:\tlearn: 4.2418603\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7664:\tlearn: 4.2415061\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7665:\tlearn: 4.2414987\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7666:\tlearn: 4.2412095\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7667:\tlearn: 4.2406949\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7668:\tlearn: 4.2405860\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7669:\tlearn: 4.2405770\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7670:\tlearn: 4.2403779\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7671:\tlearn: 4.2402114\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7672:\tlearn: 4.2400084\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7673:\tlearn: 4.2397752\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7674:\tlearn: 4.2393738\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7675:\tlearn: 4.2389794\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7676:\tlearn: 4.2385300\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7677:\tlearn: 4.2385155\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7678:\tlearn: 4.2382197\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7679:\tlearn: 4.2379977\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7680:\tlearn: 4.2376621\ttotal: 2m 47s\tremaining: 5m 34s\n",
      "7681:\tlearn: 4.2373589\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7682:\tlearn: 4.2372464\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7683:\tlearn: 4.2372378\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7684:\tlearn: 4.2369966\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7685:\tlearn: 4.2367363\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7686:\tlearn: 4.2363110\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7687:\tlearn: 4.2358699\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7688:\tlearn: 4.2355821\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7689:\tlearn: 4.2353022\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7690:\tlearn: 4.2348503\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7691:\tlearn: 4.2345822\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7692:\tlearn: 4.2342347\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7693:\tlearn: 4.2339545\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7694:\tlearn: 4.2336917\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7695:\tlearn: 4.2333797\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7696:\tlearn: 4.2330879\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7697:\tlearn: 4.2327862\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7698:\tlearn: 4.2324799\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7699:\tlearn: 4.2320521\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7700:\tlearn: 4.2319004\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7701:\tlearn: 4.2316380\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7702:\tlearn: 4.2313200\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7703:\tlearn: 4.2310314\ttotal: 2m 47s\tremaining: 5m 33s\n",
      "7704:\tlearn: 4.2306427\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7705:\tlearn: 4.2305160\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7706:\tlearn: 4.2299247\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7707:\tlearn: 4.2295555\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7708:\tlearn: 4.2291887\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7709:\tlearn: 4.2290277\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7710:\tlearn: 4.2288421\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7711:\tlearn: 4.2286772\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7712:\tlearn: 4.2284300\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7713:\tlearn: 4.2282010\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7714:\tlearn: 4.2279936\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7715:\tlearn: 4.2277023\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7716:\tlearn: 4.2273110\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7717:\tlearn: 4.2273020\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7718:\tlearn: 4.2270899\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7719:\tlearn: 4.2267706\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7720:\tlearn: 4.2265004\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7721:\tlearn: 4.2261361\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7722:\tlearn: 4.2259648\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7723:\tlearn: 4.2258274\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7724:\tlearn: 4.2254090\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7725:\tlearn: 4.2251808\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7726:\tlearn: 4.2250032\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7727:\tlearn: 4.2248415\ttotal: 2m 48s\tremaining: 5m 33s\n",
      "7728:\tlearn: 4.2246471\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7729:\tlearn: 4.2243516\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7730:\tlearn: 4.2240304\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7731:\tlearn: 4.2236764\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7732:\tlearn: 4.2233082\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7733:\tlearn: 4.2229985\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7734:\tlearn: 4.2228238\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7735:\tlearn: 4.2225822\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7736:\tlearn: 4.2222900\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7737:\tlearn: 4.2218862\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7738:\tlearn: 4.2215314\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7739:\tlearn: 4.2212516\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7740:\tlearn: 4.2209941\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7741:\tlearn: 4.2208211\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7742:\tlearn: 4.2205335\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7743:\tlearn: 4.2201548\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7744:\tlearn: 4.2198270\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7745:\tlearn: 4.2195299\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7746:\tlearn: 4.2192843\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7747:\tlearn: 4.2190948\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7748:\tlearn: 4.2187405\ttotal: 2m 48s\tremaining: 5m 32s\n",
      "7749:\tlearn: 4.2184771\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7750:\tlearn: 4.2181192\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7751:\tlearn: 4.2178844\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7752:\tlearn: 4.2175445\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7753:\tlearn: 4.2170395\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7754:\tlearn: 4.2168091\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7755:\tlearn: 4.2162790\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7756:\tlearn: 4.2159843\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7757:\tlearn: 4.2157380\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7758:\tlearn: 4.2154316\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7759:\tlearn: 4.2150132\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7760:\tlearn: 4.2145682\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7761:\tlearn: 4.2142401\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7762:\tlearn: 4.2139319\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7763:\tlearn: 4.2136663\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7764:\tlearn: 4.2133746\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7765:\tlearn: 4.2130694\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7766:\tlearn: 4.2128631\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7767:\tlearn: 4.2127812\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7768:\tlearn: 4.2124719\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7769:\tlearn: 4.2122431\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7770:\tlearn: 4.2119552\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7771:\tlearn: 4.2117158\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7772:\tlearn: 4.2115121\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7773:\tlearn: 4.2112750\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7774:\tlearn: 4.2108701\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7775:\tlearn: 4.2106145\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7776:\tlearn: 4.2104252\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7777:\tlearn: 4.2100618\ttotal: 2m 49s\tremaining: 5m 32s\n",
      "7778:\tlearn: 4.2098853\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7779:\tlearn: 4.2094601\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7780:\tlearn: 4.2089274\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7781:\tlearn: 4.2086310\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7782:\tlearn: 4.2083552\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7783:\tlearn: 4.2080794\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7784:\tlearn: 4.2076350\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7785:\tlearn: 4.2073268\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7786:\tlearn: 4.2071483\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7787:\tlearn: 4.2069290\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7788:\tlearn: 4.2065769\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7789:\tlearn: 4.2061736\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7790:\tlearn: 4.2058868\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7791:\tlearn: 4.2055868\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7792:\tlearn: 4.2053212\ttotal: 2m 49s\tremaining: 5m 31s\n",
      "7793:\tlearn: 4.2049766\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7794:\tlearn: 4.2047402\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7795:\tlearn: 4.2043034\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7796:\tlearn: 4.2040647\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7797:\tlearn: 4.2036963\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7798:\tlearn: 4.2033340\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7799:\tlearn: 4.2031643\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7800:\tlearn: 4.2027921\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7801:\tlearn: 4.2024797\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7802:\tlearn: 4.2022065\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7803:\tlearn: 4.2019327\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7804:\tlearn: 4.2017041\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7805:\tlearn: 4.2013789\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7806:\tlearn: 4.2009857\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7807:\tlearn: 4.2004824\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7808:\tlearn: 4.1999761\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7809:\tlearn: 4.1997129\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7810:\tlearn: 4.1994100\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7811:\tlearn: 4.1991107\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7812:\tlearn: 4.1989318\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7813:\tlearn: 4.1987220\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7814:\tlearn: 4.1985314\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7815:\tlearn: 4.1982831\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7816:\tlearn: 4.1981543\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7817:\tlearn: 4.1979146\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7818:\tlearn: 4.1979052\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7819:\tlearn: 4.1975510\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7820:\tlearn: 4.1974231\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7821:\tlearn: 4.1970504\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7822:\tlearn: 4.1965885\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7823:\tlearn: 4.1963347\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7824:\tlearn: 4.1959117\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7825:\tlearn: 4.1957408\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7826:\tlearn: 4.1956406\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7827:\tlearn: 4.1954726\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "7828:\tlearn: 4.1952392\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "7829:\tlearn: 4.1948766\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "7830:\tlearn: 4.1945496\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "7831:\tlearn: 4.1942288\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "7832:\tlearn: 4.1939009\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "7833:\tlearn: 4.1937472\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "7834:\tlearn: 4.1935504\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "7835:\tlearn: 4.1933164\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "7836:\tlearn: 4.1930673\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "7837:\tlearn: 4.1926121\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7838:\tlearn: 4.1921857\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7839:\tlearn: 4.1919009\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7840:\tlearn: 4.1916209\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7841:\tlearn: 4.1913481\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7842:\tlearn: 4.1911119\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7843:\tlearn: 4.1908593\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7844:\tlearn: 4.1902633\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7845:\tlearn: 4.1899556\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7846:\tlearn: 4.1896132\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7847:\tlearn: 4.1893121\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7848:\tlearn: 4.1890083\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7849:\tlearn: 4.1885734\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7850:\tlearn: 4.1882722\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7851:\tlearn: 4.1879929\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7852:\tlearn: 4.1878871\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7853:\tlearn: 4.1875632\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7854:\tlearn: 4.1873575\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7855:\tlearn: 4.1870152\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7856:\tlearn: 4.1866252\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7857:\tlearn: 4.1863319\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7858:\tlearn: 4.1861101\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7859:\tlearn: 4.1858390\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7860:\tlearn: 4.1855835\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7861:\tlearn: 4.1852309\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7862:\tlearn: 4.1847762\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7863:\tlearn: 4.1844453\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7864:\tlearn: 4.1843298\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7865:\tlearn: 4.1840678\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7866:\tlearn: 4.1838086\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7867:\tlearn: 4.1834669\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7868:\tlearn: 4.1832347\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7869:\tlearn: 4.1829182\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7870:\tlearn: 4.1827538\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7871:\tlearn: 4.1824742\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7872:\tlearn: 4.1822185\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7873:\tlearn: 4.1819007\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7874:\tlearn: 4.1816730\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7875:\tlearn: 4.1814877\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "7876:\tlearn: 4.1813575\ttotal: 2m 51s\tremaining: 5m 29s\n",
      "7877:\tlearn: 4.1811481\ttotal: 2m 51s\tremaining: 5m 29s\n",
      "7878:\tlearn: 4.1807683\ttotal: 2m 51s\tremaining: 5m 29s\n",
      "7879:\tlearn: 4.1804243\ttotal: 2m 51s\tremaining: 5m 29s\n",
      "7880:\tlearn: 4.1800177\ttotal: 2m 51s\tremaining: 5m 29s\n",
      "7881:\tlearn: 4.1796647\ttotal: 2m 51s\tremaining: 5m 29s\n",
      "7882:\tlearn: 4.1794149\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7883:\tlearn: 4.1791900\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7884:\tlearn: 4.1790169\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7885:\tlearn: 4.1785919\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7886:\tlearn: 4.1784375\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7887:\tlearn: 4.1781399\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7888:\tlearn: 4.1779875\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7889:\tlearn: 4.1775908\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7890:\tlearn: 4.1774082\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7891:\tlearn: 4.1771331\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7892:\tlearn: 4.1771252\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7893:\tlearn: 4.1767721\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7894:\tlearn: 4.1764729\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7895:\tlearn: 4.1762083\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7896:\tlearn: 4.1759246\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7897:\tlearn: 4.1759161\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7898:\tlearn: 4.1755981\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7899:\tlearn: 4.1754670\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7900:\tlearn: 4.1752580\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7901:\tlearn: 4.1750285\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7902:\tlearn: 4.1748348\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7903:\tlearn: 4.1745589\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7904:\tlearn: 4.1743494\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7905:\tlearn: 4.1740835\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7906:\tlearn: 4.1737904\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7907:\tlearn: 4.1734754\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7908:\tlearn: 4.1732263\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7909:\tlearn: 4.1731639\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7910:\tlearn: 4.1728559\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7911:\tlearn: 4.1724632\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7912:\tlearn: 4.1722267\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7913:\tlearn: 4.1720374\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7914:\tlearn: 4.1719433\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7915:\tlearn: 4.1716177\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7916:\tlearn: 4.1714958\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7917:\tlearn: 4.1712858\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7918:\tlearn: 4.1709466\ttotal: 2m 52s\tremaining: 5m 29s\n",
      "7919:\tlearn: 4.1706721\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7920:\tlearn: 4.1702719\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7921:\tlearn: 4.1699415\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7922:\tlearn: 4.1697386\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7923:\tlearn: 4.1697314\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7924:\tlearn: 4.1694771\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7925:\tlearn: 4.1692279\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7926:\tlearn: 4.1688592\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7927:\tlearn: 4.1685903\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7928:\tlearn: 4.1684351\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7929:\tlearn: 4.1680455\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "7930:\tlearn: 4.1678496\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7931:\tlearn: 4.1675621\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7932:\tlearn: 4.1673167\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7933:\tlearn: 4.1671531\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7934:\tlearn: 4.1669853\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7935:\tlearn: 4.1666715\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7936:\tlearn: 4.1666638\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7937:\tlearn: 4.1663867\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7938:\tlearn: 4.1661228\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7939:\tlearn: 4.1658782\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7940:\tlearn: 4.1655101\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7941:\tlearn: 4.1651203\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7942:\tlearn: 4.1647292\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7943:\tlearn: 4.1644824\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7944:\tlearn: 4.1641521\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7945:\tlearn: 4.1639148\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7946:\tlearn: 4.1635104\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7947:\tlearn: 4.1632603\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7948:\tlearn: 4.1629474\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7949:\tlearn: 4.1626938\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7950:\tlearn: 4.1625607\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7951:\tlearn: 4.1622349\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7952:\tlearn: 4.1619136\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7953:\tlearn: 4.1619038\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7954:\tlearn: 4.1616231\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7955:\tlearn: 4.1613368\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7956:\tlearn: 4.1611938\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7957:\tlearn: 4.1608051\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7958:\tlearn: 4.1603720\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7959:\tlearn: 4.1600739\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7960:\tlearn: 4.1598288\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7961:\tlearn: 4.1595089\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7962:\tlearn: 4.1591799\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7963:\tlearn: 4.1589401\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7964:\tlearn: 4.1586652\ttotal: 2m 53s\tremaining: 5m 28s\n",
      "7965:\tlearn: 4.1582962\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "7966:\tlearn: 4.1580011\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "7967:\tlearn: 4.1576290\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "7968:\tlearn: 4.1572962\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "7969:\tlearn: 4.1569481\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "7970:\tlearn: 4.1567923\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "7971:\tlearn: 4.1563686\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "7972:\tlearn: 4.1561633\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "7973:\tlearn: 4.1559276\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "7974:\tlearn: 4.1554360\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7975:\tlearn: 4.1550541\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7976:\tlearn: 4.1548357\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7977:\tlearn: 4.1546184\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7978:\tlearn: 4.1543320\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7979:\tlearn: 4.1541479\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7980:\tlearn: 4.1538134\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7981:\tlearn: 4.1534975\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7982:\tlearn: 4.1532261\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7983:\tlearn: 4.1528821\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7984:\tlearn: 4.1527240\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7985:\tlearn: 4.1522590\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7986:\tlearn: 4.1519585\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7987:\tlearn: 4.1517568\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7988:\tlearn: 4.1513555\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7989:\tlearn: 4.1511373\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7990:\tlearn: 4.1507745\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7991:\tlearn: 4.1504323\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7992:\tlearn: 4.1500766\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7993:\tlearn: 4.1497936\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7994:\tlearn: 4.1494831\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7995:\tlearn: 4.1492985\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7996:\tlearn: 4.1492336\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7997:\tlearn: 4.1489539\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7998:\tlearn: 4.1486653\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "7999:\tlearn: 4.1482808\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8000:\tlearn: 4.1481079\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8001:\tlearn: 4.1478416\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8002:\tlearn: 4.1478323\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8003:\tlearn: 4.1476147\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8004:\tlearn: 4.1473515\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8005:\tlearn: 4.1470218\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8006:\tlearn: 4.1466915\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8007:\tlearn: 4.1461728\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8008:\tlearn: 4.1457506\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8009:\tlearn: 4.1454591\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8010:\tlearn: 4.1451921\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8011:\tlearn: 4.1449901\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8012:\tlearn: 4.1446934\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8013:\tlearn: 4.1444414\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8014:\tlearn: 4.1444330\ttotal: 2m 54s\tremaining: 5m 27s\n",
      "8015:\tlearn: 4.1441996\ttotal: 2m 54s\tremaining: 5m 26s\n",
      "8016:\tlearn: 4.1438914\ttotal: 2m 54s\tremaining: 5m 26s\n",
      "8017:\tlearn: 4.1437234\ttotal: 2m 54s\tremaining: 5m 26s\n",
      "8018:\tlearn: 4.1434769\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8019:\tlearn: 4.1431573\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8020:\tlearn: 4.1427691\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8021:\tlearn: 4.1425708\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8022:\tlearn: 4.1422695\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8023:\tlearn: 4.1419715\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8024:\tlearn: 4.1415184\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8025:\tlearn: 4.1411297\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8026:\tlearn: 4.1407726\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8027:\tlearn: 4.1404200\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8028:\tlearn: 4.1400735\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8029:\tlearn: 4.1395913\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8030:\tlearn: 4.1392551\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8031:\tlearn: 4.1389973\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8032:\tlearn: 4.1387564\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8033:\tlearn: 4.1385898\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8034:\tlearn: 4.1384889\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8035:\tlearn: 4.1383814\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8036:\tlearn: 4.1382413\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8037:\tlearn: 4.1379789\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8038:\tlearn: 4.1377522\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8039:\tlearn: 4.1372758\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8040:\tlearn: 4.1370834\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8041:\tlearn: 4.1367665\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8042:\tlearn: 4.1365412\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8043:\tlearn: 4.1364159\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8044:\tlearn: 4.1362067\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8045:\tlearn: 4.1358355\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8046:\tlearn: 4.1358300\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8047:\tlearn: 4.1355366\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8048:\tlearn: 4.1352586\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8049:\tlearn: 4.1350251\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8050:\tlearn: 4.1350190\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8051:\tlearn: 4.1346370\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8052:\tlearn: 4.1343556\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8053:\tlearn: 4.1341106\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8054:\tlearn: 4.1337092\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8055:\tlearn: 4.1334717\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8056:\tlearn: 4.1332052\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8057:\tlearn: 4.1329528\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8058:\tlearn: 4.1328393\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8059:\tlearn: 4.1323902\ttotal: 2m 55s\tremaining: 5m 26s\n",
      "8060:\tlearn: 4.1319817\ttotal: 2m 55s\tremaining: 5m 25s\n",
      "8061:\tlearn: 4.1316099\ttotal: 2m 55s\tremaining: 5m 25s\n",
      "8062:\tlearn: 4.1314024\ttotal: 2m 55s\tremaining: 5m 25s\n",
      "8063:\tlearn: 4.1311944\ttotal: 2m 55s\tremaining: 5m 25s\n",
      "8064:\tlearn: 4.1309994\ttotal: 2m 55s\tremaining: 5m 25s\n",
      "8065:\tlearn: 4.1307429\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8066:\tlearn: 4.1304789\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8067:\tlearn: 4.1302065\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8068:\tlearn: 4.1299630\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8069:\tlearn: 4.1297309\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8070:\tlearn: 4.1293066\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8071:\tlearn: 4.1287996\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8072:\tlearn: 4.1286405\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8073:\tlearn: 4.1283228\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8074:\tlearn: 4.1279196\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8075:\tlearn: 4.1276187\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8076:\tlearn: 4.1274104\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8077:\tlearn: 4.1273964\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8078:\tlearn: 4.1270403\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8079:\tlearn: 4.1268835\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8080:\tlearn: 4.1266599\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8081:\tlearn: 4.1263346\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8082:\tlearn: 4.1260658\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8083:\tlearn: 4.1257476\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8084:\tlearn: 4.1254407\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8085:\tlearn: 4.1251895\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8086:\tlearn: 4.1249213\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8087:\tlearn: 4.1246972\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8088:\tlearn: 4.1244149\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8089:\tlearn: 4.1240521\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8090:\tlearn: 4.1237493\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8091:\tlearn: 4.1235105\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8092:\tlearn: 4.1233040\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8093:\tlearn: 4.1230822\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8094:\tlearn: 4.1228585\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8095:\tlearn: 4.1226032\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8096:\tlearn: 4.1222717\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8097:\tlearn: 4.1221679\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8098:\tlearn: 4.1217593\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8099:\tlearn: 4.1214720\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8100:\tlearn: 4.1213694\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8101:\tlearn: 4.1210606\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8102:\tlearn: 4.1207279\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8103:\tlearn: 4.1204556\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8104:\tlearn: 4.1200504\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8105:\tlearn: 4.1198532\ttotal: 2m 56s\tremaining: 5m 25s\n",
      "8106:\tlearn: 4.1198325\ttotal: 2m 56s\tremaining: 5m 24s\n",
      "8107:\tlearn: 4.1195912\ttotal: 2m 56s\tremaining: 5m 24s\n",
      "8108:\tlearn: 4.1192725\ttotal: 2m 56s\tremaining: 5m 24s\n",
      "8109:\tlearn: 4.1189478\ttotal: 2m 56s\tremaining: 5m 24s\n",
      "8110:\tlearn: 4.1185986\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8111:\tlearn: 4.1184701\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8112:\tlearn: 4.1183284\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8113:\tlearn: 4.1181726\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8114:\tlearn: 4.1179772\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8115:\tlearn: 4.1176603\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8116:\tlearn: 4.1175852\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8117:\tlearn: 4.1172253\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8118:\tlearn: 4.1170260\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8119:\tlearn: 4.1168450\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8120:\tlearn: 4.1165224\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8121:\tlearn: 4.1162497\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8122:\tlearn: 4.1159688\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8123:\tlearn: 4.1157772\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8124:\tlearn: 4.1154584\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8125:\tlearn: 4.1153525\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8126:\tlearn: 4.1150614\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8127:\tlearn: 4.1146549\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8128:\tlearn: 4.1142741\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8129:\tlearn: 4.1138829\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8130:\tlearn: 4.1138048\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8131:\tlearn: 4.1134286\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8132:\tlearn: 4.1131162\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8133:\tlearn: 4.1131098\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8134:\tlearn: 4.1128859\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8135:\tlearn: 4.1126275\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8136:\tlearn: 4.1123740\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8137:\tlearn: 4.1120245\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8138:\tlearn: 4.1117564\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8139:\tlearn: 4.1114279\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8140:\tlearn: 4.1112197\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8141:\tlearn: 4.1110459\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8142:\tlearn: 4.1108213\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8143:\tlearn: 4.1105302\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8144:\tlearn: 4.1103660\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8145:\tlearn: 4.1102259\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8146:\tlearn: 4.1100283\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8147:\tlearn: 4.1098568\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8148:\tlearn: 4.1096157\ttotal: 2m 57s\tremaining: 5m 24s\n",
      "8149:\tlearn: 4.1091891\ttotal: 2m 57s\tremaining: 5m 23s\n",
      "8150:\tlearn: 4.1090755\ttotal: 2m 57s\tremaining: 5m 23s\n",
      "8151:\tlearn: 4.1088954\ttotal: 2m 57s\tremaining: 5m 23s\n",
      "8152:\tlearn: 4.1086367\ttotal: 2m 57s\tremaining: 5m 23s\n",
      "8153:\tlearn: 4.1082275\ttotal: 2m 57s\tremaining: 5m 23s\n",
      "8154:\tlearn: 4.1080260\ttotal: 2m 57s\tremaining: 5m 23s\n",
      "8155:\tlearn: 4.1076933\ttotal: 2m 57s\tremaining: 5m 23s\n",
      "8156:\tlearn: 4.1074080\ttotal: 2m 57s\tremaining: 5m 23s\n",
      "8157:\tlearn: 4.1071867\ttotal: 2m 57s\tremaining: 5m 23s\n",
      "8158:\tlearn: 4.1068379\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8159:\tlearn: 4.1066046\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8160:\tlearn: 4.1064957\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8161:\tlearn: 4.1061011\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8162:\tlearn: 4.1057731\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8163:\tlearn: 4.1054442\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8164:\tlearn: 4.1052475\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8165:\tlearn: 4.1049674\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8166:\tlearn: 4.1048097\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8167:\tlearn: 4.1045335\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8168:\tlearn: 4.1042613\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8169:\tlearn: 4.1041626\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8170:\tlearn: 4.1038819\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8171:\tlearn: 4.1038736\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8172:\tlearn: 4.1035850\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8173:\tlearn: 4.1033023\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8174:\tlearn: 4.1030441\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8175:\tlearn: 4.1028616\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8176:\tlearn: 4.1028545\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8177:\tlearn: 4.1025183\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8178:\tlearn: 4.1023100\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8179:\tlearn: 4.1020337\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8180:\tlearn: 4.1018220\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8181:\tlearn: 4.1014944\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8182:\tlearn: 4.1009470\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8183:\tlearn: 4.1007373\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8184:\tlearn: 4.1005654\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8185:\tlearn: 4.1001533\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8186:\tlearn: 4.0998948\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8187:\tlearn: 4.0993978\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8188:\tlearn: 4.0990128\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8189:\tlearn: 4.0986997\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8190:\tlearn: 4.0985069\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8191:\tlearn: 4.0982605\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8192:\tlearn: 4.0979499\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8193:\tlearn: 4.0976304\ttotal: 2m 58s\tremaining: 5m 23s\n",
      "8194:\tlearn: 4.0971784\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8195:\tlearn: 4.0971721\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8196:\tlearn: 4.0968495\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8197:\tlearn: 4.0965487\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8198:\tlearn: 4.0963646\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8199:\tlearn: 4.0960774\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8200:\tlearn: 4.0958598\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8201:\tlearn: 4.0957300\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8202:\tlearn: 4.0955877\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8203:\tlearn: 4.0952495\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8204:\tlearn: 4.0952427\ttotal: 2m 58s\tremaining: 5m 22s\n",
      "8205:\tlearn: 4.0949510\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8206:\tlearn: 4.0945236\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8207:\tlearn: 4.0940429\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8208:\tlearn: 4.0936133\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8209:\tlearn: 4.0933211\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8210:\tlearn: 4.0931116\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8211:\tlearn: 4.0928196\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8212:\tlearn: 4.0926083\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8213:\tlearn: 4.0922865\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8214:\tlearn: 4.0921225\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8215:\tlearn: 4.0918605\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8216:\tlearn: 4.0916997\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8217:\tlearn: 4.0913902\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8218:\tlearn: 4.0913825\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8219:\tlearn: 4.0912383\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8220:\tlearn: 4.0909056\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8221:\tlearn: 4.0907005\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8222:\tlearn: 4.0904718\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8223:\tlearn: 4.0900794\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8224:\tlearn: 4.0898411\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8225:\tlearn: 4.0895401\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8226:\tlearn: 4.0893604\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8227:\tlearn: 4.0891617\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8228:\tlearn: 4.0887244\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8229:\tlearn: 4.0885710\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8230:\tlearn: 4.0880826\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8231:\tlearn: 4.0879281\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8232:\tlearn: 4.0875845\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8233:\tlearn: 4.0872420\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8234:\tlearn: 4.0869024\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8235:\tlearn: 4.0866572\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8236:\tlearn: 4.0863396\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8237:\tlearn: 4.0857975\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8238:\tlearn: 4.0854729\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8239:\tlearn: 4.0849771\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8240:\tlearn: 4.0846858\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8241:\tlearn: 4.0845295\ttotal: 2m 59s\tremaining: 5m 22s\n",
      "8242:\tlearn: 4.0842363\ttotal: 2m 59s\tremaining: 5m 21s\n",
      "8243:\tlearn: 4.0838801\ttotal: 2m 59s\tremaining: 5m 21s\n",
      "8244:\tlearn: 4.0835203\ttotal: 2m 59s\tremaining: 5m 21s\n",
      "8245:\tlearn: 4.0831225\ttotal: 2m 59s\tremaining: 5m 21s\n",
      "8246:\tlearn: 4.0831153\ttotal: 2m 59s\tremaining: 5m 21s\n",
      "8247:\tlearn: 4.0827801\ttotal: 2m 59s\tremaining: 5m 21s\n",
      "8248:\tlearn: 4.0825049\ttotal: 2m 59s\tremaining: 5m 21s\n",
      "8249:\tlearn: 4.0819882\ttotal: 3m\tremaining: 5m 21s\n",
      "8250:\tlearn: 4.0817660\ttotal: 3m\tremaining: 5m 21s\n",
      "8251:\tlearn: 4.0814002\ttotal: 3m\tremaining: 5m 21s\n",
      "8252:\tlearn: 4.0810365\ttotal: 3m\tremaining: 5m 21s\n",
      "8253:\tlearn: 4.0807552\ttotal: 3m\tremaining: 5m 21s\n",
      "8254:\tlearn: 4.0805264\ttotal: 3m\tremaining: 5m 21s\n",
      "8255:\tlearn: 4.0802995\ttotal: 3m\tremaining: 5m 21s\n",
      "8256:\tlearn: 4.0800894\ttotal: 3m\tremaining: 5m 21s\n",
      "8257:\tlearn: 4.0799301\ttotal: 3m\tremaining: 5m 21s\n",
      "8258:\tlearn: 4.0796231\ttotal: 3m\tremaining: 5m 21s\n",
      "8259:\tlearn: 4.0793477\ttotal: 3m\tremaining: 5m 21s\n",
      "8260:\tlearn: 4.0790011\ttotal: 3m\tremaining: 5m 21s\n",
      "8261:\tlearn: 4.0788462\ttotal: 3m\tremaining: 5m 21s\n",
      "8262:\tlearn: 4.0784055\ttotal: 3m\tremaining: 5m 21s\n",
      "8263:\tlearn: 4.0781188\ttotal: 3m\tremaining: 5m 21s\n",
      "8264:\tlearn: 4.0778282\ttotal: 3m\tremaining: 5m 21s\n",
      "8265:\tlearn: 4.0775310\ttotal: 3m\tremaining: 5m 21s\n",
      "8266:\tlearn: 4.0773289\ttotal: 3m\tremaining: 5m 21s\n",
      "8267:\tlearn: 4.0770424\ttotal: 3m\tremaining: 5m 21s\n",
      "8268:\tlearn: 4.0767944\ttotal: 3m\tremaining: 5m 21s\n",
      "8269:\tlearn: 4.0763031\ttotal: 3m\tremaining: 5m 21s\n",
      "8270:\tlearn: 4.0758760\ttotal: 3m\tremaining: 5m 21s\n",
      "8271:\tlearn: 4.0756312\ttotal: 3m\tremaining: 5m 21s\n",
      "8272:\tlearn: 4.0753695\ttotal: 3m\tremaining: 5m 21s\n",
      "8273:\tlearn: 4.0751265\ttotal: 3m\tremaining: 5m 21s\n",
      "8274:\tlearn: 4.0749092\ttotal: 3m\tremaining: 5m 21s\n",
      "8275:\tlearn: 4.0746617\ttotal: 3m\tremaining: 5m 21s\n",
      "8276:\tlearn: 4.0743725\ttotal: 3m\tremaining: 5m 21s\n",
      "8277:\tlearn: 4.0739949\ttotal: 3m\tremaining: 5m 21s\n",
      "8278:\tlearn: 4.0738676\ttotal: 3m\tremaining: 5m 21s\n",
      "8279:\tlearn: 4.0736845\ttotal: 3m\tremaining: 5m 21s\n",
      "8280:\tlearn: 4.0734563\ttotal: 3m\tremaining: 5m 21s\n",
      "8281:\tlearn: 4.0731240\ttotal: 3m\tremaining: 5m 21s\n",
      "8282:\tlearn: 4.0728313\ttotal: 3m\tremaining: 5m 21s\n",
      "8283:\tlearn: 4.0725715\ttotal: 3m\tremaining: 5m 21s\n",
      "8284:\tlearn: 4.0721995\ttotal: 3m\tremaining: 5m 21s\n",
      "8285:\tlearn: 4.0719443\ttotal: 3m\tremaining: 5m 21s\n",
      "8286:\tlearn: 4.0717386\ttotal: 3m\tremaining: 5m 21s\n",
      "8287:\tlearn: 4.0714106\ttotal: 3m\tremaining: 5m 20s\n",
      "8288:\tlearn: 4.0711823\ttotal: 3m\tremaining: 5m 20s\n",
      "8289:\tlearn: 4.0707414\ttotal: 3m\tremaining: 5m 20s\n",
      "8290:\tlearn: 4.0705016\ttotal: 3m\tremaining: 5m 20s\n",
      "8291:\tlearn: 4.0700875\ttotal: 3m\tremaining: 5m 20s\n",
      "8292:\tlearn: 4.0700772\ttotal: 3m\tremaining: 5m 20s\n",
      "8293:\tlearn: 4.0697757\ttotal: 3m\tremaining: 5m 20s\n",
      "8294:\tlearn: 4.0693624\ttotal: 3m\tremaining: 5m 20s\n",
      "8295:\tlearn: 4.0691270\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8296:\tlearn: 4.0688209\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8297:\tlearn: 4.0686049\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8298:\tlearn: 4.0684046\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8299:\tlearn: 4.0680669\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8300:\tlearn: 4.0676628\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8301:\tlearn: 4.0674918\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8302:\tlearn: 4.0670810\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8303:\tlearn: 4.0668849\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8304:\tlearn: 4.0665896\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8305:\tlearn: 4.0663860\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8306:\tlearn: 4.0660682\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8307:\tlearn: 4.0657801\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8308:\tlearn: 4.0654362\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8309:\tlearn: 4.0651216\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8310:\tlearn: 4.0648071\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8311:\tlearn: 4.0644993\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8312:\tlearn: 4.0642509\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8313:\tlearn: 4.0641714\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8314:\tlearn: 4.0639385\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8315:\tlearn: 4.0636323\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8316:\tlearn: 4.0631944\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8317:\tlearn: 4.0630265\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8318:\tlearn: 4.0626710\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8319:\tlearn: 4.0625940\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8320:\tlearn: 4.0623701\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8321:\tlearn: 4.0622031\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8322:\tlearn: 4.0617632\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8323:\tlearn: 4.0615836\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8324:\tlearn: 4.0614169\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8325:\tlearn: 4.0612815\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8326:\tlearn: 4.0610456\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8327:\tlearn: 4.0608091\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8328:\tlearn: 4.0605208\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8329:\tlearn: 4.0605101\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8330:\tlearn: 4.0601630\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8331:\tlearn: 4.0598430\ttotal: 3m 1s\tremaining: 5m 20s\n",
      "8332:\tlearn: 4.0594917\ttotal: 3m 1s\tremaining: 5m 19s\n",
      "8333:\tlearn: 4.0591052\ttotal: 3m 1s\tremaining: 5m 19s\n",
      "8334:\tlearn: 4.0588392\ttotal: 3m 1s\tremaining: 5m 19s\n",
      "8335:\tlearn: 4.0584454\ttotal: 3m 1s\tremaining: 5m 19s\n",
      "8336:\tlearn: 4.0582941\ttotal: 3m 1s\tremaining: 5m 19s\n",
      "8337:\tlearn: 4.0580128\ttotal: 3m 1s\tremaining: 5m 19s\n",
      "8338:\tlearn: 4.0576289\ttotal: 3m 1s\tremaining: 5m 19s\n",
      "8339:\tlearn: 4.0573135\ttotal: 3m 1s\tremaining: 5m 19s\n",
      "8340:\tlearn: 4.0569761\ttotal: 3m 1s\tremaining: 5m 19s\n",
      "8341:\tlearn: 4.0566324\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8342:\tlearn: 4.0562784\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8343:\tlearn: 4.0560279\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8344:\tlearn: 4.0559225\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8345:\tlearn: 4.0557166\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8346:\tlearn: 4.0554921\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8347:\tlearn: 4.0550620\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8348:\tlearn: 4.0548664\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8349:\tlearn: 4.0545327\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8350:\tlearn: 4.0545258\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8351:\tlearn: 4.0543591\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8352:\tlearn: 4.0540313\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8353:\tlearn: 4.0537202\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8354:\tlearn: 4.0534753\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8355:\tlearn: 4.0534693\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8356:\tlearn: 4.0530999\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8357:\tlearn: 4.0528584\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8358:\tlearn: 4.0526677\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8359:\tlearn: 4.0523730\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8360:\tlearn: 4.0521960\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8361:\tlearn: 4.0519828\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8362:\tlearn: 4.0515515\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8363:\tlearn: 4.0513329\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8364:\tlearn: 4.0510896\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8365:\tlearn: 4.0507784\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8366:\tlearn: 4.0504512\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8367:\tlearn: 4.0501753\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8368:\tlearn: 4.0497802\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8369:\tlearn: 4.0494492\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8370:\tlearn: 4.0490700\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8371:\tlearn: 4.0489509\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8372:\tlearn: 4.0485690\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8373:\tlearn: 4.0484041\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8374:\tlearn: 4.0482648\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8375:\tlearn: 4.0479662\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8376:\tlearn: 4.0478369\ttotal: 3m 2s\tremaining: 5m 19s\n",
      "8377:\tlearn: 4.0478289\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8378:\tlearn: 4.0477349\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8379:\tlearn: 4.0475122\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8380:\tlearn: 4.0470642\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8381:\tlearn: 4.0468497\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8382:\tlearn: 4.0466728\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8383:\tlearn: 4.0465803\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8384:\tlearn: 4.0465724\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8385:\tlearn: 4.0463131\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8386:\tlearn: 4.0459900\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8387:\tlearn: 4.0457116\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8388:\tlearn: 4.0453950\ttotal: 3m 2s\tremaining: 5m 18s\n",
      "8389:\tlearn: 4.0450762\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8390:\tlearn: 4.0447428\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8391:\tlearn: 4.0445605\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8392:\tlearn: 4.0441457\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8393:\tlearn: 4.0437820\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8394:\tlearn: 4.0435356\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8395:\tlearn: 4.0433670\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8396:\tlearn: 4.0432097\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8397:\tlearn: 4.0430322\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8398:\tlearn: 4.0426421\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8399:\tlearn: 4.0424767\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8400:\tlearn: 4.0422301\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8401:\tlearn: 4.0417008\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8402:\tlearn: 4.0413978\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8403:\tlearn: 4.0412562\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8404:\tlearn: 4.0410095\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8405:\tlearn: 4.0407755\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8406:\tlearn: 4.0405571\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8407:\tlearn: 4.0403014\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8408:\tlearn: 4.0401476\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8409:\tlearn: 4.0397240\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8410:\tlearn: 4.0396179\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8411:\tlearn: 4.0392956\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8412:\tlearn: 4.0391530\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8413:\tlearn: 4.0388775\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8414:\tlearn: 4.0386660\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8415:\tlearn: 4.0384951\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8416:\tlearn: 4.0381875\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8417:\tlearn: 4.0376984\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8418:\tlearn: 4.0374613\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8419:\tlearn: 4.0371882\ttotal: 3m 3s\tremaining: 5m 18s\n",
      "8420:\tlearn: 4.0370434\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8421:\tlearn: 4.0367239\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8422:\tlearn: 4.0365557\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8423:\tlearn: 4.0364341\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8424:\tlearn: 4.0362239\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8425:\tlearn: 4.0360770\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8426:\tlearn: 4.0358940\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8427:\tlearn: 4.0357167\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8428:\tlearn: 4.0354881\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8429:\tlearn: 4.0351025\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8430:\tlearn: 4.0350967\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8431:\tlearn: 4.0350905\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8432:\tlearn: 4.0349755\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8433:\tlearn: 4.0347892\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8434:\tlearn: 4.0345983\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8435:\tlearn: 4.0344559\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8436:\tlearn: 4.0343173\ttotal: 3m 3s\tremaining: 5m 17s\n",
      "8437:\tlearn: 4.0340302\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8438:\tlearn: 4.0338120\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8439:\tlearn: 4.0334145\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8440:\tlearn: 4.0330804\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8441:\tlearn: 4.0327796\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8442:\tlearn: 4.0325761\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8443:\tlearn: 4.0324066\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8444:\tlearn: 4.0319153\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8445:\tlearn: 4.0315509\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8446:\tlearn: 4.0311536\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8447:\tlearn: 4.0309151\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8448:\tlearn: 4.0306527\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8449:\tlearn: 4.0302269\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8450:\tlearn: 4.0300138\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8451:\tlearn: 4.0297506\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8452:\tlearn: 4.0294045\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8453:\tlearn: 4.0290513\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8454:\tlearn: 4.0288194\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8455:\tlearn: 4.0285225\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8456:\tlearn: 4.0283515\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8457:\tlearn: 4.0281090\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8458:\tlearn: 4.0278485\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8459:\tlearn: 4.0276542\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8460:\tlearn: 4.0273927\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8461:\tlearn: 4.0271459\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8462:\tlearn: 4.0268262\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8463:\tlearn: 4.0266193\ttotal: 3m 4s\tremaining: 5m 17s\n",
      "8464:\tlearn: 4.0264131\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8465:\tlearn: 4.0261868\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8466:\tlearn: 4.0260206\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8467:\tlearn: 4.0258700\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8468:\tlearn: 4.0255820\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8469:\tlearn: 4.0253145\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8470:\tlearn: 4.0251680\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8471:\tlearn: 4.0248805\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8472:\tlearn: 4.0246323\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8473:\tlearn: 4.0242497\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8474:\tlearn: 4.0240162\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8475:\tlearn: 4.0238915\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8476:\tlearn: 4.0235746\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8477:\tlearn: 4.0232608\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8478:\tlearn: 4.0230085\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8479:\tlearn: 4.0227967\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8480:\tlearn: 4.0225100\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8481:\tlearn: 4.0222012\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8482:\tlearn: 4.0221918\ttotal: 3m 4s\tremaining: 5m 16s\n",
      "8483:\tlearn: 4.0220560\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8484:\tlearn: 4.0218508\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8485:\tlearn: 4.0216013\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8486:\tlearn: 4.0212098\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8487:\tlearn: 4.0209748\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8488:\tlearn: 4.0206222\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8489:\tlearn: 4.0203530\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8490:\tlearn: 4.0201189\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8491:\tlearn: 4.0198161\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8492:\tlearn: 4.0195571\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8493:\tlearn: 4.0192608\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8494:\tlearn: 4.0191334\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8495:\tlearn: 4.0187698\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8496:\tlearn: 4.0184416\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8497:\tlearn: 4.0181476\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8498:\tlearn: 4.0177674\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8499:\tlearn: 4.0174030\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8500:\tlearn: 4.0171637\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8501:\tlearn: 4.0170045\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8502:\tlearn: 4.0168734\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8503:\tlearn: 4.0165398\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8504:\tlearn: 4.0164594\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8505:\tlearn: 4.0161630\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8506:\tlearn: 4.0160452\ttotal: 3m 5s\tremaining: 5m 16s\n",
      "8507:\tlearn: 4.0156954\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8508:\tlearn: 4.0155073\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8509:\tlearn: 4.0152715\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8510:\tlearn: 4.0150586\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8511:\tlearn: 4.0147301\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8512:\tlearn: 4.0145260\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8513:\tlearn: 4.0142913\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8514:\tlearn: 4.0138832\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8515:\tlearn: 4.0136991\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8516:\tlearn: 4.0136631\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8517:\tlearn: 4.0134052\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8518:\tlearn: 4.0132558\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8519:\tlearn: 4.0128822\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8520:\tlearn: 4.0126650\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8521:\tlearn: 4.0125432\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8522:\tlearn: 4.0123114\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8523:\tlearn: 4.0121137\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8524:\tlearn: 4.0118898\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8525:\tlearn: 4.0117679\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8526:\tlearn: 4.0114974\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8527:\tlearn: 4.0114308\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8528:\tlearn: 4.0112742\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8529:\tlearn: 4.0111080\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8530:\tlearn: 4.0109361\ttotal: 3m 5s\tremaining: 5m 15s\n",
      "8531:\tlearn: 4.0106670\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8532:\tlearn: 4.0102037\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8533:\tlearn: 4.0099425\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8534:\tlearn: 4.0096989\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8535:\tlearn: 4.0094492\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8536:\tlearn: 4.0090814\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8537:\tlearn: 4.0088010\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8538:\tlearn: 4.0085912\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8539:\tlearn: 4.0084035\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8540:\tlearn: 4.0081071\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8541:\tlearn: 4.0078873\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8542:\tlearn: 4.0077376\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8543:\tlearn: 4.0074565\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8544:\tlearn: 4.0072025\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8545:\tlearn: 4.0067909\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8546:\tlearn: 4.0066505\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8547:\tlearn: 4.0064979\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8548:\tlearn: 4.0063126\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8549:\tlearn: 4.0060991\ttotal: 3m 6s\tremaining: 5m 15s\n",
      "8550:\tlearn: 4.0058951\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8551:\tlearn: 4.0057186\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8552:\tlearn: 4.0055193\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8553:\tlearn: 4.0053915\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8554:\tlearn: 4.0050781\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8555:\tlearn: 4.0048655\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8556:\tlearn: 4.0046870\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8557:\tlearn: 4.0045317\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8558:\tlearn: 4.0041180\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8559:\tlearn: 4.0038527\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8560:\tlearn: 4.0036902\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8561:\tlearn: 4.0033806\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8562:\tlearn: 4.0031298\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8563:\tlearn: 4.0029242\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8564:\tlearn: 4.0026550\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8565:\tlearn: 4.0024941\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8566:\tlearn: 4.0021051\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8567:\tlearn: 4.0019564\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8568:\tlearn: 4.0016972\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8569:\tlearn: 4.0014534\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8570:\tlearn: 4.0010474\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8571:\tlearn: 4.0008888\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8572:\tlearn: 4.0008808\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8573:\tlearn: 4.0006621\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8574:\tlearn: 4.0002793\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8575:\tlearn: 3.9997502\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8576:\tlearn: 3.9996032\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8577:\tlearn: 3.9993129\ttotal: 3m 6s\tremaining: 5m 14s\n",
      "8578:\tlearn: 3.9989630\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8579:\tlearn: 3.9987215\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8580:\tlearn: 3.9983286\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8581:\tlearn: 3.9981174\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8582:\tlearn: 3.9979319\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8583:\tlearn: 3.9977543\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8584:\tlearn: 3.9976619\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8585:\tlearn: 3.9973876\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8586:\tlearn: 3.9971924\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8587:\tlearn: 3.9970015\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8588:\tlearn: 3.9967073\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8589:\tlearn: 3.9965566\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8590:\tlearn: 3.9963402\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8591:\tlearn: 3.9961751\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8592:\tlearn: 3.9960651\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8593:\tlearn: 3.9957935\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8594:\tlearn: 3.9954270\ttotal: 3m 7s\tremaining: 5m 14s\n",
      "8595:\tlearn: 3.9950168\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8596:\tlearn: 3.9947281\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8597:\tlearn: 3.9945181\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8598:\tlearn: 3.9942980\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8599:\tlearn: 3.9941975\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8600:\tlearn: 3.9940043\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8601:\tlearn: 3.9938879\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8602:\tlearn: 3.9937345\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8603:\tlearn: 3.9932531\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8604:\tlearn: 3.9931275\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8605:\tlearn: 3.9928261\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8606:\tlearn: 3.9923407\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8607:\tlearn: 3.9920967\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8608:\tlearn: 3.9920891\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8609:\tlearn: 3.9918182\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8610:\tlearn: 3.9915158\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8611:\tlearn: 3.9911247\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8612:\tlearn: 3.9908838\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8613:\tlearn: 3.9906887\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8614:\tlearn: 3.9905618\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8615:\tlearn: 3.9903856\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8616:\tlearn: 3.9900127\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8617:\tlearn: 3.9898276\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8618:\tlearn: 3.9895891\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8619:\tlearn: 3.9893388\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8620:\tlearn: 3.9889219\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8621:\tlearn: 3.9888044\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8622:\tlearn: 3.9886612\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8623:\tlearn: 3.9884954\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8624:\tlearn: 3.9881450\ttotal: 3m 7s\tremaining: 5m 13s\n",
      "8625:\tlearn: 3.9879284\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8626:\tlearn: 3.9877502\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8627:\tlearn: 3.9876262\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8628:\tlearn: 3.9874980\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8629:\tlearn: 3.9872945\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8630:\tlearn: 3.9869990\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8631:\tlearn: 3.9867525\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8632:\tlearn: 3.9866384\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8633:\tlearn: 3.9863421\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8634:\tlearn: 3.9861085\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8635:\tlearn: 3.9859196\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8636:\tlearn: 3.9856060\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8637:\tlearn: 3.9855499\ttotal: 3m 8s\tremaining: 5m 13s\n",
      "8638:\tlearn: 3.9853704\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8639:\tlearn: 3.9851728\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8640:\tlearn: 3.9850228\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8641:\tlearn: 3.9848227\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8642:\tlearn: 3.9846674\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8643:\tlearn: 3.9843719\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8644:\tlearn: 3.9838803\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8645:\tlearn: 3.9835595\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8646:\tlearn: 3.9833385\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8647:\tlearn: 3.9831697\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8648:\tlearn: 3.9829249\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8649:\tlearn: 3.9827586\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8650:\tlearn: 3.9824367\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8651:\tlearn: 3.9821096\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8652:\tlearn: 3.9818938\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8653:\tlearn: 3.9815545\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8654:\tlearn: 3.9812695\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8655:\tlearn: 3.9810691\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8656:\tlearn: 3.9808579\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8657:\tlearn: 3.9804237\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8658:\tlearn: 3.9802962\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8659:\tlearn: 3.9800398\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8660:\tlearn: 3.9799706\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8661:\tlearn: 3.9794846\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8662:\tlearn: 3.9792555\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8663:\tlearn: 3.9790109\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8664:\tlearn: 3.9787643\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8665:\tlearn: 3.9784966\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8666:\tlearn: 3.9783116\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8667:\tlearn: 3.9779788\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8668:\tlearn: 3.9776286\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8669:\tlearn: 3.9774388\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8670:\tlearn: 3.9770875\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8671:\tlearn: 3.9769899\ttotal: 3m 8s\tremaining: 5m 12s\n",
      "8672:\tlearn: 3.9767128\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8673:\tlearn: 3.9764718\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8674:\tlearn: 3.9761474\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8675:\tlearn: 3.9757925\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8676:\tlearn: 3.9755909\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8677:\tlearn: 3.9752814\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8678:\tlearn: 3.9749939\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8679:\tlearn: 3.9747526\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8680:\tlearn: 3.9745618\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8681:\tlearn: 3.9743616\ttotal: 3m 9s\tremaining: 5m 12s\n",
      "8682:\tlearn: 3.9741657\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8683:\tlearn: 3.9739544\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8684:\tlearn: 3.9737741\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8685:\tlearn: 3.9734328\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8686:\tlearn: 3.9733501\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8687:\tlearn: 3.9730122\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8688:\tlearn: 3.9728046\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8689:\tlearn: 3.9725892\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8690:\tlearn: 3.9722046\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8691:\tlearn: 3.9720975\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8692:\tlearn: 3.9718956\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8693:\tlearn: 3.9718330\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8694:\tlearn: 3.9717451\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8695:\tlearn: 3.9716264\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8696:\tlearn: 3.9714711\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8697:\tlearn: 3.9712324\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8698:\tlearn: 3.9709376\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8699:\tlearn: 3.9705832\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8700:\tlearn: 3.9701277\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8701:\tlearn: 3.9699297\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8702:\tlearn: 3.9698024\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8703:\tlearn: 3.9694841\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8704:\tlearn: 3.9692163\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8705:\tlearn: 3.9690965\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8706:\tlearn: 3.9689621\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8707:\tlearn: 3.9688424\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8708:\tlearn: 3.9686530\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8709:\tlearn: 3.9684185\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8710:\tlearn: 3.9681106\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8711:\tlearn: 3.9678121\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8712:\tlearn: 3.9676288\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8713:\tlearn: 3.9672421\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8714:\tlearn: 3.9669963\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8715:\tlearn: 3.9667285\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8716:\tlearn: 3.9665574\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8717:\tlearn: 3.9664006\ttotal: 3m 9s\tremaining: 5m 11s\n",
      "8718:\tlearn: 3.9660754\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8719:\tlearn: 3.9659038\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8720:\tlearn: 3.9657301\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8721:\tlearn: 3.9654315\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8722:\tlearn: 3.9652511\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8723:\tlearn: 3.9648562\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8724:\tlearn: 3.9645847\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8725:\tlearn: 3.9643542\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8726:\tlearn: 3.9640715\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8727:\tlearn: 3.9639531\ttotal: 3m 10s\tremaining: 5m 11s\n",
      "8728:\tlearn: 3.9637279\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8729:\tlearn: 3.9635840\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8730:\tlearn: 3.9633409\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8731:\tlearn: 3.9632008\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8732:\tlearn: 3.9629283\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8733:\tlearn: 3.9627169\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8734:\tlearn: 3.9625584\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8735:\tlearn: 3.9622458\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8736:\tlearn: 3.9620717\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8737:\tlearn: 3.9618306\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8738:\tlearn: 3.9614863\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8739:\tlearn: 3.9613535\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8740:\tlearn: 3.9611961\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8741:\tlearn: 3.9610046\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8742:\tlearn: 3.9607101\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8743:\tlearn: 3.9603789\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8744:\tlearn: 3.9601058\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8745:\tlearn: 3.9597502\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8746:\tlearn: 3.9596625\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8747:\tlearn: 3.9593579\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8748:\tlearn: 3.9591724\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8749:\tlearn: 3.9587698\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8750:\tlearn: 3.9583396\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8751:\tlearn: 3.9583306\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8752:\tlearn: 3.9580569\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8753:\tlearn: 3.9580172\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8754:\tlearn: 3.9577246\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8755:\tlearn: 3.9575900\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8756:\tlearn: 3.9572877\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8757:\tlearn: 3.9572827\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8758:\tlearn: 3.9570362\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8759:\tlearn: 3.9566679\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8760:\tlearn: 3.9565055\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8761:\tlearn: 3.9561832\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8762:\tlearn: 3.9559196\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8763:\tlearn: 3.9555668\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "8764:\tlearn: 3.9553121\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8765:\tlearn: 3.9553060\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8766:\tlearn: 3.9549538\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8767:\tlearn: 3.9546344\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8768:\tlearn: 3.9544617\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8769:\tlearn: 3.9541101\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8770:\tlearn: 3.9538092\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8771:\tlearn: 3.9536048\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8772:\tlearn: 3.9533768\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8773:\tlearn: 3.9531171\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8774:\tlearn: 3.9527229\ttotal: 3m 11s\tremaining: 5m 10s\n",
      "8775:\tlearn: 3.9522807\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8776:\tlearn: 3.9519068\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8777:\tlearn: 3.9517433\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8778:\tlearn: 3.9515364\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8779:\tlearn: 3.9512465\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8780:\tlearn: 3.9509752\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8781:\tlearn: 3.9506184\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8782:\tlearn: 3.9503048\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8783:\tlearn: 3.9500623\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8784:\tlearn: 3.9499575\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8785:\tlearn: 3.9496749\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8786:\tlearn: 3.9494656\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8787:\tlearn: 3.9490939\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8788:\tlearn: 3.9488429\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8789:\tlearn: 3.9485162\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8790:\tlearn: 3.9484176\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8791:\tlearn: 3.9481643\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8792:\tlearn: 3.9478744\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8793:\tlearn: 3.9477075\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8794:\tlearn: 3.9474011\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8795:\tlearn: 3.9471696\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8796:\tlearn: 3.9468875\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8797:\tlearn: 3.9465609\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8798:\tlearn: 3.9463491\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8799:\tlearn: 3.9461368\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8800:\tlearn: 3.9459504\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8801:\tlearn: 3.9455381\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8802:\tlearn: 3.9452656\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8803:\tlearn: 3.9451069\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8804:\tlearn: 3.9450098\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8805:\tlearn: 3.9447934\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8806:\tlearn: 3.9446407\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8807:\tlearn: 3.9444141\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8808:\tlearn: 3.9440252\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8809:\tlearn: 3.9437410\ttotal: 3m 11s\tremaining: 5m 9s\n",
      "8810:\tlearn: 3.9434992\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8811:\tlearn: 3.9432840\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8812:\tlearn: 3.9430831\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8813:\tlearn: 3.9428297\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8814:\tlearn: 3.9426251\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8815:\tlearn: 3.9424042\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8816:\tlearn: 3.9423243\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8817:\tlearn: 3.9421244\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8818:\tlearn: 3.9417388\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8819:\tlearn: 3.9413922\ttotal: 3m 12s\tremaining: 5m 9s\n",
      "8820:\tlearn: 3.9412437\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8821:\tlearn: 3.9410479\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8822:\tlearn: 3.9406014\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8823:\tlearn: 3.9403708\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8824:\tlearn: 3.9401203\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8825:\tlearn: 3.9398719\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8826:\tlearn: 3.9393773\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8827:\tlearn: 3.9391486\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8828:\tlearn: 3.9389955\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8829:\tlearn: 3.9386841\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8830:\tlearn: 3.9386788\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8831:\tlearn: 3.9385686\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8832:\tlearn: 3.9383871\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8833:\tlearn: 3.9380807\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8834:\tlearn: 3.9378816\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8835:\tlearn: 3.9374827\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8836:\tlearn: 3.9372691\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8837:\tlearn: 3.9370849\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8838:\tlearn: 3.9368781\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8839:\tlearn: 3.9366541\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8840:\tlearn: 3.9364373\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8841:\tlearn: 3.9362616\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8842:\tlearn: 3.9360948\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8843:\tlearn: 3.9358899\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8844:\tlearn: 3.9355416\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8845:\tlearn: 3.9352819\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8846:\tlearn: 3.9350169\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8847:\tlearn: 3.9347580\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8848:\tlearn: 3.9344327\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8849:\tlearn: 3.9343062\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8850:\tlearn: 3.9341307\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8851:\tlearn: 3.9339694\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8852:\tlearn: 3.9335677\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8853:\tlearn: 3.9334309\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8854:\tlearn: 3.9332359\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8855:\tlearn: 3.9328852\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8856:\tlearn: 3.9326427\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "8857:\tlearn: 3.9323664\ttotal: 3m 13s\tremaining: 5m 8s\n",
      "8858:\tlearn: 3.9323155\ttotal: 3m 13s\tremaining: 5m 8s\n",
      "8859:\tlearn: 3.9321877\ttotal: 3m 13s\tremaining: 5m 8s\n",
      "8860:\tlearn: 3.9319088\ttotal: 3m 13s\tremaining: 5m 8s\n",
      "8861:\tlearn: 3.9314876\ttotal: 3m 13s\tremaining: 5m 8s\n",
      "8862:\tlearn: 3.9310744\ttotal: 3m 13s\tremaining: 5m 8s\n",
      "8863:\tlearn: 3.9306419\ttotal: 3m 13s\tremaining: 5m 8s\n",
      "8864:\tlearn: 3.9301774\ttotal: 3m 13s\tremaining: 5m 8s\n",
      "8865:\tlearn: 3.9299913\ttotal: 3m 13s\tremaining: 5m 8s\n",
      "8866:\tlearn: 3.9296799\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8867:\tlearn: 3.9294686\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8868:\tlearn: 3.9291366\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8869:\tlearn: 3.9289777\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8870:\tlearn: 3.9286916\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8871:\tlearn: 3.9285463\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8872:\tlearn: 3.9283203\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8873:\tlearn: 3.9281425\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8874:\tlearn: 3.9278663\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8875:\tlearn: 3.9276778\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8876:\tlearn: 3.9272117\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8877:\tlearn: 3.9269323\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8878:\tlearn: 3.9266998\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8879:\tlearn: 3.9264444\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8880:\tlearn: 3.9263297\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8881:\tlearn: 3.9260618\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8882:\tlearn: 3.9258037\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8883:\tlearn: 3.9256776\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8884:\tlearn: 3.9252176\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8885:\tlearn: 3.9249890\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8886:\tlearn: 3.9245737\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8887:\tlearn: 3.9244154\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8888:\tlearn: 3.9241234\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8889:\tlearn: 3.9238391\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8890:\tlearn: 3.9235654\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8891:\tlearn: 3.9233985\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8892:\tlearn: 3.9232223\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8893:\tlearn: 3.9230759\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8894:\tlearn: 3.9228529\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8895:\tlearn: 3.9225481\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8896:\tlearn: 3.9222431\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8897:\tlearn: 3.9219640\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8898:\tlearn: 3.9217728\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8899:\tlearn: 3.9213773\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8900:\tlearn: 3.9211790\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8901:\tlearn: 3.9209146\ttotal: 3m 13s\tremaining: 5m 7s\n",
      "8902:\tlearn: 3.9205132\ttotal: 3m 14s\tremaining: 5m 7s\n",
      "8903:\tlearn: 3.9202159\ttotal: 3m 14s\tremaining: 5m 7s\n",
      "8904:\tlearn: 3.9199837\ttotal: 3m 14s\tremaining: 5m 7s\n",
      "8905:\tlearn: 3.9197812\ttotal: 3m 14s\tremaining: 5m 7s\n",
      "8906:\tlearn: 3.9195958\ttotal: 3m 14s\tremaining: 5m 7s\n",
      "8907:\tlearn: 3.9192988\ttotal: 3m 14s\tremaining: 5m 7s\n",
      "8908:\tlearn: 3.9190756\ttotal: 3m 14s\tremaining: 5m 7s\n",
      "8909:\tlearn: 3.9188627\ttotal: 3m 14s\tremaining: 5m 7s\n",
      "8910:\tlearn: 3.9184407\ttotal: 3m 14s\tremaining: 5m 7s\n",
      "8911:\tlearn: 3.9181848\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8912:\tlearn: 3.9180293\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8913:\tlearn: 3.9178170\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8914:\tlearn: 3.9175285\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8915:\tlearn: 3.9172967\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8916:\tlearn: 3.9169481\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8917:\tlearn: 3.9167230\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8918:\tlearn: 3.9164885\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8919:\tlearn: 3.9163353\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8920:\tlearn: 3.9161352\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8921:\tlearn: 3.9159664\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8922:\tlearn: 3.9157892\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8923:\tlearn: 3.9157832\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8924:\tlearn: 3.9156191\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8925:\tlearn: 3.9154234\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8926:\tlearn: 3.9152486\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8927:\tlearn: 3.9149610\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8928:\tlearn: 3.9148300\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8929:\tlearn: 3.9146051\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8930:\tlearn: 3.9144331\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8931:\tlearn: 3.9141424\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8932:\tlearn: 3.9141065\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8933:\tlearn: 3.9137045\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8934:\tlearn: 3.9134636\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8935:\tlearn: 3.9132456\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8936:\tlearn: 3.9129096\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8937:\tlearn: 3.9126233\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8938:\tlearn: 3.9124307\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8939:\tlearn: 3.9120931\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8940:\tlearn: 3.9119079\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8941:\tlearn: 3.9115579\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8942:\tlearn: 3.9114393\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8943:\tlearn: 3.9113194\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8944:\tlearn: 3.9109870\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8945:\tlearn: 3.9107933\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8946:\tlearn: 3.9104737\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8947:\tlearn: 3.9102862\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8948:\tlearn: 3.9100653\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8949:\tlearn: 3.9097571\ttotal: 3m 14s\tremaining: 5m 6s\n",
      "8950:\tlearn: 3.9097474\ttotal: 3m 15s\tremaining: 5m 6s\n",
      "8951:\tlearn: 3.9095846\ttotal: 3m 15s\tremaining: 5m 6s\n",
      "8952:\tlearn: 3.9095201\ttotal: 3m 15s\tremaining: 5m 6s\n",
      "8953:\tlearn: 3.9091936\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8954:\tlearn: 3.9090642\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8955:\tlearn: 3.9087042\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8956:\tlearn: 3.9085657\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8957:\tlearn: 3.9083760\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8958:\tlearn: 3.9081504\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8959:\tlearn: 3.9080146\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8960:\tlearn: 3.9078280\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8961:\tlearn: 3.9075341\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8962:\tlearn: 3.9074029\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8963:\tlearn: 3.9071824\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8964:\tlearn: 3.9070930\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8965:\tlearn: 3.9068913\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8966:\tlearn: 3.9066669\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8967:\tlearn: 3.9064338\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8968:\tlearn: 3.9063336\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8969:\tlearn: 3.9061400\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8970:\tlearn: 3.9059876\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8971:\tlearn: 3.9058219\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8972:\tlearn: 3.9055697\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8973:\tlearn: 3.9054145\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8974:\tlearn: 3.9052384\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8975:\tlearn: 3.9049594\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8976:\tlearn: 3.9048378\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8977:\tlearn: 3.9045983\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8978:\tlearn: 3.9042274\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8979:\tlearn: 3.9040047\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8980:\tlearn: 3.9039970\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8981:\tlearn: 3.9038602\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8982:\tlearn: 3.9036306\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8983:\tlearn: 3.9033794\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8984:\tlearn: 3.9031418\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8985:\tlearn: 3.9028955\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8986:\tlearn: 3.9026968\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8987:\tlearn: 3.9024516\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8988:\tlearn: 3.9022507\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8989:\tlearn: 3.9020430\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8990:\tlearn: 3.9018545\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8991:\tlearn: 3.9016297\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8992:\tlearn: 3.9014919\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8993:\tlearn: 3.9011523\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8994:\tlearn: 3.9009657\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8995:\tlearn: 3.9007306\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8996:\tlearn: 3.9005079\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "8997:\tlearn: 3.9003352\ttotal: 3m 16s\tremaining: 5m 5s\n",
      "8998:\tlearn: 3.9001238\ttotal: 3m 16s\tremaining: 5m 5s\n",
      "8999:\tlearn: 3.8998941\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9000:\tlearn: 3.8996833\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9001:\tlearn: 3.8995666\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9002:\tlearn: 3.8993996\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9003:\tlearn: 3.8990567\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9004:\tlearn: 3.8988415\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9005:\tlearn: 3.8985339\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9006:\tlearn: 3.8982019\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9007:\tlearn: 3.8978983\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9008:\tlearn: 3.8976565\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9009:\tlearn: 3.8975257\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9010:\tlearn: 3.8973143\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9011:\tlearn: 3.8970866\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9012:\tlearn: 3.8966854\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9013:\tlearn: 3.8965046\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9014:\tlearn: 3.8962999\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9015:\tlearn: 3.8961785\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9016:\tlearn: 3.8960218\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9017:\tlearn: 3.8957303\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9018:\tlearn: 3.8953782\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9019:\tlearn: 3.8951670\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9020:\tlearn: 3.8947337\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9021:\tlearn: 3.8945753\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9022:\tlearn: 3.8943249\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9023:\tlearn: 3.8941043\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9024:\tlearn: 3.8939324\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9025:\tlearn: 3.8937891\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9026:\tlearn: 3.8935588\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9027:\tlearn: 3.8931863\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9028:\tlearn: 3.8931793\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9029:\tlearn: 3.8929402\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9030:\tlearn: 3.8927763\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9031:\tlearn: 3.8926129\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9032:\tlearn: 3.8920734\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9033:\tlearn: 3.8919062\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9034:\tlearn: 3.8917100\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9035:\tlearn: 3.8914985\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9036:\tlearn: 3.8912043\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9037:\tlearn: 3.8909538\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9038:\tlearn: 3.8907263\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9039:\tlearn: 3.8903303\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9040:\tlearn: 3.8900865\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9041:\tlearn: 3.8899499\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9042:\tlearn: 3.8897162\ttotal: 3m 16s\tremaining: 5m 4s\n",
      "9043:\tlearn: 3.8895451\ttotal: 3m 17s\tremaining: 5m 4s\n",
      "9044:\tlearn: 3.8893908\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9045:\tlearn: 3.8889987\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9046:\tlearn: 3.8886704\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9047:\tlearn: 3.8884323\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9048:\tlearn: 3.8883004\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9049:\tlearn: 3.8880512\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9050:\tlearn: 3.8878638\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9051:\tlearn: 3.8875038\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9052:\tlearn: 3.8872833\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9053:\tlearn: 3.8870384\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9054:\tlearn: 3.8869330\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9055:\tlearn: 3.8866074\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9056:\tlearn: 3.8862694\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9057:\tlearn: 3.8859524\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9058:\tlearn: 3.8855770\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9059:\tlearn: 3.8854478\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9060:\tlearn: 3.8852795\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9061:\tlearn: 3.8849189\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9062:\tlearn: 3.8845974\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9063:\tlearn: 3.8843380\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9064:\tlearn: 3.8838976\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9065:\tlearn: 3.8836367\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9066:\tlearn: 3.8834662\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9067:\tlearn: 3.8832142\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9068:\tlearn: 3.8829341\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9069:\tlearn: 3.8826775\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9070:\tlearn: 3.8824871\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9071:\tlearn: 3.8822644\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9072:\tlearn: 3.8820724\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9073:\tlearn: 3.8817153\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9074:\tlearn: 3.8815930\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9075:\tlearn: 3.8812408\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9076:\tlearn: 3.8810830\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9077:\tlearn: 3.8809990\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9078:\tlearn: 3.8808982\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9079:\tlearn: 3.8806281\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9080:\tlearn: 3.8802409\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9081:\tlearn: 3.8802316\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9082:\tlearn: 3.8799377\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9083:\tlearn: 3.8799155\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9084:\tlearn: 3.8797893\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9085:\tlearn: 3.8794584\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9086:\tlearn: 3.8791791\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9087:\tlearn: 3.8789194\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "9088:\tlearn: 3.8787226\ttotal: 3m 17s\tremaining: 5m 2s\n",
      "9089:\tlearn: 3.8783544\ttotal: 3m 17s\tremaining: 5m 2s\n",
      "9090:\tlearn: 3.8782378\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9091:\tlearn: 3.8780028\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9092:\tlearn: 3.8777330\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9093:\tlearn: 3.8775447\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9094:\tlearn: 3.8774311\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9095:\tlearn: 3.8772476\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9096:\tlearn: 3.8770232\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9097:\tlearn: 3.8768598\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9098:\tlearn: 3.8766272\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9099:\tlearn: 3.8763922\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9100:\tlearn: 3.8762064\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9101:\tlearn: 3.8760668\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9102:\tlearn: 3.8758445\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9103:\tlearn: 3.8756470\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9104:\tlearn: 3.8754900\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9105:\tlearn: 3.8752608\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9106:\tlearn: 3.8750632\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9107:\tlearn: 3.8748101\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9108:\tlearn: 3.8745882\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9109:\tlearn: 3.8742344\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9110:\tlearn: 3.8739940\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9111:\tlearn: 3.8738154\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9112:\tlearn: 3.8736774\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9113:\tlearn: 3.8734902\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9114:\tlearn: 3.8731629\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9115:\tlearn: 3.8729253\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9116:\tlearn: 3.8726615\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9117:\tlearn: 3.8725204\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9118:\tlearn: 3.8722422\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9119:\tlearn: 3.8719985\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9120:\tlearn: 3.8717688\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9121:\tlearn: 3.8714725\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9122:\tlearn: 3.8712466\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9123:\tlearn: 3.8710532\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9124:\tlearn: 3.8707720\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9125:\tlearn: 3.8705781\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9126:\tlearn: 3.8703340\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9127:\tlearn: 3.8702062\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9128:\tlearn: 3.8699671\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9129:\tlearn: 3.8699607\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9130:\tlearn: 3.8697224\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9131:\tlearn: 3.8694645\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9132:\tlearn: 3.8691875\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9133:\tlearn: 3.8691053\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "9134:\tlearn: 3.8688977\ttotal: 3m 18s\tremaining: 5m 1s\n",
      "9135:\tlearn: 3.8686070\ttotal: 3m 18s\tremaining: 5m 1s\n",
      "9136:\tlearn: 3.8682754\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9137:\tlearn: 3.8679284\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9138:\tlearn: 3.8676559\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9139:\tlearn: 3.8674038\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9140:\tlearn: 3.8672335\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9141:\tlearn: 3.8670208\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9142:\tlearn: 3.8668202\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9143:\tlearn: 3.8665733\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9144:\tlearn: 3.8664158\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9145:\tlearn: 3.8662319\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9146:\tlearn: 3.8660111\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9147:\tlearn: 3.8657201\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9148:\tlearn: 3.8655677\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9149:\tlearn: 3.8653823\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9150:\tlearn: 3.8652573\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9151:\tlearn: 3.8651033\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9152:\tlearn: 3.8649432\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9153:\tlearn: 3.8646941\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9154:\tlearn: 3.8645632\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9155:\tlearn: 3.8643552\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9156:\tlearn: 3.8639996\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9157:\tlearn: 3.8638516\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9158:\tlearn: 3.8635930\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9159:\tlearn: 3.8634407\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9160:\tlearn: 3.8632407\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9161:\tlearn: 3.8629256\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9162:\tlearn: 3.8627270\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9163:\tlearn: 3.8624768\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9164:\tlearn: 3.8622271\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9165:\tlearn: 3.8619767\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9166:\tlearn: 3.8617958\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9167:\tlearn: 3.8617261\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9168:\tlearn: 3.8615310\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9169:\tlearn: 3.8611478\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9170:\tlearn: 3.8609322\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9171:\tlearn: 3.8607568\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9172:\tlearn: 3.8606118\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9173:\tlearn: 3.8605441\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9174:\tlearn: 3.8603552\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9175:\tlearn: 3.8601911\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9176:\tlearn: 3.8599860\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9177:\tlearn: 3.8597450\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "9178:\tlearn: 3.8594339\ttotal: 3m 19s\tremaining: 5m\n",
      "9179:\tlearn: 3.8592320\ttotal: 3m 19s\tremaining: 5m\n",
      "9180:\tlearn: 3.8589184\ttotal: 3m 19s\tremaining: 5m\n",
      "9181:\tlearn: 3.8586401\ttotal: 3m 19s\tremaining: 5m\n",
      "9182:\tlearn: 3.8583781\ttotal: 3m 19s\tremaining: 5m\n",
      "9183:\tlearn: 3.8580237\ttotal: 3m 20s\tremaining: 5m\n",
      "9184:\tlearn: 3.8576423\ttotal: 3m 20s\tremaining: 5m\n",
      "9185:\tlearn: 3.8574956\ttotal: 3m 20s\tremaining: 5m\n",
      "9186:\tlearn: 3.8572677\ttotal: 3m 20s\tremaining: 5m\n",
      "9187:\tlearn: 3.8570837\ttotal: 3m 20s\tremaining: 5m\n",
      "9188:\tlearn: 3.8568854\ttotal: 3m 20s\tremaining: 5m\n",
      "9189:\tlearn: 3.8567019\ttotal: 3m 20s\tremaining: 5m\n",
      "9190:\tlearn: 3.8564356\ttotal: 3m 20s\tremaining: 5m\n",
      "9191:\tlearn: 3.8562470\ttotal: 3m 20s\tremaining: 5m\n",
      "9192:\tlearn: 3.8559502\ttotal: 3m 20s\tremaining: 5m\n",
      "9193:\tlearn: 3.8556912\ttotal: 3m 20s\tremaining: 5m\n",
      "9194:\tlearn: 3.8552819\ttotal: 3m 20s\tremaining: 5m\n",
      "9195:\tlearn: 3.8549852\ttotal: 3m 20s\tremaining: 5m\n",
      "9196:\tlearn: 3.8546987\ttotal: 3m 20s\tremaining: 5m\n",
      "9197:\tlearn: 3.8545899\ttotal: 3m 20s\tremaining: 5m\n",
      "9198:\tlearn: 3.8541591\ttotal: 3m 20s\tremaining: 5m\n",
      "9199:\tlearn: 3.8538937\ttotal: 3m 20s\tremaining: 5m\n",
      "9200:\tlearn: 3.8537895\ttotal: 3m 20s\tremaining: 5m\n",
      "9201:\tlearn: 3.8535455\ttotal: 3m 20s\tremaining: 5m\n",
      "9202:\tlearn: 3.8535398\ttotal: 3m 20s\tremaining: 5m\n",
      "9203:\tlearn: 3.8532321\ttotal: 3m 20s\tremaining: 5m\n",
      "9204:\tlearn: 3.8529844\ttotal: 3m 20s\tremaining: 5m\n",
      "9205:\tlearn: 3.8526179\ttotal: 3m 20s\tremaining: 5m\n",
      "9206:\tlearn: 3.8522930\ttotal: 3m 20s\tremaining: 5m\n",
      "9207:\tlearn: 3.8521331\ttotal: 3m 20s\tremaining: 5m\n",
      "9208:\tlearn: 3.8519057\ttotal: 3m 20s\tremaining: 5m\n",
      "9209:\tlearn: 3.8517985\ttotal: 3m 20s\tremaining: 5m\n",
      "9210:\tlearn: 3.8515787\ttotal: 3m 20s\tremaining: 5m\n",
      "9211:\tlearn: 3.8513546\ttotal: 3m 20s\tremaining: 5m\n",
      "9212:\tlearn: 3.8512011\ttotal: 3m 20s\tremaining: 5m\n",
      "9213:\tlearn: 3.8509401\ttotal: 3m 20s\tremaining: 5m\n",
      "9214:\tlearn: 3.8507760\ttotal: 3m 20s\tremaining: 5m\n",
      "9215:\tlearn: 3.8505209\ttotal: 3m 20s\tremaining: 5m\n",
      "9216:\tlearn: 3.8502764\ttotal: 3m 20s\tremaining: 5m\n",
      "9217:\tlearn: 3.8501394\ttotal: 3m 20s\tremaining: 5m\n",
      "9218:\tlearn: 3.8499897\ttotal: 3m 20s\tremaining: 5m\n",
      "9219:\tlearn: 3.8497847\ttotal: 3m 20s\tremaining: 5m\n",
      "9220:\tlearn: 3.8495346\ttotal: 3m 20s\tremaining: 5m\n",
      "9221:\tlearn: 3.8493330\ttotal: 3m 20s\tremaining: 5m\n",
      "9222:\tlearn: 3.8491802\ttotal: 3m 20s\tremaining: 5m\n",
      "9223:\tlearn: 3.8490674\ttotal: 3m 20s\tremaining: 4m 59s\n",
      "9224:\tlearn: 3.8488174\ttotal: 3m 20s\tremaining: 4m 59s\n",
      "9225:\tlearn: 3.8488118\ttotal: 3m 20s\tremaining: 4m 59s\n",
      "9226:\tlearn: 3.8486941\ttotal: 3m 20s\tremaining: 4m 59s\n",
      "9227:\tlearn: 3.8485516\ttotal: 3m 20s\tremaining: 4m 59s\n",
      "9228:\tlearn: 3.8483695\ttotal: 3m 20s\tremaining: 4m 59s\n",
      "9229:\tlearn: 3.8481511\ttotal: 3m 20s\tremaining: 4m 59s\n",
      "9230:\tlearn: 3.8480188\ttotal: 3m 20s\tremaining: 4m 59s\n",
      "9231:\tlearn: 3.8477912\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9232:\tlearn: 3.8474038\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9233:\tlearn: 3.8471759\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9234:\tlearn: 3.8469126\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9235:\tlearn: 3.8468095\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9236:\tlearn: 3.8465881\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9237:\tlearn: 3.8464438\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9238:\tlearn: 3.8462244\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9239:\tlearn: 3.8459639\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9240:\tlearn: 3.8458077\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9241:\tlearn: 3.8455984\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9242:\tlearn: 3.8454420\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9243:\tlearn: 3.8452317\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9244:\tlearn: 3.8451138\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9245:\tlearn: 3.8448832\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9246:\tlearn: 3.8446608\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9247:\tlearn: 3.8445381\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9248:\tlearn: 3.8443254\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9249:\tlearn: 3.8442035\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9250:\tlearn: 3.8440073\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9251:\tlearn: 3.8438408\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9252:\tlearn: 3.8436683\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9253:\tlearn: 3.8434734\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9254:\tlearn: 3.8433510\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9255:\tlearn: 3.8432665\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9256:\tlearn: 3.8430645\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9257:\tlearn: 3.8427528\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9258:\tlearn: 3.8425590\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9259:\tlearn: 3.8423219\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9260:\tlearn: 3.8419130\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9261:\tlearn: 3.8417214\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9262:\tlearn: 3.8413790\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9263:\tlearn: 3.8409391\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9264:\tlearn: 3.8407824\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9265:\tlearn: 3.8405316\ttotal: 3m 21s\tremaining: 4m 59s\n",
      "9266:\tlearn: 3.8403107\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9267:\tlearn: 3.8402505\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9268:\tlearn: 3.8400308\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9269:\tlearn: 3.8398203\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9270:\tlearn: 3.8396070\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9271:\tlearn: 3.8393918\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9272:\tlearn: 3.8389803\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9273:\tlearn: 3.8387814\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9274:\tlearn: 3.8385297\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9275:\tlearn: 3.8381873\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9276:\tlearn: 3.8378993\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "9277:\tlearn: 3.8375647\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9278:\tlearn: 3.8371209\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9279:\tlearn: 3.8369673\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9280:\tlearn: 3.8367164\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9281:\tlearn: 3.8365643\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9282:\tlearn: 3.8362755\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9283:\tlearn: 3.8360037\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9284:\tlearn: 3.8358833\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9285:\tlearn: 3.8354912\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9286:\tlearn: 3.8352109\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9287:\tlearn: 3.8348063\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9288:\tlearn: 3.8342488\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9289:\tlearn: 3.8340021\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9290:\tlearn: 3.8338532\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9291:\tlearn: 3.8336511\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9292:\tlearn: 3.8333873\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9293:\tlearn: 3.8330792\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9294:\tlearn: 3.8325823\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9295:\tlearn: 3.8322886\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9296:\tlearn: 3.8321367\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9297:\tlearn: 3.8319906\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9298:\tlearn: 3.8318091\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9299:\tlearn: 3.8315214\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9300:\tlearn: 3.8311637\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9301:\tlearn: 3.8308993\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9302:\tlearn: 3.8307172\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9303:\tlearn: 3.8305663\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9304:\tlearn: 3.8304239\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9305:\tlearn: 3.8301715\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9306:\tlearn: 3.8300553\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9307:\tlearn: 3.8297887\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9308:\tlearn: 3.8295582\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9309:\tlearn: 3.8293989\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9310:\tlearn: 3.8291052\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9311:\tlearn: 3.8288959\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9312:\tlearn: 3.8285564\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "9313:\tlearn: 3.8283201\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9314:\tlearn: 3.8280495\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9315:\tlearn: 3.8277616\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9316:\tlearn: 3.8275151\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9317:\tlearn: 3.8274142\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9318:\tlearn: 3.8271112\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9319:\tlearn: 3.8269317\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9320:\tlearn: 3.8266480\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9321:\tlearn: 3.8263845\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9322:\tlearn: 3.8262782\ttotal: 3m 22s\tremaining: 4m 57s\n",
      "9323:\tlearn: 3.8260419\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9324:\tlearn: 3.8260013\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9325:\tlearn: 3.8257630\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9326:\tlearn: 3.8255243\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9327:\tlearn: 3.8252454\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9328:\tlearn: 3.8250532\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9329:\tlearn: 3.8247863\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9330:\tlearn: 3.8245756\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9331:\tlearn: 3.8243918\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9332:\tlearn: 3.8242093\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9333:\tlearn: 3.8238944\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9334:\tlearn: 3.8237273\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9335:\tlearn: 3.8234276\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9336:\tlearn: 3.8230546\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9337:\tlearn: 3.8228506\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9338:\tlearn: 3.8224834\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9339:\tlearn: 3.8222239\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9340:\tlearn: 3.8218283\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9341:\tlearn: 3.8215423\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9342:\tlearn: 3.8214221\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9343:\tlearn: 3.8212872\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9344:\tlearn: 3.8211657\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9345:\tlearn: 3.8207752\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9346:\tlearn: 3.8206930\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9347:\tlearn: 3.8205813\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9348:\tlearn: 3.8202753\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9349:\tlearn: 3.8200176\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9350:\tlearn: 3.8199204\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9351:\tlearn: 3.8197530\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9352:\tlearn: 3.8195670\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9353:\tlearn: 3.8193115\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9354:\tlearn: 3.8190665\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9355:\tlearn: 3.8187790\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9356:\tlearn: 3.8186310\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "9357:\tlearn: 3.8184180\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9358:\tlearn: 3.8181527\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9359:\tlearn: 3.8179513\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9360:\tlearn: 3.8176687\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9361:\tlearn: 3.8175405\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9362:\tlearn: 3.8172406\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9363:\tlearn: 3.8170600\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9364:\tlearn: 3.8169109\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9365:\tlearn: 3.8167033\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9366:\tlearn: 3.8164913\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9367:\tlearn: 3.8163009\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9368:\tlearn: 3.8159523\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9369:\tlearn: 3.8157871\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9370:\tlearn: 3.8156153\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "9371:\tlearn: 3.8154295\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9372:\tlearn: 3.8153470\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9373:\tlearn: 3.8151577\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9374:\tlearn: 3.8148968\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9375:\tlearn: 3.8146677\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9376:\tlearn: 3.8144126\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9377:\tlearn: 3.8141656\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9378:\tlearn: 3.8138770\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9379:\tlearn: 3.8135872\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9380:\tlearn: 3.8134786\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9381:\tlearn: 3.8133259\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9382:\tlearn: 3.8129651\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9383:\tlearn: 3.8128785\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9384:\tlearn: 3.8127024\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9385:\tlearn: 3.8123289\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9386:\tlearn: 3.8121572\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9387:\tlearn: 3.8119693\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9388:\tlearn: 3.8117103\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9389:\tlearn: 3.8114615\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9390:\tlearn: 3.8111903\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9391:\tlearn: 3.8110035\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9392:\tlearn: 3.8108086\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9393:\tlearn: 3.8105540\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9394:\tlearn: 3.8103589\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9395:\tlearn: 3.8100518\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9396:\tlearn: 3.8097347\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9397:\tlearn: 3.8095669\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9398:\tlearn: 3.8093402\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9399:\tlearn: 3.8091203\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9400:\tlearn: 3.8086800\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9401:\tlearn: 3.8085011\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "9402:\tlearn: 3.8083401\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9403:\tlearn: 3.8079846\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9404:\tlearn: 3.8077684\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9405:\tlearn: 3.8075445\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9406:\tlearn: 3.8074017\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9407:\tlearn: 3.8072281\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9408:\tlearn: 3.8070046\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9409:\tlearn: 3.8067733\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9410:\tlearn: 3.8064024\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9411:\tlearn: 3.8062362\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9412:\tlearn: 3.8060985\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9413:\tlearn: 3.8057614\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9414:\tlearn: 3.8055040\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9415:\tlearn: 3.8053770\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9416:\tlearn: 3.8050955\ttotal: 3m 24s\tremaining: 4m 55s\n",
      "9417:\tlearn: 3.8049475\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9418:\tlearn: 3.8047205\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9419:\tlearn: 3.8044703\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9420:\tlearn: 3.8042610\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9421:\tlearn: 3.8039946\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9422:\tlearn: 3.8039894\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9423:\tlearn: 3.8037609\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9424:\tlearn: 3.8034830\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9425:\tlearn: 3.8031286\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9426:\tlearn: 3.8029491\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9427:\tlearn: 3.8027355\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9428:\tlearn: 3.8024357\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9429:\tlearn: 3.8022216\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9430:\tlearn: 3.8022170\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9431:\tlearn: 3.8018992\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9432:\tlearn: 3.8015614\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9433:\tlearn: 3.8013362\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9434:\tlearn: 3.8011859\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9435:\tlearn: 3.8010172\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9436:\tlearn: 3.8008604\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9437:\tlearn: 3.8007002\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9438:\tlearn: 3.8004440\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9439:\tlearn: 3.8001744\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9440:\tlearn: 3.8000111\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9441:\tlearn: 3.7998149\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9442:\tlearn: 3.7995296\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9443:\tlearn: 3.7993630\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9444:\tlearn: 3.7991646\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9445:\tlearn: 3.7989364\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "9446:\tlearn: 3.7987299\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9447:\tlearn: 3.7984211\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9448:\tlearn: 3.7982079\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9449:\tlearn: 3.7978562\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9450:\tlearn: 3.7973968\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9451:\tlearn: 3.7972763\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9452:\tlearn: 3.7970633\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9453:\tlearn: 3.7968184\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9454:\tlearn: 3.7964535\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9455:\tlearn: 3.7960904\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9456:\tlearn: 3.7959317\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9457:\tlearn: 3.7956017\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9458:\tlearn: 3.7953188\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9459:\tlearn: 3.7951137\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9460:\tlearn: 3.7948505\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9461:\tlearn: 3.7946373\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9462:\tlearn: 3.7944645\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9463:\tlearn: 3.7942988\ttotal: 3m 25s\tremaining: 4m 54s\n",
      "9464:\tlearn: 3.7940836\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9465:\tlearn: 3.7937828\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9466:\tlearn: 3.7936077\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9467:\tlearn: 3.7932895\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9468:\tlearn: 3.7930785\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9469:\tlearn: 3.7929225\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9470:\tlearn: 3.7928128\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9471:\tlearn: 3.7924634\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9472:\tlearn: 3.7923559\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9473:\tlearn: 3.7922547\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9474:\tlearn: 3.7920393\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9475:\tlearn: 3.7918387\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9476:\tlearn: 3.7916874\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9477:\tlearn: 3.7914059\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9478:\tlearn: 3.7913300\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9479:\tlearn: 3.7910143\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9480:\tlearn: 3.7907004\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9481:\tlearn: 3.7905041\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9482:\tlearn: 3.7901993\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9483:\tlearn: 3.7898001\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9484:\tlearn: 3.7897958\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9485:\tlearn: 3.7894247\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9486:\tlearn: 3.7892297\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9487:\tlearn: 3.7890462\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9488:\tlearn: 3.7888844\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9489:\tlearn: 3.7886324\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9490:\tlearn: 3.7883258\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9491:\tlearn: 3.7880270\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9492:\tlearn: 3.7876656\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "9493:\tlearn: 3.7875636\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9494:\tlearn: 3.7874214\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9495:\tlearn: 3.7871680\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9496:\tlearn: 3.7869452\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9497:\tlearn: 3.7866424\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9498:\tlearn: 3.7862923\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9499:\tlearn: 3.7861444\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9500:\tlearn: 3.7859657\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9501:\tlearn: 3.7858832\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9502:\tlearn: 3.7857060\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9503:\tlearn: 3.7854761\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9504:\tlearn: 3.7854175\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9505:\tlearn: 3.7852618\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9506:\tlearn: 3.7850229\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9507:\tlearn: 3.7846873\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9508:\tlearn: 3.7844248\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9509:\tlearn: 3.7842361\ttotal: 3m 26s\tremaining: 4m 53s\n",
      "9510:\tlearn: 3.7838818\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9511:\tlearn: 3.7837069\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9512:\tlearn: 3.7835703\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9513:\tlearn: 3.7833064\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9514:\tlearn: 3.7831496\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9515:\tlearn: 3.7829799\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9516:\tlearn: 3.7826724\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9517:\tlearn: 3.7823767\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9518:\tlearn: 3.7820854\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9519:\tlearn: 3.7816979\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9520:\tlearn: 3.7814974\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9521:\tlearn: 3.7813363\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9522:\tlearn: 3.7812166\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9523:\tlearn: 3.7809704\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9524:\tlearn: 3.7807245\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9525:\tlearn: 3.7805678\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9526:\tlearn: 3.7803894\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9527:\tlearn: 3.7801184\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9528:\tlearn: 3.7796461\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9529:\tlearn: 3.7794641\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9530:\tlearn: 3.7791849\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9531:\tlearn: 3.7791781\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9532:\tlearn: 3.7788053\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9533:\tlearn: 3.7786875\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9534:\tlearn: 3.7783237\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9535:\tlearn: 3.7780480\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9536:\tlearn: 3.7777296\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "9537:\tlearn: 3.7776255\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9538:\tlearn: 3.7773870\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9539:\tlearn: 3.7772054\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9540:\tlearn: 3.7770967\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9541:\tlearn: 3.7770246\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9542:\tlearn: 3.7768925\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9543:\tlearn: 3.7766635\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9544:\tlearn: 3.7765025\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9545:\tlearn: 3.7763039\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9546:\tlearn: 3.7760133\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9547:\tlearn: 3.7757514\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9548:\tlearn: 3.7756225\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9549:\tlearn: 3.7753454\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9550:\tlearn: 3.7750474\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9551:\tlearn: 3.7748850\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9552:\tlearn: 3.7745927\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9553:\tlearn: 3.7742869\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9554:\tlearn: 3.7740710\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9555:\tlearn: 3.7739377\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9556:\tlearn: 3.7736596\ttotal: 3m 27s\tremaining: 4m 52s\n",
      "9557:\tlearn: 3.7732485\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9558:\tlearn: 3.7730712\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9559:\tlearn: 3.7727906\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9560:\tlearn: 3.7725691\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9561:\tlearn: 3.7723378\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9562:\tlearn: 3.7721681\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9563:\tlearn: 3.7718999\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9564:\tlearn: 3.7715268\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9565:\tlearn: 3.7710585\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9566:\tlearn: 3.7708017\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9567:\tlearn: 3.7706725\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9568:\tlearn: 3.7704938\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9569:\tlearn: 3.7702255\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9570:\tlearn: 3.7699046\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9571:\tlearn: 3.7696874\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9572:\tlearn: 3.7694863\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9573:\tlearn: 3.7693680\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9574:\tlearn: 3.7692120\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9575:\tlearn: 3.7690028\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9576:\tlearn: 3.7688048\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9577:\tlearn: 3.7686984\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9578:\tlearn: 3.7685780\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9579:\tlearn: 3.7683008\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9580:\tlearn: 3.7680939\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9581:\tlearn: 3.7678891\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "9582:\tlearn: 3.7676229\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9583:\tlearn: 3.7673327\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9584:\tlearn: 3.7671497\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9585:\tlearn: 3.7668095\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9586:\tlearn: 3.7666274\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9587:\tlearn: 3.7664401\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9588:\tlearn: 3.7660961\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9589:\tlearn: 3.7659658\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9590:\tlearn: 3.7656288\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9591:\tlearn: 3.7652587\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9592:\tlearn: 3.7650792\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9593:\tlearn: 3.7649303\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9594:\tlearn: 3.7644822\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9595:\tlearn: 3.7642236\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9596:\tlearn: 3.7640328\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9597:\tlearn: 3.7638374\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9598:\tlearn: 3.7637412\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9599:\tlearn: 3.7635327\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9600:\tlearn: 3.7634463\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9601:\tlearn: 3.7632463\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9602:\tlearn: 3.7630123\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "9603:\tlearn: 3.7628563\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9604:\tlearn: 3.7627529\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9605:\tlearn: 3.7626503\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9606:\tlearn: 3.7624534\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9607:\tlearn: 3.7622436\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9608:\tlearn: 3.7619815\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9609:\tlearn: 3.7617838\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9610:\tlearn: 3.7614583\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9611:\tlearn: 3.7613111\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9612:\tlearn: 3.7611754\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9613:\tlearn: 3.7609037\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9614:\tlearn: 3.7607448\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9615:\tlearn: 3.7603968\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9616:\tlearn: 3.7602938\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9617:\tlearn: 3.7598081\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9618:\tlearn: 3.7595492\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9619:\tlearn: 3.7592379\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9620:\tlearn: 3.7589769\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9621:\tlearn: 3.7588377\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9622:\tlearn: 3.7586044\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9623:\tlearn: 3.7584060\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9624:\tlearn: 3.7580870\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9625:\tlearn: 3.7578229\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9626:\tlearn: 3.7575499\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9627:\tlearn: 3.7574053\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "9628:\tlearn: 3.7571452\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9629:\tlearn: 3.7569172\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9630:\tlearn: 3.7566256\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9631:\tlearn: 3.7564810\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9632:\tlearn: 3.7563129\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9633:\tlearn: 3.7561370\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9634:\tlearn: 3.7559752\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9635:\tlearn: 3.7556177\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9636:\tlearn: 3.7554900\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9637:\tlearn: 3.7552707\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9638:\tlearn: 3.7550560\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9639:\tlearn: 3.7549239\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9640:\tlearn: 3.7547366\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9641:\tlearn: 3.7545102\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9642:\tlearn: 3.7543563\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9643:\tlearn: 3.7541839\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9644:\tlearn: 3.7540510\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9645:\tlearn: 3.7538599\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9646:\tlearn: 3.7537397\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9647:\tlearn: 3.7535364\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9648:\tlearn: 3.7533515\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9649:\tlearn: 3.7531175\ttotal: 3m 29s\tremaining: 4m 50s\n",
      "9650:\tlearn: 3.7528123\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9651:\tlearn: 3.7525888\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9652:\tlearn: 3.7525002\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9653:\tlearn: 3.7523740\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9654:\tlearn: 3.7522700\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9655:\tlearn: 3.7519918\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9656:\tlearn: 3.7518215\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9657:\tlearn: 3.7516657\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9658:\tlearn: 3.7513684\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9659:\tlearn: 3.7511430\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9660:\tlearn: 3.7509044\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9661:\tlearn: 3.7506457\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9662:\tlearn: 3.7503946\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9663:\tlearn: 3.7501086\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9664:\tlearn: 3.7499495\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9665:\tlearn: 3.7498278\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9666:\tlearn: 3.7496533\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9667:\tlearn: 3.7494245\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9668:\tlearn: 3.7491142\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9669:\tlearn: 3.7488497\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9670:\tlearn: 3.7484413\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9671:\tlearn: 3.7483426\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9672:\tlearn: 3.7481011\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "9673:\tlearn: 3.7477731\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9674:\tlearn: 3.7476915\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9675:\tlearn: 3.7475116\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9676:\tlearn: 3.7471616\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9677:\tlearn: 3.7468443\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9678:\tlearn: 3.7467173\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9679:\tlearn: 3.7466180\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9680:\tlearn: 3.7464068\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9681:\tlearn: 3.7461379\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9682:\tlearn: 3.7458196\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9683:\tlearn: 3.7454890\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9684:\tlearn: 3.7454834\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9685:\tlearn: 3.7452126\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9686:\tlearn: 3.7449368\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9687:\tlearn: 3.7445606\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9688:\tlearn: 3.7443579\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9689:\tlearn: 3.7442687\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9690:\tlearn: 3.7440902\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9691:\tlearn: 3.7438986\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9692:\tlearn: 3.7436337\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9693:\tlearn: 3.7432597\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9694:\tlearn: 3.7431322\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9695:\tlearn: 3.7430597\ttotal: 3m 30s\tremaining: 4m 49s\n",
      "9696:\tlearn: 3.7427853\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9697:\tlearn: 3.7426147\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9698:\tlearn: 3.7423984\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9699:\tlearn: 3.7422470\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9700:\tlearn: 3.7419632\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9701:\tlearn: 3.7418224\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9702:\tlearn: 3.7415874\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9703:\tlearn: 3.7412572\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9704:\tlearn: 3.7410534\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9705:\tlearn: 3.7408970\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9706:\tlearn: 3.7406223\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9707:\tlearn: 3.7403394\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9708:\tlearn: 3.7399540\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9709:\tlearn: 3.7396375\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9710:\tlearn: 3.7395483\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9711:\tlearn: 3.7391439\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9712:\tlearn: 3.7388689\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9713:\tlearn: 3.7387903\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9714:\tlearn: 3.7384554\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9715:\tlearn: 3.7382261\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9716:\tlearn: 3.7378587\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9717:\tlearn: 3.7376635\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9718:\tlearn: 3.7372705\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9719:\tlearn: 3.7370229\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "9720:\tlearn: 3.7367955\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9721:\tlearn: 3.7365148\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9722:\tlearn: 3.7363144\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9723:\tlearn: 3.7359342\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9724:\tlearn: 3.7358158\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9725:\tlearn: 3.7356120\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9726:\tlearn: 3.7354447\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9727:\tlearn: 3.7351054\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9728:\tlearn: 3.7349687\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9729:\tlearn: 3.7347656\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9730:\tlearn: 3.7344710\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9731:\tlearn: 3.7342095\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9732:\tlearn: 3.7339821\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9733:\tlearn: 3.7337509\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9734:\tlearn: 3.7335910\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9735:\tlearn: 3.7334025\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9736:\tlearn: 3.7331142\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9737:\tlearn: 3.7328555\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9738:\tlearn: 3.7325578\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9739:\tlearn: 3.7323798\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9740:\tlearn: 3.7322206\ttotal: 3m 31s\tremaining: 4m 48s\n",
      "9741:\tlearn: 3.7318989\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9742:\tlearn: 3.7316375\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9743:\tlearn: 3.7314330\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9744:\tlearn: 3.7312975\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9745:\tlearn: 3.7310797\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9746:\tlearn: 3.7308557\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9747:\tlearn: 3.7305760\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9748:\tlearn: 3.7304169\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9749:\tlearn: 3.7301728\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9750:\tlearn: 3.7299841\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9751:\tlearn: 3.7297472\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9752:\tlearn: 3.7294119\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9753:\tlearn: 3.7292235\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9754:\tlearn: 3.7290810\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9755:\tlearn: 3.7289221\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9756:\tlearn: 3.7286922\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9757:\tlearn: 3.7284938\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9758:\tlearn: 3.7282214\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9759:\tlearn: 3.7280191\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9760:\tlearn: 3.7278786\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9761:\tlearn: 3.7276859\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9762:\tlearn: 3.7275098\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9763:\tlearn: 3.7275023\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9764:\tlearn: 3.7272885\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "9765:\tlearn: 3.7269855\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9766:\tlearn: 3.7268066\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9767:\tlearn: 3.7265829\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9768:\tlearn: 3.7264937\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9769:\tlearn: 3.7263576\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9770:\tlearn: 3.7260235\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9771:\tlearn: 3.7257221\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9772:\tlearn: 3.7256232\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9773:\tlearn: 3.7254471\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9774:\tlearn: 3.7251038\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9775:\tlearn: 3.7249808\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9776:\tlearn: 3.7247905\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9777:\tlearn: 3.7244877\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9778:\tlearn: 3.7242256\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9779:\tlearn: 3.7238788\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9780:\tlearn: 3.7235451\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9781:\tlearn: 3.7233685\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9782:\tlearn: 3.7230926\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9783:\tlearn: 3.7229193\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9784:\tlearn: 3.7226917\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9785:\tlearn: 3.7225112\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9786:\tlearn: 3.7222508\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9787:\tlearn: 3.7219848\ttotal: 3m 32s\tremaining: 4m 47s\n",
      "9788:\tlearn: 3.7216721\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9789:\tlearn: 3.7215787\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9790:\tlearn: 3.7213406\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9791:\tlearn: 3.7211657\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9792:\tlearn: 3.7208104\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9793:\tlearn: 3.7207077\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9794:\tlearn: 3.7206391\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9795:\tlearn: 3.7203308\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9796:\tlearn: 3.7202073\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9797:\tlearn: 3.7199135\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9798:\tlearn: 3.7197137\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9799:\tlearn: 3.7193876\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9800:\tlearn: 3.7191467\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9801:\tlearn: 3.7189479\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9802:\tlearn: 3.7187776\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9803:\tlearn: 3.7187021\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9804:\tlearn: 3.7184635\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9805:\tlearn: 3.7183031\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9806:\tlearn: 3.7181748\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9807:\tlearn: 3.7180123\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9808:\tlearn: 3.7178854\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "9809:\tlearn: 3.7177718\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9810:\tlearn: 3.7175002\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9811:\tlearn: 3.7172664\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9812:\tlearn: 3.7171294\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9813:\tlearn: 3.7168964\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9814:\tlearn: 3.7165851\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9815:\tlearn: 3.7163855\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9816:\tlearn: 3.7162236\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9817:\tlearn: 3.7159221\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9818:\tlearn: 3.7157120\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9819:\tlearn: 3.7153443\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9820:\tlearn: 3.7150717\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9821:\tlearn: 3.7148805\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9822:\tlearn: 3.7146810\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9823:\tlearn: 3.7144853\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9824:\tlearn: 3.7143132\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9825:\tlearn: 3.7140560\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9826:\tlearn: 3.7137834\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9827:\tlearn: 3.7136042\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9828:\tlearn: 3.7133122\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9829:\tlearn: 3.7131264\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9830:\tlearn: 3.7128020\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9831:\tlearn: 3.7126415\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9832:\tlearn: 3.7123396\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9833:\tlearn: 3.7121806\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9834:\tlearn: 3.7119753\ttotal: 3m 33s\tremaining: 4m 46s\n",
      "9835:\tlearn: 3.7118510\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9836:\tlearn: 3.7116431\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9837:\tlearn: 3.7114880\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9838:\tlearn: 3.7112899\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9839:\tlearn: 3.7111398\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9840:\tlearn: 3.7109198\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9841:\tlearn: 3.7105873\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9842:\tlearn: 3.7103680\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9843:\tlearn: 3.7101831\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9844:\tlearn: 3.7098095\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9845:\tlearn: 3.7095053\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9846:\tlearn: 3.7092483\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9847:\tlearn: 3.7091161\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9848:\tlearn: 3.7089885\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9849:\tlearn: 3.7087281\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9850:\tlearn: 3.7086690\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9851:\tlearn: 3.7085098\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9852:\tlearn: 3.7081671\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9853:\tlearn: 3.7078977\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9854:\tlearn: 3.7076515\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9855:\tlearn: 3.7075056\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9856:\tlearn: 3.7073342\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "9857:\tlearn: 3.7070270\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9858:\tlearn: 3.7066916\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9859:\tlearn: 3.7065638\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9860:\tlearn: 3.7062494\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9861:\tlearn: 3.7060786\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9862:\tlearn: 3.7059568\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9863:\tlearn: 3.7058149\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9864:\tlearn: 3.7057133\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9865:\tlearn: 3.7055468\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9866:\tlearn: 3.7052969\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9867:\tlearn: 3.7051548\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9868:\tlearn: 3.7049661\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9869:\tlearn: 3.7046723\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9870:\tlearn: 3.7045896\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9871:\tlearn: 3.7043258\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9872:\tlearn: 3.7039468\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9873:\tlearn: 3.7038428\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9874:\tlearn: 3.7034624\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9875:\tlearn: 3.7032242\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9876:\tlearn: 3.7029317\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9877:\tlearn: 3.7027857\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9878:\tlearn: 3.7025757\ttotal: 3m 34s\tremaining: 4m 45s\n",
      "9879:\tlearn: 3.7023085\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9880:\tlearn: 3.7020350\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9881:\tlearn: 3.7018231\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9882:\tlearn: 3.7015562\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9883:\tlearn: 3.7013442\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9884:\tlearn: 3.7012320\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9885:\tlearn: 3.7010704\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9886:\tlearn: 3.7009887\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9887:\tlearn: 3.7007463\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9888:\tlearn: 3.7005362\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9889:\tlearn: 3.7001457\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9890:\tlearn: 3.6998047\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9891:\tlearn: 3.6996257\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9892:\tlearn: 3.6994322\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9893:\tlearn: 3.6992524\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9894:\tlearn: 3.6990396\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9895:\tlearn: 3.6989342\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9896:\tlearn: 3.6987107\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9897:\tlearn: 3.6985627\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9898:\tlearn: 3.6981381\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9899:\tlearn: 3.6979530\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9900:\tlearn: 3.6978032\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9901:\tlearn: 3.6975821\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9902:\tlearn: 3.6973275\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "9903:\tlearn: 3.6971509\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9904:\tlearn: 3.6969319\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9905:\tlearn: 3.6966739\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9906:\tlearn: 3.6964542\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9907:\tlearn: 3.6962410\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9908:\tlearn: 3.6960138\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9909:\tlearn: 3.6957992\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9910:\tlearn: 3.6954497\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9911:\tlearn: 3.6953125\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9912:\tlearn: 3.6951874\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9913:\tlearn: 3.6949368\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9914:\tlearn: 3.6945817\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9915:\tlearn: 3.6943371\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9916:\tlearn: 3.6941399\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9917:\tlearn: 3.6940432\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9918:\tlearn: 3.6937484\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9919:\tlearn: 3.6936282\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9920:\tlearn: 3.6934592\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9921:\tlearn: 3.6932617\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9922:\tlearn: 3.6930086\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9923:\tlearn: 3.6928047\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9924:\tlearn: 3.6925141\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9925:\tlearn: 3.6923011\ttotal: 3m 35s\tremaining: 4m 44s\n",
      "9926:\tlearn: 3.6918895\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9927:\tlearn: 3.6917065\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9928:\tlearn: 3.6915254\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9929:\tlearn: 3.6913013\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9930:\tlearn: 3.6910259\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9931:\tlearn: 3.6907257\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9932:\tlearn: 3.6904580\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9933:\tlearn: 3.6903529\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9934:\tlearn: 3.6901704\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9935:\tlearn: 3.6899161\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9936:\tlearn: 3.6895605\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9937:\tlearn: 3.6893499\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9938:\tlearn: 3.6891714\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9939:\tlearn: 3.6889966\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9940:\tlearn: 3.6888007\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9941:\tlearn: 3.6885920\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9942:\tlearn: 3.6883317\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9943:\tlearn: 3.6881881\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9944:\tlearn: 3.6879696\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9945:\tlearn: 3.6878146\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9946:\tlearn: 3.6874265\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9947:\tlearn: 3.6872814\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "9948:\tlearn: 3.6871119\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9949:\tlearn: 3.6869100\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9950:\tlearn: 3.6866554\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9951:\tlearn: 3.6863523\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9952:\tlearn: 3.6861243\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9953:\tlearn: 3.6859322\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9954:\tlearn: 3.6858203\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9955:\tlearn: 3.6857104\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9956:\tlearn: 3.6854963\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9957:\tlearn: 3.6852255\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9958:\tlearn: 3.6850988\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9959:\tlearn: 3.6849039\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9960:\tlearn: 3.6846850\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9961:\tlearn: 3.6846074\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9962:\tlearn: 3.6844786\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9963:\tlearn: 3.6843301\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9964:\tlearn: 3.6841804\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9965:\tlearn: 3.6839482\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9966:\tlearn: 3.6837765\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9967:\tlearn: 3.6836522\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9968:\tlearn: 3.6833647\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9969:\tlearn: 3.6832072\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9970:\tlearn: 3.6830316\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9971:\tlearn: 3.6829722\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9972:\tlearn: 3.6827692\ttotal: 3m 36s\tremaining: 4m 43s\n",
      "9973:\tlearn: 3.6825456\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9974:\tlearn: 3.6823179\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9975:\tlearn: 3.6821286\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9976:\tlearn: 3.6819286\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9977:\tlearn: 3.6816132\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9978:\tlearn: 3.6814935\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9979:\tlearn: 3.6814888\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9980:\tlearn: 3.6812066\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9981:\tlearn: 3.6809906\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9982:\tlearn: 3.6808752\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9983:\tlearn: 3.6806742\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9984:\tlearn: 3.6805081\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9985:\tlearn: 3.6803379\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9986:\tlearn: 3.6802071\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9987:\tlearn: 3.6800600\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9988:\tlearn: 3.6799271\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9989:\tlearn: 3.6797375\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9990:\tlearn: 3.6795613\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "9991:\tlearn: 3.6793965\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "9992:\tlearn: 3.6792118\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "9993:\tlearn: 3.6790765\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "9994:\tlearn: 3.6789117\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "9995:\tlearn: 3.6786589\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "9996:\tlearn: 3.6784974\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "9997:\tlearn: 3.6783324\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "9998:\tlearn: 3.6781836\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "9999:\tlearn: 3.6779586\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10000:\tlearn: 3.6776287\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10001:\tlearn: 3.6776207\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10002:\tlearn: 3.6772764\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10003:\tlearn: 3.6771746\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10004:\tlearn: 3.6770386\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10005:\tlearn: 3.6769477\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10006:\tlearn: 3.6768260\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10007:\tlearn: 3.6764628\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10008:\tlearn: 3.6763050\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10009:\tlearn: 3.6761330\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10010:\tlearn: 3.6759367\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10011:\tlearn: 3.6757898\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10012:\tlearn: 3.6756704\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10013:\tlearn: 3.6754325\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10014:\tlearn: 3.6753063\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10015:\tlearn: 3.6751271\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10016:\tlearn: 3.6748897\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10017:\tlearn: 3.6746371\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10018:\tlearn: 3.6744894\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10019:\tlearn: 3.6743327\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10020:\tlearn: 3.6741053\ttotal: 3m 37s\tremaining: 4m 42s\n",
      "10021:\tlearn: 3.6738980\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10022:\tlearn: 3.6736804\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10023:\tlearn: 3.6734622\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10024:\tlearn: 3.6732454\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10025:\tlearn: 3.6729293\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10026:\tlearn: 3.6726539\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10027:\tlearn: 3.6723507\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10028:\tlearn: 3.6721458\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10029:\tlearn: 3.6719151\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10030:\tlearn: 3.6717246\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10031:\tlearn: 3.6716164\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10032:\tlearn: 3.6715134\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10033:\tlearn: 3.6713378\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10034:\tlearn: 3.6712431\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "10035:\tlearn: 3.6710711\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10036:\tlearn: 3.6708372\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10037:\tlearn: 3.6706643\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10038:\tlearn: 3.6704044\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10039:\tlearn: 3.6702091\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10040:\tlearn: 3.6699737\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10041:\tlearn: 3.6698198\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10042:\tlearn: 3.6695493\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10043:\tlearn: 3.6693971\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10044:\tlearn: 3.6691661\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10045:\tlearn: 3.6689593\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10046:\tlearn: 3.6686424\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10047:\tlearn: 3.6683537\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10048:\tlearn: 3.6680872\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10049:\tlearn: 3.6678940\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10050:\tlearn: 3.6677527\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10051:\tlearn: 3.6674975\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10052:\tlearn: 3.6673481\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10053:\tlearn: 3.6671277\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10054:\tlearn: 3.6669389\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10055:\tlearn: 3.6666793\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10056:\tlearn: 3.6663867\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10057:\tlearn: 3.6662113\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10058:\tlearn: 3.6660385\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10059:\tlearn: 3.6658206\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10060:\tlearn: 3.6656599\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10061:\tlearn: 3.6654526\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10062:\tlearn: 3.6654477\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10063:\tlearn: 3.6651417\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10064:\tlearn: 3.6649538\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10065:\tlearn: 3.6647715\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10066:\tlearn: 3.6646641\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10067:\tlearn: 3.6643709\ttotal: 3m 38s\tremaining: 4m 41s\n",
      "10068:\tlearn: 3.6642659\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10069:\tlearn: 3.6641712\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10070:\tlearn: 3.6640302\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10071:\tlearn: 3.6638326\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10072:\tlearn: 3.6636377\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10073:\tlearn: 3.6635053\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10074:\tlearn: 3.6633278\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10075:\tlearn: 3.6631897\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10076:\tlearn: 3.6630808\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10077:\tlearn: 3.6626689\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10078:\tlearn: 3.6625621\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10079:\tlearn: 3.6624024\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "10080:\tlearn: 3.6623031\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10081:\tlearn: 3.6621239\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10082:\tlearn: 3.6617733\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10083:\tlearn: 3.6616693\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10084:\tlearn: 3.6612983\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10085:\tlearn: 3.6610413\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10086:\tlearn: 3.6608769\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10087:\tlearn: 3.6607411\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10088:\tlearn: 3.6605093\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10089:\tlearn: 3.6602576\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10090:\tlearn: 3.6599972\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10091:\tlearn: 3.6598268\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10092:\tlearn: 3.6594041\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10093:\tlearn: 3.6592554\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10094:\tlearn: 3.6591669\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10095:\tlearn: 3.6589332\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10096:\tlearn: 3.6588109\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10097:\tlearn: 3.6588037\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10098:\tlearn: 3.6586549\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10099:\tlearn: 3.6584526\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10100:\tlearn: 3.6582486\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10101:\tlearn: 3.6581806\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10102:\tlearn: 3.6580339\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10103:\tlearn: 3.6579597\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10104:\tlearn: 3.6577704\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10105:\tlearn: 3.6575937\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10106:\tlearn: 3.6574395\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10107:\tlearn: 3.6572635\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10108:\tlearn: 3.6571429\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10109:\tlearn: 3.6568708\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10110:\tlearn: 3.6566791\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10111:\tlearn: 3.6564732\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10112:\tlearn: 3.6561190\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10113:\tlearn: 3.6561124\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10114:\tlearn: 3.6558626\ttotal: 3m 39s\tremaining: 4m 40s\n",
      "10115:\tlearn: 3.6556243\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "10116:\tlearn: 3.6554526\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "10117:\tlearn: 3.6551991\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "10118:\tlearn: 3.6550065\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "10119:\tlearn: 3.6548983\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "10120:\tlearn: 3.6547967\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "10121:\tlearn: 3.6545330\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "10122:\tlearn: 3.6543526\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "10123:\tlearn: 3.6541260\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "10124:\tlearn: 3.6539396\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10125:\tlearn: 3.6537604\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10126:\tlearn: 3.6534819\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10127:\tlearn: 3.6532515\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10128:\tlearn: 3.6530206\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10129:\tlearn: 3.6526785\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10130:\tlearn: 3.6523228\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10131:\tlearn: 3.6521372\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10132:\tlearn: 3.6519061\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10133:\tlearn: 3.6516768\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10134:\tlearn: 3.6512678\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10135:\tlearn: 3.6510497\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10136:\tlearn: 3.6508526\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10137:\tlearn: 3.6505809\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10138:\tlearn: 3.6504022\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10139:\tlearn: 3.6502220\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10140:\tlearn: 3.6499804\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10141:\tlearn: 3.6497548\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10142:\tlearn: 3.6495218\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10143:\tlearn: 3.6492824\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10144:\tlearn: 3.6490610\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10145:\tlearn: 3.6488557\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10146:\tlearn: 3.6486358\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10147:\tlearn: 3.6485201\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10148:\tlearn: 3.6484373\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10149:\tlearn: 3.6483181\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10150:\tlearn: 3.6480888\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10151:\tlearn: 3.6478965\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10152:\tlearn: 3.6476587\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10153:\tlearn: 3.6476555\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10154:\tlearn: 3.6474560\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10155:\tlearn: 3.6472775\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10156:\tlearn: 3.6471322\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10157:\tlearn: 3.6469634\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10158:\tlearn: 3.6467282\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10159:\tlearn: 3.6464753\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10160:\tlearn: 3.6463026\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10161:\tlearn: 3.6460651\ttotal: 3m 40s\tremaining: 4m 39s\n",
      "10162:\tlearn: 3.6459484\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "10163:\tlearn: 3.6457199\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "10164:\tlearn: 3.6455864\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "10165:\tlearn: 3.6453128\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "10166:\tlearn: 3.6451044\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "10167:\tlearn: 3.6448589\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "10168:\tlearn: 3.6445732\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "10169:\tlearn: 3.6444986\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "10170:\tlearn: 3.6442073\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10171:\tlearn: 3.6439047\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10172:\tlearn: 3.6436943\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10173:\tlearn: 3.6435009\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10174:\tlearn: 3.6432740\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10175:\tlearn: 3.6429936\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10176:\tlearn: 3.6428249\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10177:\tlearn: 3.6426754\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10178:\tlearn: 3.6425713\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10179:\tlearn: 3.6422781\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10180:\tlearn: 3.6420391\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10181:\tlearn: 3.6419163\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10182:\tlearn: 3.6416614\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10183:\tlearn: 3.6414063\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10184:\tlearn: 3.6412261\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10185:\tlearn: 3.6410607\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10186:\tlearn: 3.6408090\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10187:\tlearn: 3.6405741\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10188:\tlearn: 3.6402690\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10189:\tlearn: 3.6399282\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10190:\tlearn: 3.6397243\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10191:\tlearn: 3.6395745\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10192:\tlearn: 3.6394257\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10193:\tlearn: 3.6392264\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10194:\tlearn: 3.6388851\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10195:\tlearn: 3.6387023\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10196:\tlearn: 3.6383099\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10197:\tlearn: 3.6380862\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10198:\tlearn: 3.6378822\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10199:\tlearn: 3.6377381\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10200:\tlearn: 3.6374074\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10201:\tlearn: 3.6370932\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10202:\tlearn: 3.6367958\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10203:\tlearn: 3.6365728\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10204:\tlearn: 3.6364022\ttotal: 3m 41s\tremaining: 4m 38s\n",
      "10205:\tlearn: 3.6361673\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10206:\tlearn: 3.6359313\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10207:\tlearn: 3.6357286\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10208:\tlearn: 3.6354643\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10209:\tlearn: 3.6351874\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10210:\tlearn: 3.6349896\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10211:\tlearn: 3.6347714\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10212:\tlearn: 3.6345076\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10213:\tlearn: 3.6343080\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10214:\tlearn: 3.6341286\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10215:\tlearn: 3.6338474\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10216:\tlearn: 3.6336960\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10217:\tlearn: 3.6335526\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10218:\tlearn: 3.6334380\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10219:\tlearn: 3.6333002\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "10220:\tlearn: 3.6331008\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10221:\tlearn: 3.6329899\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10222:\tlearn: 3.6327858\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10223:\tlearn: 3.6325690\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10224:\tlearn: 3.6323679\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10225:\tlearn: 3.6321297\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10226:\tlearn: 3.6318406\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10227:\tlearn: 3.6316869\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10228:\tlearn: 3.6314236\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10229:\tlearn: 3.6312139\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10230:\tlearn: 3.6310350\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10231:\tlearn: 3.6307975\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10232:\tlearn: 3.6307127\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10233:\tlearn: 3.6304141\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10234:\tlearn: 3.6301739\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10235:\tlearn: 3.6300187\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10236:\tlearn: 3.6298458\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10237:\tlearn: 3.6298036\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10238:\tlearn: 3.6295732\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10239:\tlearn: 3.6294760\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10240:\tlearn: 3.6293295\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10241:\tlearn: 3.6290353\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10242:\tlearn: 3.6287520\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10243:\tlearn: 3.6285083\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10244:\tlearn: 3.6283794\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10245:\tlearn: 3.6282291\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10246:\tlearn: 3.6280752\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10247:\tlearn: 3.6278324\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10248:\tlearn: 3.6277121\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10249:\tlearn: 3.6275196\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10250:\tlearn: 3.6273207\ttotal: 3m 42s\tremaining: 4m 37s\n",
      "10251:\tlearn: 3.6271817\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10252:\tlearn: 3.6268676\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10253:\tlearn: 3.6268342\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10254:\tlearn: 3.6266765\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10255:\tlearn: 3.6264418\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10256:\tlearn: 3.6261665\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10257:\tlearn: 3.6259132\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10258:\tlearn: 3.6256791\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10259:\tlearn: 3.6255483\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10260:\tlearn: 3.6255403\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10261:\tlearn: 3.6253368\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10262:\tlearn: 3.6251583\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10263:\tlearn: 3.6249539\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10264:\tlearn: 3.6246338\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "10265:\tlearn: 3.6243357\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10266:\tlearn: 3.6241728\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10267:\tlearn: 3.6240478\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10268:\tlearn: 3.6237895\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10269:\tlearn: 3.6236042\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10270:\tlearn: 3.6233551\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10271:\tlearn: 3.6230964\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10272:\tlearn: 3.6230322\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10273:\tlearn: 3.6228175\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10274:\tlearn: 3.6225819\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10275:\tlearn: 3.6224018\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10276:\tlearn: 3.6221890\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10277:\tlearn: 3.6219784\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10278:\tlearn: 3.6217794\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10279:\tlearn: 3.6214830\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10280:\tlearn: 3.6211856\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10281:\tlearn: 3.6209508\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10282:\tlearn: 3.6206346\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10283:\tlearn: 3.6204295\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10284:\tlearn: 3.6201182\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10285:\tlearn: 3.6199300\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10286:\tlearn: 3.6197573\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10287:\tlearn: 3.6195784\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10288:\tlearn: 3.6194260\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10289:\tlearn: 3.6191955\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10290:\tlearn: 3.6189696\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10291:\tlearn: 3.6188190\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10292:\tlearn: 3.6183889\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10293:\tlearn: 3.6182405\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10294:\tlearn: 3.6180872\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10295:\tlearn: 3.6178949\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10296:\tlearn: 3.6177044\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10297:\tlearn: 3.6175661\ttotal: 3m 43s\tremaining: 4m 36s\n",
      "10298:\tlearn: 3.6173539\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10299:\tlearn: 3.6172087\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10300:\tlearn: 3.6170061\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10301:\tlearn: 3.6167853\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10302:\tlearn: 3.6165653\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10303:\tlearn: 3.6164292\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10304:\tlearn: 3.6161504\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10305:\tlearn: 3.6160057\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10306:\tlearn: 3.6158482\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10307:\tlearn: 3.6156819\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10308:\tlearn: 3.6154886\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10309:\tlearn: 3.6153577\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "10310:\tlearn: 3.6151543\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10311:\tlearn: 3.6149192\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10312:\tlearn: 3.6147305\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10313:\tlearn: 3.6145993\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10314:\tlearn: 3.6143672\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10315:\tlearn: 3.6140697\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10316:\tlearn: 3.6137401\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10317:\tlearn: 3.6133600\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10318:\tlearn: 3.6133437\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10319:\tlearn: 3.6130943\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10320:\tlearn: 3.6128360\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10321:\tlearn: 3.6126463\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10322:\tlearn: 3.6123628\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10323:\tlearn: 3.6121755\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10324:\tlearn: 3.6119472\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10325:\tlearn: 3.6117421\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10326:\tlearn: 3.6115308\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10327:\tlearn: 3.6114096\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10328:\tlearn: 3.6112801\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10329:\tlearn: 3.6111261\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10330:\tlearn: 3.6108914\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10331:\tlearn: 3.6107195\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10332:\tlearn: 3.6105311\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10333:\tlearn: 3.6103999\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10334:\tlearn: 3.6102529\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10335:\tlearn: 3.6100921\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10336:\tlearn: 3.6099208\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10337:\tlearn: 3.6097040\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10338:\tlearn: 3.6095368\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10339:\tlearn: 3.6092786\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10340:\tlearn: 3.6090440\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10341:\tlearn: 3.6088361\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10342:\tlearn: 3.6085413\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10343:\tlearn: 3.6083240\ttotal: 3m 44s\tremaining: 4m 35s\n",
      "10344:\tlearn: 3.6081609\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10345:\tlearn: 3.6079872\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10346:\tlearn: 3.6077459\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10347:\tlearn: 3.6074660\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10348:\tlearn: 3.6074357\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10349:\tlearn: 3.6073295\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10350:\tlearn: 3.6072466\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10351:\tlearn: 3.6070848\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10352:\tlearn: 3.6067498\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10353:\tlearn: 3.6065793\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10354:\tlearn: 3.6063082\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10355:\tlearn: 3.6060086\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "10356:\tlearn: 3.6058705\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10357:\tlearn: 3.6057392\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10358:\tlearn: 3.6055391\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10359:\tlearn: 3.6052713\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10360:\tlearn: 3.6050950\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10361:\tlearn: 3.6048599\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10362:\tlearn: 3.6047232\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10363:\tlearn: 3.6045321\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10364:\tlearn: 3.6044605\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10365:\tlearn: 3.6041512\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10366:\tlearn: 3.6039467\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10367:\tlearn: 3.6037026\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10368:\tlearn: 3.6032744\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10369:\tlearn: 3.6029282\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10370:\tlearn: 3.6027723\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10371:\tlearn: 3.6024624\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10372:\tlearn: 3.6021781\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10373:\tlearn: 3.6020523\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10374:\tlearn: 3.6017551\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10375:\tlearn: 3.6016108\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10376:\tlearn: 3.6013681\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10377:\tlearn: 3.6010629\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10378:\tlearn: 3.6008478\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10379:\tlearn: 3.6006337\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10380:\tlearn: 3.6004101\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10381:\tlearn: 3.6002513\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10382:\tlearn: 3.5999262\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10383:\tlearn: 3.5998565\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10384:\tlearn: 3.5997333\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10385:\tlearn: 3.5995476\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10386:\tlearn: 3.5993922\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10387:\tlearn: 3.5992032\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10388:\tlearn: 3.5989925\ttotal: 3m 45s\tremaining: 4m 34s\n",
      "10389:\tlearn: 3.5988350\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10390:\tlearn: 3.5986235\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10391:\tlearn: 3.5984039\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10392:\tlearn: 3.5982896\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10393:\tlearn: 3.5980484\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10394:\tlearn: 3.5978136\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10395:\tlearn: 3.5976326\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10396:\tlearn: 3.5974888\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10397:\tlearn: 3.5971733\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10398:\tlearn: 3.5968955\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10399:\tlearn: 3.5967114\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10400:\tlearn: 3.5964493\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10401:\tlearn: 3.5964451\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10402:\tlearn: 3.5961493\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "10403:\tlearn: 3.5960040\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10404:\tlearn: 3.5958205\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10405:\tlearn: 3.5954991\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10406:\tlearn: 3.5952584\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10407:\tlearn: 3.5949482\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10408:\tlearn: 3.5948137\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10409:\tlearn: 3.5946099\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10410:\tlearn: 3.5943801\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10411:\tlearn: 3.5941682\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10412:\tlearn: 3.5939929\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10413:\tlearn: 3.5938610\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10414:\tlearn: 3.5936717\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10415:\tlearn: 3.5933602\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10416:\tlearn: 3.5931166\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10417:\tlearn: 3.5928375\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10418:\tlearn: 3.5927559\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10419:\tlearn: 3.5926306\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10420:\tlearn: 3.5924851\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10421:\tlearn: 3.5923725\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10422:\tlearn: 3.5922668\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10423:\tlearn: 3.5920957\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10424:\tlearn: 3.5919062\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10425:\tlearn: 3.5917456\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10426:\tlearn: 3.5914822\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10427:\tlearn: 3.5913504\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10428:\tlearn: 3.5912523\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10429:\tlearn: 3.5909809\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10430:\tlearn: 3.5909020\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10431:\tlearn: 3.5907151\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10432:\tlearn: 3.5904964\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10433:\tlearn: 3.5903350\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10434:\tlearn: 3.5901760\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10435:\tlearn: 3.5900462\ttotal: 3m 46s\tremaining: 4m 33s\n",
      "10436:\tlearn: 3.5899295\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10437:\tlearn: 3.5896970\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10438:\tlearn: 3.5893396\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10439:\tlearn: 3.5889589\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10440:\tlearn: 3.5887307\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10441:\tlearn: 3.5884517\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10442:\tlearn: 3.5882224\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10443:\tlearn: 3.5880652\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10444:\tlearn: 3.5878338\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10445:\tlearn: 3.5876094\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10446:\tlearn: 3.5874123\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10447:\tlearn: 3.5872537\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "10448:\tlearn: 3.5871159\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10449:\tlearn: 3.5868574\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10450:\tlearn: 3.5868478\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10451:\tlearn: 3.5866669\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10452:\tlearn: 3.5865257\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10453:\tlearn: 3.5862257\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10454:\tlearn: 3.5859563\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10455:\tlearn: 3.5857965\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10456:\tlearn: 3.5856982\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10457:\tlearn: 3.5853516\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10458:\tlearn: 3.5851698\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10459:\tlearn: 3.5848627\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10460:\tlearn: 3.5846993\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10461:\tlearn: 3.5844761\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10462:\tlearn: 3.5841577\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10463:\tlearn: 3.5839047\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10464:\tlearn: 3.5837061\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10465:\tlearn: 3.5834616\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10466:\tlearn: 3.5832831\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10467:\tlearn: 3.5831634\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10468:\tlearn: 3.5828899\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10469:\tlearn: 3.5826673\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10470:\tlearn: 3.5824812\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10471:\tlearn: 3.5822697\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10472:\tlearn: 3.5819963\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10473:\tlearn: 3.5818827\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10474:\tlearn: 3.5817226\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10475:\tlearn: 3.5815409\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10476:\tlearn: 3.5813538\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10477:\tlearn: 3.5811963\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10478:\tlearn: 3.5810448\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10479:\tlearn: 3.5809487\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10480:\tlearn: 3.5807604\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10481:\tlearn: 3.5805826\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10482:\tlearn: 3.5804020\ttotal: 3m 47s\tremaining: 4m 32s\n",
      "10483:\tlearn: 3.5801175\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10484:\tlearn: 3.5799865\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10485:\tlearn: 3.5797197\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10486:\tlearn: 3.5794998\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10487:\tlearn: 3.5792863\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10488:\tlearn: 3.5791688\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10489:\tlearn: 3.5788620\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10490:\tlearn: 3.5786793\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10491:\tlearn: 3.5785636\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10492:\tlearn: 3.5784161\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "10493:\tlearn: 3.5782590\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10494:\tlearn: 3.5780593\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10495:\tlearn: 3.5779303\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10496:\tlearn: 3.5777936\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10497:\tlearn: 3.5775483\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10498:\tlearn: 3.5774202\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10499:\tlearn: 3.5772773\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10500:\tlearn: 3.5770190\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10501:\tlearn: 3.5768975\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10502:\tlearn: 3.5767461\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10503:\tlearn: 3.5766211\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10504:\tlearn: 3.5763861\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10505:\tlearn: 3.5761366\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10506:\tlearn: 3.5758802\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10507:\tlearn: 3.5757924\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10508:\tlearn: 3.5755336\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10509:\tlearn: 3.5753910\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10510:\tlearn: 3.5750773\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10511:\tlearn: 3.5747369\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10512:\tlearn: 3.5745070\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10513:\tlearn: 3.5742581\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10514:\tlearn: 3.5740688\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10515:\tlearn: 3.5739178\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10516:\tlearn: 3.5735714\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10517:\tlearn: 3.5733209\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10518:\tlearn: 3.5732049\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10519:\tlearn: 3.5730822\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10520:\tlearn: 3.5729513\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10521:\tlearn: 3.5726544\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10522:\tlearn: 3.5723782\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10523:\tlearn: 3.5722725\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10524:\tlearn: 3.5721032\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10525:\tlearn: 3.5719434\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10526:\tlearn: 3.5716893\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10527:\tlearn: 3.5714263\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10528:\tlearn: 3.5712637\ttotal: 3m 48s\tremaining: 4m 31s\n",
      "10529:\tlearn: 3.5711600\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "10530:\tlearn: 3.5709434\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "10531:\tlearn: 3.5706440\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "10532:\tlearn: 3.5704661\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "10533:\tlearn: 3.5703185\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "10534:\tlearn: 3.5701051\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "10535:\tlearn: 3.5700982\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "10536:\tlearn: 3.5700365\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "10537:\tlearn: 3.5696620\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "10538:\tlearn: 3.5694933\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10539:\tlearn: 3.5693484\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10540:\tlearn: 3.5691130\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10541:\tlearn: 3.5689518\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10542:\tlearn: 3.5687849\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10543:\tlearn: 3.5687072\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10544:\tlearn: 3.5685045\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10545:\tlearn: 3.5683913\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10546:\tlearn: 3.5681430\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10547:\tlearn: 3.5679451\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10548:\tlearn: 3.5677124\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10549:\tlearn: 3.5675203\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10550:\tlearn: 3.5674237\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10551:\tlearn: 3.5672913\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10552:\tlearn: 3.5670880\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10553:\tlearn: 3.5670817\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10554:\tlearn: 3.5668605\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10555:\tlearn: 3.5666304\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10556:\tlearn: 3.5664861\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10557:\tlearn: 3.5662766\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10558:\tlearn: 3.5661092\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10559:\tlearn: 3.5659128\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10560:\tlearn: 3.5657573\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10561:\tlearn: 3.5654770\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10562:\tlearn: 3.5652718\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10563:\tlearn: 3.5650272\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10564:\tlearn: 3.5648880\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10565:\tlearn: 3.5647049\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10566:\tlearn: 3.5644425\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10567:\tlearn: 3.5643176\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10568:\tlearn: 3.5641427\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10569:\tlearn: 3.5637032\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10570:\tlearn: 3.5634863\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10571:\tlearn: 3.5631991\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10572:\tlearn: 3.5630285\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10573:\tlearn: 3.5628445\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10574:\tlearn: 3.5626909\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10575:\tlearn: 3.5624731\ttotal: 3m 49s\tremaining: 4m 30s\n",
      "10576:\tlearn: 3.5624683\ttotal: 3m 50s\tremaining: 4m 30s\n",
      "10577:\tlearn: 3.5622985\ttotal: 3m 50s\tremaining: 4m 30s\n",
      "10578:\tlearn: 3.5620402\ttotal: 3m 50s\tremaining: 4m 30s\n",
      "10579:\tlearn: 3.5618864\ttotal: 3m 50s\tremaining: 4m 30s\n",
      "10580:\tlearn: 3.5617089\ttotal: 3m 50s\tremaining: 4m 30s\n",
      "10581:\tlearn: 3.5614928\ttotal: 3m 50s\tremaining: 4m 30s\n",
      "10582:\tlearn: 3.5613243\ttotal: 3m 50s\tremaining: 4m 30s\n",
      "10583:\tlearn: 3.5611762\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10584:\tlearn: 3.5608694\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10585:\tlearn: 3.5607439\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10586:\tlearn: 3.5606455\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10587:\tlearn: 3.5604728\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10588:\tlearn: 3.5603209\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10589:\tlearn: 3.5601645\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10590:\tlearn: 3.5600438\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10591:\tlearn: 3.5597748\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10592:\tlearn: 3.5595328\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10593:\tlearn: 3.5593949\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10594:\tlearn: 3.5592028\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10595:\tlearn: 3.5590606\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10596:\tlearn: 3.5588139\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10597:\tlearn: 3.5586663\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10598:\tlearn: 3.5584169\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10599:\tlearn: 3.5582937\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10600:\tlearn: 3.5580686\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10601:\tlearn: 3.5579255\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10602:\tlearn: 3.5578706\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10603:\tlearn: 3.5576232\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10604:\tlearn: 3.5574761\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10605:\tlearn: 3.5572953\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10606:\tlearn: 3.5570057\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10607:\tlearn: 3.5567884\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10608:\tlearn: 3.5565030\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10609:\tlearn: 3.5563104\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10610:\tlearn: 3.5560773\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10611:\tlearn: 3.5559321\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10612:\tlearn: 3.5557094\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10613:\tlearn: 3.5554626\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10614:\tlearn: 3.5551924\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10615:\tlearn: 3.5550405\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10616:\tlearn: 3.5547668\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10617:\tlearn: 3.5545911\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10618:\tlearn: 3.5544366\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10619:\tlearn: 3.5542520\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10620:\tlearn: 3.5540425\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10621:\tlearn: 3.5538391\ttotal: 3m 50s\tremaining: 4m 29s\n",
      "10622:\tlearn: 3.5536937\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "10623:\tlearn: 3.5534239\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "10624:\tlearn: 3.5532487\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "10625:\tlearn: 3.5529299\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "10626:\tlearn: 3.5527913\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "10627:\tlearn: 3.5527007\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "10628:\tlearn: 3.5525910\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "10629:\tlearn: 3.5522973\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "10630:\tlearn: 3.5522373\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10631:\tlearn: 3.5520574\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10632:\tlearn: 3.5518683\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10633:\tlearn: 3.5516921\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10634:\tlearn: 3.5514390\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10635:\tlearn: 3.5512111\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10636:\tlearn: 3.5509705\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10637:\tlearn: 3.5508634\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10638:\tlearn: 3.5506810\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10639:\tlearn: 3.5504129\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10640:\tlearn: 3.5502416\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10641:\tlearn: 3.5501396\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10642:\tlearn: 3.5499916\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10643:\tlearn: 3.5499088\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10644:\tlearn: 3.5497700\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10645:\tlearn: 3.5495750\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10646:\tlearn: 3.5493324\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10647:\tlearn: 3.5491378\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10648:\tlearn: 3.5489270\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10649:\tlearn: 3.5487765\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10650:\tlearn: 3.5486347\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10651:\tlearn: 3.5484505\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10652:\tlearn: 3.5482569\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10653:\tlearn: 3.5479609\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10654:\tlearn: 3.5477734\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10655:\tlearn: 3.5475400\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10656:\tlearn: 3.5473515\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10657:\tlearn: 3.5470149\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10658:\tlearn: 3.5468235\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10659:\tlearn: 3.5464946\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10660:\tlearn: 3.5462963\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10661:\tlearn: 3.5460883\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10662:\tlearn: 3.5458598\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10663:\tlearn: 3.5456286\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10664:\tlearn: 3.5453883\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10665:\tlearn: 3.5452658\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10666:\tlearn: 3.5450136\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10667:\tlearn: 3.5447658\ttotal: 3m 51s\tremaining: 4m 28s\n",
      "10668:\tlearn: 3.5444974\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "10669:\tlearn: 3.5441854\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "10670:\tlearn: 3.5440443\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "10671:\tlearn: 3.5437277\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "10672:\tlearn: 3.5435109\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "10673:\tlearn: 3.5434316\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "10674:\tlearn: 3.5432712\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "10675:\tlearn: 3.5430230\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "10676:\tlearn: 3.5427750\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "10677:\tlearn: 3.5427698\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10678:\tlearn: 3.5425693\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10679:\tlearn: 3.5423816\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10680:\tlearn: 3.5421838\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10681:\tlearn: 3.5419992\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10682:\tlearn: 3.5418630\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10683:\tlearn: 3.5417533\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10684:\tlearn: 3.5416435\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10685:\tlearn: 3.5415360\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10686:\tlearn: 3.5412370\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10687:\tlearn: 3.5410512\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10688:\tlearn: 3.5410453\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10689:\tlearn: 3.5408850\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10690:\tlearn: 3.5406929\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10691:\tlearn: 3.5405034\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10692:\tlearn: 3.5402543\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10693:\tlearn: 3.5401459\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10694:\tlearn: 3.5399029\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10695:\tlearn: 3.5397118\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10696:\tlearn: 3.5395553\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10697:\tlearn: 3.5392661\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10698:\tlearn: 3.5391370\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10699:\tlearn: 3.5390026\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10700:\tlearn: 3.5387625\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10701:\tlearn: 3.5384047\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10702:\tlearn: 3.5382473\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10703:\tlearn: 3.5380795\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10704:\tlearn: 3.5378407\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10705:\tlearn: 3.5377096\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10706:\tlearn: 3.5374193\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10707:\tlearn: 3.5372330\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10708:\tlearn: 3.5368947\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10709:\tlearn: 3.5366881\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10710:\tlearn: 3.5365598\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10711:\tlearn: 3.5363526\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10712:\tlearn: 3.5361820\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10713:\tlearn: 3.5360401\ttotal: 3m 52s\tremaining: 4m 27s\n",
      "10714:\tlearn: 3.5358270\ttotal: 3m 53s\tremaining: 4m 27s\n",
      "10715:\tlearn: 3.5355587\ttotal: 3m 53s\tremaining: 4m 27s\n",
      "10716:\tlearn: 3.5354361\ttotal: 3m 53s\tremaining: 4m 27s\n",
      "10717:\tlearn: 3.5352203\ttotal: 3m 53s\tremaining: 4m 27s\n",
      "10718:\tlearn: 3.5350155\ttotal: 3m 53s\tremaining: 4m 27s\n",
      "10719:\tlearn: 3.5348130\ttotal: 3m 53s\tremaining: 4m 27s\n",
      "10720:\tlearn: 3.5346491\ttotal: 3m 53s\tremaining: 4m 27s\n",
      "10721:\tlearn: 3.5344406\ttotal: 3m 53s\tremaining: 4m 27s\n",
      "10722:\tlearn: 3.5343285\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10723:\tlearn: 3.5341050\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10724:\tlearn: 3.5339538\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10725:\tlearn: 3.5336634\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10726:\tlearn: 3.5335707\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10727:\tlearn: 3.5333022\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10728:\tlearn: 3.5331591\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10729:\tlearn: 3.5329229\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10730:\tlearn: 3.5327272\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10731:\tlearn: 3.5325463\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10732:\tlearn: 3.5323977\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10733:\tlearn: 3.5319879\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10734:\tlearn: 3.5318458\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10735:\tlearn: 3.5315704\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10736:\tlearn: 3.5313010\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10737:\tlearn: 3.5311757\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10738:\tlearn: 3.5309709\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10739:\tlearn: 3.5308781\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10740:\tlearn: 3.5306975\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10741:\tlearn: 3.5305075\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10742:\tlearn: 3.5303963\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10743:\tlearn: 3.5302279\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10744:\tlearn: 3.5300244\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10745:\tlearn: 3.5298097\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10746:\tlearn: 3.5296040\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10747:\tlearn: 3.5294286\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10748:\tlearn: 3.5294239\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10749:\tlearn: 3.5291743\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10750:\tlearn: 3.5289976\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10751:\tlearn: 3.5288033\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10752:\tlearn: 3.5286075\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10753:\tlearn: 3.5284505\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10754:\tlearn: 3.5281886\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10755:\tlearn: 3.5278946\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10756:\tlearn: 3.5277127\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10757:\tlearn: 3.5274552\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10758:\tlearn: 3.5272731\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10759:\tlearn: 3.5271290\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10760:\tlearn: 3.5268952\ttotal: 3m 53s\tremaining: 4m 26s\n",
      "10761:\tlearn: 3.5267611\ttotal: 3m 54s\tremaining: 4m 26s\n",
      "10762:\tlearn: 3.5266007\ttotal: 3m 54s\tremaining: 4m 26s\n",
      "10763:\tlearn: 3.5263749\ttotal: 3m 54s\tremaining: 4m 26s\n",
      "10764:\tlearn: 3.5261999\ttotal: 3m 54s\tremaining: 4m 26s\n",
      "10765:\tlearn: 3.5259367\ttotal: 3m 54s\tremaining: 4m 26s\n",
      "10766:\tlearn: 3.5259329\ttotal: 3m 54s\tremaining: 4m 26s\n",
      "10767:\tlearn: 3.5258920\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10768:\tlearn: 3.5255119\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10769:\tlearn: 3.5252814\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10770:\tlearn: 3.5250317\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10771:\tlearn: 3.5249614\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10772:\tlearn: 3.5247401\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10773:\tlearn: 3.5246516\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10774:\tlearn: 3.5244960\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10775:\tlearn: 3.5243252\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10776:\tlearn: 3.5241684\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10777:\tlearn: 3.5239787\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10778:\tlearn: 3.5236860\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10779:\tlearn: 3.5235100\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10780:\tlearn: 3.5233781\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10781:\tlearn: 3.5232849\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10782:\tlearn: 3.5232380\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10783:\tlearn: 3.5230072\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10784:\tlearn: 3.5227604\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10785:\tlearn: 3.5224220\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10786:\tlearn: 3.5222238\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10787:\tlearn: 3.5221253\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10788:\tlearn: 3.5219125\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10789:\tlearn: 3.5217572\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10790:\tlearn: 3.5215455\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10791:\tlearn: 3.5214519\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10792:\tlearn: 3.5211166\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10793:\tlearn: 3.5208993\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10794:\tlearn: 3.5207466\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10795:\tlearn: 3.5207284\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10796:\tlearn: 3.5206313\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10797:\tlearn: 3.5204558\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10798:\tlearn: 3.5203145\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10799:\tlearn: 3.5201102\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10800:\tlearn: 3.5198850\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10801:\tlearn: 3.5195536\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10802:\tlearn: 3.5193328\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10803:\tlearn: 3.5191625\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10804:\tlearn: 3.5189410\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10805:\tlearn: 3.5186621\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10806:\tlearn: 3.5185289\ttotal: 3m 54s\tremaining: 4m 25s\n",
      "10807:\tlearn: 3.5183169\ttotal: 3m 55s\tremaining: 4m 25s\n",
      "10808:\tlearn: 3.5182343\ttotal: 3m 55s\tremaining: 4m 25s\n",
      "10809:\tlearn: 3.5180736\ttotal: 3m 55s\tremaining: 4m 25s\n",
      "10810:\tlearn: 3.5179089\ttotal: 3m 55s\tremaining: 4m 25s\n",
      "10811:\tlearn: 3.5175998\ttotal: 3m 55s\tremaining: 4m 25s\n",
      "10812:\tlearn: 3.5173183\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10813:\tlearn: 3.5171089\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10814:\tlearn: 3.5169105\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10815:\tlearn: 3.5167383\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10816:\tlearn: 3.5164880\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10817:\tlearn: 3.5161795\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10818:\tlearn: 3.5158759\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10819:\tlearn: 3.5156229\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10820:\tlearn: 3.5154131\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10821:\tlearn: 3.5152316\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10822:\tlearn: 3.5151172\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10823:\tlearn: 3.5149437\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10824:\tlearn: 3.5146823\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10825:\tlearn: 3.5143931\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10826:\tlearn: 3.5141931\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10827:\tlearn: 3.5140567\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10828:\tlearn: 3.5137587\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10829:\tlearn: 3.5136351\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10830:\tlearn: 3.5135154\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10831:\tlearn: 3.5133326\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10832:\tlearn: 3.5131797\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10833:\tlearn: 3.5130470\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10834:\tlearn: 3.5127551\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10835:\tlearn: 3.5124946\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10836:\tlearn: 3.5123586\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10837:\tlearn: 3.5121788\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10838:\tlearn: 3.5119382\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10839:\tlearn: 3.5117517\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10840:\tlearn: 3.5115729\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10841:\tlearn: 3.5114384\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10842:\tlearn: 3.5111427\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10843:\tlearn: 3.5110089\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10844:\tlearn: 3.5108081\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10845:\tlearn: 3.5106497\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10846:\tlearn: 3.5105032\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10847:\tlearn: 3.5101798\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10848:\tlearn: 3.5099883\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10849:\tlearn: 3.5098088\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10850:\tlearn: 3.5095472\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10851:\tlearn: 3.5093399\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10852:\tlearn: 3.5091124\ttotal: 3m 55s\tremaining: 4m 24s\n",
      "10853:\tlearn: 3.5089107\ttotal: 3m 56s\tremaining: 4m 24s\n",
      "10854:\tlearn: 3.5086929\ttotal: 3m 56s\tremaining: 4m 24s\n",
      "10855:\tlearn: 3.5083975\ttotal: 3m 56s\tremaining: 4m 24s\n",
      "10856:\tlearn: 3.5081475\ttotal: 3m 56s\tremaining: 4m 24s\n",
      "10857:\tlearn: 3.5079929\ttotal: 3m 56s\tremaining: 4m 24s\n",
      "10858:\tlearn: 3.5077630\ttotal: 3m 56s\tremaining: 4m 24s\n",
      "10859:\tlearn: 3.5074961\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10860:\tlearn: 3.5073675\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10861:\tlearn: 3.5071718\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10862:\tlearn: 3.5070412\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10863:\tlearn: 3.5069070\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10864:\tlearn: 3.5067354\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10865:\tlearn: 3.5066084\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10866:\tlearn: 3.5063707\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10867:\tlearn: 3.5062446\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10868:\tlearn: 3.5060827\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10869:\tlearn: 3.5059034\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10870:\tlearn: 3.5058393\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10871:\tlearn: 3.5055342\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10872:\tlearn: 3.5053461\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10873:\tlearn: 3.5051404\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10874:\tlearn: 3.5048567\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10875:\tlearn: 3.5047576\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10876:\tlearn: 3.5045742\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10877:\tlearn: 3.5044296\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10878:\tlearn: 3.5041407\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10879:\tlearn: 3.5038039\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10880:\tlearn: 3.5035407\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10881:\tlearn: 3.5034121\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10882:\tlearn: 3.5031919\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10883:\tlearn: 3.5030014\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10884:\tlearn: 3.5028169\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10885:\tlearn: 3.5026618\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10886:\tlearn: 3.5024159\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10887:\tlearn: 3.5022406\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10888:\tlearn: 3.5020445\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10889:\tlearn: 3.5020398\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10890:\tlearn: 3.5018287\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10891:\tlearn: 3.5016485\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10892:\tlearn: 3.5015094\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10893:\tlearn: 3.5012684\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10894:\tlearn: 3.5011291\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10895:\tlearn: 3.5010121\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10896:\tlearn: 3.5008583\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10897:\tlearn: 3.5006869\ttotal: 3m 56s\tremaining: 4m 23s\n",
      "10898:\tlearn: 3.5006012\ttotal: 3m 57s\tremaining: 4m 23s\n",
      "10899:\tlearn: 3.5005954\ttotal: 3m 57s\tremaining: 4m 23s\n",
      "10900:\tlearn: 3.5003115\ttotal: 3m 57s\tremaining: 4m 23s\n",
      "10901:\tlearn: 3.5000612\ttotal: 3m 57s\tremaining: 4m 23s\n",
      "10902:\tlearn: 3.4998693\ttotal: 3m 57s\tremaining: 4m 23s\n",
      "10903:\tlearn: 3.4994861\ttotal: 3m 57s\tremaining: 4m 23s\n",
      "10904:\tlearn: 3.4993682\ttotal: 3m 57s\tremaining: 4m 23s\n",
      "10905:\tlearn: 3.4991514\ttotal: 3m 57s\tremaining: 4m 23s\n",
      "10906:\tlearn: 3.4988996\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10907:\tlearn: 3.4987535\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10908:\tlearn: 3.4986083\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10909:\tlearn: 3.4984881\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10910:\tlearn: 3.4982772\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10911:\tlearn: 3.4981643\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10912:\tlearn: 3.4980135\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10913:\tlearn: 3.4978199\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10914:\tlearn: 3.4976417\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10915:\tlearn: 3.4974992\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10916:\tlearn: 3.4972960\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10917:\tlearn: 3.4971071\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10918:\tlearn: 3.4967800\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10919:\tlearn: 3.4967646\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10920:\tlearn: 3.4966407\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10921:\tlearn: 3.4964500\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10922:\tlearn: 3.4962531\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10923:\tlearn: 3.4961440\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10924:\tlearn: 3.4960039\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10925:\tlearn: 3.4958299\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10926:\tlearn: 3.4956737\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10927:\tlearn: 3.4954816\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10928:\tlearn: 3.4953578\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10929:\tlearn: 3.4951398\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10930:\tlearn: 3.4949195\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10931:\tlearn: 3.4946312\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10932:\tlearn: 3.4944781\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10933:\tlearn: 3.4942680\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10934:\tlearn: 3.4940774\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10935:\tlearn: 3.4938003\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10936:\tlearn: 3.4936676\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10937:\tlearn: 3.4934281\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10938:\tlearn: 3.4932500\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10939:\tlearn: 3.4930464\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10940:\tlearn: 3.4929441\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10941:\tlearn: 3.4927550\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10942:\tlearn: 3.4925577\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10943:\tlearn: 3.4923822\ttotal: 3m 57s\tremaining: 4m 22s\n",
      "10944:\tlearn: 3.4922443\ttotal: 3m 58s\tremaining: 4m 22s\n",
      "10945:\tlearn: 3.4920188\ttotal: 3m 58s\tremaining: 4m 22s\n",
      "10946:\tlearn: 3.4918424\ttotal: 3m 58s\tremaining: 4m 22s\n",
      "10947:\tlearn: 3.4916082\ttotal: 3m 58s\tremaining: 4m 22s\n",
      "10948:\tlearn: 3.4914853\ttotal: 3m 58s\tremaining: 4m 22s\n",
      "10949:\tlearn: 3.4913389\ttotal: 3m 58s\tremaining: 4m 22s\n",
      "10950:\tlearn: 3.4912331\ttotal: 3m 58s\tremaining: 4m 22s\n",
      "10951:\tlearn: 3.4910811\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10952:\tlearn: 3.4908665\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10953:\tlearn: 3.4907283\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10954:\tlearn: 3.4905229\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10955:\tlearn: 3.4902265\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10956:\tlearn: 3.4900975\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10957:\tlearn: 3.4898167\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10958:\tlearn: 3.4894546\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10959:\tlearn: 3.4893162\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10960:\tlearn: 3.4891420\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10961:\tlearn: 3.4889503\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10962:\tlearn: 3.4887865\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10963:\tlearn: 3.4885405\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10964:\tlearn: 3.4884404\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10965:\tlearn: 3.4883082\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10966:\tlearn: 3.4881493\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10967:\tlearn: 3.4878956\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10968:\tlearn: 3.4877064\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10969:\tlearn: 3.4877019\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10970:\tlearn: 3.4875763\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10971:\tlearn: 3.4874658\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10972:\tlearn: 3.4871424\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10973:\tlearn: 3.4869644\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10974:\tlearn: 3.4868560\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10975:\tlearn: 3.4867810\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10976:\tlearn: 3.4866540\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10977:\tlearn: 3.4864762\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10978:\tlearn: 3.4863227\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10979:\tlearn: 3.4860993\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10980:\tlearn: 3.4859045\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10981:\tlearn: 3.4857622\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10982:\tlearn: 3.4854972\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10983:\tlearn: 3.4853405\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10984:\tlearn: 3.4851784\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10985:\tlearn: 3.4849774\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10986:\tlearn: 3.4847388\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10987:\tlearn: 3.4845039\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10988:\tlearn: 3.4843648\ttotal: 3m 58s\tremaining: 4m 21s\n",
      "10989:\tlearn: 3.4841365\ttotal: 3m 59s\tremaining: 4m 21s\n",
      "10990:\tlearn: 3.4839514\ttotal: 3m 59s\tremaining: 4m 21s\n",
      "10991:\tlearn: 3.4836630\ttotal: 3m 59s\tremaining: 4m 21s\n",
      "10992:\tlearn: 3.4835327\ttotal: 3m 59s\tremaining: 4m 21s\n",
      "10993:\tlearn: 3.4834631\ttotal: 3m 59s\tremaining: 4m 21s\n",
      "10994:\tlearn: 3.4833628\ttotal: 3m 59s\tremaining: 4m 21s\n",
      "10995:\tlearn: 3.4831579\ttotal: 3m 59s\tremaining: 4m 21s\n",
      "10996:\tlearn: 3.4830843\ttotal: 3m 59s\tremaining: 4m 21s\n",
      "10997:\tlearn: 3.4829307\ttotal: 3m 59s\tremaining: 4m 21s\n",
      "10998:\tlearn: 3.4827961\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "10999:\tlearn: 3.4826411\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11000:\tlearn: 3.4822832\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11001:\tlearn: 3.4822063\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11002:\tlearn: 3.4820451\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11003:\tlearn: 3.4819404\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11004:\tlearn: 3.4816619\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11005:\tlearn: 3.4815241\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11006:\tlearn: 3.4814353\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11007:\tlearn: 3.4812415\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11008:\tlearn: 3.4810814\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11009:\tlearn: 3.4808658\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11010:\tlearn: 3.4807319\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11011:\tlearn: 3.4804654\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11012:\tlearn: 3.4803254\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11013:\tlearn: 3.4801071\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11014:\tlearn: 3.4798143\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11015:\tlearn: 3.4795812\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11016:\tlearn: 3.4794321\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11017:\tlearn: 3.4792027\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11018:\tlearn: 3.4790738\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11019:\tlearn: 3.4788105\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11020:\tlearn: 3.4786855\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11021:\tlearn: 3.4784395\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11022:\tlearn: 3.4783080\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11023:\tlearn: 3.4780506\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11024:\tlearn: 3.4778155\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11025:\tlearn: 3.4775331\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11026:\tlearn: 3.4771814\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11027:\tlearn: 3.4769985\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11028:\tlearn: 3.4767719\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11029:\tlearn: 3.4765161\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11030:\tlearn: 3.4763989\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11031:\tlearn: 3.4761714\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11032:\tlearn: 3.4758927\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11033:\tlearn: 3.4756488\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11034:\tlearn: 3.4754675\ttotal: 3m 59s\tremaining: 4m 20s\n",
      "11035:\tlearn: 3.4753193\ttotal: 4m\tremaining: 4m 20s\n",
      "11036:\tlearn: 3.4751822\ttotal: 4m\tremaining: 4m 20s\n",
      "11037:\tlearn: 3.4749476\ttotal: 4m\tremaining: 4m 20s\n",
      "11038:\tlearn: 3.4748346\ttotal: 4m\tremaining: 4m 20s\n",
      "11039:\tlearn: 3.4746623\ttotal: 4m\tremaining: 4m 20s\n",
      "11040:\tlearn: 3.4745382\ttotal: 4m\tremaining: 4m 20s\n",
      "11041:\tlearn: 3.4743576\ttotal: 4m\tremaining: 4m 20s\n",
      "11042:\tlearn: 3.4741836\ttotal: 4m\tremaining: 4m 20s\n",
      "11043:\tlearn: 3.4739909\ttotal: 4m\tremaining: 4m 20s\n",
      "11044:\tlearn: 3.4737578\ttotal: 4m\tremaining: 4m 20s\n",
      "11045:\tlearn: 3.4736078\ttotal: 4m\tremaining: 4m 19s\n",
      "11046:\tlearn: 3.4734435\ttotal: 4m\tremaining: 4m 19s\n",
      "11047:\tlearn: 3.4732066\ttotal: 4m\tremaining: 4m 19s\n",
      "11048:\tlearn: 3.4730727\ttotal: 4m\tremaining: 4m 19s\n",
      "11049:\tlearn: 3.4728582\ttotal: 4m\tremaining: 4m 19s\n",
      "11050:\tlearn: 3.4727859\ttotal: 4m\tremaining: 4m 19s\n",
      "11051:\tlearn: 3.4726746\ttotal: 4m\tremaining: 4m 19s\n",
      "11052:\tlearn: 3.4724303\ttotal: 4m\tremaining: 4m 19s\n",
      "11053:\tlearn: 3.4722192\ttotal: 4m\tremaining: 4m 19s\n",
      "11054:\tlearn: 3.4721530\ttotal: 4m\tremaining: 4m 19s\n",
      "11055:\tlearn: 3.4719748\ttotal: 4m\tremaining: 4m 19s\n",
      "11056:\tlearn: 3.4717676\ttotal: 4m\tremaining: 4m 19s\n",
      "11057:\tlearn: 3.4715874\ttotal: 4m\tremaining: 4m 19s\n",
      "11058:\tlearn: 3.4714027\ttotal: 4m\tremaining: 4m 19s\n",
      "11059:\tlearn: 3.4711933\ttotal: 4m\tremaining: 4m 19s\n",
      "11060:\tlearn: 3.4709295\ttotal: 4m\tremaining: 4m 19s\n",
      "11061:\tlearn: 3.4708258\ttotal: 4m\tremaining: 4m 19s\n",
      "11062:\tlearn: 3.4704949\ttotal: 4m\tremaining: 4m 19s\n",
      "11063:\tlearn: 3.4703817\ttotal: 4m\tremaining: 4m 19s\n",
      "11064:\tlearn: 3.4703094\ttotal: 4m\tremaining: 4m 19s\n",
      "11065:\tlearn: 3.4701683\ttotal: 4m\tremaining: 4m 19s\n",
      "11066:\tlearn: 3.4699341\ttotal: 4m\tremaining: 4m 19s\n",
      "11067:\tlearn: 3.4697092\ttotal: 4m\tremaining: 4m 19s\n",
      "11068:\tlearn: 3.4695837\ttotal: 4m\tremaining: 4m 19s\n",
      "11069:\tlearn: 3.4693647\ttotal: 4m\tremaining: 4m 19s\n",
      "11070:\tlearn: 3.4691328\ttotal: 4m\tremaining: 4m 19s\n",
      "11071:\tlearn: 3.4690143\ttotal: 4m\tremaining: 4m 19s\n",
      "11072:\tlearn: 3.4688726\ttotal: 4m\tremaining: 4m 19s\n",
      "11073:\tlearn: 3.4685031\ttotal: 4m\tremaining: 4m 19s\n",
      "11074:\tlearn: 3.4684103\ttotal: 4m\tremaining: 4m 19s\n",
      "11075:\tlearn: 3.4681392\ttotal: 4m\tremaining: 4m 19s\n",
      "11076:\tlearn: 3.4679541\ttotal: 4m\tremaining: 4m 19s\n",
      "11077:\tlearn: 3.4677721\ttotal: 4m\tremaining: 4m 19s\n",
      "11078:\tlearn: 3.4677258\ttotal: 4m\tremaining: 4m 19s\n",
      "11079:\tlearn: 3.4676609\ttotal: 4m\tremaining: 4m 19s\n",
      "11080:\tlearn: 3.4675465\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11081:\tlearn: 3.4672445\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11082:\tlearn: 3.4669239\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11083:\tlearn: 3.4667454\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11084:\tlearn: 3.4665101\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11085:\tlearn: 3.4664148\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11086:\tlearn: 3.4660955\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11087:\tlearn: 3.4659181\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11088:\tlearn: 3.4657652\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11089:\tlearn: 3.4656768\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11090:\tlearn: 3.4655356\ttotal: 4m 1s\tremaining: 4m 19s\n",
      "11091:\tlearn: 3.4653656\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11092:\tlearn: 3.4651550\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11093:\tlearn: 3.4650775\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11094:\tlearn: 3.4648207\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11095:\tlearn: 3.4645163\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11096:\tlearn: 3.4643204\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11097:\tlearn: 3.4642235\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11098:\tlearn: 3.4641283\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11099:\tlearn: 3.4638542\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11100:\tlearn: 3.4637267\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11101:\tlearn: 3.4633804\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11102:\tlearn: 3.4632570\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11103:\tlearn: 3.4630459\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11104:\tlearn: 3.4629032\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11105:\tlearn: 3.4626988\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11106:\tlearn: 3.4626071\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11107:\tlearn: 3.4623688\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11108:\tlearn: 3.4622513\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11109:\tlearn: 3.4620981\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11110:\tlearn: 3.4619007\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11111:\tlearn: 3.4617223\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11112:\tlearn: 3.4616048\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11113:\tlearn: 3.4614156\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11114:\tlearn: 3.4611376\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11115:\tlearn: 3.4608704\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11116:\tlearn: 3.4606351\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11117:\tlearn: 3.4604827\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11118:\tlearn: 3.4602988\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11119:\tlearn: 3.4601328\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11120:\tlearn: 3.4599392\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11121:\tlearn: 3.4596847\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11122:\tlearn: 3.4596357\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11123:\tlearn: 3.4594284\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11124:\tlearn: 3.4592541\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11125:\tlearn: 3.4591454\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11126:\tlearn: 3.4589444\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11127:\tlearn: 3.4588545\ttotal: 4m 1s\tremaining: 4m 18s\n",
      "11128:\tlearn: 3.4586255\ttotal: 4m 2s\tremaining: 4m 18s\n",
      "11129:\tlearn: 3.4584964\ttotal: 4m 2s\tremaining: 4m 18s\n",
      "11130:\tlearn: 3.4582673\ttotal: 4m 2s\tremaining: 4m 18s\n",
      "11131:\tlearn: 3.4581405\ttotal: 4m 2s\tremaining: 4m 18s\n",
      "11132:\tlearn: 3.4579397\ttotal: 4m 2s\tremaining: 4m 18s\n",
      "11133:\tlearn: 3.4576999\ttotal: 4m 2s\tremaining: 4m 18s\n",
      "11134:\tlearn: 3.4574623\ttotal: 4m 2s\tremaining: 4m 18s\n",
      "11135:\tlearn: 3.4570818\ttotal: 4m 2s\tremaining: 4m 18s\n",
      "11136:\tlearn: 3.4567804\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11137:\tlearn: 3.4566101\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11138:\tlearn: 3.4564991\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11139:\tlearn: 3.4564210\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11140:\tlearn: 3.4562135\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11141:\tlearn: 3.4559795\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11142:\tlearn: 3.4558915\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11143:\tlearn: 3.4557246\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11144:\tlearn: 3.4552982\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11145:\tlearn: 3.4551434\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11146:\tlearn: 3.4549033\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11147:\tlearn: 3.4547036\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11148:\tlearn: 3.4545264\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11149:\tlearn: 3.4543001\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11150:\tlearn: 3.4541134\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11151:\tlearn: 3.4539689\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11152:\tlearn: 3.4537983\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11153:\tlearn: 3.4536875\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11154:\tlearn: 3.4535209\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11155:\tlearn: 3.4534317\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11156:\tlearn: 3.4531664\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11157:\tlearn: 3.4530271\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11158:\tlearn: 3.4528588\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11159:\tlearn: 3.4526714\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11160:\tlearn: 3.4524476\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11161:\tlearn: 3.4522980\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11162:\tlearn: 3.4521366\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11163:\tlearn: 3.4519224\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11164:\tlearn: 3.4516456\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11165:\tlearn: 3.4514929\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11166:\tlearn: 3.4513863\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11167:\tlearn: 3.4512353\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11168:\tlearn: 3.4510330\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11169:\tlearn: 3.4508755\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11170:\tlearn: 3.4506842\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11171:\tlearn: 3.4504771\ttotal: 4m 2s\tremaining: 4m 17s\n",
      "11172:\tlearn: 3.4503673\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11173:\tlearn: 3.4501497\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11174:\tlearn: 3.4498438\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11175:\tlearn: 3.4495853\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11176:\tlearn: 3.4494181\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11177:\tlearn: 3.4491878\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11178:\tlearn: 3.4490662\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11179:\tlearn: 3.4489499\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11180:\tlearn: 3.4487535\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11181:\tlearn: 3.4484592\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11182:\tlearn: 3.4483298\ttotal: 4m 3s\tremaining: 4m 17s\n",
      "11183:\tlearn: 3.4482082\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11184:\tlearn: 3.4479219\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11185:\tlearn: 3.4478215\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11186:\tlearn: 3.4476461\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11187:\tlearn: 3.4475093\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11188:\tlearn: 3.4474099\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11189:\tlearn: 3.4471816\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11190:\tlearn: 3.4468769\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11191:\tlearn: 3.4466405\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11192:\tlearn: 3.4464298\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11193:\tlearn: 3.4462768\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11194:\tlearn: 3.4461732\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11195:\tlearn: 3.4460207\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11196:\tlearn: 3.4458176\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11197:\tlearn: 3.4456545\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11198:\tlearn: 3.4453963\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11199:\tlearn: 3.4452863\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11200:\tlearn: 3.4450338\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11201:\tlearn: 3.4449096\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11202:\tlearn: 3.4447880\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11203:\tlearn: 3.4445044\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11204:\tlearn: 3.4441850\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11205:\tlearn: 3.4441144\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11206:\tlearn: 3.4438119\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11207:\tlearn: 3.4436811\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11208:\tlearn: 3.4434534\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11209:\tlearn: 3.4432030\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11210:\tlearn: 3.4430343\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11211:\tlearn: 3.4427898\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11212:\tlearn: 3.4426212\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11213:\tlearn: 3.4423416\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11214:\tlearn: 3.4420296\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11215:\tlearn: 3.4417937\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11216:\tlearn: 3.4415079\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11217:\tlearn: 3.4413556\ttotal: 4m 3s\tremaining: 4m 16s\n",
      "11218:\tlearn: 3.4411936\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11219:\tlearn: 3.4410092\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11220:\tlearn: 3.4407577\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11221:\tlearn: 3.4405996\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11222:\tlearn: 3.4404721\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11223:\tlearn: 3.4402385\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11224:\tlearn: 3.4401380\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11225:\tlearn: 3.4400249\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11226:\tlearn: 3.4398650\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11227:\tlearn: 3.4397658\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11228:\tlearn: 3.4395813\ttotal: 4m 4s\tremaining: 4m 16s\n",
      "11229:\tlearn: 3.4394612\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11230:\tlearn: 3.4393148\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11231:\tlearn: 3.4391225\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11232:\tlearn: 3.4391183\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11233:\tlearn: 3.4389694\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11234:\tlearn: 3.4388221\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11235:\tlearn: 3.4385706\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11236:\tlearn: 3.4384054\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11237:\tlearn: 3.4382278\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11238:\tlearn: 3.4380121\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11239:\tlearn: 3.4378510\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11240:\tlearn: 3.4376881\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11241:\tlearn: 3.4375532\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11242:\tlearn: 3.4373308\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11243:\tlearn: 3.4371184\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11244:\tlearn: 3.4367331\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11245:\tlearn: 3.4365043\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11246:\tlearn: 3.4363535\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11247:\tlearn: 3.4360926\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11248:\tlearn: 3.4358595\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11249:\tlearn: 3.4356371\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11250:\tlearn: 3.4353653\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11251:\tlearn: 3.4350924\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11252:\tlearn: 3.4349573\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11253:\tlearn: 3.4347933\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11254:\tlearn: 3.4344891\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11255:\tlearn: 3.4342009\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11256:\tlearn: 3.4339940\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11257:\tlearn: 3.4337997\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11258:\tlearn: 3.4336534\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11259:\tlearn: 3.4335696\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11260:\tlearn: 3.4334431\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11261:\tlearn: 3.4333399\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11262:\tlearn: 3.4332007\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11263:\tlearn: 3.4329336\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11264:\tlearn: 3.4327567\ttotal: 4m 4s\tremaining: 4m 15s\n",
      "11265:\tlearn: 3.4325086\ttotal: 4m 5s\tremaining: 4m 15s\n",
      "11266:\tlearn: 3.4323595\ttotal: 4m 5s\tremaining: 4m 15s\n",
      "11267:\tlearn: 3.4321687\ttotal: 4m 5s\tremaining: 4m 15s\n",
      "11268:\tlearn: 3.4320263\ttotal: 4m 5s\tremaining: 4m 15s\n",
      "11269:\tlearn: 3.4318410\ttotal: 4m 5s\tremaining: 4m 15s\n",
      "11270:\tlearn: 3.4316845\ttotal: 4m 5s\tremaining: 4m 15s\n",
      "11271:\tlearn: 3.4314487\ttotal: 4m 5s\tremaining: 4m 15s\n",
      "11272:\tlearn: 3.4314443\ttotal: 4m 5s\tremaining: 4m 15s\n",
      "11273:\tlearn: 3.4312335\ttotal: 4m 5s\tremaining: 4m 15s\n",
      "11274:\tlearn: 3.4310754\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11275:\tlearn: 3.4308919\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11276:\tlearn: 3.4306301\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11277:\tlearn: 3.4303714\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11278:\tlearn: 3.4302125\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11279:\tlearn: 3.4300336\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11280:\tlearn: 3.4297833\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11281:\tlearn: 3.4296204\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11282:\tlearn: 3.4293067\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11283:\tlearn: 3.4291470\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11284:\tlearn: 3.4290264\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11285:\tlearn: 3.4287942\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11286:\tlearn: 3.4285901\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11287:\tlearn: 3.4284082\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11288:\tlearn: 3.4283374\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11289:\tlearn: 3.4281614\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11290:\tlearn: 3.4279884\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11291:\tlearn: 3.4277815\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11292:\tlearn: 3.4275821\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11293:\tlearn: 3.4274305\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11294:\tlearn: 3.4272700\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11295:\tlearn: 3.4271503\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11296:\tlearn: 3.4269919\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11297:\tlearn: 3.4267866\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11298:\tlearn: 3.4266642\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11299:\tlearn: 3.4264751\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11300:\tlearn: 3.4263252\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11301:\tlearn: 3.4260949\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11302:\tlearn: 3.4259519\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11303:\tlearn: 3.4258239\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11304:\tlearn: 3.4256336\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11305:\tlearn: 3.4254567\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11306:\tlearn: 3.4252578\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11307:\tlearn: 3.4251488\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11308:\tlearn: 3.4249099\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11309:\tlearn: 3.4248103\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11310:\tlearn: 3.4246150\ttotal: 4m 5s\tremaining: 4m 14s\n",
      "11311:\tlearn: 3.4244525\ttotal: 4m 6s\tremaining: 4m 14s\n",
      "11312:\tlearn: 3.4242894\ttotal: 4m 6s\tremaining: 4m 14s\n",
      "11313:\tlearn: 3.4240428\ttotal: 4m 6s\tremaining: 4m 14s\n",
      "11314:\tlearn: 3.4238289\ttotal: 4m 6s\tremaining: 4m 14s\n",
      "11315:\tlearn: 3.4237217\ttotal: 4m 6s\tremaining: 4m 14s\n",
      "11316:\tlearn: 3.4235434\ttotal: 4m 6s\tremaining: 4m 14s\n",
      "11317:\tlearn: 3.4233930\ttotal: 4m 6s\tremaining: 4m 14s\n",
      "11318:\tlearn: 3.4232725\ttotal: 4m 6s\tremaining: 4m 14s\n",
      "11319:\tlearn: 3.4231115\ttotal: 4m 6s\tremaining: 4m 14s\n",
      "11320:\tlearn: 3.4229369\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11321:\tlearn: 3.4226348\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11322:\tlearn: 3.4223411\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11323:\tlearn: 3.4222325\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11324:\tlearn: 3.4220108\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11325:\tlearn: 3.4217937\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11326:\tlearn: 3.4215892\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11327:\tlearn: 3.4214599\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11328:\tlearn: 3.4212612\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11329:\tlearn: 3.4209923\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11330:\tlearn: 3.4208504\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11331:\tlearn: 3.4206342\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11332:\tlearn: 3.4205524\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11333:\tlearn: 3.4203946\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11334:\tlearn: 3.4202921\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11335:\tlearn: 3.4199623\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11336:\tlearn: 3.4197467\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11337:\tlearn: 3.4195681\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11338:\tlearn: 3.4193738\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11339:\tlearn: 3.4192544\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11340:\tlearn: 3.4190728\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11341:\tlearn: 3.4188712\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11342:\tlearn: 3.4184994\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11343:\tlearn: 3.4183098\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11344:\tlearn: 3.4182146\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11345:\tlearn: 3.4180615\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11346:\tlearn: 3.4178147\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11347:\tlearn: 3.4176264\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11348:\tlearn: 3.4175110\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11349:\tlearn: 3.4172973\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11350:\tlearn: 3.4171603\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11351:\tlearn: 3.4170917\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11352:\tlearn: 3.4169693\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11353:\tlearn: 3.4167172\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11354:\tlearn: 3.4166588\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11355:\tlearn: 3.4165077\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11356:\tlearn: 3.4162687\ttotal: 4m 6s\tremaining: 4m 13s\n",
      "11357:\tlearn: 3.4161039\ttotal: 4m 7s\tremaining: 4m 13s\n",
      "11358:\tlearn: 3.4158836\ttotal: 4m 7s\tremaining: 4m 13s\n",
      "11359:\tlearn: 3.4156475\ttotal: 4m 7s\tremaining: 4m 13s\n",
      "11360:\tlearn: 3.4154817\ttotal: 4m 7s\tremaining: 4m 13s\n",
      "11361:\tlearn: 3.4153161\ttotal: 4m 7s\tremaining: 4m 13s\n",
      "11362:\tlearn: 3.4151307\ttotal: 4m 7s\tremaining: 4m 13s\n",
      "11363:\tlearn: 3.4148259\ttotal: 4m 7s\tremaining: 4m 13s\n",
      "11364:\tlearn: 3.4146461\ttotal: 4m 7s\tremaining: 4m 13s\n",
      "11365:\tlearn: 3.4143903\ttotal: 4m 7s\tremaining: 4m 13s\n",
      "11366:\tlearn: 3.4142351\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11367:\tlearn: 3.4141630\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11368:\tlearn: 3.4140348\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11369:\tlearn: 3.4137682\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11370:\tlearn: 3.4135943\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11371:\tlearn: 3.4133854\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11372:\tlearn: 3.4132192\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11373:\tlearn: 3.4130322\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11374:\tlearn: 3.4128115\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11375:\tlearn: 3.4125691\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11376:\tlearn: 3.4123748\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11377:\tlearn: 3.4121296\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11378:\tlearn: 3.4118453\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11379:\tlearn: 3.4117367\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11380:\tlearn: 3.4115691\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11381:\tlearn: 3.4113769\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11382:\tlearn: 3.4111103\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11383:\tlearn: 3.4108402\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11384:\tlearn: 3.4106418\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11385:\tlearn: 3.4104603\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11386:\tlearn: 3.4102714\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11387:\tlearn: 3.4101628\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11388:\tlearn: 3.4100336\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11389:\tlearn: 3.4098688\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11390:\tlearn: 3.4096498\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11391:\tlearn: 3.4093698\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11392:\tlearn: 3.4091842\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11393:\tlearn: 3.4090108\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11394:\tlearn: 3.4088353\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11395:\tlearn: 3.4086547\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11396:\tlearn: 3.4085039\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11397:\tlearn: 3.4082715\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11398:\tlearn: 3.4081139\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11399:\tlearn: 3.4077992\ttotal: 4m 7s\tremaining: 4m 12s\n",
      "11400:\tlearn: 3.4075804\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11401:\tlearn: 3.4073796\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11402:\tlearn: 3.4071849\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11403:\tlearn: 3.4070466\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11404:\tlearn: 3.4068042\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11405:\tlearn: 3.4066176\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11406:\tlearn: 3.4063105\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11407:\tlearn: 3.4060546\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11408:\tlearn: 3.4059188\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11409:\tlearn: 3.4057893\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11410:\tlearn: 3.4056849\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11411:\tlearn: 3.4054742\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11412:\tlearn: 3.4053048\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11413:\tlearn: 3.4051669\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11414:\tlearn: 3.4050164\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11415:\tlearn: 3.4048417\ttotal: 4m 8s\tremaining: 4m 12s\n",
      "11416:\tlearn: 3.4046633\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11417:\tlearn: 3.4045649\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11418:\tlearn: 3.4044226\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11419:\tlearn: 3.4042671\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11420:\tlearn: 3.4041437\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11421:\tlearn: 3.4040122\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11422:\tlearn: 3.4038177\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11423:\tlearn: 3.4035888\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11424:\tlearn: 3.4034174\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11425:\tlearn: 3.4032185\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11426:\tlearn: 3.4030074\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11427:\tlearn: 3.4028453\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11428:\tlearn: 3.4026678\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11429:\tlearn: 3.4025842\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11430:\tlearn: 3.4024341\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11431:\tlearn: 3.4021909\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11432:\tlearn: 3.4021489\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11433:\tlearn: 3.4019195\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11434:\tlearn: 3.4015754\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11435:\tlearn: 3.4013181\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11436:\tlearn: 3.4011644\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11437:\tlearn: 3.4009756\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11438:\tlearn: 3.4007479\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11439:\tlearn: 3.4005913\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11440:\tlearn: 3.4004454\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11441:\tlearn: 3.4002959\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11442:\tlearn: 3.4001225\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11443:\tlearn: 3.4001165\ttotal: 4m 8s\tremaining: 4m 11s\n",
      "11444:\tlearn: 3.3999486\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11445:\tlearn: 3.3997884\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11446:\tlearn: 3.3996832\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11447:\tlearn: 3.3995374\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11448:\tlearn: 3.3993702\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11449:\tlearn: 3.3991293\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11450:\tlearn: 3.3988400\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11451:\tlearn: 3.3986627\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11452:\tlearn: 3.3984487\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11453:\tlearn: 3.3982861\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11454:\tlearn: 3.3981655\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11455:\tlearn: 3.3979060\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11456:\tlearn: 3.3976257\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11457:\tlearn: 3.3974531\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11458:\tlearn: 3.3972270\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11459:\tlearn: 3.3970898\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11460:\tlearn: 3.3969509\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11461:\tlearn: 3.3967108\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11462:\tlearn: 3.3966015\ttotal: 4m 9s\tremaining: 4m 11s\n",
      "11463:\tlearn: 3.3964782\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11464:\tlearn: 3.3960788\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11465:\tlearn: 3.3959567\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11466:\tlearn: 3.3957496\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11467:\tlearn: 3.3955699\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11468:\tlearn: 3.3954168\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11469:\tlearn: 3.3952810\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11470:\tlearn: 3.3952444\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11471:\tlearn: 3.3951473\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11472:\tlearn: 3.3949243\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11473:\tlearn: 3.3947431\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11474:\tlearn: 3.3945976\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11475:\tlearn: 3.3944547\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11476:\tlearn: 3.3942665\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11477:\tlearn: 3.3941454\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11478:\tlearn: 3.3939291\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11479:\tlearn: 3.3936697\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11480:\tlearn: 3.3934709\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11481:\tlearn: 3.3932756\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11482:\tlearn: 3.3930953\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11483:\tlearn: 3.3929932\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11484:\tlearn: 3.3928721\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11485:\tlearn: 3.3927005\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11486:\tlearn: 3.3925988\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11487:\tlearn: 3.3923914\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11488:\tlearn: 3.3922686\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11489:\tlearn: 3.3921569\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11490:\tlearn: 3.3919891\ttotal: 4m 9s\tremaining: 4m 10s\n",
      "11491:\tlearn: 3.3917104\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11492:\tlearn: 3.3915032\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11493:\tlearn: 3.3913336\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11494:\tlearn: 3.3911529\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11495:\tlearn: 3.3909552\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11496:\tlearn: 3.3907640\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11497:\tlearn: 3.3906100\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11498:\tlearn: 3.3904628\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11499:\tlearn: 3.3903182\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11500:\tlearn: 3.3903139\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11501:\tlearn: 3.3902145\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11502:\tlearn: 3.3901040\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11503:\tlearn: 3.3899699\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11504:\tlearn: 3.3898169\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11505:\tlearn: 3.3896391\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11506:\tlearn: 3.3893336\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11507:\tlearn: 3.3890514\ttotal: 4m 10s\tremaining: 4m 10s\n",
      "11508:\tlearn: 3.3889165\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11509:\tlearn: 3.3886709\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11510:\tlearn: 3.3884602\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11511:\tlearn: 3.3882171\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11512:\tlearn: 3.3880764\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11513:\tlearn: 3.3878603\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11514:\tlearn: 3.3876627\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11515:\tlearn: 3.3874583\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11516:\tlearn: 3.3872573\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11517:\tlearn: 3.3871328\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11518:\tlearn: 3.3867794\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11519:\tlearn: 3.3865249\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11520:\tlearn: 3.3863985\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11521:\tlearn: 3.3862727\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11522:\tlearn: 3.3861187\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11523:\tlearn: 3.3858808\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11524:\tlearn: 3.3857381\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11525:\tlearn: 3.3856206\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11526:\tlearn: 3.3854594\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11527:\tlearn: 3.3851910\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11528:\tlearn: 3.3849837\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11529:\tlearn: 3.3849442\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11530:\tlearn: 3.3847757\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11531:\tlearn: 3.3845744\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11532:\tlearn: 3.3843739\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11533:\tlearn: 3.3841235\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11534:\tlearn: 3.3839129\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11535:\tlearn: 3.3836682\ttotal: 4m 10s\tremaining: 4m 9s\n",
      "11536:\tlearn: 3.3834899\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11537:\tlearn: 3.3833436\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11538:\tlearn: 3.3831951\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11539:\tlearn: 3.3829455\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11540:\tlearn: 3.3827496\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11541:\tlearn: 3.3825351\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11542:\tlearn: 3.3823493\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11543:\tlearn: 3.3820789\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11544:\tlearn: 3.3818521\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11545:\tlearn: 3.3816874\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11546:\tlearn: 3.3815295\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11547:\tlearn: 3.3813388\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11548:\tlearn: 3.3811918\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11549:\tlearn: 3.3809469\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11550:\tlearn: 3.3807566\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11551:\tlearn: 3.3805824\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11552:\tlearn: 3.3804583\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11553:\tlearn: 3.3802836\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11554:\tlearn: 3.3801451\ttotal: 4m 11s\tremaining: 4m 9s\n",
      "11555:\tlearn: 3.3799885\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11556:\tlearn: 3.3797270\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11557:\tlearn: 3.3795581\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11558:\tlearn: 3.3794645\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11559:\tlearn: 3.3792242\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11560:\tlearn: 3.3791102\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11561:\tlearn: 3.3790143\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11562:\tlearn: 3.3788634\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11563:\tlearn: 3.3786738\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11564:\tlearn: 3.3784904\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11565:\tlearn: 3.3783598\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11566:\tlearn: 3.3779809\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11567:\tlearn: 3.3778581\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11568:\tlearn: 3.3775771\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11569:\tlearn: 3.3774183\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11570:\tlearn: 3.3772167\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11571:\tlearn: 3.3770569\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11572:\tlearn: 3.3769351\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11573:\tlearn: 3.3768099\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11574:\tlearn: 3.3766785\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11575:\tlearn: 3.3765250\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11576:\tlearn: 3.3765202\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11577:\tlearn: 3.3764295\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11578:\tlearn: 3.3763531\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11579:\tlearn: 3.3762437\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11580:\tlearn: 3.3760567\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11581:\tlearn: 3.3758327\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11582:\tlearn: 3.3755411\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "11583:\tlearn: 3.3753407\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11584:\tlearn: 3.3750754\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11585:\tlearn: 3.3749558\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11586:\tlearn: 3.3747916\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11587:\tlearn: 3.3746244\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11588:\tlearn: 3.3744827\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11589:\tlearn: 3.3743843\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11590:\tlearn: 3.3742424\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11591:\tlearn: 3.3741302\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11592:\tlearn: 3.3739009\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11593:\tlearn: 3.3737323\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11594:\tlearn: 3.3735325\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11595:\tlearn: 3.3733222\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11596:\tlearn: 3.3731378\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11597:\tlearn: 3.3730279\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11598:\tlearn: 3.3728029\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11599:\tlearn: 3.3726632\ttotal: 4m 12s\tremaining: 4m 8s\n",
      "11600:\tlearn: 3.3725573\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11601:\tlearn: 3.3724481\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11602:\tlearn: 3.3723163\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11603:\tlearn: 3.3722891\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11604:\tlearn: 3.3721223\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11605:\tlearn: 3.3718774\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11606:\tlearn: 3.3717200\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11607:\tlearn: 3.3714860\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11608:\tlearn: 3.3712845\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11609:\tlearn: 3.3710280\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11610:\tlearn: 3.3709513\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11611:\tlearn: 3.3707090\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11612:\tlearn: 3.3705586\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11613:\tlearn: 3.3703253\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11614:\tlearn: 3.3701519\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11615:\tlearn: 3.3699759\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11616:\tlearn: 3.3698654\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11617:\tlearn: 3.3696583\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11618:\tlearn: 3.3696526\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11619:\tlearn: 3.3694568\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11620:\tlearn: 3.3692234\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11621:\tlearn: 3.3691027\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11622:\tlearn: 3.3689748\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11623:\tlearn: 3.3688824\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11624:\tlearn: 3.3688779\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11625:\tlearn: 3.3686615\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11626:\tlearn: 3.3685159\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11627:\tlearn: 3.3684287\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11628:\tlearn: 3.3682911\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11629:\tlearn: 3.3681379\ttotal: 4m 12s\tremaining: 4m 7s\n",
      "11630:\tlearn: 3.3679182\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11631:\tlearn: 3.3677607\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11632:\tlearn: 3.3675627\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11633:\tlearn: 3.3673557\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11634:\tlearn: 3.3672078\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11635:\tlearn: 3.3670325\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11636:\tlearn: 3.3669736\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11637:\tlearn: 3.3668770\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11638:\tlearn: 3.3667087\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11639:\tlearn: 3.3666014\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11640:\tlearn: 3.3664720\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11641:\tlearn: 3.3662521\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11642:\tlearn: 3.3661628\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11643:\tlearn: 3.3660455\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11644:\tlearn: 3.3659898\ttotal: 4m 13s\tremaining: 4m 7s\n",
      "11645:\tlearn: 3.3658021\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11646:\tlearn: 3.3656307\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11647:\tlearn: 3.3654236\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11648:\tlearn: 3.3651990\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11649:\tlearn: 3.3650248\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11650:\tlearn: 3.3648824\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11651:\tlearn: 3.3647063\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11652:\tlearn: 3.3645345\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11653:\tlearn: 3.3642985\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11654:\tlearn: 3.3641606\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11655:\tlearn: 3.3639042\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11656:\tlearn: 3.3636998\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11657:\tlearn: 3.3635358\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11658:\tlearn: 3.3634000\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11659:\tlearn: 3.3632847\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11660:\tlearn: 3.3631874\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11661:\tlearn: 3.3629446\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11662:\tlearn: 3.3628328\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11663:\tlearn: 3.3627253\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11664:\tlearn: 3.3625037\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11665:\tlearn: 3.3623222\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11666:\tlearn: 3.3620975\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11667:\tlearn: 3.3618885\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11668:\tlearn: 3.3617620\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11669:\tlearn: 3.3616580\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11670:\tlearn: 3.3615627\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11671:\tlearn: 3.3614733\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11672:\tlearn: 3.3613359\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11673:\tlearn: 3.3611671\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11674:\tlearn: 3.3610619\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11675:\tlearn: 3.3608625\ttotal: 4m 13s\tremaining: 4m 6s\n",
      "11676:\tlearn: 3.3607212\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11677:\tlearn: 3.3606157\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11678:\tlearn: 3.3604321\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11679:\tlearn: 3.3602529\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11680:\tlearn: 3.3600539\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11681:\tlearn: 3.3598461\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11682:\tlearn: 3.3597125\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11683:\tlearn: 3.3595131\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11684:\tlearn: 3.3593686\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11685:\tlearn: 3.3591956\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11686:\tlearn: 3.3589733\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11687:\tlearn: 3.3589223\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11688:\tlearn: 3.3587436\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11689:\tlearn: 3.3585649\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11690:\tlearn: 3.3583911\ttotal: 4m 14s\tremaining: 4m 6s\n",
      "11691:\tlearn: 3.3581624\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11692:\tlearn: 3.3580068\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11693:\tlearn: 3.3578759\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11694:\tlearn: 3.3577643\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11695:\tlearn: 3.3574932\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11696:\tlearn: 3.3572768\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11697:\tlearn: 3.3570614\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11698:\tlearn: 3.3568506\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11699:\tlearn: 3.3567083\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11700:\tlearn: 3.3564530\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11701:\tlearn: 3.3562677\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11702:\tlearn: 3.3561877\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11703:\tlearn: 3.3559833\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11704:\tlearn: 3.3558536\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11705:\tlearn: 3.3556881\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11706:\tlearn: 3.3555790\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11707:\tlearn: 3.3554832\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11708:\tlearn: 3.3553010\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11709:\tlearn: 3.3551491\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11710:\tlearn: 3.3549524\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11711:\tlearn: 3.3548815\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11712:\tlearn: 3.3548134\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11713:\tlearn: 3.3546689\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11714:\tlearn: 3.3544917\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11715:\tlearn: 3.3542426\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11716:\tlearn: 3.3541362\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11717:\tlearn: 3.3540043\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11718:\tlearn: 3.3539261\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11719:\tlearn: 3.3538515\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11720:\tlearn: 3.3536908\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11721:\tlearn: 3.3534336\ttotal: 4m 14s\tremaining: 4m 5s\n",
      "11722:\tlearn: 3.3532490\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11723:\tlearn: 3.3530973\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11724:\tlearn: 3.3528840\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11725:\tlearn: 3.3527528\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11726:\tlearn: 3.3525508\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11727:\tlearn: 3.3523562\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11728:\tlearn: 3.3520497\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11729:\tlearn: 3.3519258\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11730:\tlearn: 3.3517653\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11731:\tlearn: 3.3515075\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11732:\tlearn: 3.3512492\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11733:\tlearn: 3.3510310\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11734:\tlearn: 3.3508739\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11735:\tlearn: 3.3505698\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11736:\tlearn: 3.3503823\ttotal: 4m 15s\tremaining: 4m 5s\n",
      "11737:\tlearn: 3.3501915\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11738:\tlearn: 3.3500396\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11739:\tlearn: 3.3498918\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11740:\tlearn: 3.3498413\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11741:\tlearn: 3.3495637\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11742:\tlearn: 3.3492912\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11743:\tlearn: 3.3491129\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11744:\tlearn: 3.3488245\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11745:\tlearn: 3.3485454\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11746:\tlearn: 3.3483826\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11747:\tlearn: 3.3482104\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11748:\tlearn: 3.3480269\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11749:\tlearn: 3.3478737\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11750:\tlearn: 3.3476523\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11751:\tlearn: 3.3474464\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11752:\tlearn: 3.3472152\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11753:\tlearn: 3.3469328\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11754:\tlearn: 3.3467145\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11755:\tlearn: 3.3465006\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11756:\tlearn: 3.3463262\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11757:\tlearn: 3.3461969\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11758:\tlearn: 3.3460301\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11759:\tlearn: 3.3459229\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11760:\tlearn: 3.3459187\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11761:\tlearn: 3.3459148\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11762:\tlearn: 3.3458041\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11763:\tlearn: 3.3457192\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11764:\tlearn: 3.3455250\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11765:\tlearn: 3.3453944\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11766:\tlearn: 3.3452458\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11767:\tlearn: 3.3450104\ttotal: 4m 15s\tremaining: 4m 4s\n",
      "11768:\tlearn: 3.3448272\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11769:\tlearn: 3.3446608\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11770:\tlearn: 3.3444437\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11771:\tlearn: 3.3442040\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11772:\tlearn: 3.3439091\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11773:\tlearn: 3.3437544\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11774:\tlearn: 3.3437158\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11775:\tlearn: 3.3434910\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11776:\tlearn: 3.3434050\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11777:\tlearn: 3.3432428\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11778:\tlearn: 3.3430828\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11779:\tlearn: 3.3428786\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11780:\tlearn: 3.3428098\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11781:\tlearn: 3.3427591\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11782:\tlearn: 3.3426311\ttotal: 4m 16s\tremaining: 4m 4s\n",
      "11783:\tlearn: 3.3424242\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11784:\tlearn: 3.3422866\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11785:\tlearn: 3.3420408\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11786:\tlearn: 3.3418486\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11787:\tlearn: 3.3417181\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11788:\tlearn: 3.3415486\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11789:\tlearn: 3.3414151\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11790:\tlearn: 3.3412347\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11791:\tlearn: 3.3411020\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11792:\tlearn: 3.3409768\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11793:\tlearn: 3.3408125\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11794:\tlearn: 3.3406515\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11795:\tlearn: 3.3405126\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11796:\tlearn: 3.3403035\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11797:\tlearn: 3.3400835\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11798:\tlearn: 3.3400152\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11799:\tlearn: 3.3398846\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11800:\tlearn: 3.3397661\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11801:\tlearn: 3.3395615\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11802:\tlearn: 3.3393500\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11803:\tlearn: 3.3392108\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11804:\tlearn: 3.3390396\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11805:\tlearn: 3.3389284\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11806:\tlearn: 3.3387316\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11807:\tlearn: 3.3386237\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11808:\tlearn: 3.3382921\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11809:\tlearn: 3.3381272\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11810:\tlearn: 3.3380183\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11811:\tlearn: 3.3378985\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11812:\tlearn: 3.3376366\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11813:\tlearn: 3.3374372\ttotal: 4m 16s\tremaining: 4m 3s\n",
      "11814:\tlearn: 3.3371927\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11815:\tlearn: 3.3370060\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11816:\tlearn: 3.3369104\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11817:\tlearn: 3.3367919\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11818:\tlearn: 3.3365975\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11819:\tlearn: 3.3362313\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11820:\tlearn: 3.3360856\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11821:\tlearn: 3.3359465\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11822:\tlearn: 3.3358209\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11823:\tlearn: 3.3356585\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11824:\tlearn: 3.3354674\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11825:\tlearn: 3.3352752\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11826:\tlearn: 3.3351182\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11827:\tlearn: 3.3348549\ttotal: 4m 17s\tremaining: 4m 3s\n",
      "11828:\tlearn: 3.3345961\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11829:\tlearn: 3.3344646\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11830:\tlearn: 3.3343397\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11831:\tlearn: 3.3341012\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11832:\tlearn: 3.3338907\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11833:\tlearn: 3.3337283\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11834:\tlearn: 3.3336046\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11835:\tlearn: 3.3334798\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11836:\tlearn: 3.3333760\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11837:\tlearn: 3.3331880\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11838:\tlearn: 3.3331033\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11839:\tlearn: 3.3329748\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11840:\tlearn: 3.3327703\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11841:\tlearn: 3.3324829\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11842:\tlearn: 3.3323561\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11843:\tlearn: 3.3322551\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11844:\tlearn: 3.3320366\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11845:\tlearn: 3.3318615\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11846:\tlearn: 3.3315820\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11847:\tlearn: 3.3315777\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11848:\tlearn: 3.3314755\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11849:\tlearn: 3.3313445\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11850:\tlearn: 3.3311889\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11851:\tlearn: 3.3311379\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11852:\tlearn: 3.3308627\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11853:\tlearn: 3.3307325\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11854:\tlearn: 3.3307119\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11855:\tlearn: 3.3304802\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11856:\tlearn: 3.3303149\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11857:\tlearn: 3.3300169\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11858:\tlearn: 3.3297331\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11859:\tlearn: 3.3295692\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11860:\tlearn: 3.3294666\ttotal: 4m 17s\tremaining: 4m 2s\n",
      "11861:\tlearn: 3.3292053\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11862:\tlearn: 3.3290303\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11863:\tlearn: 3.3288743\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11864:\tlearn: 3.3286932\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11865:\tlearn: 3.3285328\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11866:\tlearn: 3.3284523\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11867:\tlearn: 3.3283683\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11868:\tlearn: 3.3283629\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11869:\tlearn: 3.3281527\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11870:\tlearn: 3.3279972\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11871:\tlearn: 3.3278177\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11872:\tlearn: 3.3276561\ttotal: 4m 18s\tremaining: 4m 2s\n",
      "11873:\tlearn: 3.3275264\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11874:\tlearn: 3.3274439\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11875:\tlearn: 3.3272395\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11876:\tlearn: 3.3270927\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11877:\tlearn: 3.3269315\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11878:\tlearn: 3.3266291\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11879:\tlearn: 3.3264954\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11880:\tlearn: 3.3263622\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11881:\tlearn: 3.3262243\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11882:\tlearn: 3.3260314\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11883:\tlearn: 3.3257926\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11884:\tlearn: 3.3256483\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11885:\tlearn: 3.3253420\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11886:\tlearn: 3.3251832\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11887:\tlearn: 3.3248146\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11888:\tlearn: 3.3246205\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11889:\tlearn: 3.3244327\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11890:\tlearn: 3.3242817\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11891:\tlearn: 3.3241572\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11892:\tlearn: 3.3240342\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11893:\tlearn: 3.3239534\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11894:\tlearn: 3.3239033\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11895:\tlearn: 3.3236663\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11896:\tlearn: 3.3235727\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11897:\tlearn: 3.3234013\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11898:\tlearn: 3.3232846\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11899:\tlearn: 3.3231069\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11900:\tlearn: 3.3228587\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11901:\tlearn: 3.3227966\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11902:\tlearn: 3.3225772\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11903:\tlearn: 3.3224799\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11904:\tlearn: 3.3223590\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11905:\tlearn: 3.3222683\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11906:\tlearn: 3.3220282\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11907:\tlearn: 3.3218740\ttotal: 4m 18s\tremaining: 4m 1s\n",
      "11908:\tlearn: 3.3215020\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11909:\tlearn: 3.3213851\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11910:\tlearn: 3.3211305\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11911:\tlearn: 3.3209998\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11912:\tlearn: 3.3207068\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11913:\tlearn: 3.3205082\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11914:\tlearn: 3.3203702\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11915:\tlearn: 3.3202301\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11916:\tlearn: 3.3201227\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11917:\tlearn: 3.3199268\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11918:\tlearn: 3.3199232\ttotal: 4m 19s\tremaining: 4m 1s\n",
      "11919:\tlearn: 3.3197157\ttotal: 4m 19s\tremaining: 4m\n",
      "11920:\tlearn: 3.3196047\ttotal: 4m 19s\tremaining: 4m\n",
      "11921:\tlearn: 3.3194396\ttotal: 4m 19s\tremaining: 4m\n",
      "11922:\tlearn: 3.3192863\ttotal: 4m 19s\tremaining: 4m\n",
      "11923:\tlearn: 3.3191736\ttotal: 4m 19s\tremaining: 4m\n",
      "11924:\tlearn: 3.3189782\ttotal: 4m 19s\tremaining: 4m\n",
      "11925:\tlearn: 3.3187631\ttotal: 4m 19s\tremaining: 4m\n",
      "11926:\tlearn: 3.3186492\ttotal: 4m 19s\tremaining: 4m\n",
      "11927:\tlearn: 3.3184735\ttotal: 4m 19s\tremaining: 4m\n",
      "11928:\tlearn: 3.3182361\ttotal: 4m 19s\tremaining: 4m\n",
      "11929:\tlearn: 3.3180880\ttotal: 4m 19s\tremaining: 4m\n",
      "11930:\tlearn: 3.3179370\ttotal: 4m 19s\tremaining: 4m\n",
      "11931:\tlearn: 3.3177849\ttotal: 4m 19s\tremaining: 4m\n",
      "11932:\tlearn: 3.3175916\ttotal: 4m 19s\tremaining: 4m\n",
      "11933:\tlearn: 3.3173618\ttotal: 4m 19s\tremaining: 4m\n",
      "11934:\tlearn: 3.3170098\ttotal: 4m 19s\tremaining: 4m\n",
      "11935:\tlearn: 3.3168715\ttotal: 4m 19s\tremaining: 4m\n",
      "11936:\tlearn: 3.3167066\ttotal: 4m 19s\tremaining: 4m\n",
      "11937:\tlearn: 3.3167010\ttotal: 4m 19s\tremaining: 4m\n",
      "11938:\tlearn: 3.3165263\ttotal: 4m 19s\tremaining: 4m\n",
      "11939:\tlearn: 3.3164037\ttotal: 4m 19s\tremaining: 4m\n",
      "11940:\tlearn: 3.3161870\ttotal: 4m 19s\tremaining: 4m\n",
      "11941:\tlearn: 3.3159031\ttotal: 4m 19s\tremaining: 4m\n",
      "11942:\tlearn: 3.3157218\ttotal: 4m 19s\tremaining: 4m\n",
      "11943:\tlearn: 3.3155256\ttotal: 4m 19s\tremaining: 4m\n",
      "11944:\tlearn: 3.3153771\ttotal: 4m 19s\tremaining: 4m\n",
      "11945:\tlearn: 3.3152803\ttotal: 4m 19s\tremaining: 4m\n",
      "11946:\tlearn: 3.3150761\ttotal: 4m 19s\tremaining: 4m\n",
      "11947:\tlearn: 3.3149835\ttotal: 4m 19s\tremaining: 4m\n",
      "11948:\tlearn: 3.3148962\ttotal: 4m 19s\tremaining: 4m\n",
      "11949:\tlearn: 3.3147673\ttotal: 4m 19s\tremaining: 4m\n",
      "11950:\tlearn: 3.3146086\ttotal: 4m 19s\tremaining: 4m\n",
      "11951:\tlearn: 3.3145232\ttotal: 4m 19s\tremaining: 4m\n",
      "11952:\tlearn: 3.3142660\ttotal: 4m 19s\tremaining: 4m\n",
      "11953:\tlearn: 3.3140835\ttotal: 4m 19s\tremaining: 4m\n",
      "11954:\tlearn: 3.3138596\ttotal: 4m 20s\tremaining: 4m\n",
      "11955:\tlearn: 3.3137888\ttotal: 4m 20s\tremaining: 4m\n",
      "11956:\tlearn: 3.3135751\ttotal: 4m 20s\tremaining: 4m\n",
      "11957:\tlearn: 3.3134501\ttotal: 4m 20s\tremaining: 4m\n",
      "11958:\tlearn: 3.3133362\ttotal: 4m 20s\tremaining: 4m\n",
      "11959:\tlearn: 3.3132175\ttotal: 4m 20s\tremaining: 4m\n",
      "11960:\tlearn: 3.3130359\ttotal: 4m 20s\tremaining: 4m\n",
      "11961:\tlearn: 3.3127948\ttotal: 4m 20s\tremaining: 4m\n",
      "11962:\tlearn: 3.3127847\ttotal: 4m 20s\tremaining: 4m\n",
      "11963:\tlearn: 3.3126083\ttotal: 4m 20s\tremaining: 4m\n",
      "11964:\tlearn: 3.3125359\ttotal: 4m 20s\tremaining: 4m\n",
      "11965:\tlearn: 3.3124233\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11966:\tlearn: 3.3122451\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11967:\tlearn: 3.3119678\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11968:\tlearn: 3.3118530\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11969:\tlearn: 3.3116413\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11970:\tlearn: 3.3114321\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11971:\tlearn: 3.3113241\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11972:\tlearn: 3.3111630\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11973:\tlearn: 3.3110423\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11974:\tlearn: 3.3108768\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11975:\tlearn: 3.3107540\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11976:\tlearn: 3.3105498\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11977:\tlearn: 3.3103409\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11978:\tlearn: 3.3101635\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11979:\tlearn: 3.3099715\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11980:\tlearn: 3.3098475\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11981:\tlearn: 3.3096963\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11982:\tlearn: 3.3095817\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11983:\tlearn: 3.3094045\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11984:\tlearn: 3.3093318\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11985:\tlearn: 3.3091915\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11986:\tlearn: 3.3089643\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11987:\tlearn: 3.3088201\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11988:\tlearn: 3.3085532\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11989:\tlearn: 3.3084139\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11990:\tlearn: 3.3082762\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11991:\tlearn: 3.3081135\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11992:\tlearn: 3.3080323\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11993:\tlearn: 3.3078262\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11994:\tlearn: 3.3076153\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11995:\tlearn: 3.3074918\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11996:\tlearn: 3.3073346\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11997:\tlearn: 3.3071856\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11998:\tlearn: 3.3070197\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "11999:\tlearn: 3.3068253\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "12000:\tlearn: 3.3065984\ttotal: 4m 20s\tremaining: 3m 59s\n",
      "12001:\tlearn: 3.3064414\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12002:\tlearn: 3.3063220\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12003:\tlearn: 3.3060509\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12004:\tlearn: 3.3058675\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12005:\tlearn: 3.3057448\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12006:\tlearn: 3.3056787\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12007:\tlearn: 3.3055246\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12008:\tlearn: 3.3054288\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12009:\tlearn: 3.3051915\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12010:\tlearn: 3.3050339\ttotal: 4m 21s\tremaining: 3m 59s\n",
      "12011:\tlearn: 3.3049314\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12012:\tlearn: 3.3047544\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12013:\tlearn: 3.3046308\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12014:\tlearn: 3.3044977\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12015:\tlearn: 3.3044194\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12016:\tlearn: 3.3041304\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12017:\tlearn: 3.3040054\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12018:\tlearn: 3.3038450\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12019:\tlearn: 3.3036473\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12020:\tlearn: 3.3035393\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12021:\tlearn: 3.3033580\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12022:\tlearn: 3.3031995\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12023:\tlearn: 3.3029987\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12024:\tlearn: 3.3028058\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12025:\tlearn: 3.3025895\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12026:\tlearn: 3.3024510\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12027:\tlearn: 3.3022740\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12028:\tlearn: 3.3020685\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12029:\tlearn: 3.3018802\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12030:\tlearn: 3.3017716\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12031:\tlearn: 3.3015805\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12032:\tlearn: 3.3013795\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12033:\tlearn: 3.3013749\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12034:\tlearn: 3.3012781\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12035:\tlearn: 3.3010819\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12036:\tlearn: 3.3008967\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12037:\tlearn: 3.3007038\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12038:\tlearn: 3.3005017\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12039:\tlearn: 3.3003380\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12040:\tlearn: 3.3002499\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12041:\tlearn: 3.3000491\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12042:\tlearn: 3.2999127\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12043:\tlearn: 3.2997387\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12044:\tlearn: 3.2995127\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12045:\tlearn: 3.2993853\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12046:\tlearn: 3.2992997\ttotal: 4m 21s\tremaining: 3m 58s\n",
      "12047:\tlearn: 3.2991239\ttotal: 4m 22s\tremaining: 3m 58s\n",
      "12048:\tlearn: 3.2989343\ttotal: 4m 22s\tremaining: 3m 58s\n",
      "12049:\tlearn: 3.2987654\ttotal: 4m 22s\tremaining: 3m 58s\n",
      "12050:\tlearn: 3.2985913\ttotal: 4m 22s\tremaining: 3m 58s\n",
      "12051:\tlearn: 3.2984233\ttotal: 4m 22s\tremaining: 3m 58s\n",
      "12052:\tlearn: 3.2981669\ttotal: 4m 22s\tremaining: 3m 58s\n",
      "12053:\tlearn: 3.2979993\ttotal: 4m 22s\tremaining: 3m 58s\n",
      "12054:\tlearn: 3.2979067\ttotal: 4m 22s\tremaining: 3m 58s\n",
      "12055:\tlearn: 3.2977969\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12056:\tlearn: 3.2976546\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12057:\tlearn: 3.2975334\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12058:\tlearn: 3.2973813\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12059:\tlearn: 3.2973538\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12060:\tlearn: 3.2971725\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12061:\tlearn: 3.2971687\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12062:\tlearn: 3.2970629\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12063:\tlearn: 3.2969822\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12064:\tlearn: 3.2968215\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12065:\tlearn: 3.2965856\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12066:\tlearn: 3.2963769\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12067:\tlearn: 3.2961804\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12068:\tlearn: 3.2961766\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12069:\tlearn: 3.2960700\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12070:\tlearn: 3.2958407\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12071:\tlearn: 3.2958104\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12072:\tlearn: 3.2956275\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12073:\tlearn: 3.2955335\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12074:\tlearn: 3.2954078\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12075:\tlearn: 3.2953011\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12076:\tlearn: 3.2950331\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12077:\tlearn: 3.2948863\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12078:\tlearn: 3.2947505\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12079:\tlearn: 3.2945019\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12080:\tlearn: 3.2943535\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12081:\tlearn: 3.2942202\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12082:\tlearn: 3.2940530\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12083:\tlearn: 3.2938656\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12084:\tlearn: 3.2936774\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12085:\tlearn: 3.2935678\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12086:\tlearn: 3.2934377\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12087:\tlearn: 3.2932897\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12088:\tlearn: 3.2932242\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12089:\tlearn: 3.2930518\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12090:\tlearn: 3.2927903\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12091:\tlearn: 3.2927034\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12092:\tlearn: 3.2926346\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12093:\tlearn: 3.2924874\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12094:\tlearn: 3.2923860\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12095:\tlearn: 3.2923242\ttotal: 4m 22s\tremaining: 3m 57s\n",
      "12096:\tlearn: 3.2922560\ttotal: 4m 23s\tremaining: 3m 57s\n",
      "12097:\tlearn: 3.2919263\ttotal: 4m 23s\tremaining: 3m 57s\n",
      "12098:\tlearn: 3.2916961\ttotal: 4m 23s\tremaining: 3m 57s\n",
      "12099:\tlearn: 3.2915709\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12100:\tlearn: 3.2914289\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12101:\tlearn: 3.2913093\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12102:\tlearn: 3.2912058\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12103:\tlearn: 3.2910158\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12104:\tlearn: 3.2907838\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12105:\tlearn: 3.2905862\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12106:\tlearn: 3.2904179\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12107:\tlearn: 3.2902751\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12108:\tlearn: 3.2899943\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12109:\tlearn: 3.2898715\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12110:\tlearn: 3.2896253\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12111:\tlearn: 3.2894611\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12112:\tlearn: 3.2893427\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12113:\tlearn: 3.2892010\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12114:\tlearn: 3.2890921\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12115:\tlearn: 3.2889695\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12116:\tlearn: 3.2887735\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12117:\tlearn: 3.2885926\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12118:\tlearn: 3.2883389\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12119:\tlearn: 3.2882364\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12120:\tlearn: 3.2880354\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12121:\tlearn: 3.2879288\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12122:\tlearn: 3.2878046\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12123:\tlearn: 3.2876965\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12124:\tlearn: 3.2875426\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12125:\tlearn: 3.2873844\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12126:\tlearn: 3.2872948\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12127:\tlearn: 3.2871425\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12128:\tlearn: 3.2869355\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12129:\tlearn: 3.2867132\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12130:\tlearn: 3.2865693\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12131:\tlearn: 3.2864471\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12132:\tlearn: 3.2862760\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12133:\tlearn: 3.2861060\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12134:\tlearn: 3.2859387\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12135:\tlearn: 3.2858081\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12136:\tlearn: 3.2856306\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12137:\tlearn: 3.2855253\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12138:\tlearn: 3.2853783\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12139:\tlearn: 3.2852642\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12140:\tlearn: 3.2851468\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12141:\tlearn: 3.2850484\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12142:\tlearn: 3.2848030\ttotal: 4m 23s\tremaining: 3m 56s\n",
      "12143:\tlearn: 3.2846417\ttotal: 4m 24s\tremaining: 3m 56s\n",
      "12144:\tlearn: 3.2844956\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12145:\tlearn: 3.2843535\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12146:\tlearn: 3.2840276\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12147:\tlearn: 3.2839010\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12148:\tlearn: 3.2837949\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12149:\tlearn: 3.2836704\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12150:\tlearn: 3.2834410\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12151:\tlearn: 3.2832306\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12152:\tlearn: 3.2831261\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12153:\tlearn: 3.2829300\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12154:\tlearn: 3.2827644\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12155:\tlearn: 3.2825875\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12156:\tlearn: 3.2825205\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12157:\tlearn: 3.2823793\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12158:\tlearn: 3.2822164\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12159:\tlearn: 3.2820105\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12160:\tlearn: 3.2819074\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12161:\tlearn: 3.2817713\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12162:\tlearn: 3.2815924\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12163:\tlearn: 3.2814284\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12164:\tlearn: 3.2812580\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12165:\tlearn: 3.2811246\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12166:\tlearn: 3.2810816\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12167:\tlearn: 3.2808435\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12168:\tlearn: 3.2806178\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12169:\tlearn: 3.2804109\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12170:\tlearn: 3.2803403\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12171:\tlearn: 3.2801424\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12172:\tlearn: 3.2800218\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12173:\tlearn: 3.2798874\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12174:\tlearn: 3.2797825\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12175:\tlearn: 3.2796202\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12176:\tlearn: 3.2794577\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12177:\tlearn: 3.2793802\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12178:\tlearn: 3.2792318\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12179:\tlearn: 3.2790866\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12180:\tlearn: 3.2789706\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12181:\tlearn: 3.2787551\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12182:\tlearn: 3.2786250\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12183:\tlearn: 3.2783064\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12184:\tlearn: 3.2781321\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12185:\tlearn: 3.2779784\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12186:\tlearn: 3.2778167\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12187:\tlearn: 3.2775509\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12188:\tlearn: 3.2774041\ttotal: 4m 24s\tremaining: 3m 55s\n",
      "12189:\tlearn: 3.2772700\ttotal: 4m 24s\tremaining: 3m 54s\n",
      "12190:\tlearn: 3.2771614\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12191:\tlearn: 3.2770441\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12192:\tlearn: 3.2768420\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12193:\tlearn: 3.2766830\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12194:\tlearn: 3.2765525\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12195:\tlearn: 3.2764072\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12196:\tlearn: 3.2762249\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12197:\tlearn: 3.2760835\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12198:\tlearn: 3.2759487\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12199:\tlearn: 3.2759029\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12200:\tlearn: 3.2756782\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12201:\tlearn: 3.2755408\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12202:\tlearn: 3.2754439\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12203:\tlearn: 3.2751971\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12204:\tlearn: 3.2750157\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12205:\tlearn: 3.2748617\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12206:\tlearn: 3.2747293\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12207:\tlearn: 3.2745691\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12208:\tlearn: 3.2744456\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12209:\tlearn: 3.2743459\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12210:\tlearn: 3.2742253\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12211:\tlearn: 3.2741062\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12212:\tlearn: 3.2739591\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12213:\tlearn: 3.2737865\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12214:\tlearn: 3.2736628\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12215:\tlearn: 3.2735576\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12216:\tlearn: 3.2733952\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12217:\tlearn: 3.2732771\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12218:\tlearn: 3.2731174\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12219:\tlearn: 3.2729820\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12220:\tlearn: 3.2728259\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12221:\tlearn: 3.2726570\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12222:\tlearn: 3.2723481\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12223:\tlearn: 3.2722194\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12224:\tlearn: 3.2721618\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12225:\tlearn: 3.2720395\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12226:\tlearn: 3.2717930\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12227:\tlearn: 3.2716261\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12228:\tlearn: 3.2714674\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12229:\tlearn: 3.2713613\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12230:\tlearn: 3.2712232\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12231:\tlearn: 3.2710852\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12232:\tlearn: 3.2709200\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12233:\tlearn: 3.2707703\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12234:\tlearn: 3.2704740\ttotal: 4m 25s\tremaining: 3m 54s\n",
      "12235:\tlearn: 3.2703576\ttotal: 4m 25s\tremaining: 3m 53s\n",
      "12236:\tlearn: 3.2701164\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12237:\tlearn: 3.2700163\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12238:\tlearn: 3.2698688\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12239:\tlearn: 3.2697388\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12240:\tlearn: 3.2696682\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12241:\tlearn: 3.2694895\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12242:\tlearn: 3.2694838\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12243:\tlearn: 3.2692954\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12244:\tlearn: 3.2692118\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12245:\tlearn: 3.2690506\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12246:\tlearn: 3.2688301\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12247:\tlearn: 3.2686879\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12248:\tlearn: 3.2685635\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12249:\tlearn: 3.2684800\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12250:\tlearn: 3.2683006\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12251:\tlearn: 3.2681599\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12252:\tlearn: 3.2679949\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12253:\tlearn: 3.2678158\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12254:\tlearn: 3.2676440\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12255:\tlearn: 3.2675467\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12256:\tlearn: 3.2675405\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12257:\tlearn: 3.2672619\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12258:\tlearn: 3.2670207\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12259:\tlearn: 3.2668753\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12260:\tlearn: 3.2666447\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12261:\tlearn: 3.2665477\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12262:\tlearn: 3.2663671\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12263:\tlearn: 3.2661501\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12264:\tlearn: 3.2659476\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12265:\tlearn: 3.2658764\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12266:\tlearn: 3.2657762\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12267:\tlearn: 3.2656047\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12268:\tlearn: 3.2654395\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12269:\tlearn: 3.2652592\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12270:\tlearn: 3.2651327\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12271:\tlearn: 3.2649069\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12272:\tlearn: 3.2647265\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12273:\tlearn: 3.2643369\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12274:\tlearn: 3.2642013\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12275:\tlearn: 3.2639764\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12276:\tlearn: 3.2638594\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12277:\tlearn: 3.2637066\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12278:\tlearn: 3.2636757\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12279:\tlearn: 3.2635011\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12280:\tlearn: 3.2633845\ttotal: 4m 26s\tremaining: 3m 53s\n",
      "12281:\tlearn: 3.2631646\ttotal: 4m 26s\tremaining: 3m 52s\n",
      "12282:\tlearn: 3.2629381\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12283:\tlearn: 3.2627674\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12284:\tlearn: 3.2625862\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12285:\tlearn: 3.2623125\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12286:\tlearn: 3.2621320\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12287:\tlearn: 3.2619462\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12288:\tlearn: 3.2618821\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12289:\tlearn: 3.2615990\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12290:\tlearn: 3.2614371\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12291:\tlearn: 3.2613590\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12292:\tlearn: 3.2612485\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12293:\tlearn: 3.2611192\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12294:\tlearn: 3.2608765\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12295:\tlearn: 3.2606832\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12296:\tlearn: 3.2604498\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12297:\tlearn: 3.2603078\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12298:\tlearn: 3.2601786\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12299:\tlearn: 3.2600035\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12300:\tlearn: 3.2597725\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12301:\tlearn: 3.2596738\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12302:\tlearn: 3.2594100\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12303:\tlearn: 3.2592262\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12304:\tlearn: 3.2590562\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12305:\tlearn: 3.2589579\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12306:\tlearn: 3.2588336\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12307:\tlearn: 3.2585763\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12308:\tlearn: 3.2584459\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12309:\tlearn: 3.2583375\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12310:\tlearn: 3.2582104\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12311:\tlearn: 3.2580851\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12312:\tlearn: 3.2579590\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12313:\tlearn: 3.2578102\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12314:\tlearn: 3.2575226\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12315:\tlearn: 3.2572644\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12316:\tlearn: 3.2570517\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12317:\tlearn: 3.2569607\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12318:\tlearn: 3.2567940\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12319:\tlearn: 3.2564706\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12320:\tlearn: 3.2562669\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12321:\tlearn: 3.2560974\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12322:\tlearn: 3.2558834\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12323:\tlearn: 3.2557671\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12324:\tlearn: 3.2555796\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12325:\tlearn: 3.2553705\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12326:\tlearn: 3.2552333\ttotal: 4m 27s\tremaining: 3m 52s\n",
      "12327:\tlearn: 3.2550139\ttotal: 4m 27s\tremaining: 3m 51s\n",
      "12328:\tlearn: 3.2547654\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12329:\tlearn: 3.2546472\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12330:\tlearn: 3.2544890\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12331:\tlearn: 3.2543834\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12332:\tlearn: 3.2542358\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12333:\tlearn: 3.2540489\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12334:\tlearn: 3.2539185\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12335:\tlearn: 3.2539148\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12336:\tlearn: 3.2537528\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12337:\tlearn: 3.2535490\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12338:\tlearn: 3.2532982\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12339:\tlearn: 3.2530255\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12340:\tlearn: 3.2529353\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12341:\tlearn: 3.2529271\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12342:\tlearn: 3.2526868\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12343:\tlearn: 3.2525763\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12344:\tlearn: 3.2523871\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12345:\tlearn: 3.2521264\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12346:\tlearn: 3.2519944\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12347:\tlearn: 3.2518279\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12348:\tlearn: 3.2516831\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12349:\tlearn: 3.2514655\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12350:\tlearn: 3.2514016\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12351:\tlearn: 3.2512179\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12352:\tlearn: 3.2510744\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12353:\tlearn: 3.2508025\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12354:\tlearn: 3.2506091\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12355:\tlearn: 3.2505481\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12356:\tlearn: 3.2503926\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12357:\tlearn: 3.2501070\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12358:\tlearn: 3.2499644\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12359:\tlearn: 3.2498474\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12360:\tlearn: 3.2498189\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12361:\tlearn: 3.2496280\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12362:\tlearn: 3.2493591\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12363:\tlearn: 3.2492377\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12364:\tlearn: 3.2490949\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12365:\tlearn: 3.2489383\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12366:\tlearn: 3.2487277\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12367:\tlearn: 3.2485559\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12368:\tlearn: 3.2483675\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12369:\tlearn: 3.2481861\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12370:\tlearn: 3.2480853\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12371:\tlearn: 3.2478841\ttotal: 4m 28s\tremaining: 3m 51s\n",
      "12372:\tlearn: 3.2476990\ttotal: 4m 28s\tremaining: 3m 50s\n",
      "12373:\tlearn: 3.2476108\ttotal: 4m 28s\tremaining: 3m 50s\n",
      "12374:\tlearn: 3.2474169\ttotal: 4m 28s\tremaining: 3m 50s\n",
      "12375:\tlearn: 3.2473352\ttotal: 4m 28s\tremaining: 3m 50s\n",
      "12376:\tlearn: 3.2470733\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12377:\tlearn: 3.2468892\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12378:\tlearn: 3.2467153\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12379:\tlearn: 3.2465463\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12380:\tlearn: 3.2463947\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12381:\tlearn: 3.2462262\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12382:\tlearn: 3.2460369\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12383:\tlearn: 3.2458896\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12384:\tlearn: 3.2456723\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12385:\tlearn: 3.2455049\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12386:\tlearn: 3.2453615\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12387:\tlearn: 3.2453109\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12388:\tlearn: 3.2452020\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12389:\tlearn: 3.2450595\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12390:\tlearn: 3.2449217\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12391:\tlearn: 3.2446745\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12392:\tlearn: 3.2445081\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12393:\tlearn: 3.2444188\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12394:\tlearn: 3.2441396\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12395:\tlearn: 3.2439854\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12396:\tlearn: 3.2437413\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12397:\tlearn: 3.2435485\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12398:\tlearn: 3.2434172\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12399:\tlearn: 3.2432003\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12400:\tlearn: 3.2431205\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12401:\tlearn: 3.2429838\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12402:\tlearn: 3.2427371\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12403:\tlearn: 3.2426214\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12404:\tlearn: 3.2424579\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12405:\tlearn: 3.2422910\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12406:\tlearn: 3.2421360\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12407:\tlearn: 3.2418956\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12408:\tlearn: 3.2417590\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12409:\tlearn: 3.2416682\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12410:\tlearn: 3.2414882\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12411:\tlearn: 3.2414183\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12412:\tlearn: 3.2413190\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12413:\tlearn: 3.2411316\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12414:\tlearn: 3.2408839\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12415:\tlearn: 3.2407897\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12416:\tlearn: 3.2406902\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12417:\tlearn: 3.2405970\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12418:\tlearn: 3.2404058\ttotal: 4m 29s\tremaining: 3m 50s\n",
      "12419:\tlearn: 3.2401815\ttotal: 4m 29s\tremaining: 3m 49s\n",
      "12420:\tlearn: 3.2399606\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12421:\tlearn: 3.2399097\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12422:\tlearn: 3.2398436\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12423:\tlearn: 3.2396043\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12424:\tlearn: 3.2393773\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12425:\tlearn: 3.2392649\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12426:\tlearn: 3.2390467\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12427:\tlearn: 3.2389572\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12428:\tlearn: 3.2388075\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12429:\tlearn: 3.2386285\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12430:\tlearn: 3.2386249\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12431:\tlearn: 3.2383910\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12432:\tlearn: 3.2380797\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12433:\tlearn: 3.2379209\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12434:\tlearn: 3.2377871\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12435:\tlearn: 3.2376634\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12436:\tlearn: 3.2375118\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12437:\tlearn: 3.2374766\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12438:\tlearn: 3.2373468\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12439:\tlearn: 3.2370768\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12440:\tlearn: 3.2369172\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12441:\tlearn: 3.2366391\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12442:\tlearn: 3.2364914\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12443:\tlearn: 3.2362969\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12444:\tlearn: 3.2361234\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12445:\tlearn: 3.2358384\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12446:\tlearn: 3.2357276\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12447:\tlearn: 3.2355480\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12448:\tlearn: 3.2354317\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12449:\tlearn: 3.2352845\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12450:\tlearn: 3.2352093\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12451:\tlearn: 3.2352058\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12452:\tlearn: 3.2349889\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12453:\tlearn: 3.2348865\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12454:\tlearn: 3.2347478\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12455:\tlearn: 3.2346302\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12456:\tlearn: 3.2344488\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12457:\tlearn: 3.2343046\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12458:\tlearn: 3.2341621\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12459:\tlearn: 3.2340126\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12460:\tlearn: 3.2339222\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12461:\tlearn: 3.2337290\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12462:\tlearn: 3.2335431\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12463:\tlearn: 3.2332699\ttotal: 4m 30s\tremaining: 3m 49s\n",
      "12464:\tlearn: 3.2330839\ttotal: 4m 30s\tremaining: 3m 48s\n",
      "12465:\tlearn: 3.2328796\ttotal: 4m 30s\tremaining: 3m 48s\n",
      "12466:\tlearn: 3.2327320\ttotal: 4m 30s\tremaining: 3m 48s\n",
      "12467:\tlearn: 3.2325869\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12468:\tlearn: 3.2324006\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12469:\tlearn: 3.2323859\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12470:\tlearn: 3.2321641\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12471:\tlearn: 3.2319785\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12472:\tlearn: 3.2319267\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12473:\tlearn: 3.2317849\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12474:\tlearn: 3.2315213\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12475:\tlearn: 3.2313666\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12476:\tlearn: 3.2311608\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12477:\tlearn: 3.2310169\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12478:\tlearn: 3.2309369\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12479:\tlearn: 3.2307281\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12480:\tlearn: 3.2305427\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12481:\tlearn: 3.2304560\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12482:\tlearn: 3.2302669\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12483:\tlearn: 3.2301335\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12484:\tlearn: 3.2300417\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12485:\tlearn: 3.2298433\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12486:\tlearn: 3.2297624\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12487:\tlearn: 3.2296362\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12488:\tlearn: 3.2293377\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12489:\tlearn: 3.2291041\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12490:\tlearn: 3.2289746\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12491:\tlearn: 3.2287388\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12492:\tlearn: 3.2286013\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12493:\tlearn: 3.2283990\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12494:\tlearn: 3.2283145\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12495:\tlearn: 3.2281537\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12496:\tlearn: 3.2280112\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12497:\tlearn: 3.2278436\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12498:\tlearn: 3.2276925\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12499:\tlearn: 3.2275590\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12500:\tlearn: 3.2272296\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12501:\tlearn: 3.2270395\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12502:\tlearn: 3.2267586\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12503:\tlearn: 3.2265666\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12504:\tlearn: 3.2264224\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12505:\tlearn: 3.2262322\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12506:\tlearn: 3.2260513\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12507:\tlearn: 3.2259063\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12508:\tlearn: 3.2257884\ttotal: 4m 31s\tremaining: 3m 48s\n",
      "12509:\tlearn: 3.2257080\ttotal: 4m 31s\tremaining: 3m 47s\n",
      "12510:\tlearn: 3.2255543\ttotal: 4m 31s\tremaining: 3m 47s\n",
      "12511:\tlearn: 3.2254405\ttotal: 4m 31s\tremaining: 3m 47s\n",
      "12512:\tlearn: 3.2252638\ttotal: 4m 31s\tremaining: 3m 47s\n",
      "12513:\tlearn: 3.2250344\ttotal: 4m 31s\tremaining: 3m 47s\n",
      "12514:\tlearn: 3.2248900\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12515:\tlearn: 3.2246478\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12516:\tlearn: 3.2244386\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12517:\tlearn: 3.2241995\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12518:\tlearn: 3.2239873\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12519:\tlearn: 3.2237741\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12520:\tlearn: 3.2235628\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12521:\tlearn: 3.2233422\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12522:\tlearn: 3.2231520\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12523:\tlearn: 3.2230435\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12524:\tlearn: 3.2229434\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12525:\tlearn: 3.2228152\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12526:\tlearn: 3.2226280\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12527:\tlearn: 3.2224286\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12528:\tlearn: 3.2223391\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12529:\tlearn: 3.2222772\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12530:\tlearn: 3.2220797\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12531:\tlearn: 3.2219264\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12532:\tlearn: 3.2216674\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12533:\tlearn: 3.2214472\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12534:\tlearn: 3.2213208\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12535:\tlearn: 3.2211329\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12536:\tlearn: 3.2209807\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12537:\tlearn: 3.2207700\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12538:\tlearn: 3.2206194\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12539:\tlearn: 3.2206077\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12540:\tlearn: 3.2204871\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12541:\tlearn: 3.2203883\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12542:\tlearn: 3.2202742\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12543:\tlearn: 3.2200760\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12544:\tlearn: 3.2198434\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12545:\tlearn: 3.2197203\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12546:\tlearn: 3.2196415\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12547:\tlearn: 3.2194440\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12548:\tlearn: 3.2192143\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12549:\tlearn: 3.2191153\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12550:\tlearn: 3.2189375\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12551:\tlearn: 3.2187887\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12552:\tlearn: 3.2186110\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12553:\tlearn: 3.2184716\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12554:\tlearn: 3.2183476\ttotal: 4m 32s\tremaining: 3m 47s\n",
      "12555:\tlearn: 3.2182431\ttotal: 4m 32s\tremaining: 3m 46s\n",
      "12556:\tlearn: 3.2181254\ttotal: 4m 32s\tremaining: 3m 46s\n",
      "12557:\tlearn: 3.2179872\ttotal: 4m 32s\tremaining: 3m 46s\n",
      "12558:\tlearn: 3.2177572\ttotal: 4m 32s\tremaining: 3m 46s\n",
      "12559:\tlearn: 3.2175085\ttotal: 4m 32s\tremaining: 3m 46s\n",
      "12560:\tlearn: 3.2173262\ttotal: 4m 32s\tremaining: 3m 46s\n",
      "12561:\tlearn: 3.2172525\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12562:\tlearn: 3.2171138\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12563:\tlearn: 3.2169977\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12564:\tlearn: 3.2168064\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12565:\tlearn: 3.2166960\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12566:\tlearn: 3.2165328\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12567:\tlearn: 3.2164819\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12568:\tlearn: 3.2163942\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12569:\tlearn: 3.2161299\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12570:\tlearn: 3.2159738\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12571:\tlearn: 3.2157125\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12572:\tlearn: 3.2155036\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12573:\tlearn: 3.2154068\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12574:\tlearn: 3.2152704\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12575:\tlearn: 3.2150704\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12576:\tlearn: 3.2149119\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12577:\tlearn: 3.2147671\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12578:\tlearn: 3.2145529\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12579:\tlearn: 3.2144022\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12580:\tlearn: 3.2142745\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12581:\tlearn: 3.2140876\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12582:\tlearn: 3.2139428\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12583:\tlearn: 3.2139370\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12584:\tlearn: 3.2137637\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12585:\tlearn: 3.2135388\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12586:\tlearn: 3.2134265\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12587:\tlearn: 3.2131983\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12588:\tlearn: 3.2131508\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12589:\tlearn: 3.2129797\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12590:\tlearn: 3.2127353\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12591:\tlearn: 3.2126511\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12592:\tlearn: 3.2124987\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12593:\tlearn: 3.2123094\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12594:\tlearn: 3.2122141\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12595:\tlearn: 3.2119666\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12596:\tlearn: 3.2118191\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12597:\tlearn: 3.2115971\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12598:\tlearn: 3.2114861\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12599:\tlearn: 3.2112910\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12600:\tlearn: 3.2110294\ttotal: 4m 33s\tremaining: 3m 46s\n",
      "12601:\tlearn: 3.2108742\ttotal: 4m 33s\tremaining: 3m 45s\n",
      "12602:\tlearn: 3.2105837\ttotal: 4m 33s\tremaining: 3m 45s\n",
      "12603:\tlearn: 3.2104446\ttotal: 4m 33s\tremaining: 3m 45s\n",
      "12604:\tlearn: 3.2101808\ttotal: 4m 33s\tremaining: 3m 45s\n",
      "12605:\tlearn: 3.2100373\ttotal: 4m 33s\tremaining: 3m 45s\n",
      "12606:\tlearn: 3.2098051\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12607:\tlearn: 3.2096033\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12608:\tlearn: 3.2094343\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12609:\tlearn: 3.2093626\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12610:\tlearn: 3.2092293\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12611:\tlearn: 3.2090837\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12612:\tlearn: 3.2088872\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12613:\tlearn: 3.2087245\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12614:\tlearn: 3.2086108\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12615:\tlearn: 3.2084417\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12616:\tlearn: 3.2083615\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12617:\tlearn: 3.2082163\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12618:\tlearn: 3.2081216\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12619:\tlearn: 3.2079233\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12620:\tlearn: 3.2077620\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12621:\tlearn: 3.2074876\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12622:\tlearn: 3.2073367\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12623:\tlearn: 3.2071328\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12624:\tlearn: 3.2069610\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12625:\tlearn: 3.2067486\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12626:\tlearn: 3.2065682\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12627:\tlearn: 3.2064238\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12628:\tlearn: 3.2063066\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12629:\tlearn: 3.2061325\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12630:\tlearn: 3.2059707\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12631:\tlearn: 3.2057204\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12632:\tlearn: 3.2057147\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12633:\tlearn: 3.2055753\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12634:\tlearn: 3.2053580\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12635:\tlearn: 3.2052156\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12636:\tlearn: 3.2050434\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12637:\tlearn: 3.2049304\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12638:\tlearn: 3.2048148\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12639:\tlearn: 3.2046167\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12640:\tlearn: 3.2043607\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12641:\tlearn: 3.2042410\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12642:\tlearn: 3.2040005\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12643:\tlearn: 3.2038210\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12644:\tlearn: 3.2035846\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12645:\tlearn: 3.2034112\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12646:\tlearn: 3.2032449\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12647:\tlearn: 3.2031530\ttotal: 4m 34s\tremaining: 3m 45s\n",
      "12648:\tlearn: 3.2030318\ttotal: 4m 34s\tremaining: 3m 44s\n",
      "12649:\tlearn: 3.2029655\ttotal: 4m 34s\tremaining: 3m 44s\n",
      "12650:\tlearn: 3.2028446\ttotal: 4m 34s\tremaining: 3m 44s\n",
      "12651:\tlearn: 3.2026343\ttotal: 4m 34s\tremaining: 3m 44s\n",
      "12652:\tlearn: 3.2024979\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12653:\tlearn: 3.2024046\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12654:\tlearn: 3.2023283\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12655:\tlearn: 3.2020786\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12656:\tlearn: 3.2019991\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12657:\tlearn: 3.2018375\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12658:\tlearn: 3.2016134\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12659:\tlearn: 3.2015622\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12660:\tlearn: 3.2013458\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12661:\tlearn: 3.2011016\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12662:\tlearn: 3.2009814\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12663:\tlearn: 3.2007565\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12664:\tlearn: 3.2006106\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12665:\tlearn: 3.2004793\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12666:\tlearn: 3.2002959\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12667:\tlearn: 3.2001985\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12668:\tlearn: 3.2000829\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12669:\tlearn: 3.2000263\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12670:\tlearn: 3.1999095\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12671:\tlearn: 3.1997594\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12672:\tlearn: 3.1995523\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12673:\tlearn: 3.1993215\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12674:\tlearn: 3.1991672\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12675:\tlearn: 3.1989818\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12676:\tlearn: 3.1988947\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12677:\tlearn: 3.1988160\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12678:\tlearn: 3.1986135\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12679:\tlearn: 3.1983587\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12680:\tlearn: 3.1982398\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12681:\tlearn: 3.1981199\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12682:\tlearn: 3.1978525\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12683:\tlearn: 3.1977472\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12684:\tlearn: 3.1976410\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12685:\tlearn: 3.1973379\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12686:\tlearn: 3.1972412\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12687:\tlearn: 3.1971146\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12688:\tlearn: 3.1970464\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12689:\tlearn: 3.1968734\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12690:\tlearn: 3.1966735\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12691:\tlearn: 3.1964870\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12692:\tlearn: 3.1962724\ttotal: 4m 35s\tremaining: 3m 44s\n",
      "12693:\tlearn: 3.1961791\ttotal: 4m 35s\tremaining: 3m 43s\n",
      "12694:\tlearn: 3.1960138\ttotal: 4m 35s\tremaining: 3m 43s\n",
      "12695:\tlearn: 3.1958189\ttotal: 4m 35s\tremaining: 3m 43s\n",
      "12696:\tlearn: 3.1957669\ttotal: 4m 35s\tremaining: 3m 43s\n",
      "12697:\tlearn: 3.1957613\ttotal: 4m 35s\tremaining: 3m 43s\n",
      "12698:\tlearn: 3.1955836\ttotal: 4m 35s\tremaining: 3m 43s\n",
      "12699:\tlearn: 3.1953435\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12700:\tlearn: 3.1952490\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12701:\tlearn: 3.1950723\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12702:\tlearn: 3.1948396\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12703:\tlearn: 3.1946356\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12704:\tlearn: 3.1944844\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12705:\tlearn: 3.1942419\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12706:\tlearn: 3.1941386\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12707:\tlearn: 3.1939701\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12708:\tlearn: 3.1938084\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12709:\tlearn: 3.1936030\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12710:\tlearn: 3.1935146\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12711:\tlearn: 3.1933807\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12712:\tlearn: 3.1932494\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12713:\tlearn: 3.1930734\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12714:\tlearn: 3.1928922\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12715:\tlearn: 3.1927593\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12716:\tlearn: 3.1925615\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12717:\tlearn: 3.1922978\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12718:\tlearn: 3.1920041\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12719:\tlearn: 3.1918248\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12720:\tlearn: 3.1916803\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12721:\tlearn: 3.1915435\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12722:\tlearn: 3.1913895\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12723:\tlearn: 3.1912486\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12724:\tlearn: 3.1911366\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12725:\tlearn: 3.1909316\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12726:\tlearn: 3.1907763\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12727:\tlearn: 3.1906434\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12728:\tlearn: 3.1904570\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12729:\tlearn: 3.1903037\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12730:\tlearn: 3.1901498\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12731:\tlearn: 3.1900089\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12732:\tlearn: 3.1898725\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12733:\tlearn: 3.1897413\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12734:\tlearn: 3.1895478\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12735:\tlearn: 3.1893445\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12736:\tlearn: 3.1892119\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12737:\tlearn: 3.1889401\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12738:\tlearn: 3.1887652\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12739:\tlearn: 3.1885226\ttotal: 4m 36s\tremaining: 3m 43s\n",
      "12740:\tlearn: 3.1883814\ttotal: 4m 36s\tremaining: 3m 42s\n",
      "12741:\tlearn: 3.1882317\ttotal: 4m 36s\tremaining: 3m 42s\n",
      "12742:\tlearn: 3.1880467\ttotal: 4m 36s\tremaining: 3m 42s\n",
      "12743:\tlearn: 3.1879280\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12744:\tlearn: 3.1877961\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12745:\tlearn: 3.1876292\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12746:\tlearn: 3.1875233\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12747:\tlearn: 3.1874434\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12748:\tlearn: 3.1873518\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12749:\tlearn: 3.1871934\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12750:\tlearn: 3.1870264\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12751:\tlearn: 3.1868930\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12752:\tlearn: 3.1867805\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12753:\tlearn: 3.1867043\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12754:\tlearn: 3.1865349\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12755:\tlearn: 3.1863586\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12756:\tlearn: 3.1862059\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12757:\tlearn: 3.1860614\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12758:\tlearn: 3.1858279\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12759:\tlearn: 3.1856595\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12760:\tlearn: 3.1854724\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12761:\tlearn: 3.1853494\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12762:\tlearn: 3.1851497\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12763:\tlearn: 3.1850388\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12764:\tlearn: 3.1849165\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12765:\tlearn: 3.1848242\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12766:\tlearn: 3.1846478\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12767:\tlearn: 3.1844801\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12768:\tlearn: 3.1843559\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12769:\tlearn: 3.1842241\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12770:\tlearn: 3.1840078\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12771:\tlearn: 3.1838828\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12772:\tlearn: 3.1838310\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12773:\tlearn: 3.1836750\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12774:\tlearn: 3.1834566\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12775:\tlearn: 3.1833656\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12776:\tlearn: 3.1832115\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12777:\tlearn: 3.1829878\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12778:\tlearn: 3.1826823\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12779:\tlearn: 3.1825261\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12780:\tlearn: 3.1823600\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12781:\tlearn: 3.1821638\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12782:\tlearn: 3.1819009\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12783:\tlearn: 3.1816758\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12784:\tlearn: 3.1814285\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12785:\tlearn: 3.1812443\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12786:\tlearn: 3.1809996\ttotal: 4m 37s\tremaining: 3m 42s\n",
      "12787:\tlearn: 3.1808817\ttotal: 4m 37s\tremaining: 3m 41s\n",
      "12788:\tlearn: 3.1807777\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12789:\tlearn: 3.1806019\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12790:\tlearn: 3.1805066\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12791:\tlearn: 3.1802853\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12792:\tlearn: 3.1801530\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12793:\tlearn: 3.1799128\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12794:\tlearn: 3.1798763\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12795:\tlearn: 3.1798468\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12796:\tlearn: 3.1795963\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12797:\tlearn: 3.1794421\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12798:\tlearn: 3.1792412\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12799:\tlearn: 3.1790863\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12800:\tlearn: 3.1789773\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12801:\tlearn: 3.1787159\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12802:\tlearn: 3.1784747\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12803:\tlearn: 3.1782663\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12804:\tlearn: 3.1780832\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12805:\tlearn: 3.1779440\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12806:\tlearn: 3.1777527\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12807:\tlearn: 3.1777166\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12808:\tlearn: 3.1776596\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12809:\tlearn: 3.1775277\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12810:\tlearn: 3.1772962\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12811:\tlearn: 3.1772180\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12812:\tlearn: 3.1770085\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12813:\tlearn: 3.1769277\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12814:\tlearn: 3.1767791\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12815:\tlearn: 3.1766308\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12816:\tlearn: 3.1763060\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12817:\tlearn: 3.1762105\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12818:\tlearn: 3.1760030\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12819:\tlearn: 3.1758931\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12820:\tlearn: 3.1758310\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12821:\tlearn: 3.1757813\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12822:\tlearn: 3.1756691\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12823:\tlearn: 3.1755369\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12824:\tlearn: 3.1753943\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12825:\tlearn: 3.1751873\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12826:\tlearn: 3.1750854\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12827:\tlearn: 3.1748772\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12828:\tlearn: 3.1747319\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12829:\tlearn: 3.1746399\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12830:\tlearn: 3.1745129\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12831:\tlearn: 3.1743004\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12832:\tlearn: 3.1741859\ttotal: 4m 38s\tremaining: 3m 41s\n",
      "12833:\tlearn: 3.1740174\ttotal: 4m 38s\tremaining: 3m 40s\n",
      "12834:\tlearn: 3.1738984\ttotal: 4m 38s\tremaining: 3m 40s\n",
      "12835:\tlearn: 3.1737790\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12836:\tlearn: 3.1736545\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12837:\tlearn: 3.1734668\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12838:\tlearn: 3.1732285\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12839:\tlearn: 3.1731137\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12840:\tlearn: 3.1729332\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12841:\tlearn: 3.1727526\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12842:\tlearn: 3.1725934\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12843:\tlearn: 3.1723465\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12844:\tlearn: 3.1722019\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12845:\tlearn: 3.1720333\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12846:\tlearn: 3.1718928\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12847:\tlearn: 3.1716092\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12848:\tlearn: 3.1715460\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12849:\tlearn: 3.1713928\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12850:\tlearn: 3.1712018\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12851:\tlearn: 3.1710493\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12852:\tlearn: 3.1708594\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12853:\tlearn: 3.1707701\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12854:\tlearn: 3.1706076\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12855:\tlearn: 3.1704323\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12856:\tlearn: 3.1702975\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12857:\tlearn: 3.1701443\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12858:\tlearn: 3.1699277\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12859:\tlearn: 3.1697989\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12860:\tlearn: 3.1697399\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12861:\tlearn: 3.1696115\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12862:\tlearn: 3.1694784\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12863:\tlearn: 3.1694044\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12864:\tlearn: 3.1692924\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12865:\tlearn: 3.1692361\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12866:\tlearn: 3.1691134\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12867:\tlearn: 3.1690400\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12868:\tlearn: 3.1689377\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12869:\tlearn: 3.1687433\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12870:\tlearn: 3.1685773\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12871:\tlearn: 3.1683443\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12872:\tlearn: 3.1682341\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12873:\tlearn: 3.1679935\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12874:\tlearn: 3.1678628\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12875:\tlearn: 3.1677556\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12876:\tlearn: 3.1675189\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12877:\tlearn: 3.1674044\ttotal: 4m 39s\tremaining: 3m 40s\n",
      "12878:\tlearn: 3.1673347\ttotal: 4m 39s\tremaining: 3m 39s\n",
      "12879:\tlearn: 3.1672288\ttotal: 4m 39s\tremaining: 3m 39s\n",
      "12880:\tlearn: 3.1670600\ttotal: 4m 39s\tremaining: 3m 39s\n",
      "12881:\tlearn: 3.1668419\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12882:\tlearn: 3.1666418\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12883:\tlearn: 3.1665448\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12884:\tlearn: 3.1663978\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12885:\tlearn: 3.1661725\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12886:\tlearn: 3.1660423\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12887:\tlearn: 3.1658519\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12888:\tlearn: 3.1656621\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12889:\tlearn: 3.1655681\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12890:\tlearn: 3.1654393\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12891:\tlearn: 3.1652436\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12892:\tlearn: 3.1650489\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12893:\tlearn: 3.1648922\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12894:\tlearn: 3.1647210\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12895:\tlearn: 3.1645102\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12896:\tlearn: 3.1643784\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12897:\tlearn: 3.1642748\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12898:\tlearn: 3.1641357\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12899:\tlearn: 3.1639398\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12900:\tlearn: 3.1638113\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12901:\tlearn: 3.1636260\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12902:\tlearn: 3.1635016\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12903:\tlearn: 3.1633759\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12904:\tlearn: 3.1632627\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12905:\tlearn: 3.1631319\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12906:\tlearn: 3.1630077\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12907:\tlearn: 3.1628730\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12908:\tlearn: 3.1626331\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12909:\tlearn: 3.1624826\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12910:\tlearn: 3.1623535\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12911:\tlearn: 3.1622878\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12912:\tlearn: 3.1620686\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12913:\tlearn: 3.1619477\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12914:\tlearn: 3.1617221\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12915:\tlearn: 3.1615489\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12916:\tlearn: 3.1613686\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12917:\tlearn: 3.1611970\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12918:\tlearn: 3.1610704\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12919:\tlearn: 3.1609004\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12920:\tlearn: 3.1606121\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12921:\tlearn: 3.1604869\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12922:\tlearn: 3.1603548\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12923:\tlearn: 3.1601529\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12924:\tlearn: 3.1600048\ttotal: 4m 40s\tremaining: 3m 39s\n",
      "12925:\tlearn: 3.1597270\ttotal: 4m 40s\tremaining: 3m 38s\n",
      "12926:\tlearn: 3.1595424\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12927:\tlearn: 3.1593245\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12928:\tlearn: 3.1591148\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12929:\tlearn: 3.1590235\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12930:\tlearn: 3.1588533\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12931:\tlearn: 3.1587712\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12932:\tlearn: 3.1585769\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12933:\tlearn: 3.1584475\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12934:\tlearn: 3.1582345\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12935:\tlearn: 3.1580785\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12936:\tlearn: 3.1579090\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12937:\tlearn: 3.1577917\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12938:\tlearn: 3.1576327\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12939:\tlearn: 3.1574532\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12940:\tlearn: 3.1572234\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12941:\tlearn: 3.1571133\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12942:\tlearn: 3.1569975\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12943:\tlearn: 3.1568256\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12944:\tlearn: 3.1566127\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12945:\tlearn: 3.1565030\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12946:\tlearn: 3.1563011\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12947:\tlearn: 3.1561952\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12948:\tlearn: 3.1561288\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12949:\tlearn: 3.1560181\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12950:\tlearn: 3.1557395\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12951:\tlearn: 3.1556834\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12952:\tlearn: 3.1554241\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12953:\tlearn: 3.1551274\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12954:\tlearn: 3.1550365\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12955:\tlearn: 3.1548069\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12956:\tlearn: 3.1545973\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12957:\tlearn: 3.1544750\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12958:\tlearn: 3.1542811\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12959:\tlearn: 3.1540171\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12960:\tlearn: 3.1538275\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12961:\tlearn: 3.1535759\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12962:\tlearn: 3.1534372\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12963:\tlearn: 3.1532130\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12964:\tlearn: 3.1531244\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12965:\tlearn: 3.1529764\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12966:\tlearn: 3.1528568\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12967:\tlearn: 3.1527126\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12968:\tlearn: 3.1526416\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12969:\tlearn: 3.1525350\ttotal: 4m 41s\tremaining: 3m 38s\n",
      "12970:\tlearn: 3.1524119\ttotal: 4m 42s\tremaining: 3m 38s\n",
      "12971:\tlearn: 3.1523545\ttotal: 4m 42s\tremaining: 3m 38s\n",
      "12972:\tlearn: 3.1522002\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12973:\tlearn: 3.1520439\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12974:\tlearn: 3.1518925\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12975:\tlearn: 3.1517473\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12976:\tlearn: 3.1516527\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12977:\tlearn: 3.1513442\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12978:\tlearn: 3.1511740\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12979:\tlearn: 3.1510110\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12980:\tlearn: 3.1509163\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12981:\tlearn: 3.1507284\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12982:\tlearn: 3.1506178\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12983:\tlearn: 3.1504729\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12984:\tlearn: 3.1503234\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12985:\tlearn: 3.1501688\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12986:\tlearn: 3.1500534\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12987:\tlearn: 3.1498552\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12988:\tlearn: 3.1496470\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12989:\tlearn: 3.1493811\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12990:\tlearn: 3.1491754\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12991:\tlearn: 3.1490128\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12992:\tlearn: 3.1489189\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12993:\tlearn: 3.1489127\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12994:\tlearn: 3.1487756\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12995:\tlearn: 3.1485099\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12996:\tlearn: 3.1483289\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12997:\tlearn: 3.1481629\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12998:\tlearn: 3.1480155\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "12999:\tlearn: 3.1476913\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13000:\tlearn: 3.1475500\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13001:\tlearn: 3.1474012\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13002:\tlearn: 3.1472750\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13003:\tlearn: 3.1471915\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13004:\tlearn: 3.1470247\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13005:\tlearn: 3.1469556\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13006:\tlearn: 3.1466916\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13007:\tlearn: 3.1464255\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13008:\tlearn: 3.1463060\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13009:\tlearn: 3.1460706\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13010:\tlearn: 3.1459793\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13011:\tlearn: 3.1458474\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13012:\tlearn: 3.1457377\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13013:\tlearn: 3.1456590\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13014:\tlearn: 3.1454744\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13015:\tlearn: 3.1452077\ttotal: 4m 42s\tremaining: 3m 37s\n",
      "13016:\tlearn: 3.1450416\ttotal: 4m 43s\tremaining: 3m 37s\n",
      "13017:\tlearn: 3.1448689\ttotal: 4m 43s\tremaining: 3m 37s\n",
      "13018:\tlearn: 3.1446916\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13019:\tlearn: 3.1446036\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13020:\tlearn: 3.1444065\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13021:\tlearn: 3.1443008\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13022:\tlearn: 3.1441851\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13023:\tlearn: 3.1440364\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13024:\tlearn: 3.1439510\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13025:\tlearn: 3.1438301\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13026:\tlearn: 3.1436068\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13027:\tlearn: 3.1434388\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13028:\tlearn: 3.1433068\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13029:\tlearn: 3.1430889\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13030:\tlearn: 3.1428642\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13031:\tlearn: 3.1426398\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13032:\tlearn: 3.1424549\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13033:\tlearn: 3.1422793\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13034:\tlearn: 3.1421623\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13035:\tlearn: 3.1421140\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13036:\tlearn: 3.1420109\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13037:\tlearn: 3.1419185\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13038:\tlearn: 3.1417526\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13039:\tlearn: 3.1416176\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13040:\tlearn: 3.1414322\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13041:\tlearn: 3.1412813\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13042:\tlearn: 3.1410351\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13043:\tlearn: 3.1410316\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13044:\tlearn: 3.1409180\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13045:\tlearn: 3.1407382\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13046:\tlearn: 3.1405032\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13047:\tlearn: 3.1403542\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13048:\tlearn: 3.1402181\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13049:\tlearn: 3.1401519\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13050:\tlearn: 3.1400534\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13051:\tlearn: 3.1398632\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13052:\tlearn: 3.1397924\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13053:\tlearn: 3.1396305\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13054:\tlearn: 3.1394808\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13055:\tlearn: 3.1393297\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13056:\tlearn: 3.1392164\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13057:\tlearn: 3.1390362\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13058:\tlearn: 3.1388494\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13059:\tlearn: 3.1386958\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13060:\tlearn: 3.1385513\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13061:\tlearn: 3.1384313\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13062:\tlearn: 3.1382183\ttotal: 4m 43s\tremaining: 3m 36s\n",
      "13063:\tlearn: 3.1379949\ttotal: 4m 44s\tremaining: 3m 36s\n",
      "13064:\tlearn: 3.1377826\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13065:\tlearn: 3.1376549\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13066:\tlearn: 3.1375182\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13067:\tlearn: 3.1373202\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13068:\tlearn: 3.1371524\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13069:\tlearn: 3.1369685\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13070:\tlearn: 3.1368022\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13071:\tlearn: 3.1365286\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13072:\tlearn: 3.1362868\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13073:\tlearn: 3.1360756\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13074:\tlearn: 3.1359463\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13075:\tlearn: 3.1357955\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13076:\tlearn: 3.1356455\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13077:\tlearn: 3.1355599\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13078:\tlearn: 3.1353817\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13079:\tlearn: 3.1352870\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13080:\tlearn: 3.1351732\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13081:\tlearn: 3.1349523\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13082:\tlearn: 3.1347421\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13083:\tlearn: 3.1344749\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13084:\tlearn: 3.1344120\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13085:\tlearn: 3.1342346\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13086:\tlearn: 3.1341499\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13087:\tlearn: 3.1340608\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13088:\tlearn: 3.1337708\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13089:\tlearn: 3.1336348\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13090:\tlearn: 3.1334386\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13091:\tlearn: 3.1333013\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13092:\tlearn: 3.1332157\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13093:\tlearn: 3.1330650\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13094:\tlearn: 3.1328898\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13095:\tlearn: 3.1327906\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13096:\tlearn: 3.1326456\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13097:\tlearn: 3.1325786\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13098:\tlearn: 3.1325044\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13099:\tlearn: 3.1324998\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13100:\tlearn: 3.1324038\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13101:\tlearn: 3.1322604\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13102:\tlearn: 3.1320730\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13103:\tlearn: 3.1319542\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13104:\tlearn: 3.1318448\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13105:\tlearn: 3.1317193\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13106:\tlearn: 3.1315950\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13107:\tlearn: 3.1314945\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13108:\tlearn: 3.1313607\ttotal: 4m 44s\tremaining: 3m 35s\n",
      "13109:\tlearn: 3.1312193\ttotal: 4m 44s\tremaining: 3m 34s\n",
      "13110:\tlearn: 3.1311529\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13111:\tlearn: 3.1310303\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13112:\tlearn: 3.1309175\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13113:\tlearn: 3.1307137\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13114:\tlearn: 3.1305372\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13115:\tlearn: 3.1302854\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13116:\tlearn: 3.1301819\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13117:\tlearn: 3.1300730\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13118:\tlearn: 3.1298753\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13119:\tlearn: 3.1297274\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13120:\tlearn: 3.1295393\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13121:\tlearn: 3.1294443\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13122:\tlearn: 3.1292217\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13123:\tlearn: 3.1290334\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13124:\tlearn: 3.1289668\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13125:\tlearn: 3.1287682\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13126:\tlearn: 3.1286408\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13127:\tlearn: 3.1284952\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13128:\tlearn: 3.1283673\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13129:\tlearn: 3.1282895\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13130:\tlearn: 3.1281234\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13131:\tlearn: 3.1280162\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13132:\tlearn: 3.1279104\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13133:\tlearn: 3.1277666\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13134:\tlearn: 3.1275819\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13135:\tlearn: 3.1273681\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13136:\tlearn: 3.1271287\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13137:\tlearn: 3.1270816\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13138:\tlearn: 3.1269280\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13139:\tlearn: 3.1267332\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13140:\tlearn: 3.1265903\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13141:\tlearn: 3.1265074\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13142:\tlearn: 3.1263381\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13143:\tlearn: 3.1262339\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13144:\tlearn: 3.1260994\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13145:\tlearn: 3.1259720\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13146:\tlearn: 3.1258433\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13147:\tlearn: 3.1257273\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13148:\tlearn: 3.1256210\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13149:\tlearn: 3.1255160\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13150:\tlearn: 3.1253565\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13151:\tlearn: 3.1252251\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13152:\tlearn: 3.1250654\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13153:\tlearn: 3.1248401\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13154:\tlearn: 3.1247195\ttotal: 4m 45s\tremaining: 3m 34s\n",
      "13155:\tlearn: 3.1247129\ttotal: 4m 46s\tremaining: 3m 34s\n",
      "13156:\tlearn: 3.1245629\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13157:\tlearn: 3.1243868\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13158:\tlearn: 3.1242099\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13159:\tlearn: 3.1241017\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13160:\tlearn: 3.1239179\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13161:\tlearn: 3.1237514\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13162:\tlearn: 3.1235907\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13163:\tlearn: 3.1234915\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13164:\tlearn: 3.1233124\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13165:\tlearn: 3.1231150\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13166:\tlearn: 3.1229203\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13167:\tlearn: 3.1227557\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13168:\tlearn: 3.1226054\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13169:\tlearn: 3.1225349\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13170:\tlearn: 3.1223911\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13171:\tlearn: 3.1221410\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13172:\tlearn: 3.1218625\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13173:\tlearn: 3.1216447\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13174:\tlearn: 3.1214889\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13175:\tlearn: 3.1213453\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13176:\tlearn: 3.1211963\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13177:\tlearn: 3.1211094\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13178:\tlearn: 3.1208673\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13179:\tlearn: 3.1206693\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13180:\tlearn: 3.1204927\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13181:\tlearn: 3.1203920\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13182:\tlearn: 3.1202150\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13183:\tlearn: 3.1201518\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13184:\tlearn: 3.1200418\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13185:\tlearn: 3.1198535\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13186:\tlearn: 3.1197183\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13187:\tlearn: 3.1195758\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13188:\tlearn: 3.1194089\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13189:\tlearn: 3.1193130\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13190:\tlearn: 3.1190847\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13191:\tlearn: 3.1190260\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13192:\tlearn: 3.1188229\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13193:\tlearn: 3.1186456\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13194:\tlearn: 3.1185111\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13195:\tlearn: 3.1183390\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13196:\tlearn: 3.1182534\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13197:\tlearn: 3.1180556\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13198:\tlearn: 3.1178616\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13199:\tlearn: 3.1176836\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13200:\tlearn: 3.1175443\ttotal: 4m 46s\tremaining: 3m 33s\n",
      "13201:\tlearn: 3.1174729\ttotal: 4m 46s\tremaining: 3m 32s\n",
      "13202:\tlearn: 3.1173303\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13203:\tlearn: 3.1171008\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13204:\tlearn: 3.1170014\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13205:\tlearn: 3.1168581\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13206:\tlearn: 3.1166236\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13207:\tlearn: 3.1164651\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13208:\tlearn: 3.1163664\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13209:\tlearn: 3.1162435\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13210:\tlearn: 3.1160943\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13211:\tlearn: 3.1158463\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13212:\tlearn: 3.1157616\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13213:\tlearn: 3.1156380\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13214:\tlearn: 3.1154991\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13215:\tlearn: 3.1153009\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13216:\tlearn: 3.1151890\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13217:\tlearn: 3.1150898\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13218:\tlearn: 3.1149366\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13219:\tlearn: 3.1147849\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13220:\tlearn: 3.1146075\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13221:\tlearn: 3.1144750\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13222:\tlearn: 3.1142734\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13223:\tlearn: 3.1140795\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13224:\tlearn: 3.1139958\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13225:\tlearn: 3.1138447\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13226:\tlearn: 3.1137834\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13227:\tlearn: 3.1134753\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13228:\tlearn: 3.1132207\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13229:\tlearn: 3.1130291\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13230:\tlearn: 3.1128496\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13231:\tlearn: 3.1127684\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13232:\tlearn: 3.1124099\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13233:\tlearn: 3.1122173\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13234:\tlearn: 3.1120901\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13235:\tlearn: 3.1119248\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13236:\tlearn: 3.1117507\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13237:\tlearn: 3.1115375\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13238:\tlearn: 3.1114389\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13239:\tlearn: 3.1113247\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13240:\tlearn: 3.1111931\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13241:\tlearn: 3.1110636\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13242:\tlearn: 3.1109956\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13243:\tlearn: 3.1108118\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13244:\tlearn: 3.1106809\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13245:\tlearn: 3.1106450\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13246:\tlearn: 3.1105465\ttotal: 4m 47s\tremaining: 3m 32s\n",
      "13247:\tlearn: 3.1103327\ttotal: 4m 48s\tremaining: 3m 32s\n",
      "13248:\tlearn: 3.1101260\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13249:\tlearn: 3.1099766\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13250:\tlearn: 3.1098544\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13251:\tlearn: 3.1096833\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13252:\tlearn: 3.1095769\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13253:\tlearn: 3.1094475\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13254:\tlearn: 3.1093214\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13255:\tlearn: 3.1092427\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13256:\tlearn: 3.1091194\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13257:\tlearn: 3.1090169\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13258:\tlearn: 3.1088350\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13259:\tlearn: 3.1087474\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13260:\tlearn: 3.1086800\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13261:\tlearn: 3.1085197\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13262:\tlearn: 3.1083586\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13263:\tlearn: 3.1082470\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13264:\tlearn: 3.1079875\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13265:\tlearn: 3.1078142\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13266:\tlearn: 3.1076002\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13267:\tlearn: 3.1074551\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13268:\tlearn: 3.1073944\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13269:\tlearn: 3.1073389\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13270:\tlearn: 3.1071742\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13271:\tlearn: 3.1070141\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13272:\tlearn: 3.1068555\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13273:\tlearn: 3.1067624\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13274:\tlearn: 3.1066512\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13275:\tlearn: 3.1064949\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13276:\tlearn: 3.1063704\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13277:\tlearn: 3.1062175\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13278:\tlearn: 3.1060710\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13279:\tlearn: 3.1059845\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13280:\tlearn: 3.1057800\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13281:\tlearn: 3.1055955\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13282:\tlearn: 3.1053871\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13283:\tlearn: 3.1052615\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13284:\tlearn: 3.1052052\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13285:\tlearn: 3.1049978\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13286:\tlearn: 3.1048269\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13287:\tlearn: 3.1046311\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13288:\tlearn: 3.1045128\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13289:\tlearn: 3.1044572\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13290:\tlearn: 3.1044524\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13291:\tlearn: 3.1043541\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13292:\tlearn: 3.1042888\ttotal: 4m 48s\tremaining: 3m 31s\n",
      "13293:\tlearn: 3.1041627\ttotal: 4m 48s\tremaining: 3m 30s\n",
      "13294:\tlearn: 3.1039910\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13295:\tlearn: 3.1038199\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13296:\tlearn: 3.1037397\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13297:\tlearn: 3.1036712\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13298:\tlearn: 3.1035342\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13299:\tlearn: 3.1033858\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13300:\tlearn: 3.1031303\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13301:\tlearn: 3.1029768\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13302:\tlearn: 3.1028467\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13303:\tlearn: 3.1027303\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13304:\tlearn: 3.1026138\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13305:\tlearn: 3.1024333\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13306:\tlearn: 3.1023509\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13307:\tlearn: 3.1022285\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13308:\tlearn: 3.1021770\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13309:\tlearn: 3.1020794\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13310:\tlearn: 3.1019472\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13311:\tlearn: 3.1018048\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13312:\tlearn: 3.1017332\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13313:\tlearn: 3.1015105\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13314:\tlearn: 3.1012946\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13315:\tlearn: 3.1011309\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13316:\tlearn: 3.1010436\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13317:\tlearn: 3.1010228\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13318:\tlearn: 3.1009499\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13319:\tlearn: 3.1007610\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13320:\tlearn: 3.1005820\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13321:\tlearn: 3.1004260\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13322:\tlearn: 3.1003091\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13323:\tlearn: 3.1001018\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13324:\tlearn: 3.1000346\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13325:\tlearn: 3.0999026\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13326:\tlearn: 3.0997097\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13327:\tlearn: 3.0995392\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13328:\tlearn: 3.0994196\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13329:\tlearn: 3.0992149\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13330:\tlearn: 3.0990524\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13331:\tlearn: 3.0989629\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13332:\tlearn: 3.0987032\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13333:\tlearn: 3.0985663\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13334:\tlearn: 3.0983851\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13335:\tlearn: 3.0982455\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13336:\tlearn: 3.0981001\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13337:\tlearn: 3.0979624\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13338:\tlearn: 3.0977450\ttotal: 4m 49s\tremaining: 3m 30s\n",
      "13339:\tlearn: 3.0976108\ttotal: 4m 49s\tremaining: 3m 29s\n",
      "13340:\tlearn: 3.0974784\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13341:\tlearn: 3.0973393\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13342:\tlearn: 3.0972315\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13343:\tlearn: 3.0971142\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13344:\tlearn: 3.0969603\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13345:\tlearn: 3.0968617\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13346:\tlearn: 3.0967307\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13347:\tlearn: 3.0965801\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13348:\tlearn: 3.0964149\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13349:\tlearn: 3.0962769\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13350:\tlearn: 3.0961132\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13351:\tlearn: 3.0960468\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13352:\tlearn: 3.0958994\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13353:\tlearn: 3.0957846\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13354:\tlearn: 3.0957095\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13355:\tlearn: 3.0956074\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13356:\tlearn: 3.0955048\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13357:\tlearn: 3.0953327\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13358:\tlearn: 3.0953287\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13359:\tlearn: 3.0951886\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13360:\tlearn: 3.0950076\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13361:\tlearn: 3.0949495\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13362:\tlearn: 3.0947767\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13363:\tlearn: 3.0946550\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13364:\tlearn: 3.0945226\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13365:\tlearn: 3.0944164\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13366:\tlearn: 3.0942608\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13367:\tlearn: 3.0941274\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13368:\tlearn: 3.0940338\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13369:\tlearn: 3.0938446\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13370:\tlearn: 3.0936984\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13371:\tlearn: 3.0935140\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13372:\tlearn: 3.0933041\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13373:\tlearn: 3.0932319\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13374:\tlearn: 3.0931575\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13375:\tlearn: 3.0930400\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13376:\tlearn: 3.0929191\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13377:\tlearn: 3.0927927\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13378:\tlearn: 3.0925645\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13379:\tlearn: 3.0923978\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13380:\tlearn: 3.0922062\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13381:\tlearn: 3.0919807\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13382:\tlearn: 3.0918881\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13383:\tlearn: 3.0917962\ttotal: 4m 50s\tremaining: 3m 29s\n",
      "13384:\tlearn: 3.0916161\ttotal: 4m 50s\tremaining: 3m 28s\n",
      "13385:\tlearn: 3.0914602\ttotal: 4m 50s\tremaining: 3m 28s\n",
      "13386:\tlearn: 3.0913556\ttotal: 4m 50s\tremaining: 3m 28s\n",
      "13387:\tlearn: 3.0912118\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13388:\tlearn: 3.0910827\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13389:\tlearn: 3.0909257\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13390:\tlearn: 3.0907424\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13391:\tlearn: 3.0906155\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13392:\tlearn: 3.0904513\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13393:\tlearn: 3.0903461\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13394:\tlearn: 3.0902178\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13395:\tlearn: 3.0901146\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13396:\tlearn: 3.0899024\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13397:\tlearn: 3.0897672\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13398:\tlearn: 3.0897063\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13399:\tlearn: 3.0897014\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13400:\tlearn: 3.0896030\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13401:\tlearn: 3.0893186\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13402:\tlearn: 3.0891915\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13403:\tlearn: 3.0890180\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13404:\tlearn: 3.0888393\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13405:\tlearn: 3.0886344\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13406:\tlearn: 3.0884909\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13407:\tlearn: 3.0883657\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13408:\tlearn: 3.0882286\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13409:\tlearn: 3.0880610\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13410:\tlearn: 3.0879042\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13411:\tlearn: 3.0876624\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13412:\tlearn: 3.0876060\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13413:\tlearn: 3.0873734\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13414:\tlearn: 3.0871653\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13415:\tlearn: 3.0870351\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13416:\tlearn: 3.0869048\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13417:\tlearn: 3.0867345\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13418:\tlearn: 3.0865980\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13419:\tlearn: 3.0864983\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13420:\tlearn: 3.0863666\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13421:\tlearn: 3.0861605\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13422:\tlearn: 3.0860448\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13423:\tlearn: 3.0858660\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13424:\tlearn: 3.0856967\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13425:\tlearn: 3.0856409\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13426:\tlearn: 3.0855833\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13427:\tlearn: 3.0853972\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13428:\tlearn: 3.0853620\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13429:\tlearn: 3.0853314\ttotal: 4m 51s\tremaining: 3m 28s\n",
      "13430:\tlearn: 3.0851134\ttotal: 4m 51s\tremaining: 3m 27s\n",
      "13431:\tlearn: 3.0849601\ttotal: 4m 51s\tremaining: 3m 27s\n",
      "13432:\tlearn: 3.0848475\ttotal: 4m 51s\tremaining: 3m 27s\n",
      "13433:\tlearn: 3.0846548\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13434:\tlearn: 3.0845358\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13435:\tlearn: 3.0842935\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13436:\tlearn: 3.0840547\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13437:\tlearn: 3.0839322\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13438:\tlearn: 3.0838307\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13439:\tlearn: 3.0836829\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13440:\tlearn: 3.0835342\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13441:\tlearn: 3.0833693\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13442:\tlearn: 3.0832587\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13443:\tlearn: 3.0832171\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13444:\tlearn: 3.0830616\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13445:\tlearn: 3.0828898\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13446:\tlearn: 3.0827404\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13447:\tlearn: 3.0826115\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13448:\tlearn: 3.0824604\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13449:\tlearn: 3.0823696\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13450:\tlearn: 3.0822472\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13451:\tlearn: 3.0821110\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13452:\tlearn: 3.0819669\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13453:\tlearn: 3.0817454\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13454:\tlearn: 3.0816061\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13455:\tlearn: 3.0815542\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13456:\tlearn: 3.0813680\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13457:\tlearn: 3.0813302\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13458:\tlearn: 3.0812103\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13459:\tlearn: 3.0811041\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13460:\tlearn: 3.0809725\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13461:\tlearn: 3.0808188\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13462:\tlearn: 3.0806548\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13463:\tlearn: 3.0805008\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13464:\tlearn: 3.0803168\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13465:\tlearn: 3.0801358\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13466:\tlearn: 3.0800037\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13467:\tlearn: 3.0798440\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13468:\tlearn: 3.0796910\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13469:\tlearn: 3.0795603\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13470:\tlearn: 3.0793294\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13471:\tlearn: 3.0791501\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13472:\tlearn: 3.0790574\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13473:\tlearn: 3.0789455\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13474:\tlearn: 3.0788721\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13475:\tlearn: 3.0787144\ttotal: 4m 52s\tremaining: 3m 27s\n",
      "13476:\tlearn: 3.0785858\ttotal: 4m 52s\tremaining: 3m 26s\n",
      "13477:\tlearn: 3.0784969\ttotal: 4m 52s\tremaining: 3m 26s\n",
      "13478:\tlearn: 3.0783807\ttotal: 4m 52s\tremaining: 3m 26s\n",
      "13479:\tlearn: 3.0781922\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13480:\tlearn: 3.0781209\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13481:\tlearn: 3.0779221\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13482:\tlearn: 3.0777661\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13483:\tlearn: 3.0775891\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13484:\tlearn: 3.0774171\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13485:\tlearn: 3.0773566\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13486:\tlearn: 3.0770895\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13487:\tlearn: 3.0769885\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13488:\tlearn: 3.0767997\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13489:\tlearn: 3.0766681\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13490:\tlearn: 3.0764855\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13491:\tlearn: 3.0763937\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13492:\tlearn: 3.0762912\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13493:\tlearn: 3.0761242\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13494:\tlearn: 3.0759942\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13495:\tlearn: 3.0758696\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13496:\tlearn: 3.0756695\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13497:\tlearn: 3.0754513\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13498:\tlearn: 3.0752781\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13499:\tlearn: 3.0751816\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13500:\tlearn: 3.0751076\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13501:\tlearn: 3.0749699\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13502:\tlearn: 3.0748134\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13503:\tlearn: 3.0746560\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13504:\tlearn: 3.0745821\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13505:\tlearn: 3.0743907\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13506:\tlearn: 3.0742865\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13507:\tlearn: 3.0740529\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13508:\tlearn: 3.0738611\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13509:\tlearn: 3.0737455\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13510:\tlearn: 3.0736325\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13511:\tlearn: 3.0734919\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13512:\tlearn: 3.0732276\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13513:\tlearn: 3.0731162\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13514:\tlearn: 3.0729373\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13515:\tlearn: 3.0728138\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13516:\tlearn: 3.0725575\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13517:\tlearn: 3.0725069\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13518:\tlearn: 3.0723788\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13519:\tlearn: 3.0722472\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13520:\tlearn: 3.0721190\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13521:\tlearn: 3.0719204\ttotal: 4m 53s\tremaining: 3m 26s\n",
      "13522:\tlearn: 3.0718673\ttotal: 4m 53s\tremaining: 3m 25s\n",
      "13523:\tlearn: 3.0717805\ttotal: 4m 53s\tremaining: 3m 25s\n",
      "13524:\tlearn: 3.0716672\ttotal: 4m 53s\tremaining: 3m 25s\n",
      "13525:\tlearn: 3.0715195\ttotal: 4m 53s\tremaining: 3m 25s\n",
      "13526:\tlearn: 3.0713303\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13527:\tlearn: 3.0712955\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13528:\tlearn: 3.0710630\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13529:\tlearn: 3.0709530\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13530:\tlearn: 3.0708442\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13531:\tlearn: 3.0707612\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13532:\tlearn: 3.0705663\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13533:\tlearn: 3.0704426\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13534:\tlearn: 3.0703376\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13535:\tlearn: 3.0701641\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13536:\tlearn: 3.0700158\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13537:\tlearn: 3.0698850\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13538:\tlearn: 3.0696767\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13539:\tlearn: 3.0695755\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13540:\tlearn: 3.0694621\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13541:\tlearn: 3.0693895\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13542:\tlearn: 3.0692597\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13543:\tlearn: 3.0691711\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13544:\tlearn: 3.0690000\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13545:\tlearn: 3.0689319\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13546:\tlearn: 3.0687879\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13547:\tlearn: 3.0686600\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13548:\tlearn: 3.0684272\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13549:\tlearn: 3.0683108\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13550:\tlearn: 3.0682125\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13551:\tlearn: 3.0681009\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13552:\tlearn: 3.0678385\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13553:\tlearn: 3.0677393\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13554:\tlearn: 3.0676169\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13555:\tlearn: 3.0674837\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13556:\tlearn: 3.0673906\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13557:\tlearn: 3.0672697\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13558:\tlearn: 3.0671692\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13559:\tlearn: 3.0669987\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13560:\tlearn: 3.0668647\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13561:\tlearn: 3.0667346\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13562:\tlearn: 3.0665346\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13563:\tlearn: 3.0663814\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13564:\tlearn: 3.0661922\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13565:\tlearn: 3.0659273\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13566:\tlearn: 3.0657626\ttotal: 4m 54s\tremaining: 3m 25s\n",
      "13567:\tlearn: 3.0655905\ttotal: 4m 54s\tremaining: 3m 24s\n",
      "13568:\tlearn: 3.0654125\ttotal: 4m 54s\tremaining: 3m 24s\n",
      "13569:\tlearn: 3.0651322\ttotal: 4m 54s\tremaining: 3m 24s\n",
      "13570:\tlearn: 3.0650436\ttotal: 4m 54s\tremaining: 3m 24s\n",
      "13571:\tlearn: 3.0648501\ttotal: 4m 54s\tremaining: 3m 24s\n",
      "13572:\tlearn: 3.0646358\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13573:\tlearn: 3.0645062\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13574:\tlearn: 3.0644219\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13575:\tlearn: 3.0643167\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13576:\tlearn: 3.0641908\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13577:\tlearn: 3.0640725\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13578:\tlearn: 3.0638725\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13579:\tlearn: 3.0637335\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13580:\tlearn: 3.0635784\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13581:\tlearn: 3.0634715\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13582:\tlearn: 3.0633434\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13583:\tlearn: 3.0631694\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13584:\tlearn: 3.0631054\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13585:\tlearn: 3.0629474\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13586:\tlearn: 3.0628179\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13587:\tlearn: 3.0627034\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13588:\tlearn: 3.0625744\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13589:\tlearn: 3.0624058\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13590:\tlearn: 3.0622634\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13591:\tlearn: 3.0620472\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13592:\tlearn: 3.0619128\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13593:\tlearn: 3.0617713\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13594:\tlearn: 3.0616473\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13595:\tlearn: 3.0615257\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13596:\tlearn: 3.0613755\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13597:\tlearn: 3.0612212\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13598:\tlearn: 3.0609670\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13599:\tlearn: 3.0608397\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13600:\tlearn: 3.0606601\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13601:\tlearn: 3.0605651\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13602:\tlearn: 3.0604478\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13603:\tlearn: 3.0603084\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13604:\tlearn: 3.0601363\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13605:\tlearn: 3.0600121\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13606:\tlearn: 3.0598283\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13607:\tlearn: 3.0597480\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13608:\tlearn: 3.0596156\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13609:\tlearn: 3.0594901\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13610:\tlearn: 3.0594395\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13611:\tlearn: 3.0592531\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13612:\tlearn: 3.0591405\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13613:\tlearn: 3.0589519\ttotal: 4m 55s\tremaining: 3m 24s\n",
      "13614:\tlearn: 3.0588390\ttotal: 4m 55s\tremaining: 3m 23s\n",
      "13615:\tlearn: 3.0587989\ttotal: 4m 55s\tremaining: 3m 23s\n",
      "13616:\tlearn: 3.0587791\ttotal: 4m 55s\tremaining: 3m 23s\n",
      "13617:\tlearn: 3.0586832\ttotal: 4m 55s\tremaining: 3m 23s\n",
      "13618:\tlearn: 3.0586109\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13619:\tlearn: 3.0583888\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13620:\tlearn: 3.0582628\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13621:\tlearn: 3.0580602\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13622:\tlearn: 3.0579296\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13623:\tlearn: 3.0578174\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13624:\tlearn: 3.0576566\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13625:\tlearn: 3.0575250\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13626:\tlearn: 3.0573352\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13627:\tlearn: 3.0571346\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13628:\tlearn: 3.0570325\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13629:\tlearn: 3.0569897\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13630:\tlearn: 3.0568397\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13631:\tlearn: 3.0567181\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13632:\tlearn: 3.0566140\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13633:\tlearn: 3.0564740\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13634:\tlearn: 3.0563223\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13635:\tlearn: 3.0562464\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13636:\tlearn: 3.0561212\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13637:\tlearn: 3.0560287\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13638:\tlearn: 3.0558879\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13639:\tlearn: 3.0558201\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13640:\tlearn: 3.0556547\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13641:\tlearn: 3.0554957\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13642:\tlearn: 3.0553509\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13643:\tlearn: 3.0552900\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13644:\tlearn: 3.0551188\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13645:\tlearn: 3.0550294\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13646:\tlearn: 3.0548169\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13647:\tlearn: 3.0547002\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13648:\tlearn: 3.0545498\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13649:\tlearn: 3.0544087\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13650:\tlearn: 3.0543283\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13651:\tlearn: 3.0541886\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13652:\tlearn: 3.0540273\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13653:\tlearn: 3.0538462\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13654:\tlearn: 3.0536995\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13655:\tlearn: 3.0535938\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13656:\tlearn: 3.0534745\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13657:\tlearn: 3.0533124\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13658:\tlearn: 3.0532607\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13659:\tlearn: 3.0530928\ttotal: 4m 56s\tremaining: 3m 23s\n",
      "13660:\tlearn: 3.0529549\ttotal: 4m 56s\tremaining: 3m 22s\n",
      "13661:\tlearn: 3.0529012\ttotal: 4m 56s\tremaining: 3m 22s\n",
      "13662:\tlearn: 3.0527458\ttotal: 4m 56s\tremaining: 3m 22s\n",
      "13663:\tlearn: 3.0526050\ttotal: 4m 56s\tremaining: 3m 22s\n",
      "13664:\tlearn: 3.0524383\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13665:\tlearn: 3.0521443\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13666:\tlearn: 3.0519775\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13667:\tlearn: 3.0518260\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13668:\tlearn: 3.0517010\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13669:\tlearn: 3.0515840\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13670:\tlearn: 3.0514851\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13671:\tlearn: 3.0514300\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13672:\tlearn: 3.0512544\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13673:\tlearn: 3.0510926\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13674:\tlearn: 3.0509598\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13675:\tlearn: 3.0508499\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13676:\tlearn: 3.0506891\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13677:\tlearn: 3.0506464\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13678:\tlearn: 3.0504514\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13679:\tlearn: 3.0502861\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13680:\tlearn: 3.0501935\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13681:\tlearn: 3.0500192\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13682:\tlearn: 3.0498564\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13683:\tlearn: 3.0497623\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13684:\tlearn: 3.0496290\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13685:\tlearn: 3.0495205\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13686:\tlearn: 3.0493958\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13687:\tlearn: 3.0491112\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13688:\tlearn: 3.0489722\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13689:\tlearn: 3.0487732\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13690:\tlearn: 3.0485785\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13691:\tlearn: 3.0483163\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13692:\tlearn: 3.0481389\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13693:\tlearn: 3.0479843\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13694:\tlearn: 3.0478155\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13695:\tlearn: 3.0477118\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13696:\tlearn: 3.0476217\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13697:\tlearn: 3.0474842\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13698:\tlearn: 3.0473595\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13699:\tlearn: 3.0472469\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13700:\tlearn: 3.0471601\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13701:\tlearn: 3.0470410\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13702:\tlearn: 3.0468230\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13703:\tlearn: 3.0466844\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13704:\tlearn: 3.0464312\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13705:\tlearn: 3.0463467\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13706:\tlearn: 3.0461751\ttotal: 4m 57s\tremaining: 3m 22s\n",
      "13707:\tlearn: 3.0460351\ttotal: 4m 57s\tremaining: 3m 21s\n",
      "13708:\tlearn: 3.0459567\ttotal: 4m 57s\tremaining: 3m 21s\n",
      "13709:\tlearn: 3.0458067\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13710:\tlearn: 3.0455771\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13711:\tlearn: 3.0455180\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13712:\tlearn: 3.0452984\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13713:\tlearn: 3.0451870\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13714:\tlearn: 3.0450849\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13715:\tlearn: 3.0449561\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13716:\tlearn: 3.0448391\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13717:\tlearn: 3.0446860\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13718:\tlearn: 3.0445427\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13719:\tlearn: 3.0443765\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13720:\tlearn: 3.0441266\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13721:\tlearn: 3.0440063\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13722:\tlearn: 3.0438376\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13723:\tlearn: 3.0436962\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13724:\tlearn: 3.0436077\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13725:\tlearn: 3.0435277\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13726:\tlearn: 3.0433469\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13727:\tlearn: 3.0432434\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13728:\tlearn: 3.0431636\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13729:\tlearn: 3.0429890\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13730:\tlearn: 3.0428257\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13731:\tlearn: 3.0426696\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13732:\tlearn: 3.0423962\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13733:\tlearn: 3.0422893\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13734:\tlearn: 3.0422369\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13735:\tlearn: 3.0421241\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13736:\tlearn: 3.0419822\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13737:\tlearn: 3.0418353\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13738:\tlearn: 3.0416762\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13739:\tlearn: 3.0415790\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13740:\tlearn: 3.0414416\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13741:\tlearn: 3.0413840\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13742:\tlearn: 3.0412893\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13743:\tlearn: 3.0411511\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13744:\tlearn: 3.0410415\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13745:\tlearn: 3.0409040\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13746:\tlearn: 3.0406643\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13747:\tlearn: 3.0405310\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13748:\tlearn: 3.0404189\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13749:\tlearn: 3.0402877\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13750:\tlearn: 3.0401242\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13751:\tlearn: 3.0399752\ttotal: 4m 58s\tremaining: 3m 21s\n",
      "13752:\tlearn: 3.0398543\ttotal: 4m 58s\tremaining: 3m 20s\n",
      "13753:\tlearn: 3.0396866\ttotal: 4m 58s\tremaining: 3m 20s\n",
      "13754:\tlearn: 3.0396045\ttotal: 4m 58s\tremaining: 3m 20s\n",
      "13755:\tlearn: 3.0395069\ttotal: 4m 58s\tremaining: 3m 20s\n",
      "13756:\tlearn: 3.0395038\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13757:\tlearn: 3.0393940\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13758:\tlearn: 3.0393062\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13759:\tlearn: 3.0390676\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13760:\tlearn: 3.0389418\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13761:\tlearn: 3.0387849\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13762:\tlearn: 3.0387277\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13763:\tlearn: 3.0386031\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13764:\tlearn: 3.0384209\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13765:\tlearn: 3.0382818\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13766:\tlearn: 3.0381406\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13767:\tlearn: 3.0380377\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13768:\tlearn: 3.0379118\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13769:\tlearn: 3.0377160\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13770:\tlearn: 3.0375186\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13771:\tlearn: 3.0373685\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13772:\tlearn: 3.0372741\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13773:\tlearn: 3.0371282\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13774:\tlearn: 3.0369788\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13775:\tlearn: 3.0368509\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13776:\tlearn: 3.0366651\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13777:\tlearn: 3.0364884\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13778:\tlearn: 3.0362651\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13779:\tlearn: 3.0361495\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13780:\tlearn: 3.0360707\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13781:\tlearn: 3.0359518\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13782:\tlearn: 3.0358381\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13783:\tlearn: 3.0357218\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13784:\tlearn: 3.0355994\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13785:\tlearn: 3.0353886\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13786:\tlearn: 3.0352349\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13787:\tlearn: 3.0349985\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13788:\tlearn: 3.0348936\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13789:\tlearn: 3.0347569\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13790:\tlearn: 3.0345377\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13791:\tlearn: 3.0343784\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13792:\tlearn: 3.0342855\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13793:\tlearn: 3.0341643\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13794:\tlearn: 3.0339235\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13795:\tlearn: 3.0338222\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13796:\tlearn: 3.0336876\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13797:\tlearn: 3.0335350\ttotal: 4m 59s\tremaining: 3m 20s\n",
      "13798:\tlearn: 3.0333920\ttotal: 4m 59s\tremaining: 3m 19s\n",
      "13799:\tlearn: 3.0333239\ttotal: 4m 59s\tremaining: 3m 19s\n",
      "13800:\tlearn: 3.0331805\ttotal: 4m 59s\tremaining: 3m 19s\n",
      "13801:\tlearn: 3.0329667\ttotal: 4m 59s\tremaining: 3m 19s\n",
      "13802:\tlearn: 3.0328860\ttotal: 5m\tremaining: 3m 19s\n",
      "13803:\tlearn: 3.0327051\ttotal: 5m\tremaining: 3m 19s\n",
      "13804:\tlearn: 3.0325457\ttotal: 5m\tremaining: 3m 19s\n",
      "13805:\tlearn: 3.0324007\ttotal: 5m\tremaining: 3m 19s\n",
      "13806:\tlearn: 3.0322798\ttotal: 5m\tremaining: 3m 19s\n",
      "13807:\tlearn: 3.0321016\ttotal: 5m\tremaining: 3m 19s\n",
      "13808:\tlearn: 3.0320678\ttotal: 5m\tremaining: 3m 19s\n",
      "13809:\tlearn: 3.0320160\ttotal: 5m\tremaining: 3m 19s\n",
      "13810:\tlearn: 3.0318173\ttotal: 5m\tremaining: 3m 19s\n",
      "13811:\tlearn: 3.0317390\ttotal: 5m\tremaining: 3m 19s\n",
      "13812:\tlearn: 3.0315680\ttotal: 5m\tremaining: 3m 19s\n",
      "13813:\tlearn: 3.0314003\ttotal: 5m\tremaining: 3m 19s\n",
      "13814:\tlearn: 3.0312666\ttotal: 5m\tremaining: 3m 19s\n",
      "13815:\tlearn: 3.0312241\ttotal: 5m\tremaining: 3m 19s\n",
      "13816:\tlearn: 3.0311179\ttotal: 5m\tremaining: 3m 19s\n",
      "13817:\tlearn: 3.0309371\ttotal: 5m\tremaining: 3m 19s\n",
      "13818:\tlearn: 3.0307949\ttotal: 5m\tremaining: 3m 19s\n",
      "13819:\tlearn: 3.0306809\ttotal: 5m\tremaining: 3m 19s\n",
      "13820:\tlearn: 3.0305438\ttotal: 5m\tremaining: 3m 19s\n",
      "13821:\tlearn: 3.0304917\ttotal: 5m\tremaining: 3m 19s\n",
      "13822:\tlearn: 3.0304021\ttotal: 5m\tremaining: 3m 19s\n",
      "13823:\tlearn: 3.0302113\ttotal: 5m\tremaining: 3m 19s\n",
      "13824:\tlearn: 3.0300788\ttotal: 5m\tremaining: 3m 19s\n",
      "13825:\tlearn: 3.0299454\ttotal: 5m\tremaining: 3m 19s\n",
      "13826:\tlearn: 3.0298378\ttotal: 5m\tremaining: 3m 19s\n",
      "13827:\tlearn: 3.0296933\ttotal: 5m\tremaining: 3m 19s\n",
      "13828:\tlearn: 3.0294829\ttotal: 5m\tremaining: 3m 19s\n",
      "13829:\tlearn: 3.0293749\ttotal: 5m\tremaining: 3m 19s\n",
      "13830:\tlearn: 3.0292917\ttotal: 5m\tremaining: 3m 19s\n",
      "13831:\tlearn: 3.0291505\ttotal: 5m\tremaining: 3m 19s\n",
      "13832:\tlearn: 3.0290595\ttotal: 5m\tremaining: 3m 19s\n",
      "13833:\tlearn: 3.0290137\ttotal: 5m\tremaining: 3m 19s\n",
      "13834:\tlearn: 3.0288840\ttotal: 5m\tremaining: 3m 19s\n",
      "13835:\tlearn: 3.0287741\ttotal: 5m\tremaining: 3m 19s\n",
      "13836:\tlearn: 3.0286838\ttotal: 5m\tremaining: 3m 19s\n",
      "13837:\tlearn: 3.0286388\ttotal: 5m\tremaining: 3m 19s\n",
      "13838:\tlearn: 3.0285084\ttotal: 5m\tremaining: 3m 19s\n",
      "13839:\tlearn: 3.0284024\ttotal: 5m\tremaining: 3m 19s\n",
      "13840:\tlearn: 3.0281985\ttotal: 5m\tremaining: 3m 19s\n",
      "13841:\tlearn: 3.0279949\ttotal: 5m\tremaining: 3m 19s\n",
      "13842:\tlearn: 3.0278784\ttotal: 5m\tremaining: 3m 19s\n",
      "13843:\tlearn: 3.0277855\ttotal: 5m\tremaining: 3m 19s\n",
      "13844:\tlearn: 3.0276640\ttotal: 5m\tremaining: 3m 18s\n",
      "13845:\tlearn: 3.0275601\ttotal: 5m\tremaining: 3m 18s\n",
      "13846:\tlearn: 3.0273937\ttotal: 5m\tremaining: 3m 18s\n",
      "13847:\tlearn: 3.0271880\ttotal: 5m\tremaining: 3m 18s\n",
      "13848:\tlearn: 3.0270731\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13849:\tlearn: 3.0269560\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13850:\tlearn: 3.0267340\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13851:\tlearn: 3.0265451\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13852:\tlearn: 3.0264192\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13853:\tlearn: 3.0262321\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13854:\tlearn: 3.0261005\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13855:\tlearn: 3.0259415\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13856:\tlearn: 3.0257811\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13857:\tlearn: 3.0255011\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13858:\tlearn: 3.0253814\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13859:\tlearn: 3.0252659\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13860:\tlearn: 3.0251363\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13861:\tlearn: 3.0250213\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13862:\tlearn: 3.0248985\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13863:\tlearn: 3.0247921\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13864:\tlearn: 3.0246498\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13865:\tlearn: 3.0243997\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13866:\tlearn: 3.0243156\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13867:\tlearn: 3.0242165\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13868:\tlearn: 3.0239867\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13869:\tlearn: 3.0238442\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13870:\tlearn: 3.0237318\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13871:\tlearn: 3.0235411\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13872:\tlearn: 3.0234051\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13873:\tlearn: 3.0233245\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13874:\tlearn: 3.0231010\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13875:\tlearn: 3.0229753\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13876:\tlearn: 3.0228143\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13877:\tlearn: 3.0226894\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13878:\tlearn: 3.0224823\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13879:\tlearn: 3.0224797\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13880:\tlearn: 3.0223497\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13881:\tlearn: 3.0222249\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13882:\tlearn: 3.0220321\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13883:\tlearn: 3.0219508\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13884:\tlearn: 3.0218379\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13885:\tlearn: 3.0216899\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13886:\tlearn: 3.0215070\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13887:\tlearn: 3.0213337\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13888:\tlearn: 3.0211492\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13889:\tlearn: 3.0209687\ttotal: 5m 1s\tremaining: 3m 18s\n",
      "13890:\tlearn: 3.0208925\ttotal: 5m 1s\tremaining: 3m 17s\n",
      "13891:\tlearn: 3.0207709\ttotal: 5m 1s\tremaining: 3m 17s\n",
      "13892:\tlearn: 3.0206307\ttotal: 5m 1s\tremaining: 3m 17s\n",
      "13893:\tlearn: 3.0205503\ttotal: 5m 1s\tremaining: 3m 17s\n",
      "13894:\tlearn: 3.0204009\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13895:\tlearn: 3.0202138\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13896:\tlearn: 3.0202089\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13897:\tlearn: 3.0200358\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13898:\tlearn: 3.0199240\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13899:\tlearn: 3.0198131\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13900:\tlearn: 3.0197003\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13901:\tlearn: 3.0195107\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13902:\tlearn: 3.0192373\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13903:\tlearn: 3.0191282\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13904:\tlearn: 3.0189797\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13905:\tlearn: 3.0187897\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13906:\tlearn: 3.0187422\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13907:\tlearn: 3.0185818\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13908:\tlearn: 3.0184228\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13909:\tlearn: 3.0182814\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13910:\tlearn: 3.0181346\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13911:\tlearn: 3.0179833\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13912:\tlearn: 3.0178987\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13913:\tlearn: 3.0178058\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13914:\tlearn: 3.0177232\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13915:\tlearn: 3.0176439\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13916:\tlearn: 3.0174607\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13917:\tlearn: 3.0172667\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13918:\tlearn: 3.0171664\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13919:\tlearn: 3.0169993\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13920:\tlearn: 3.0168657\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13921:\tlearn: 3.0166169\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13922:\tlearn: 3.0164029\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13923:\tlearn: 3.0162640\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13924:\tlearn: 3.0160898\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13925:\tlearn: 3.0159953\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13926:\tlearn: 3.0158688\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13927:\tlearn: 3.0158665\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13928:\tlearn: 3.0157241\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13929:\tlearn: 3.0156225\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13930:\tlearn: 3.0154644\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13931:\tlearn: 3.0153434\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13932:\tlearn: 3.0152739\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13933:\tlearn: 3.0151260\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13934:\tlearn: 3.0150633\ttotal: 5m 2s\tremaining: 3m 17s\n",
      "13935:\tlearn: 3.0149289\ttotal: 5m 2s\tremaining: 3m 16s\n",
      "13936:\tlearn: 3.0148301\ttotal: 5m 2s\tremaining: 3m 16s\n",
      "13937:\tlearn: 3.0147629\ttotal: 5m 2s\tremaining: 3m 16s\n",
      "13938:\tlearn: 3.0146266\ttotal: 5m 2s\tremaining: 3m 16s\n",
      "13939:\tlearn: 3.0144857\ttotal: 5m 2s\tremaining: 3m 16s\n",
      "13940:\tlearn: 3.0143277\ttotal: 5m 2s\tremaining: 3m 16s\n",
      "13941:\tlearn: 3.0141471\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13942:\tlearn: 3.0141345\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13943:\tlearn: 3.0140109\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13944:\tlearn: 3.0138755\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13945:\tlearn: 3.0137469\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13946:\tlearn: 3.0135901\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13947:\tlearn: 3.0135029\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13948:\tlearn: 3.0134380\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13949:\tlearn: 3.0133423\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13950:\tlearn: 3.0132623\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13951:\tlearn: 3.0131820\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13952:\tlearn: 3.0130601\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13953:\tlearn: 3.0129659\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13954:\tlearn: 3.0128466\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13955:\tlearn: 3.0127175\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13956:\tlearn: 3.0126021\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13957:\tlearn: 3.0125310\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13958:\tlearn: 3.0124822\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13959:\tlearn: 3.0124647\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13960:\tlearn: 3.0123564\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13961:\tlearn: 3.0122345\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13962:\tlearn: 3.0120202\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13963:\tlearn: 3.0118515\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13964:\tlearn: 3.0117190\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13965:\tlearn: 3.0116203\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13966:\tlearn: 3.0113584\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13967:\tlearn: 3.0112839\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13968:\tlearn: 3.0110221\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13969:\tlearn: 3.0108163\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13970:\tlearn: 3.0106912\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13971:\tlearn: 3.0105524\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13972:\tlearn: 3.0102422\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13973:\tlearn: 3.0102385\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13974:\tlearn: 3.0101412\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13975:\tlearn: 3.0100112\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13976:\tlearn: 3.0099184\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13977:\tlearn: 3.0097893\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13978:\tlearn: 3.0096413\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13979:\tlearn: 3.0094761\ttotal: 5m 3s\tremaining: 3m 16s\n",
      "13980:\tlearn: 3.0092933\ttotal: 5m 3s\tremaining: 3m 15s\n",
      "13981:\tlearn: 3.0090717\ttotal: 5m 3s\tremaining: 3m 15s\n",
      "13982:\tlearn: 3.0089516\ttotal: 5m 3s\tremaining: 3m 15s\n",
      "13983:\tlearn: 3.0088315\ttotal: 5m 3s\tremaining: 3m 15s\n",
      "13984:\tlearn: 3.0087340\ttotal: 5m 3s\tremaining: 3m 15s\n",
      "13985:\tlearn: 3.0085812\ttotal: 5m 3s\tremaining: 3m 15s\n",
      "13986:\tlearn: 3.0084201\ttotal: 5m 3s\tremaining: 3m 15s\n",
      "13987:\tlearn: 3.0082418\ttotal: 5m 3s\tremaining: 3m 15s\n",
      "13988:\tlearn: 3.0080676\ttotal: 5m 3s\tremaining: 3m 15s\n",
      "13989:\tlearn: 3.0078576\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13990:\tlearn: 3.0077439\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13991:\tlearn: 3.0075943\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13992:\tlearn: 3.0075127\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13993:\tlearn: 3.0073661\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13994:\tlearn: 3.0072179\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13995:\tlearn: 3.0070742\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13996:\tlearn: 3.0068215\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13997:\tlearn: 3.0067586\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13998:\tlearn: 3.0067456\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "13999:\tlearn: 3.0066064\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14000:\tlearn: 3.0064147\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14001:\tlearn: 3.0062381\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14002:\tlearn: 3.0061058\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14003:\tlearn: 3.0059783\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14004:\tlearn: 3.0058916\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14005:\tlearn: 3.0057800\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14006:\tlearn: 3.0056270\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14007:\tlearn: 3.0055163\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14008:\tlearn: 3.0053858\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14009:\tlearn: 3.0051688\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14010:\tlearn: 3.0051350\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14011:\tlearn: 3.0050422\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14012:\tlearn: 3.0048967\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14013:\tlearn: 3.0047681\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14014:\tlearn: 3.0046626\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14015:\tlearn: 3.0045056\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14016:\tlearn: 3.0042938\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14017:\tlearn: 3.0041641\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14018:\tlearn: 3.0040044\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14019:\tlearn: 3.0038968\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14020:\tlearn: 3.0037233\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14021:\tlearn: 3.0035912\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14022:\tlearn: 3.0034729\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14023:\tlearn: 3.0033586\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14024:\tlearn: 3.0032047\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14025:\tlearn: 3.0030729\ttotal: 5m 4s\tremaining: 3m 15s\n",
      "14026:\tlearn: 3.0028696\ttotal: 5m 4s\tremaining: 3m 14s\n",
      "14027:\tlearn: 3.0027884\ttotal: 5m 4s\tremaining: 3m 14s\n",
      "14028:\tlearn: 3.0026794\ttotal: 5m 4s\tremaining: 3m 14s\n",
      "14029:\tlearn: 3.0026518\ttotal: 5m 4s\tremaining: 3m 14s\n",
      "14030:\tlearn: 3.0025284\ttotal: 5m 4s\tremaining: 3m 14s\n",
      "14031:\tlearn: 3.0023902\ttotal: 5m 4s\tremaining: 3m 14s\n",
      "14032:\tlearn: 3.0022473\ttotal: 5m 4s\tremaining: 3m 14s\n",
      "14033:\tlearn: 3.0020832\ttotal: 5m 4s\tremaining: 3m 14s\n",
      "14034:\tlearn: 3.0019763\ttotal: 5m 4s\tremaining: 3m 14s\n",
      "14035:\tlearn: 3.0018598\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14036:\tlearn: 3.0017678\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14037:\tlearn: 3.0015929\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14038:\tlearn: 3.0014428\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14039:\tlearn: 3.0013729\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14040:\tlearn: 3.0011588\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14041:\tlearn: 3.0010906\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14042:\tlearn: 3.0009533\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14043:\tlearn: 3.0008656\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14044:\tlearn: 3.0006099\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14045:\tlearn: 3.0005016\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14046:\tlearn: 3.0004247\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14047:\tlearn: 3.0002755\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14048:\tlearn: 3.0001455\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14049:\tlearn: 3.0000035\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14050:\tlearn: 2.9998992\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14051:\tlearn: 2.9997814\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14052:\tlearn: 2.9995733\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14053:\tlearn: 2.9993899\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14054:\tlearn: 2.9991949\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14055:\tlearn: 2.9990462\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14056:\tlearn: 2.9988847\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14057:\tlearn: 2.9988188\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14058:\tlearn: 2.9987300\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14059:\tlearn: 2.9985771\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14060:\tlearn: 2.9984198\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14061:\tlearn: 2.9983401\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14062:\tlearn: 2.9982359\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14063:\tlearn: 2.9979928\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14064:\tlearn: 2.9978212\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14065:\tlearn: 2.9976821\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14066:\tlearn: 2.9975461\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14067:\tlearn: 2.9974887\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14068:\tlearn: 2.9974304\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14069:\tlearn: 2.9972775\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14070:\tlearn: 2.9971535\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14071:\tlearn: 2.9969011\ttotal: 5m 5s\tremaining: 3m 14s\n",
      "14072:\tlearn: 2.9968112\ttotal: 5m 5s\tremaining: 3m 13s\n",
      "14073:\tlearn: 2.9967213\ttotal: 5m 5s\tremaining: 3m 13s\n",
      "14074:\tlearn: 2.9965207\ttotal: 5m 5s\tremaining: 3m 13s\n",
      "14075:\tlearn: 2.9964029\ttotal: 5m 5s\tremaining: 3m 13s\n",
      "14076:\tlearn: 2.9962507\ttotal: 5m 5s\tremaining: 3m 13s\n",
      "14077:\tlearn: 2.9961463\ttotal: 5m 5s\tremaining: 3m 13s\n",
      "14078:\tlearn: 2.9960066\ttotal: 5m 5s\tremaining: 3m 13s\n",
      "14079:\tlearn: 2.9959117\ttotal: 5m 5s\tremaining: 3m 13s\n",
      "14080:\tlearn: 2.9957128\ttotal: 5m 5s\tremaining: 3m 13s\n",
      "14081:\tlearn: 2.9956125\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14082:\tlearn: 2.9955282\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14083:\tlearn: 2.9954273\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14084:\tlearn: 2.9953217\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14085:\tlearn: 2.9952510\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14086:\tlearn: 2.9951351\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14087:\tlearn: 2.9949388\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14088:\tlearn: 2.9948938\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14089:\tlearn: 2.9947351\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14090:\tlearn: 2.9946887\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14091:\tlearn: 2.9943945\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14092:\tlearn: 2.9942429\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14093:\tlearn: 2.9941238\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14094:\tlearn: 2.9939992\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14095:\tlearn: 2.9939209\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14096:\tlearn: 2.9937855\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14097:\tlearn: 2.9935670\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14098:\tlearn: 2.9934428\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14099:\tlearn: 2.9933420\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14100:\tlearn: 2.9932409\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14101:\tlearn: 2.9931099\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14102:\tlearn: 2.9930190\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14103:\tlearn: 2.9929088\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14104:\tlearn: 2.9928219\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14105:\tlearn: 2.9926118\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14106:\tlearn: 2.9925108\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14107:\tlearn: 2.9924433\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14108:\tlearn: 2.9923433\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14109:\tlearn: 2.9922691\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14110:\tlearn: 2.9921144\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14111:\tlearn: 2.9919232\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14112:\tlearn: 2.9917304\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14113:\tlearn: 2.9915937\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14114:\tlearn: 2.9913598\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14115:\tlearn: 2.9912108\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14116:\tlearn: 2.9910032\ttotal: 5m 6s\tremaining: 3m 13s\n",
      "14117:\tlearn: 2.9909179\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14118:\tlearn: 2.9908118\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14119:\tlearn: 2.9906573\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14120:\tlearn: 2.9905173\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14121:\tlearn: 2.9904012\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14122:\tlearn: 2.9902866\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14123:\tlearn: 2.9901386\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14124:\tlearn: 2.9900501\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14125:\tlearn: 2.9898426\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14126:\tlearn: 2.9897025\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14127:\tlearn: 2.9895187\ttotal: 5m 6s\tremaining: 3m 12s\n",
      "14128:\tlearn: 2.9893785\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14129:\tlearn: 2.9891952\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14130:\tlearn: 2.9890414\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14131:\tlearn: 2.9889457\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14132:\tlearn: 2.9889439\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14133:\tlearn: 2.9887949\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14134:\tlearn: 2.9885561\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14135:\tlearn: 2.9883809\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14136:\tlearn: 2.9882910\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14137:\tlearn: 2.9882349\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14138:\tlearn: 2.9880500\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14139:\tlearn: 2.9879044\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14140:\tlearn: 2.9876435\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14141:\tlearn: 2.9875512\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14142:\tlearn: 2.9874468\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14143:\tlearn: 2.9872856\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14144:\tlearn: 2.9871429\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14145:\tlearn: 2.9870311\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14146:\tlearn: 2.9868969\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14147:\tlearn: 2.9866343\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14148:\tlearn: 2.9864656\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14149:\tlearn: 2.9863750\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14150:\tlearn: 2.9861840\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14151:\tlearn: 2.9861405\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14152:\tlearn: 2.9859972\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14153:\tlearn: 2.9859006\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14154:\tlearn: 2.9858237\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14155:\tlearn: 2.9856472\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14156:\tlearn: 2.9854702\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14157:\tlearn: 2.9853219\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14158:\tlearn: 2.9852030\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14159:\tlearn: 2.9851055\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14160:\tlearn: 2.9849486\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14161:\tlearn: 2.9848154\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14162:\tlearn: 2.9847219\ttotal: 5m 7s\tremaining: 3m 12s\n",
      "14163:\tlearn: 2.9846255\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14164:\tlearn: 2.9844909\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14165:\tlearn: 2.9843577\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14166:\tlearn: 2.9842038\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14167:\tlearn: 2.9841526\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14168:\tlearn: 2.9840383\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14169:\tlearn: 2.9839399\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14170:\tlearn: 2.9838484\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14171:\tlearn: 2.9837242\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14172:\tlearn: 2.9835616\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14173:\tlearn: 2.9834164\ttotal: 5m 7s\tremaining: 3m 11s\n",
      "14174:\tlearn: 2.9832958\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14175:\tlearn: 2.9831911\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14176:\tlearn: 2.9829832\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14177:\tlearn: 2.9827353\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14178:\tlearn: 2.9826539\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14179:\tlearn: 2.9824463\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14180:\tlearn: 2.9822973\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14181:\tlearn: 2.9821392\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14182:\tlearn: 2.9820221\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14183:\tlearn: 2.9819840\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14184:\tlearn: 2.9818167\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14185:\tlearn: 2.9817033\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14186:\tlearn: 2.9816068\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14187:\tlearn: 2.9814510\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14188:\tlearn: 2.9813086\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14189:\tlearn: 2.9812186\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14190:\tlearn: 2.9810801\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14191:\tlearn: 2.9809790\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14192:\tlearn: 2.9808548\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14193:\tlearn: 2.9807665\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14194:\tlearn: 2.9806122\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14195:\tlearn: 2.9804926\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14196:\tlearn: 2.9804058\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14197:\tlearn: 2.9802667\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14198:\tlearn: 2.9802094\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14199:\tlearn: 2.9801472\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14200:\tlearn: 2.9800366\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14201:\tlearn: 2.9799027\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14202:\tlearn: 2.9797531\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14203:\tlearn: 2.9796054\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14204:\tlearn: 2.9794946\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14205:\tlearn: 2.9793472\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14206:\tlearn: 2.9792399\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14207:\tlearn: 2.9791103\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14208:\tlearn: 2.9789839\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14209:\tlearn: 2.9788622\ttotal: 5m 8s\tremaining: 3m 11s\n",
      "14210:\tlearn: 2.9787878\ttotal: 5m 8s\tremaining: 3m 10s\n",
      "14211:\tlearn: 2.9786523\ttotal: 5m 8s\tremaining: 3m 10s\n",
      "14212:\tlearn: 2.9785346\ttotal: 5m 8s\tremaining: 3m 10s\n",
      "14213:\tlearn: 2.9784730\ttotal: 5m 8s\tremaining: 3m 10s\n",
      "14214:\tlearn: 2.9781852\ttotal: 5m 8s\tremaining: 3m 10s\n",
      "14215:\tlearn: 2.9780711\ttotal: 5m 8s\tremaining: 3m 10s\n",
      "14216:\tlearn: 2.9780041\ttotal: 5m 8s\tremaining: 3m 10s\n",
      "14217:\tlearn: 2.9778699\ttotal: 5m 8s\tremaining: 3m 10s\n",
      "14218:\tlearn: 2.9777102\ttotal: 5m 8s\tremaining: 3m 10s\n",
      "14219:\tlearn: 2.9775406\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14220:\tlearn: 2.9774654\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14221:\tlearn: 2.9773015\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14222:\tlearn: 2.9771975\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14223:\tlearn: 2.9770396\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14224:\tlearn: 2.9768833\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14225:\tlearn: 2.9767923\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14226:\tlearn: 2.9765482\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14227:\tlearn: 2.9763767\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14228:\tlearn: 2.9762786\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14229:\tlearn: 2.9761420\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14230:\tlearn: 2.9758846\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14231:\tlearn: 2.9757240\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14232:\tlearn: 2.9756620\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14233:\tlearn: 2.9755519\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14234:\tlearn: 2.9754328\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14235:\tlearn: 2.9753121\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14236:\tlearn: 2.9751809\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14237:\tlearn: 2.9750669\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14238:\tlearn: 2.9749714\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14239:\tlearn: 2.9748511\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14240:\tlearn: 2.9747466\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14241:\tlearn: 2.9745968\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14242:\tlearn: 2.9745040\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14243:\tlearn: 2.9744117\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14244:\tlearn: 2.9742926\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14245:\tlearn: 2.9742300\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14246:\tlearn: 2.9741371\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14247:\tlearn: 2.9739730\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14248:\tlearn: 2.9737859\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14249:\tlearn: 2.9735860\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14250:\tlearn: 2.9733972\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14251:\tlearn: 2.9732801\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14252:\tlearn: 2.9730622\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14253:\tlearn: 2.9728739\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14254:\tlearn: 2.9726706\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14255:\tlearn: 2.9724807\ttotal: 5m 9s\tremaining: 3m 10s\n",
      "14256:\tlearn: 2.9723551\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14257:\tlearn: 2.9722508\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14258:\tlearn: 2.9720261\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14259:\tlearn: 2.9718733\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14260:\tlearn: 2.9718244\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14261:\tlearn: 2.9716982\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14262:\tlearn: 2.9716277\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14263:\tlearn: 2.9716127\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14264:\tlearn: 2.9714853\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14265:\tlearn: 2.9713384\ttotal: 5m 9s\tremaining: 3m 9s\n",
      "14266:\tlearn: 2.9712445\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14267:\tlearn: 2.9711009\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14268:\tlearn: 2.9709553\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14269:\tlearn: 2.9707582\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14270:\tlearn: 2.9706211\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14271:\tlearn: 2.9704335\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14272:\tlearn: 2.9703652\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14273:\tlearn: 2.9703153\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14274:\tlearn: 2.9701702\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14275:\tlearn: 2.9700793\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14276:\tlearn: 2.9699409\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14277:\tlearn: 2.9698077\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14278:\tlearn: 2.9697326\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14279:\tlearn: 2.9695839\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14280:\tlearn: 2.9694587\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14281:\tlearn: 2.9693240\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14282:\tlearn: 2.9692265\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14283:\tlearn: 2.9691464\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14284:\tlearn: 2.9690777\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14285:\tlearn: 2.9689097\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14286:\tlearn: 2.9688644\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14287:\tlearn: 2.9687615\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14288:\tlearn: 2.9686220\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14289:\tlearn: 2.9684751\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14290:\tlearn: 2.9683294\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14291:\tlearn: 2.9681889\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14292:\tlearn: 2.9679764\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14293:\tlearn: 2.9678459\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14294:\tlearn: 2.9676707\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14295:\tlearn: 2.9675973\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14296:\tlearn: 2.9674665\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14297:\tlearn: 2.9673496\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14298:\tlearn: 2.9672196\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14299:\tlearn: 2.9670626\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14300:\tlearn: 2.9669347\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14301:\tlearn: 2.9667095\ttotal: 5m 10s\tremaining: 3m 9s\n",
      "14302:\tlearn: 2.9665099\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14303:\tlearn: 2.9664407\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14304:\tlearn: 2.9663350\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14305:\tlearn: 2.9662402\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14306:\tlearn: 2.9662065\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14307:\tlearn: 2.9661006\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14308:\tlearn: 2.9660082\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14309:\tlearn: 2.9658765\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14310:\tlearn: 2.9656509\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14311:\tlearn: 2.9654979\ttotal: 5m 10s\tremaining: 3m 8s\n",
      "14312:\tlearn: 2.9653856\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14313:\tlearn: 2.9651416\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14314:\tlearn: 2.9651050\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14315:\tlearn: 2.9650104\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14316:\tlearn: 2.9648124\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14317:\tlearn: 2.9646577\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14318:\tlearn: 2.9645639\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14319:\tlearn: 2.9644135\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14320:\tlearn: 2.9643611\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14321:\tlearn: 2.9642580\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14322:\tlearn: 2.9641269\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14323:\tlearn: 2.9639306\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14324:\tlearn: 2.9637857\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14325:\tlearn: 2.9636270\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14326:\tlearn: 2.9635164\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14327:\tlearn: 2.9633919\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14328:\tlearn: 2.9632606\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14329:\tlearn: 2.9631060\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14330:\tlearn: 2.9630346\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14331:\tlearn: 2.9629513\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14332:\tlearn: 2.9628281\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14333:\tlearn: 2.9626177\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14334:\tlearn: 2.9624827\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14335:\tlearn: 2.9624245\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14336:\tlearn: 2.9621246\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14337:\tlearn: 2.9619691\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14338:\tlearn: 2.9617646\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14339:\tlearn: 2.9615889\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14340:\tlearn: 2.9614574\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14341:\tlearn: 2.9613170\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14342:\tlearn: 2.9612272\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14343:\tlearn: 2.9609832\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14344:\tlearn: 2.9608755\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14345:\tlearn: 2.9606852\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14346:\tlearn: 2.9605602\ttotal: 5m 11s\tremaining: 3m 8s\n",
      "14347:\tlearn: 2.9605587\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14348:\tlearn: 2.9604873\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14349:\tlearn: 2.9602853\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14350:\tlearn: 2.9601639\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14351:\tlearn: 2.9599989\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14352:\tlearn: 2.9599959\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14353:\tlearn: 2.9598824\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14354:\tlearn: 2.9598163\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14355:\tlearn: 2.9597291\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14356:\tlearn: 2.9596663\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14357:\tlearn: 2.9595139\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14358:\tlearn: 2.9593765\ttotal: 5m 11s\tremaining: 3m 7s\n",
      "14359:\tlearn: 2.9591534\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14360:\tlearn: 2.9590291\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14361:\tlearn: 2.9589884\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14362:\tlearn: 2.9587956\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14363:\tlearn: 2.9586822\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14364:\tlearn: 2.9585723\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14365:\tlearn: 2.9584401\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14366:\tlearn: 2.9582660\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14367:\tlearn: 2.9582222\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14368:\tlearn: 2.9581701\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14369:\tlearn: 2.9579758\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14370:\tlearn: 2.9578573\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14371:\tlearn: 2.9577058\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14372:\tlearn: 2.9575976\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14373:\tlearn: 2.9574734\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14374:\tlearn: 2.9572804\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14375:\tlearn: 2.9571715\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14376:\tlearn: 2.9570510\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14377:\tlearn: 2.9569196\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14378:\tlearn: 2.9567157\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14379:\tlearn: 2.9565826\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14380:\tlearn: 2.9563534\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14381:\tlearn: 2.9562027\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14382:\tlearn: 2.9560792\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14383:\tlearn: 2.9559822\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14384:\tlearn: 2.9558515\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14385:\tlearn: 2.9556991\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14386:\tlearn: 2.9555780\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14387:\tlearn: 2.9555367\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14388:\tlearn: 2.9554028\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14389:\tlearn: 2.9553043\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14390:\tlearn: 2.9550913\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14391:\tlearn: 2.9549135\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14392:\tlearn: 2.9547169\ttotal: 5m 12s\tremaining: 3m 7s\n",
      "14393:\tlearn: 2.9546103\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14394:\tlearn: 2.9544708\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14395:\tlearn: 2.9543329\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14396:\tlearn: 2.9542770\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14397:\tlearn: 2.9541976\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14398:\tlearn: 2.9540454\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14399:\tlearn: 2.9539265\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14400:\tlearn: 2.9537729\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14401:\tlearn: 2.9535396\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14402:\tlearn: 2.9534342\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14403:\tlearn: 2.9532455\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14404:\tlearn: 2.9531421\ttotal: 5m 12s\tremaining: 3m 6s\n",
      "14405:\tlearn: 2.9529959\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14406:\tlearn: 2.9528271\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14407:\tlearn: 2.9526960\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14408:\tlearn: 2.9525921\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14409:\tlearn: 2.9525228\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14410:\tlearn: 2.9523977\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14411:\tlearn: 2.9522791\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14412:\tlearn: 2.9521331\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14413:\tlearn: 2.9520388\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14414:\tlearn: 2.9520350\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14415:\tlearn: 2.9519016\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14416:\tlearn: 2.9517508\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14417:\tlearn: 2.9516150\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14418:\tlearn: 2.9515529\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14419:\tlearn: 2.9514603\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14420:\tlearn: 2.9513855\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14421:\tlearn: 2.9512057\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14422:\tlearn: 2.9511301\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14423:\tlearn: 2.9509312\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14424:\tlearn: 2.9507778\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14425:\tlearn: 2.9506544\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14426:\tlearn: 2.9505111\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14427:\tlearn: 2.9503665\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14428:\tlearn: 2.9502635\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14429:\tlearn: 2.9500980\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14430:\tlearn: 2.9500951\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14431:\tlearn: 2.9499299\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14432:\tlearn: 2.9497764\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14433:\tlearn: 2.9496257\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14434:\tlearn: 2.9494474\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14435:\tlearn: 2.9493045\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14436:\tlearn: 2.9491919\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14437:\tlearn: 2.9491067\ttotal: 5m 13s\tremaining: 3m 6s\n",
      "14438:\tlearn: 2.9489578\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14439:\tlearn: 2.9488377\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14440:\tlearn: 2.9487427\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14441:\tlearn: 2.9485822\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14442:\tlearn: 2.9484960\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14443:\tlearn: 2.9482374\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14444:\tlearn: 2.9481172\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14445:\tlearn: 2.9479956\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14446:\tlearn: 2.9479601\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14447:\tlearn: 2.9478786\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14448:\tlearn: 2.9478162\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14449:\tlearn: 2.9477070\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14450:\tlearn: 2.9476019\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14451:\tlearn: 2.9474744\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14452:\tlearn: 2.9473601\ttotal: 5m 13s\tremaining: 3m 5s\n",
      "14453:\tlearn: 2.9472869\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14454:\tlearn: 2.9472106\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14455:\tlearn: 2.9469586\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14456:\tlearn: 2.9467638\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14457:\tlearn: 2.9465984\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14458:\tlearn: 2.9464250\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14459:\tlearn: 2.9463368\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14460:\tlearn: 2.9461954\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14461:\tlearn: 2.9460807\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14462:\tlearn: 2.9460041\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14463:\tlearn: 2.9458677\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14464:\tlearn: 2.9457085\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14465:\tlearn: 2.9456248\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14466:\tlearn: 2.9455106\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14467:\tlearn: 2.9453760\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14468:\tlearn: 2.9452809\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14469:\tlearn: 2.9450720\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14470:\tlearn: 2.9449910\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14471:\tlearn: 2.9449114\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14472:\tlearn: 2.9447231\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14473:\tlearn: 2.9445968\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14474:\tlearn: 2.9444396\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14475:\tlearn: 2.9443519\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14476:\tlearn: 2.9441940\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14477:\tlearn: 2.9440611\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14478:\tlearn: 2.9439358\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14479:\tlearn: 2.9437953\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14480:\tlearn: 2.9437058\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14481:\tlearn: 2.9435580\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14482:\tlearn: 2.9434144\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14483:\tlearn: 2.9433412\ttotal: 5m 14s\tremaining: 3m 5s\n",
      "14484:\tlearn: 2.9432769\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14485:\tlearn: 2.9431917\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14486:\tlearn: 2.9430843\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14487:\tlearn: 2.9428872\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14488:\tlearn: 2.9427467\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14489:\tlearn: 2.9425768\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14490:\tlearn: 2.9423324\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14491:\tlearn: 2.9423292\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14492:\tlearn: 2.9422200\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14493:\tlearn: 2.9421669\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14494:\tlearn: 2.9420682\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14495:\tlearn: 2.9419665\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14496:\tlearn: 2.9418841\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14497:\tlearn: 2.9417292\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14498:\tlearn: 2.9415372\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14499:\tlearn: 2.9414646\ttotal: 5m 14s\tremaining: 3m 4s\n",
      "14500:\tlearn: 2.9413514\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14501:\tlearn: 2.9412878\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14502:\tlearn: 2.9410932\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14503:\tlearn: 2.9409629\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14504:\tlearn: 2.9408512\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14505:\tlearn: 2.9406708\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14506:\tlearn: 2.9404934\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14507:\tlearn: 2.9403848\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14508:\tlearn: 2.9401843\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14509:\tlearn: 2.9399949\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14510:\tlearn: 2.9398375\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14511:\tlearn: 2.9397709\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14512:\tlearn: 2.9396724\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14513:\tlearn: 2.9395857\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14514:\tlearn: 2.9395199\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14515:\tlearn: 2.9393943\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14516:\tlearn: 2.9392856\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14517:\tlearn: 2.9392097\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14518:\tlearn: 2.9391055\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14519:\tlearn: 2.9389730\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14520:\tlearn: 2.9388682\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14521:\tlearn: 2.9387285\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14522:\tlearn: 2.9386463\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14523:\tlearn: 2.9385050\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14524:\tlearn: 2.9384008\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14525:\tlearn: 2.9383155\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14526:\tlearn: 2.9381316\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14527:\tlearn: 2.9379383\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14528:\tlearn: 2.9377209\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14529:\tlearn: 2.9375979\ttotal: 5m 15s\tremaining: 3m 4s\n",
      "14530:\tlearn: 2.9375500\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14531:\tlearn: 2.9374369\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14532:\tlearn: 2.9372344\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14533:\tlearn: 2.9370820\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14534:\tlearn: 2.9369651\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14535:\tlearn: 2.9368790\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14536:\tlearn: 2.9367808\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14537:\tlearn: 2.9366150\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14538:\tlearn: 2.9364867\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14539:\tlearn: 2.9363179\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14540:\tlearn: 2.9361633\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14541:\tlearn: 2.9359736\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14542:\tlearn: 2.9358995\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14543:\tlearn: 2.9357524\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14544:\tlearn: 2.9355978\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14545:\tlearn: 2.9354849\ttotal: 5m 15s\tremaining: 3m 3s\n",
      "14546:\tlearn: 2.9353694\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14547:\tlearn: 2.9353650\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14548:\tlearn: 2.9352884\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14549:\tlearn: 2.9350880\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14550:\tlearn: 2.9349904\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14551:\tlearn: 2.9349158\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14552:\tlearn: 2.9348707\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14553:\tlearn: 2.9347332\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14554:\tlearn: 2.9345482\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14555:\tlearn: 2.9344022\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14556:\tlearn: 2.9342366\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14557:\tlearn: 2.9340991\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14558:\tlearn: 2.9339732\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14559:\tlearn: 2.9337518\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14560:\tlearn: 2.9336247\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14561:\tlearn: 2.9335494\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14562:\tlearn: 2.9334805\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14563:\tlearn: 2.9333370\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14564:\tlearn: 2.9332429\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14565:\tlearn: 2.9330487\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14566:\tlearn: 2.9329557\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14567:\tlearn: 2.9327530\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14568:\tlearn: 2.9326523\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14569:\tlearn: 2.9325265\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14570:\tlearn: 2.9323709\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14571:\tlearn: 2.9322108\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14572:\tlearn: 2.9320369\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14573:\tlearn: 2.9318460\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14574:\tlearn: 2.9317942\ttotal: 5m 16s\tremaining: 3m 3s\n",
      "14575:\tlearn: 2.9316090\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14576:\tlearn: 2.9314118\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14577:\tlearn: 2.9312391\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14578:\tlearn: 2.9309837\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14579:\tlearn: 2.9308485\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14580:\tlearn: 2.9308010\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14581:\tlearn: 2.9306916\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14582:\tlearn: 2.9305105\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14583:\tlearn: 2.9304357\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14584:\tlearn: 2.9303454\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14585:\tlearn: 2.9300995\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14586:\tlearn: 2.9299625\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14587:\tlearn: 2.9298434\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14588:\tlearn: 2.9296995\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14589:\tlearn: 2.9296591\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14590:\tlearn: 2.9295204\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14591:\tlearn: 2.9294080\ttotal: 5m 16s\tremaining: 3m 2s\n",
      "14592:\tlearn: 2.9292348\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14593:\tlearn: 2.9291273\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14594:\tlearn: 2.9289873\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14595:\tlearn: 2.9288793\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14596:\tlearn: 2.9288061\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14597:\tlearn: 2.9286873\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14598:\tlearn: 2.9285566\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14599:\tlearn: 2.9284197\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14600:\tlearn: 2.9283401\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14601:\tlearn: 2.9281738\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14602:\tlearn: 2.9280672\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14603:\tlearn: 2.9279179\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14604:\tlearn: 2.9277645\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14605:\tlearn: 2.9276525\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14606:\tlearn: 2.9275373\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14607:\tlearn: 2.9273131\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14608:\tlearn: 2.9271031\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14609:\tlearn: 2.9269204\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14610:\tlearn: 2.9268632\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14611:\tlearn: 2.9267228\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14612:\tlearn: 2.9266056\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14613:\tlearn: 2.9264600\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14614:\tlearn: 2.9263634\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14615:\tlearn: 2.9262064\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14616:\tlearn: 2.9260886\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14617:\tlearn: 2.9258973\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14618:\tlearn: 2.9257100\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14619:\tlearn: 2.9256018\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14620:\tlearn: 2.9253695\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14621:\tlearn: 2.9252391\ttotal: 5m 17s\tremaining: 3m 2s\n",
      "14622:\tlearn: 2.9251499\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14623:\tlearn: 2.9250691\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14624:\tlearn: 2.9249959\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14625:\tlearn: 2.9248480\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14626:\tlearn: 2.9247558\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14627:\tlearn: 2.9246782\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14628:\tlearn: 2.9246078\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14629:\tlearn: 2.9244214\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14630:\tlearn: 2.9243060\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14631:\tlearn: 2.9242676\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14632:\tlearn: 2.9241641\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14633:\tlearn: 2.9241584\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14634:\tlearn: 2.9239836\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14635:\tlearn: 2.9237832\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14636:\tlearn: 2.9237434\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14637:\tlearn: 2.9235729\ttotal: 5m 17s\tremaining: 3m 1s\n",
      "14638:\tlearn: 2.9234397\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14639:\tlearn: 2.9233882\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14640:\tlearn: 2.9232726\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14641:\tlearn: 2.9231094\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14642:\tlearn: 2.9229856\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14643:\tlearn: 2.9228925\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14644:\tlearn: 2.9227720\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14645:\tlearn: 2.9226920\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14646:\tlearn: 2.9225538\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14647:\tlearn: 2.9224636\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14648:\tlearn: 2.9222908\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14649:\tlearn: 2.9222236\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14650:\tlearn: 2.9220748\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14651:\tlearn: 2.9219858\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14652:\tlearn: 2.9218156\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14653:\tlearn: 2.9217216\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14654:\tlearn: 2.9216139\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14655:\tlearn: 2.9215674\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14656:\tlearn: 2.9214412\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14657:\tlearn: 2.9213126\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14658:\tlearn: 2.9212200\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14659:\tlearn: 2.9210166\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14660:\tlearn: 2.9209588\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14661:\tlearn: 2.9208663\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14662:\tlearn: 2.9207512\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14663:\tlearn: 2.9206485\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14664:\tlearn: 2.9205500\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14665:\tlearn: 2.9204140\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14666:\tlearn: 2.9202382\ttotal: 5m 18s\tremaining: 3m 1s\n",
      "14667:\tlearn: 2.9201030\ttotal: 5m 18s\tremaining: 3m\n",
      "14668:\tlearn: 2.9198810\ttotal: 5m 18s\tremaining: 3m\n",
      "14669:\tlearn: 2.9197788\ttotal: 5m 18s\tremaining: 3m\n",
      "14670:\tlearn: 2.9197019\ttotal: 5m 18s\tremaining: 3m\n",
      "14671:\tlearn: 2.9195674\ttotal: 5m 18s\tremaining: 3m\n",
      "14672:\tlearn: 2.9193821\ttotal: 5m 18s\tremaining: 3m\n",
      "14673:\tlearn: 2.9191988\ttotal: 5m 18s\tremaining: 3m\n",
      "14674:\tlearn: 2.9191109\ttotal: 5m 18s\tremaining: 3m\n",
      "14675:\tlearn: 2.9189631\ttotal: 5m 18s\tremaining: 3m\n",
      "14676:\tlearn: 2.9188792\ttotal: 5m 18s\tremaining: 3m\n",
      "14677:\tlearn: 2.9187328\ttotal: 5m 18s\tremaining: 3m\n",
      "14678:\tlearn: 2.9186872\ttotal: 5m 18s\tremaining: 3m\n",
      "14679:\tlearn: 2.9185596\ttotal: 5m 18s\tremaining: 3m\n",
      "14680:\tlearn: 2.9184041\ttotal: 5m 18s\tremaining: 3m\n",
      "14681:\tlearn: 2.9183171\ttotal: 5m 18s\tremaining: 3m\n",
      "14682:\tlearn: 2.9181540\ttotal: 5m 18s\tremaining: 3m\n",
      "14683:\tlearn: 2.9180064\ttotal: 5m 18s\tremaining: 3m\n",
      "14684:\tlearn: 2.9178679\ttotal: 5m 19s\tremaining: 3m\n",
      "14685:\tlearn: 2.9177014\ttotal: 5m 19s\tremaining: 3m\n",
      "14686:\tlearn: 2.9175721\ttotal: 5m 19s\tremaining: 3m\n",
      "14687:\tlearn: 2.9174754\ttotal: 5m 19s\tremaining: 3m\n",
      "14688:\tlearn: 2.9174710\ttotal: 5m 19s\tremaining: 3m\n",
      "14689:\tlearn: 2.9173652\ttotal: 5m 19s\tremaining: 3m\n",
      "14690:\tlearn: 2.9172740\ttotal: 5m 19s\tremaining: 3m\n",
      "14691:\tlearn: 2.9172255\ttotal: 5m 19s\tremaining: 3m\n",
      "14692:\tlearn: 2.9171364\ttotal: 5m 19s\tremaining: 3m\n",
      "14693:\tlearn: 2.9170211\ttotal: 5m 19s\tremaining: 3m\n",
      "14694:\tlearn: 2.9169243\ttotal: 5m 19s\tremaining: 3m\n",
      "14695:\tlearn: 2.9167728\ttotal: 5m 19s\tremaining: 3m\n",
      "14696:\tlearn: 2.9165983\ttotal: 5m 19s\tremaining: 3m\n",
      "14697:\tlearn: 2.9164641\ttotal: 5m 19s\tremaining: 3m\n",
      "14698:\tlearn: 2.9163486\ttotal: 5m 19s\tremaining: 3m\n",
      "14699:\tlearn: 2.9162589\ttotal: 5m 19s\tremaining: 3m\n",
      "14700:\tlearn: 2.9161018\ttotal: 5m 19s\tremaining: 3m\n",
      "14701:\tlearn: 2.9159471\ttotal: 5m 19s\tremaining: 3m\n",
      "14702:\tlearn: 2.9158805\ttotal: 5m 19s\tremaining: 3m\n",
      "14703:\tlearn: 2.9156700\ttotal: 5m 19s\tremaining: 3m\n",
      "14704:\tlearn: 2.9155835\ttotal: 5m 19s\tremaining: 3m\n",
      "14705:\tlearn: 2.9154178\ttotal: 5m 19s\tremaining: 3m\n",
      "14706:\tlearn: 2.9153597\ttotal: 5m 19s\tremaining: 3m\n",
      "14707:\tlearn: 2.9152758\ttotal: 5m 19s\tremaining: 3m\n",
      "14708:\tlearn: 2.9151326\ttotal: 5m 19s\tremaining: 3m\n",
      "14709:\tlearn: 2.9150619\ttotal: 5m 19s\tremaining: 3m\n",
      "14710:\tlearn: 2.9149227\ttotal: 5m 19s\tremaining: 3m\n",
      "14711:\tlearn: 2.9147807\ttotal: 5m 19s\tremaining: 3m\n",
      "14712:\tlearn: 2.9145879\ttotal: 5m 19s\tremaining: 3m\n",
      "14713:\tlearn: 2.9144424\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14714:\tlearn: 2.9143115\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14715:\tlearn: 2.9142290\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14716:\tlearn: 2.9141455\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14717:\tlearn: 2.9140345\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14718:\tlearn: 2.9139204\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14719:\tlearn: 2.9139174\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14720:\tlearn: 2.9138301\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14721:\tlearn: 2.9136838\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14722:\tlearn: 2.9135848\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14723:\tlearn: 2.9134322\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14724:\tlearn: 2.9132633\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14725:\tlearn: 2.9130920\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14726:\tlearn: 2.9129520\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14727:\tlearn: 2.9128683\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14728:\tlearn: 2.9127767\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14729:\tlearn: 2.9126527\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14730:\tlearn: 2.9125103\ttotal: 5m 19s\tremaining: 2m 59s\n",
      "14731:\tlearn: 2.9124441\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14732:\tlearn: 2.9123141\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14733:\tlearn: 2.9122265\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14734:\tlearn: 2.9120624\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14735:\tlearn: 2.9118494\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14736:\tlearn: 2.9117419\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14737:\tlearn: 2.9116084\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14738:\tlearn: 2.9115298\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14739:\tlearn: 2.9114203\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14740:\tlearn: 2.9113300\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14741:\tlearn: 2.9111898\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14742:\tlearn: 2.9110389\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14743:\tlearn: 2.9108378\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14744:\tlearn: 2.9107649\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14745:\tlearn: 2.9105961\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14746:\tlearn: 2.9104855\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14747:\tlearn: 2.9103093\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14748:\tlearn: 2.9101084\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14749:\tlearn: 2.9099237\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14750:\tlearn: 2.9098488\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14751:\tlearn: 2.9097750\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14752:\tlearn: 2.9096698\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14753:\tlearn: 2.9095318\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14754:\tlearn: 2.9093684\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14755:\tlearn: 2.9091705\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14756:\tlearn: 2.9089633\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14757:\tlearn: 2.9087861\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14758:\tlearn: 2.9086991\ttotal: 5m 20s\tremaining: 2m 59s\n",
      "14759:\tlearn: 2.9086511\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14760:\tlearn: 2.9085784\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14761:\tlearn: 2.9084324\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14762:\tlearn: 2.9082474\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14763:\tlearn: 2.9081148\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14764:\tlearn: 2.9078598\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14765:\tlearn: 2.9078441\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14766:\tlearn: 2.9077136\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14767:\tlearn: 2.9076208\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14768:\tlearn: 2.9075837\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14769:\tlearn: 2.9074818\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14770:\tlearn: 2.9073153\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14771:\tlearn: 2.9071808\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14772:\tlearn: 2.9070123\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14773:\tlearn: 2.9068261\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14774:\tlearn: 2.9066939\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14775:\tlearn: 2.9065779\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14776:\tlearn: 2.9063689\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14777:\tlearn: 2.9062894\ttotal: 5m 20s\tremaining: 2m 58s\n",
      "14778:\tlearn: 2.9061904\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14779:\tlearn: 2.9061064\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14780:\tlearn: 2.9059364\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14781:\tlearn: 2.9057887\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14782:\tlearn: 2.9055994\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14783:\tlearn: 2.9054286\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14784:\tlearn: 2.9052593\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14785:\tlearn: 2.9051426\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14786:\tlearn: 2.9049992\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14787:\tlearn: 2.9049108\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14788:\tlearn: 2.9046609\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14789:\tlearn: 2.9045225\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14790:\tlearn: 2.9044336\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14791:\tlearn: 2.9043183\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14792:\tlearn: 2.9041530\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14793:\tlearn: 2.9040247\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14794:\tlearn: 2.9039310\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14795:\tlearn: 2.9037048\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14796:\tlearn: 2.9035647\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14797:\tlearn: 2.9033961\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14798:\tlearn: 2.9032678\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14799:\tlearn: 2.9031070\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14800:\tlearn: 2.9030319\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14801:\tlearn: 2.9029619\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14802:\tlearn: 2.9029125\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14803:\tlearn: 2.9028105\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14804:\tlearn: 2.9026620\ttotal: 5m 21s\tremaining: 2m 58s\n",
      "14805:\tlearn: 2.9026087\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14806:\tlearn: 2.9025375\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14807:\tlearn: 2.9024184\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14808:\tlearn: 2.9022422\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14809:\tlearn: 2.9020755\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14810:\tlearn: 2.9019771\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14811:\tlearn: 2.9018491\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14812:\tlearn: 2.9015811\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14813:\tlearn: 2.9014419\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14814:\tlearn: 2.9013247\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14815:\tlearn: 2.9010970\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14816:\tlearn: 2.9010930\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14817:\tlearn: 2.9009510\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14818:\tlearn: 2.9009480\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14819:\tlearn: 2.9008485\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14820:\tlearn: 2.9007874\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14821:\tlearn: 2.9006157\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14822:\tlearn: 2.9004596\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14823:\tlearn: 2.9003233\ttotal: 5m 21s\tremaining: 2m 57s\n",
      "14824:\tlearn: 2.9001740\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14825:\tlearn: 2.9000369\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14826:\tlearn: 2.8998299\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14827:\tlearn: 2.8997194\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14828:\tlearn: 2.8995487\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14829:\tlearn: 2.8994165\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14830:\tlearn: 2.8993260\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14831:\tlearn: 2.8991613\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14832:\tlearn: 2.8991163\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14833:\tlearn: 2.8989775\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14834:\tlearn: 2.8988585\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14835:\tlearn: 2.8987423\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14836:\tlearn: 2.8986543\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14837:\tlearn: 2.8985516\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14838:\tlearn: 2.8984696\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14839:\tlearn: 2.8983113\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14840:\tlearn: 2.8982184\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14841:\tlearn: 2.8980444\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14842:\tlearn: 2.8979268\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14843:\tlearn: 2.8979239\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14844:\tlearn: 2.8977506\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14845:\tlearn: 2.8976515\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14846:\tlearn: 2.8974659\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14847:\tlearn: 2.8973840\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14848:\tlearn: 2.8972130\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14849:\tlearn: 2.8970407\ttotal: 5m 22s\tremaining: 2m 57s\n",
      "14850:\tlearn: 2.8969105\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14851:\tlearn: 2.8967577\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14852:\tlearn: 2.8965930\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14853:\tlearn: 2.8964597\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14854:\tlearn: 2.8963581\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14855:\tlearn: 2.8962631\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14856:\tlearn: 2.8961133\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14857:\tlearn: 2.8960099\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14858:\tlearn: 2.8958905\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14859:\tlearn: 2.8957067\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14860:\tlearn: 2.8955902\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14861:\tlearn: 2.8954756\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14862:\tlearn: 2.8953612\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14863:\tlearn: 2.8952468\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14864:\tlearn: 2.8951115\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14865:\tlearn: 2.8949721\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14866:\tlearn: 2.8948214\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14867:\tlearn: 2.8946802\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14868:\tlearn: 2.8945732\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14869:\tlearn: 2.8944576\ttotal: 5m 22s\tremaining: 2m 56s\n",
      "14870:\tlearn: 2.8942958\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14871:\tlearn: 2.8941868\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14872:\tlearn: 2.8940978\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14873:\tlearn: 2.8939205\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14874:\tlearn: 2.8938097\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14875:\tlearn: 2.8937545\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14876:\tlearn: 2.8936002\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14877:\tlearn: 2.8934374\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14878:\tlearn: 2.8932973\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14879:\tlearn: 2.8931379\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14880:\tlearn: 2.8929866\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14881:\tlearn: 2.8929241\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14882:\tlearn: 2.8926847\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14883:\tlearn: 2.8925176\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14884:\tlearn: 2.8923685\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14885:\tlearn: 2.8921953\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14886:\tlearn: 2.8921413\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14887:\tlearn: 2.8918852\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14888:\tlearn: 2.8916871\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14889:\tlearn: 2.8915891\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14890:\tlearn: 2.8915087\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14891:\tlearn: 2.8913497\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14892:\tlearn: 2.8912339\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14893:\tlearn: 2.8911747\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14894:\tlearn: 2.8910610\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14895:\tlearn: 2.8909231\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14896:\tlearn: 2.8908068\ttotal: 5m 23s\tremaining: 2m 56s\n",
      "14897:\tlearn: 2.8905572\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14898:\tlearn: 2.8904499\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14899:\tlearn: 2.8903457\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14900:\tlearn: 2.8902429\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14901:\tlearn: 2.8901507\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14902:\tlearn: 2.8899905\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14903:\tlearn: 2.8899880\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14904:\tlearn: 2.8898321\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14905:\tlearn: 2.8897134\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14906:\tlearn: 2.8896180\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14907:\tlearn: 2.8894266\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14908:\tlearn: 2.8892832\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14909:\tlearn: 2.8891380\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14910:\tlearn: 2.8889515\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14911:\tlearn: 2.8888206\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14912:\tlearn: 2.8887357\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14913:\tlearn: 2.8886288\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14914:\tlearn: 2.8885035\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14915:\tlearn: 2.8883464\ttotal: 5m 23s\tremaining: 2m 55s\n",
      "14916:\tlearn: 2.8881647\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14917:\tlearn: 2.8880769\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14918:\tlearn: 2.8880135\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14919:\tlearn: 2.8879144\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14920:\tlearn: 2.8877405\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14921:\tlearn: 2.8876212\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14922:\tlearn: 2.8875138\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14923:\tlearn: 2.8874366\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14924:\tlearn: 2.8873352\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14925:\tlearn: 2.8871713\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14926:\tlearn: 2.8869876\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14927:\tlearn: 2.8868398\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14928:\tlearn: 2.8867250\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14929:\tlearn: 2.8865425\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14930:\tlearn: 2.8864839\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14931:\tlearn: 2.8863759\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14932:\tlearn: 2.8863028\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14933:\tlearn: 2.8861762\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14934:\tlearn: 2.8860748\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14935:\tlearn: 2.8859284\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14936:\tlearn: 2.8857682\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14937:\tlearn: 2.8856931\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14938:\tlearn: 2.8854871\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14939:\tlearn: 2.8853672\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14940:\tlearn: 2.8852060\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14941:\tlearn: 2.8850765\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14942:\tlearn: 2.8849632\ttotal: 5m 24s\tremaining: 2m 55s\n",
      "14943:\tlearn: 2.8848284\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14944:\tlearn: 2.8846962\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14945:\tlearn: 2.8845122\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14946:\tlearn: 2.8843793\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14947:\tlearn: 2.8842761\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14948:\tlearn: 2.8841051\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14949:\tlearn: 2.8840463\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14950:\tlearn: 2.8839962\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14951:\tlearn: 2.8838720\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14952:\tlearn: 2.8836839\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14953:\tlearn: 2.8835742\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14954:\tlearn: 2.8835626\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14955:\tlearn: 2.8834253\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14956:\tlearn: 2.8832890\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14957:\tlearn: 2.8832459\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14958:\tlearn: 2.8830165\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14959:\tlearn: 2.8828850\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14960:\tlearn: 2.8827938\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14961:\tlearn: 2.8827125\ttotal: 5m 24s\tremaining: 2m 54s\n",
      "14962:\tlearn: 2.8826142\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14963:\tlearn: 2.8825745\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14964:\tlearn: 2.8824710\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14965:\tlearn: 2.8822578\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14966:\tlearn: 2.8821199\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14967:\tlearn: 2.8820213\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14968:\tlearn: 2.8819530\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14969:\tlearn: 2.8818524\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14970:\tlearn: 2.8817235\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14971:\tlearn: 2.8815972\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14972:\tlearn: 2.8814585\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14973:\tlearn: 2.8813293\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14974:\tlearn: 2.8812101\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14975:\tlearn: 2.8810488\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14976:\tlearn: 2.8809360\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14977:\tlearn: 2.8808062\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14978:\tlearn: 2.8807306\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14979:\tlearn: 2.8805534\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14980:\tlearn: 2.8803780\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14981:\tlearn: 2.8802107\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14982:\tlearn: 2.8801534\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14983:\tlearn: 2.8800619\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14984:\tlearn: 2.8799558\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14985:\tlearn: 2.8797099\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14986:\tlearn: 2.8794711\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14987:\tlearn: 2.8793482\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14988:\tlearn: 2.8792368\ttotal: 5m 25s\tremaining: 2m 54s\n",
      "14989:\tlearn: 2.8790651\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14990:\tlearn: 2.8789673\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14991:\tlearn: 2.8788539\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14992:\tlearn: 2.8787561\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14993:\tlearn: 2.8786145\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14994:\tlearn: 2.8786009\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14995:\tlearn: 2.8784504\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14996:\tlearn: 2.8784227\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14997:\tlearn: 2.8782826\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14998:\tlearn: 2.8781970\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "14999:\tlearn: 2.8781293\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15000:\tlearn: 2.8779618\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15001:\tlearn: 2.8778129\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15002:\tlearn: 2.8777527\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15003:\tlearn: 2.8775953\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15004:\tlearn: 2.8775065\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15005:\tlearn: 2.8774710\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15006:\tlearn: 2.8773638\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15007:\tlearn: 2.8772348\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15008:\tlearn: 2.8770749\ttotal: 5m 25s\tremaining: 2m 53s\n",
      "15009:\tlearn: 2.8769597\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15010:\tlearn: 2.8768732\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15011:\tlearn: 2.8766626\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15012:\tlearn: 2.8765317\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15013:\tlearn: 2.8763795\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15014:\tlearn: 2.8761442\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15015:\tlearn: 2.8760084\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15016:\tlearn: 2.8758031\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15017:\tlearn: 2.8756343\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15018:\tlearn: 2.8754771\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15019:\tlearn: 2.8754273\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15020:\tlearn: 2.8752948\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15021:\tlearn: 2.8750940\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15022:\tlearn: 2.8749069\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15023:\tlearn: 2.8747982\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15024:\tlearn: 2.8746714\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15025:\tlearn: 2.8745824\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15026:\tlearn: 2.8743794\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15027:\tlearn: 2.8743166\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15028:\tlearn: 2.8741665\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15029:\tlearn: 2.8739892\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15030:\tlearn: 2.8739200\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15031:\tlearn: 2.8737816\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15032:\tlearn: 2.8737142\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15033:\tlearn: 2.8736121\ttotal: 5m 26s\tremaining: 2m 53s\n",
      "15034:\tlearn: 2.8734549\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15035:\tlearn: 2.8732973\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15036:\tlearn: 2.8731472\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15037:\tlearn: 2.8730231\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15038:\tlearn: 2.8729777\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15039:\tlearn: 2.8728241\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15040:\tlearn: 2.8726404\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15041:\tlearn: 2.8724660\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15042:\tlearn: 2.8724098\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15043:\tlearn: 2.8722340\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15044:\tlearn: 2.8721287\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15045:\tlearn: 2.8719778\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15046:\tlearn: 2.8719176\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15047:\tlearn: 2.8718004\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15048:\tlearn: 2.8717697\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15049:\tlearn: 2.8715939\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15050:\tlearn: 2.8713975\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15051:\tlearn: 2.8713115\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15052:\tlearn: 2.8712169\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15053:\tlearn: 2.8711229\ttotal: 5m 26s\tremaining: 2m 52s\n",
      "15054:\tlearn: 2.8709940\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15055:\tlearn: 2.8709039\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15056:\tlearn: 2.8708113\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15057:\tlearn: 2.8707298\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15058:\tlearn: 2.8706318\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15059:\tlearn: 2.8705161\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15060:\tlearn: 2.8704343\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15061:\tlearn: 2.8703411\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15062:\tlearn: 2.8702345\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15063:\tlearn: 2.8701797\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15064:\tlearn: 2.8700516\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15065:\tlearn: 2.8699756\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15066:\tlearn: 2.8697857\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15067:\tlearn: 2.8696994\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15068:\tlearn: 2.8695061\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15069:\tlearn: 2.8693373\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15070:\tlearn: 2.8691780\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15071:\tlearn: 2.8689914\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15072:\tlearn: 2.8689377\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15073:\tlearn: 2.8687858\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15074:\tlearn: 2.8686341\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15075:\tlearn: 2.8684144\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15076:\tlearn: 2.8684084\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15077:\tlearn: 2.8682728\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15078:\tlearn: 2.8682010\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15079:\tlearn: 2.8680336\ttotal: 5m 27s\tremaining: 2m 52s\n",
      "15080:\tlearn: 2.8679439\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15081:\tlearn: 2.8677950\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15082:\tlearn: 2.8676517\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15083:\tlearn: 2.8675952\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15084:\tlearn: 2.8674143\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15085:\tlearn: 2.8673009\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15086:\tlearn: 2.8671978\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15087:\tlearn: 2.8670761\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15088:\tlearn: 2.8670276\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15089:\tlearn: 2.8668942\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15090:\tlearn: 2.8668908\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15091:\tlearn: 2.8667417\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15092:\tlearn: 2.8666368\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15093:\tlearn: 2.8665283\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15094:\tlearn: 2.8663752\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15095:\tlearn: 2.8662711\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15096:\tlearn: 2.8661266\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15097:\tlearn: 2.8660727\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15098:\tlearn: 2.8659908\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15099:\tlearn: 2.8658722\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15100:\tlearn: 2.8658173\ttotal: 5m 27s\tremaining: 2m 51s\n",
      "15101:\tlearn: 2.8657276\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15102:\tlearn: 2.8656590\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15103:\tlearn: 2.8655293\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15104:\tlearn: 2.8654128\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15105:\tlearn: 2.8652783\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15106:\tlearn: 2.8651320\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15107:\tlearn: 2.8650659\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15108:\tlearn: 2.8649717\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15109:\tlearn: 2.8648958\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15110:\tlearn: 2.8648118\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15111:\tlearn: 2.8647213\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15112:\tlearn: 2.8646425\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15113:\tlearn: 2.8644430\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15114:\tlearn: 2.8642565\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15115:\tlearn: 2.8640510\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15116:\tlearn: 2.8639602\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15117:\tlearn: 2.8638852\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15118:\tlearn: 2.8637514\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15119:\tlearn: 2.8635424\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15120:\tlearn: 2.8634158\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15121:\tlearn: 2.8632213\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15122:\tlearn: 2.8631378\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15123:\tlearn: 2.8631343\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15124:\tlearn: 2.8629650\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15125:\tlearn: 2.8628398\ttotal: 5m 28s\tremaining: 2m 51s\n",
      "15126:\tlearn: 2.8626951\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15127:\tlearn: 2.8625724\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15128:\tlearn: 2.8624224\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15129:\tlearn: 2.8623764\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15130:\tlearn: 2.8622501\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15131:\tlearn: 2.8621891\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15132:\tlearn: 2.8620413\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15133:\tlearn: 2.8618955\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15134:\tlearn: 2.8617920\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15135:\tlearn: 2.8616531\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15136:\tlearn: 2.8615149\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15137:\tlearn: 2.8614022\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15138:\tlearn: 2.8612250\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15139:\tlearn: 2.8610619\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15140:\tlearn: 2.8610367\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15141:\tlearn: 2.8609297\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15142:\tlearn: 2.8607839\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15143:\tlearn: 2.8606558\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15144:\tlearn: 2.8606235\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15145:\tlearn: 2.8605124\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15146:\tlearn: 2.8604457\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15147:\tlearn: 2.8603221\ttotal: 5m 28s\tremaining: 2m 50s\n",
      "15148:\tlearn: 2.8602025\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15149:\tlearn: 2.8601212\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15150:\tlearn: 2.8600388\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15151:\tlearn: 2.8598781\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15152:\tlearn: 2.8597405\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15153:\tlearn: 2.8596417\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15154:\tlearn: 2.8595262\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15155:\tlearn: 2.8593862\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15156:\tlearn: 2.8593241\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15157:\tlearn: 2.8591381\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15158:\tlearn: 2.8590130\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15159:\tlearn: 2.8588704\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15160:\tlearn: 2.8588361\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15161:\tlearn: 2.8586789\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15162:\tlearn: 2.8585349\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15163:\tlearn: 2.8584614\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15164:\tlearn: 2.8583508\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15165:\tlearn: 2.8582351\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15166:\tlearn: 2.8581299\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15167:\tlearn: 2.8580677\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15168:\tlearn: 2.8579689\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15169:\tlearn: 2.8577332\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15170:\tlearn: 2.8575994\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15171:\tlearn: 2.8574631\ttotal: 5m 29s\tremaining: 2m 50s\n",
      "15172:\tlearn: 2.8573015\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15173:\tlearn: 2.8571620\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15174:\tlearn: 2.8570856\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15175:\tlearn: 2.8569966\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15176:\tlearn: 2.8568735\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15177:\tlearn: 2.8568198\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15178:\tlearn: 2.8566414\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15179:\tlearn: 2.8565714\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15180:\tlearn: 2.8563559\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15181:\tlearn: 2.8562708\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15182:\tlearn: 2.8561499\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15183:\tlearn: 2.8560002\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15184:\tlearn: 2.8559007\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15185:\tlearn: 2.8556880\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15186:\tlearn: 2.8554584\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15187:\tlearn: 2.8553030\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15188:\tlearn: 2.8551767\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15189:\tlearn: 2.8550548\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15190:\tlearn: 2.8549524\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15191:\tlearn: 2.8548909\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15192:\tlearn: 2.8547097\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15193:\tlearn: 2.8545411\ttotal: 5m 29s\tremaining: 2m 49s\n",
      "15194:\tlearn: 2.8544379\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15195:\tlearn: 2.8542659\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15196:\tlearn: 2.8541244\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15197:\tlearn: 2.8539302\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15198:\tlearn: 2.8538325\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15199:\tlearn: 2.8536654\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15200:\tlearn: 2.8535673\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15201:\tlearn: 2.8534828\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15202:\tlearn: 2.8533758\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15203:\tlearn: 2.8533737\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15204:\tlearn: 2.8532531\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15205:\tlearn: 2.8531809\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15206:\tlearn: 2.8531279\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15207:\tlearn: 2.8529855\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15208:\tlearn: 2.8528507\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15209:\tlearn: 2.8527242\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15210:\tlearn: 2.8526525\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15211:\tlearn: 2.8524101\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15212:\tlearn: 2.8522967\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15213:\tlearn: 2.8520946\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15214:\tlearn: 2.8519474\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15215:\tlearn: 2.8517860\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15216:\tlearn: 2.8516538\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15217:\tlearn: 2.8515363\ttotal: 5m 30s\tremaining: 2m 49s\n",
      "15218:\tlearn: 2.8514868\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15219:\tlearn: 2.8513460\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15220:\tlearn: 2.8512636\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15221:\tlearn: 2.8510634\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15222:\tlearn: 2.8509272\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15223:\tlearn: 2.8507469\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15224:\tlearn: 2.8506388\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15225:\tlearn: 2.8504489\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15226:\tlearn: 2.8503406\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15227:\tlearn: 2.8502219\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15228:\tlearn: 2.8501325\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15229:\tlearn: 2.8500122\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15230:\tlearn: 2.8499180\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15231:\tlearn: 2.8497323\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15232:\tlearn: 2.8495603\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15233:\tlearn: 2.8493716\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15234:\tlearn: 2.8492645\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15235:\tlearn: 2.8490665\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15236:\tlearn: 2.8489543\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15237:\tlearn: 2.8488991\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15238:\tlearn: 2.8487704\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15239:\tlearn: 2.8486670\ttotal: 5m 30s\tremaining: 2m 48s\n",
      "15240:\tlearn: 2.8486436\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15241:\tlearn: 2.8485239\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15242:\tlearn: 2.8483798\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15243:\tlearn: 2.8482818\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15244:\tlearn: 2.8481164\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15245:\tlearn: 2.8480505\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15246:\tlearn: 2.8479217\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15247:\tlearn: 2.8478463\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15248:\tlearn: 2.8477268\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15249:\tlearn: 2.8475869\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15250:\tlearn: 2.8474642\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15251:\tlearn: 2.8472391\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15252:\tlearn: 2.8471448\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15253:\tlearn: 2.8470184\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15254:\tlearn: 2.8469211\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15255:\tlearn: 2.8468616\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15256:\tlearn: 2.8466967\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15257:\tlearn: 2.8465169\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15258:\tlearn: 2.8464236\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15259:\tlearn: 2.8463421\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15260:\tlearn: 2.8461552\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15261:\tlearn: 2.8459944\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15262:\tlearn: 2.8458837\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15263:\tlearn: 2.8457099\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "15264:\tlearn: 2.8456426\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15265:\tlearn: 2.8455185\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15266:\tlearn: 2.8454654\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15267:\tlearn: 2.8453650\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15268:\tlearn: 2.8452496\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15269:\tlearn: 2.8451143\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15270:\tlearn: 2.8450680\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15271:\tlearn: 2.8449671\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15272:\tlearn: 2.8448986\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15273:\tlearn: 2.8448420\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15274:\tlearn: 2.8447249\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15275:\tlearn: 2.8446234\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15276:\tlearn: 2.8445152\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15277:\tlearn: 2.8443956\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15278:\tlearn: 2.8442341\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15279:\tlearn: 2.8440665\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15280:\tlearn: 2.8440056\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15281:\tlearn: 2.8438394\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15282:\tlearn: 2.8436422\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15283:\tlearn: 2.8435462\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15284:\tlearn: 2.8434400\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15285:\tlearn: 2.8433335\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15286:\tlearn: 2.8432357\ttotal: 5m 31s\tremaining: 2m 47s\n",
      "15287:\tlearn: 2.8432284\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15288:\tlearn: 2.8430817\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15289:\tlearn: 2.8429612\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15290:\tlearn: 2.8428647\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15291:\tlearn: 2.8427203\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15292:\tlearn: 2.8425788\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15293:\tlearn: 2.8424881\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15294:\tlearn: 2.8423087\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15295:\tlearn: 2.8421744\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15296:\tlearn: 2.8420826\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15297:\tlearn: 2.8419350\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15298:\tlearn: 2.8418529\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15299:\tlearn: 2.8417995\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15300:\tlearn: 2.8417157\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15301:\tlearn: 2.8416252\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15302:\tlearn: 2.8415259\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15303:\tlearn: 2.8413986\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15304:\tlearn: 2.8412536\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15305:\tlearn: 2.8411338\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15306:\tlearn: 2.8409781\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15307:\tlearn: 2.8408933\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15308:\tlearn: 2.8407247\ttotal: 5m 32s\tremaining: 2m 47s\n",
      "15309:\tlearn: 2.8406607\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15310:\tlearn: 2.8405376\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15311:\tlearn: 2.8403926\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15312:\tlearn: 2.8402507\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15313:\tlearn: 2.8402021\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15314:\tlearn: 2.8400907\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15315:\tlearn: 2.8399145\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15316:\tlearn: 2.8397817\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15317:\tlearn: 2.8396803\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15318:\tlearn: 2.8394514\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15319:\tlearn: 2.8392615\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15320:\tlearn: 2.8391321\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15321:\tlearn: 2.8389910\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15322:\tlearn: 2.8388704\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15323:\tlearn: 2.8388355\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15324:\tlearn: 2.8387310\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15325:\tlearn: 2.8387278\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15326:\tlearn: 2.8385786\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15327:\tlearn: 2.8383735\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15328:\tlearn: 2.8383719\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15329:\tlearn: 2.8382955\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15330:\tlearn: 2.8381172\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15331:\tlearn: 2.8379435\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15332:\tlearn: 2.8379397\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15333:\tlearn: 2.8378133\ttotal: 5m 32s\tremaining: 2m 46s\n",
      "15334:\tlearn: 2.8377297\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15335:\tlearn: 2.8375204\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15336:\tlearn: 2.8374528\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15337:\tlearn: 2.8373047\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15338:\tlearn: 2.8372035\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15339:\tlearn: 2.8370748\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15340:\tlearn: 2.8370268\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15341:\tlearn: 2.8369603\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15342:\tlearn: 2.8368868\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15343:\tlearn: 2.8367995\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15344:\tlearn: 2.8366084\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15345:\tlearn: 2.8364191\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15346:\tlearn: 2.8363138\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15347:\tlearn: 2.8362257\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15348:\tlearn: 2.8360454\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15349:\tlearn: 2.8359526\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15350:\tlearn: 2.8358537\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15351:\tlearn: 2.8357627\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15352:\tlearn: 2.8356758\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15353:\tlearn: 2.8355826\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15354:\tlearn: 2.8353941\ttotal: 5m 33s\tremaining: 2m 46s\n",
      "15355:\tlearn: 2.8353468\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15356:\tlearn: 2.8352145\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15357:\tlearn: 2.8350230\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15358:\tlearn: 2.8349428\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15359:\tlearn: 2.8348736\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15360:\tlearn: 2.8348183\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15361:\tlearn: 2.8346491\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15362:\tlearn: 2.8346087\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15363:\tlearn: 2.8344590\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15364:\tlearn: 2.8343383\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15365:\tlearn: 2.8342097\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15366:\tlearn: 2.8340554\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15367:\tlearn: 2.8339952\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15368:\tlearn: 2.8337689\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15369:\tlearn: 2.8336477\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15370:\tlearn: 2.8335860\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15371:\tlearn: 2.8334682\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15372:\tlearn: 2.8332852\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15373:\tlearn: 2.8332232\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15374:\tlearn: 2.8330439\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15375:\tlearn: 2.8329290\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15376:\tlearn: 2.8328009\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15377:\tlearn: 2.8327102\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15378:\tlearn: 2.8325859\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15379:\tlearn: 2.8325412\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15380:\tlearn: 2.8323981\ttotal: 5m 33s\tremaining: 2m 45s\n",
      "15381:\tlearn: 2.8323030\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15382:\tlearn: 2.8321761\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15383:\tlearn: 2.8320856\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15384:\tlearn: 2.8320542\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15385:\tlearn: 2.8319255\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15386:\tlearn: 2.8318794\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15387:\tlearn: 2.8318243\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15388:\tlearn: 2.8317058\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15389:\tlearn: 2.8314483\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15390:\tlearn: 2.8313067\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15391:\tlearn: 2.8311960\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15392:\tlearn: 2.8310993\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15393:\tlearn: 2.8309850\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15394:\tlearn: 2.8308750\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15395:\tlearn: 2.8307761\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15396:\tlearn: 2.8306079\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15397:\tlearn: 2.8304135\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15398:\tlearn: 2.8303500\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15399:\tlearn: 2.8302706\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15400:\tlearn: 2.8301220\ttotal: 5m 34s\tremaining: 2m 45s\n",
      "15401:\tlearn: 2.8299628\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15402:\tlearn: 2.8298217\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15403:\tlearn: 2.8296359\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15404:\tlearn: 2.8295349\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15405:\tlearn: 2.8293758\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15406:\tlearn: 2.8292514\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15407:\tlearn: 2.8291291\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15408:\tlearn: 2.8290527\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15409:\tlearn: 2.8290495\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15410:\tlearn: 2.8288798\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15411:\tlearn: 2.8287518\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15412:\tlearn: 2.8285859\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15413:\tlearn: 2.8283889\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15414:\tlearn: 2.8283223\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15415:\tlearn: 2.8281314\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15416:\tlearn: 2.8279794\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15417:\tlearn: 2.8278960\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15418:\tlearn: 2.8277244\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15419:\tlearn: 2.8275790\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15420:\tlearn: 2.8274253\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15421:\tlearn: 2.8273203\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15422:\tlearn: 2.8271755\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15423:\tlearn: 2.8270213\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15424:\tlearn: 2.8269134\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15425:\tlearn: 2.8268114\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15426:\tlearn: 2.8267545\ttotal: 5m 34s\tremaining: 2m 44s\n",
      "15427:\tlearn: 2.8265311\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15428:\tlearn: 2.8264036\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15429:\tlearn: 2.8263104\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15430:\tlearn: 2.8261984\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15431:\tlearn: 2.8261960\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15432:\tlearn: 2.8260410\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15433:\tlearn: 2.8259262\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15434:\tlearn: 2.8258720\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15435:\tlearn: 2.8257348\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15436:\tlearn: 2.8256607\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15437:\tlearn: 2.8255743\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15438:\tlearn: 2.8253971\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15439:\tlearn: 2.8252631\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15440:\tlearn: 2.8251877\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15441:\tlearn: 2.8250609\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15442:\tlearn: 2.8249944\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15443:\tlearn: 2.8249167\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15444:\tlearn: 2.8247590\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15445:\tlearn: 2.8247246\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15446:\tlearn: 2.8246418\ttotal: 5m 35s\tremaining: 2m 44s\n",
      "15447:\tlearn: 2.8245784\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15448:\tlearn: 2.8243855\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15449:\tlearn: 2.8241968\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15450:\tlearn: 2.8240729\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15451:\tlearn: 2.8239943\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15452:\tlearn: 2.8237888\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15453:\tlearn: 2.8236766\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15454:\tlearn: 2.8236059\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15455:\tlearn: 2.8236027\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15456:\tlearn: 2.8234761\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15457:\tlearn: 2.8234736\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15458:\tlearn: 2.8232914\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15459:\tlearn: 2.8232171\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15460:\tlearn: 2.8231074\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15461:\tlearn: 2.8230116\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15462:\tlearn: 2.8228968\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15463:\tlearn: 2.8227273\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15464:\tlearn: 2.8226215\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15465:\tlearn: 2.8224195\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15466:\tlearn: 2.8223877\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15467:\tlearn: 2.8223344\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15468:\tlearn: 2.8222337\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15469:\tlearn: 2.8221322\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15470:\tlearn: 2.8220072\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15471:\tlearn: 2.8219290\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15472:\tlearn: 2.8218779\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15473:\tlearn: 2.8218032\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15474:\tlearn: 2.8217078\ttotal: 5m 35s\tremaining: 2m 43s\n",
      "15475:\tlearn: 2.8215429\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15476:\tlearn: 2.8214381\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15477:\tlearn: 2.8212848\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15478:\tlearn: 2.8211092\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15479:\tlearn: 2.8209861\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15480:\tlearn: 2.8208490\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15481:\tlearn: 2.8207790\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15482:\tlearn: 2.8206754\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15483:\tlearn: 2.8205613\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15484:\tlearn: 2.8204981\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15485:\tlearn: 2.8203676\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15486:\tlearn: 2.8202577\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15487:\tlearn: 2.8201907\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15488:\tlearn: 2.8201119\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15489:\tlearn: 2.8200016\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15490:\tlearn: 2.8198855\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15491:\tlearn: 2.8197824\ttotal: 5m 36s\tremaining: 2m 43s\n",
      "15492:\tlearn: 2.8196558\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15493:\tlearn: 2.8194724\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15494:\tlearn: 2.8193098\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15495:\tlearn: 2.8192329\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15496:\tlearn: 2.8191384\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15497:\tlearn: 2.8190087\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15498:\tlearn: 2.8187906\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15499:\tlearn: 2.8186286\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15500:\tlearn: 2.8185518\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15501:\tlearn: 2.8184437\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15502:\tlearn: 2.8183676\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15503:\tlearn: 2.8182646\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15504:\tlearn: 2.8182003\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15505:\tlearn: 2.8180734\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15506:\tlearn: 2.8179165\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15507:\tlearn: 2.8178207\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15508:\tlearn: 2.8176932\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15509:\tlearn: 2.8175890\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15510:\tlearn: 2.8174841\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15511:\tlearn: 2.8174123\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15512:\tlearn: 2.8173039\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15513:\tlearn: 2.8171917\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15514:\tlearn: 2.8170172\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15515:\tlearn: 2.8170150\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15516:\tlearn: 2.8168327\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15517:\tlearn: 2.8167180\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15518:\tlearn: 2.8166049\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15519:\tlearn: 2.8165337\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15520:\tlearn: 2.8163706\ttotal: 5m 36s\tremaining: 2m 42s\n",
      "15521:\tlearn: 2.8162680\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15522:\tlearn: 2.8161925\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15523:\tlearn: 2.8160452\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15524:\tlearn: 2.8159824\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15525:\tlearn: 2.8158899\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15526:\tlearn: 2.8157605\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15527:\tlearn: 2.8156373\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15528:\tlearn: 2.8155323\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15529:\tlearn: 2.8153484\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15530:\tlearn: 2.8152416\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15531:\tlearn: 2.8151697\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15532:\tlearn: 2.8150622\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15533:\tlearn: 2.8149962\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15534:\tlearn: 2.8148449\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15535:\tlearn: 2.8146894\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15536:\tlearn: 2.8145626\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15537:\tlearn: 2.8145094\ttotal: 5m 37s\tremaining: 2m 42s\n",
      "15538:\tlearn: 2.8144848\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15539:\tlearn: 2.8142875\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15540:\tlearn: 2.8142040\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15541:\tlearn: 2.8140458\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15542:\tlearn: 2.8139650\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15543:\tlearn: 2.8138417\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15544:\tlearn: 2.8136926\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15545:\tlearn: 2.8136376\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15546:\tlearn: 2.8135398\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15547:\tlearn: 2.8133548\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15548:\tlearn: 2.8132702\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15549:\tlearn: 2.8131250\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15550:\tlearn: 2.8129589\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15551:\tlearn: 2.8128826\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15552:\tlearn: 2.8127470\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15553:\tlearn: 2.8125808\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15554:\tlearn: 2.8124230\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15555:\tlearn: 2.8123193\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15556:\tlearn: 2.8123178\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15557:\tlearn: 2.8120542\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15558:\tlearn: 2.8119855\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15559:\tlearn: 2.8119252\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15560:\tlearn: 2.8118285\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15561:\tlearn: 2.8117132\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15562:\tlearn: 2.8115970\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15563:\tlearn: 2.8114506\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15564:\tlearn: 2.8113224\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15565:\tlearn: 2.8111402\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15566:\tlearn: 2.8110754\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15567:\tlearn: 2.8108949\ttotal: 5m 37s\tremaining: 2m 41s\n",
      "15568:\tlearn: 2.8106635\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15569:\tlearn: 2.8105072\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15570:\tlearn: 2.8103839\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15571:\tlearn: 2.8102333\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15572:\tlearn: 2.8100818\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15573:\tlearn: 2.8099255\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15574:\tlearn: 2.8097524\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15575:\tlearn: 2.8096134\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15576:\tlearn: 2.8094913\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15577:\tlearn: 2.8093619\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15578:\tlearn: 2.8092372\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15579:\tlearn: 2.8091590\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15580:\tlearn: 2.8090742\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15581:\tlearn: 2.8089019\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15582:\tlearn: 2.8088362\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15583:\tlearn: 2.8086798\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15584:\tlearn: 2.8086416\ttotal: 5m 38s\tremaining: 2m 41s\n",
      "15585:\tlearn: 2.8085263\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15586:\tlearn: 2.8084544\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15587:\tlearn: 2.8083546\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15588:\tlearn: 2.8083522\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15589:\tlearn: 2.8082722\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15590:\tlearn: 2.8081477\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15591:\tlearn: 2.8080476\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15592:\tlearn: 2.8079553\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15593:\tlearn: 2.8077880\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15594:\tlearn: 2.8077407\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15595:\tlearn: 2.8076533\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15596:\tlearn: 2.8075440\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15597:\tlearn: 2.8074316\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15598:\tlearn: 2.8073358\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15599:\tlearn: 2.8072699\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15600:\tlearn: 2.8071963\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15601:\tlearn: 2.8071399\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15602:\tlearn: 2.8070458\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15603:\tlearn: 2.8068904\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15604:\tlearn: 2.8068007\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15605:\tlearn: 2.8066439\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15606:\tlearn: 2.8065580\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15607:\tlearn: 2.8064487\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15608:\tlearn: 2.8063356\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15609:\tlearn: 2.8061916\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15610:\tlearn: 2.8060655\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15611:\tlearn: 2.8058896\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15612:\tlearn: 2.8057802\ttotal: 5m 38s\tremaining: 2m 40s\n",
      "15613:\tlearn: 2.8056317\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15614:\tlearn: 2.8055066\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15615:\tlearn: 2.8053615\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15616:\tlearn: 2.8053319\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15617:\tlearn: 2.8052501\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15618:\tlearn: 2.8050745\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15619:\tlearn: 2.8050338\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15620:\tlearn: 2.8049046\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15621:\tlearn: 2.8046933\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15622:\tlearn: 2.8046265\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15623:\tlearn: 2.8045214\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15624:\tlearn: 2.8043868\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15625:\tlearn: 2.8042798\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15626:\tlearn: 2.8041230\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15627:\tlearn: 2.8039954\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15628:\tlearn: 2.8038504\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15629:\tlearn: 2.8037766\ttotal: 5m 39s\tremaining: 2m 40s\n",
      "15630:\tlearn: 2.8037744\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15631:\tlearn: 2.8037718\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15632:\tlearn: 2.8035900\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15633:\tlearn: 2.8035431\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15634:\tlearn: 2.8034704\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15635:\tlearn: 2.8033307\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15636:\tlearn: 2.8031637\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15637:\tlearn: 2.8030375\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15638:\tlearn: 2.8029555\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15639:\tlearn: 2.8027894\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15640:\tlearn: 2.8026442\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15641:\tlearn: 2.8025160\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15642:\tlearn: 2.8023536\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15643:\tlearn: 2.8022321\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15644:\tlearn: 2.8020601\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15645:\tlearn: 2.8019608\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15646:\tlearn: 2.8018767\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15647:\tlearn: 2.8017503\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15648:\tlearn: 2.8016170\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15649:\tlearn: 2.8015643\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15650:\tlearn: 2.8013858\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15651:\tlearn: 2.8012004\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15652:\tlearn: 2.8010969\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15653:\tlearn: 2.8009939\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15654:\tlearn: 2.8008884\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15655:\tlearn: 2.8007375\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15656:\tlearn: 2.8006179\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15657:\tlearn: 2.8005472\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15658:\tlearn: 2.8004620\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15659:\tlearn: 2.8003323\ttotal: 5m 39s\tremaining: 2m 39s\n",
      "15660:\tlearn: 2.8001223\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15661:\tlearn: 2.7999702\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15662:\tlearn: 2.7999155\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15663:\tlearn: 2.7998209\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15664:\tlearn: 2.7996855\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15665:\tlearn: 2.7995331\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15666:\tlearn: 2.7993792\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15667:\tlearn: 2.7993095\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15668:\tlearn: 2.7992012\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15669:\tlearn: 2.7990484\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15670:\tlearn: 2.7988684\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15671:\tlearn: 2.7987713\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15672:\tlearn: 2.7987175\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15673:\tlearn: 2.7985650\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15674:\tlearn: 2.7985398\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15675:\tlearn: 2.7983109\ttotal: 5m 40s\tremaining: 2m 39s\n",
      "15676:\tlearn: 2.7981613\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15677:\tlearn: 2.7980065\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15678:\tlearn: 2.7979546\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15679:\tlearn: 2.7978561\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15680:\tlearn: 2.7977314\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15681:\tlearn: 2.7976758\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15682:\tlearn: 2.7975035\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15683:\tlearn: 2.7974417\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15684:\tlearn: 2.7972436\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15685:\tlearn: 2.7971432\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15686:\tlearn: 2.7970291\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15687:\tlearn: 2.7969270\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15688:\tlearn: 2.7968940\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15689:\tlearn: 2.7968074\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15690:\tlearn: 2.7966814\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15691:\tlearn: 2.7965963\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15692:\tlearn: 2.7964498\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15693:\tlearn: 2.7963773\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15694:\tlearn: 2.7962050\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15695:\tlearn: 2.7962010\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15696:\tlearn: 2.7960811\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15697:\tlearn: 2.7960144\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15698:\tlearn: 2.7958781\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15699:\tlearn: 2.7958003\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15700:\tlearn: 2.7956565\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15701:\tlearn: 2.7956126\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15702:\tlearn: 2.7954842\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15703:\tlearn: 2.7954126\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15704:\tlearn: 2.7953527\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15705:\tlearn: 2.7953511\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15706:\tlearn: 2.7952660\ttotal: 5m 40s\tremaining: 2m 38s\n",
      "15707:\tlearn: 2.7950808\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15708:\tlearn: 2.7949607\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15709:\tlearn: 2.7948229\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15710:\tlearn: 2.7946994\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15711:\tlearn: 2.7945277\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15712:\tlearn: 2.7944005\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15713:\tlearn: 2.7943275\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15714:\tlearn: 2.7941760\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15715:\tlearn: 2.7940734\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15716:\tlearn: 2.7939993\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15717:\tlearn: 2.7938145\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15718:\tlearn: 2.7936767\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15719:\tlearn: 2.7934226\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15720:\tlearn: 2.7932713\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15721:\tlearn: 2.7931947\ttotal: 5m 41s\tremaining: 2m 38s\n",
      "15722:\tlearn: 2.7931352\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15723:\tlearn: 2.7930070\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15724:\tlearn: 2.7928856\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15725:\tlearn: 2.7927570\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15726:\tlearn: 2.7926457\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15727:\tlearn: 2.7924991\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15728:\tlearn: 2.7923547\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15729:\tlearn: 2.7921130\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15730:\tlearn: 2.7919932\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15731:\tlearn: 2.7919281\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15732:\tlearn: 2.7918416\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15733:\tlearn: 2.7916884\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15734:\tlearn: 2.7915675\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15735:\tlearn: 2.7913367\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15736:\tlearn: 2.7912144\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15737:\tlearn: 2.7911922\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15738:\tlearn: 2.7910485\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15739:\tlearn: 2.7909594\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15740:\tlearn: 2.7908182\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15741:\tlearn: 2.7906284\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15742:\tlearn: 2.7905471\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15743:\tlearn: 2.7903508\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15744:\tlearn: 2.7902460\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15745:\tlearn: 2.7901100\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15746:\tlearn: 2.7898943\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15747:\tlearn: 2.7897515\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15748:\tlearn: 2.7896162\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15749:\tlearn: 2.7895264\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15750:\tlearn: 2.7893951\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15751:\tlearn: 2.7893562\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15752:\tlearn: 2.7892495\ttotal: 5m 41s\tremaining: 2m 37s\n",
      "15753:\tlearn: 2.7890741\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15754:\tlearn: 2.7890439\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15755:\tlearn: 2.7889210\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15756:\tlearn: 2.7888068\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15757:\tlearn: 2.7887023\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15758:\tlearn: 2.7885774\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15759:\tlearn: 2.7884876\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15760:\tlearn: 2.7884090\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15761:\tlearn: 2.7883019\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15762:\tlearn: 2.7881743\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15763:\tlearn: 2.7880119\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15764:\tlearn: 2.7878821\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15765:\tlearn: 2.7877415\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15766:\tlearn: 2.7875836\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15767:\tlearn: 2.7874777\ttotal: 5m 42s\tremaining: 2m 37s\n",
      "15768:\tlearn: 2.7874042\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15769:\tlearn: 2.7872590\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15770:\tlearn: 2.7872161\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15771:\tlearn: 2.7870212\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15772:\tlearn: 2.7869674\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15773:\tlearn: 2.7868701\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15774:\tlearn: 2.7868078\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15775:\tlearn: 2.7868053\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15776:\tlearn: 2.7866358\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15777:\tlearn: 2.7865589\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15778:\tlearn: 2.7863911\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15779:\tlearn: 2.7862638\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15780:\tlearn: 2.7861974\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15781:\tlearn: 2.7860362\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15782:\tlearn: 2.7859995\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15783:\tlearn: 2.7859258\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15784:\tlearn: 2.7858339\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15785:\tlearn: 2.7857015\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15786:\tlearn: 2.7855873\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15787:\tlearn: 2.7854458\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15788:\tlearn: 2.7853719\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15789:\tlearn: 2.7852667\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15790:\tlearn: 2.7852107\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15791:\tlearn: 2.7851677\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15792:\tlearn: 2.7850805\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15793:\tlearn: 2.7849825\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15794:\tlearn: 2.7848803\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15795:\tlearn: 2.7848781\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15796:\tlearn: 2.7847556\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15797:\tlearn: 2.7846469\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15798:\tlearn: 2.7845396\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15799:\tlearn: 2.7844025\ttotal: 5m 42s\tremaining: 2m 36s\n",
      "15800:\tlearn: 2.7842562\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15801:\tlearn: 2.7841433\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15802:\tlearn: 2.7840361\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15803:\tlearn: 2.7838871\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15804:\tlearn: 2.7838020\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15805:\tlearn: 2.7836423\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15806:\tlearn: 2.7835045\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15807:\tlearn: 2.7833701\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15808:\tlearn: 2.7832538\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15809:\tlearn: 2.7831322\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15810:\tlearn: 2.7831306\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15811:\tlearn: 2.7830693\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15812:\tlearn: 2.7829310\ttotal: 5m 43s\tremaining: 2m 36s\n",
      "15813:\tlearn: 2.7827566\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15814:\tlearn: 2.7826415\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15815:\tlearn: 2.7825551\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15816:\tlearn: 2.7824458\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15817:\tlearn: 2.7823375\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15818:\tlearn: 2.7822513\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15819:\tlearn: 2.7822386\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15820:\tlearn: 2.7821336\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15821:\tlearn: 2.7820115\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15822:\tlearn: 2.7818975\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15823:\tlearn: 2.7817915\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15824:\tlearn: 2.7816679\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15825:\tlearn: 2.7815272\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15826:\tlearn: 2.7814420\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15827:\tlearn: 2.7813597\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15828:\tlearn: 2.7811708\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15829:\tlearn: 2.7810885\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15830:\tlearn: 2.7810029\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15831:\tlearn: 2.7809123\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15832:\tlearn: 2.7808150\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15833:\tlearn: 2.7807474\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15834:\tlearn: 2.7806213\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15835:\tlearn: 2.7805071\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15836:\tlearn: 2.7803930\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15837:\tlearn: 2.7802824\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15838:\tlearn: 2.7801076\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15839:\tlearn: 2.7800448\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15840:\tlearn: 2.7799082\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15841:\tlearn: 2.7797829\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15842:\tlearn: 2.7796936\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15843:\tlearn: 2.7794749\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15844:\tlearn: 2.7793474\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15845:\tlearn: 2.7792704\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15846:\tlearn: 2.7791023\ttotal: 5m 43s\tremaining: 2m 35s\n",
      "15847:\tlearn: 2.7790312\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15848:\tlearn: 2.7789272\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15849:\tlearn: 2.7789243\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15850:\tlearn: 2.7787238\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15851:\tlearn: 2.7785923\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15852:\tlearn: 2.7784832\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15853:\tlearn: 2.7784806\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15854:\tlearn: 2.7783941\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15855:\tlearn: 2.7781637\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15856:\tlearn: 2.7780544\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15857:\tlearn: 2.7779451\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15858:\tlearn: 2.7778706\ttotal: 5m 44s\tremaining: 2m 35s\n",
      "15859:\tlearn: 2.7777212\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15860:\tlearn: 2.7775795\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15861:\tlearn: 2.7774253\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15862:\tlearn: 2.7772257\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15863:\tlearn: 2.7770804\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15864:\tlearn: 2.7769328\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15865:\tlearn: 2.7767094\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15866:\tlearn: 2.7765399\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15867:\tlearn: 2.7764062\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15868:\tlearn: 2.7762975\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15869:\tlearn: 2.7761607\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15870:\tlearn: 2.7760299\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15871:\tlearn: 2.7759250\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15872:\tlearn: 2.7757313\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15873:\tlearn: 2.7755565\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15874:\tlearn: 2.7754586\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15875:\tlearn: 2.7753464\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15876:\tlearn: 2.7752408\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15877:\tlearn: 2.7752292\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15878:\tlearn: 2.7750449\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15879:\tlearn: 2.7748342\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15880:\tlearn: 2.7747846\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15881:\tlearn: 2.7746478\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15882:\tlearn: 2.7745461\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15883:\tlearn: 2.7744240\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15884:\tlearn: 2.7742997\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15885:\tlearn: 2.7741995\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15886:\tlearn: 2.7740678\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15887:\tlearn: 2.7739187\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15888:\tlearn: 2.7738245\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15889:\tlearn: 2.7736818\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15890:\tlearn: 2.7735058\ttotal: 5m 44s\tremaining: 2m 34s\n",
      "15891:\tlearn: 2.7734014\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15892:\tlearn: 2.7731863\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15893:\tlearn: 2.7730223\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15894:\tlearn: 2.7729101\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15895:\tlearn: 2.7727901\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15896:\tlearn: 2.7726811\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15897:\tlearn: 2.7725047\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15898:\tlearn: 2.7724394\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15899:\tlearn: 2.7723648\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15900:\tlearn: 2.7722410\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15901:\tlearn: 2.7721263\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15902:\tlearn: 2.7720271\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15903:\tlearn: 2.7719422\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15904:\tlearn: 2.7718211\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15905:\tlearn: 2.7716335\ttotal: 5m 45s\tremaining: 2m 34s\n",
      "15906:\tlearn: 2.7716311\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15907:\tlearn: 2.7715156\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15908:\tlearn: 2.7713581\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15909:\tlearn: 2.7712029\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15910:\tlearn: 2.7710482\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15911:\tlearn: 2.7709302\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15912:\tlearn: 2.7708356\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15913:\tlearn: 2.7707008\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15914:\tlearn: 2.7705744\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15915:\tlearn: 2.7704351\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15916:\tlearn: 2.7703366\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15917:\tlearn: 2.7702533\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15918:\tlearn: 2.7701854\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15919:\tlearn: 2.7700739\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15920:\tlearn: 2.7698874\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15921:\tlearn: 2.7697405\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15922:\tlearn: 2.7695882\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15923:\tlearn: 2.7695329\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15924:\tlearn: 2.7694729\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15925:\tlearn: 2.7692864\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15926:\tlearn: 2.7691447\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15927:\tlearn: 2.7689842\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15928:\tlearn: 2.7688945\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15929:\tlearn: 2.7688719\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15930:\tlearn: 2.7687673\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15931:\tlearn: 2.7687141\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15932:\tlearn: 2.7686422\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15933:\tlearn: 2.7685260\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15934:\tlearn: 2.7683382\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15935:\tlearn: 2.7682144\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15936:\tlearn: 2.7680789\ttotal: 5m 45s\tremaining: 2m 33s\n",
      "15937:\tlearn: 2.7679090\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15938:\tlearn: 2.7678331\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15939:\tlearn: 2.7677723\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15940:\tlearn: 2.7676316\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15941:\tlearn: 2.7675165\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15942:\tlearn: 2.7675066\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15943:\tlearn: 2.7674204\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15944:\tlearn: 2.7672193\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15945:\tlearn: 2.7671724\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15946:\tlearn: 2.7671063\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15947:\tlearn: 2.7669081\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15948:\tlearn: 2.7668027\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15949:\tlearn: 2.7667151\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15950:\tlearn: 2.7665581\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15951:\tlearn: 2.7664693\ttotal: 5m 46s\tremaining: 2m 33s\n",
      "15952:\tlearn: 2.7664670\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15953:\tlearn: 2.7663073\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15954:\tlearn: 2.7661482\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15955:\tlearn: 2.7660646\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15956:\tlearn: 2.7658351\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15957:\tlearn: 2.7657300\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15958:\tlearn: 2.7655871\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15959:\tlearn: 2.7654794\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15960:\tlearn: 2.7654195\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15961:\tlearn: 2.7652780\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15962:\tlearn: 2.7651470\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15963:\tlearn: 2.7649553\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15964:\tlearn: 2.7649107\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15965:\tlearn: 2.7648389\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15966:\tlearn: 2.7647152\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15967:\tlearn: 2.7646634\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15968:\tlearn: 2.7645599\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15969:\tlearn: 2.7644088\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15970:\tlearn: 2.7642513\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15971:\tlearn: 2.7641951\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15972:\tlearn: 2.7639972\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15973:\tlearn: 2.7638062\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15974:\tlearn: 2.7636841\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15975:\tlearn: 2.7635845\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15976:\tlearn: 2.7634768\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15977:\tlearn: 2.7633674\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15978:\tlearn: 2.7632292\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15979:\tlearn: 2.7631605\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15980:\tlearn: 2.7631058\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15981:\tlearn: 2.7630002\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15982:\tlearn: 2.7629678\ttotal: 5m 46s\tremaining: 2m 32s\n",
      "15983:\tlearn: 2.7628403\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15984:\tlearn: 2.7626191\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15985:\tlearn: 2.7624632\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15986:\tlearn: 2.7623448\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15987:\tlearn: 2.7621585\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15988:\tlearn: 2.7619065\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15989:\tlearn: 2.7617217\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15990:\tlearn: 2.7616082\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15991:\tlearn: 2.7615170\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15992:\tlearn: 2.7613268\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15993:\tlearn: 2.7612629\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15994:\tlearn: 2.7611613\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15995:\tlearn: 2.7610241\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15996:\tlearn: 2.7609256\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15997:\tlearn: 2.7608912\ttotal: 5m 47s\tremaining: 2m 32s\n",
      "15998:\tlearn: 2.7607038\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "15999:\tlearn: 2.7605648\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16000:\tlearn: 2.7605635\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16001:\tlearn: 2.7604082\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16002:\tlearn: 2.7602766\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16003:\tlearn: 2.7600525\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16004:\tlearn: 2.7599375\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16005:\tlearn: 2.7598672\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16006:\tlearn: 2.7596986\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16007:\tlearn: 2.7595821\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16008:\tlearn: 2.7594728\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16009:\tlearn: 2.7593655\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16010:\tlearn: 2.7592623\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16011:\tlearn: 2.7591544\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16012:\tlearn: 2.7590711\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16013:\tlearn: 2.7589685\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16014:\tlearn: 2.7588560\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16015:\tlearn: 2.7587544\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16016:\tlearn: 2.7586430\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16017:\tlearn: 2.7585584\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16018:\tlearn: 2.7584754\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16019:\tlearn: 2.7582791\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16020:\tlearn: 2.7581728\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16021:\tlearn: 2.7580550\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16022:\tlearn: 2.7579435\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16023:\tlearn: 2.7578839\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16024:\tlearn: 2.7577828\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16025:\tlearn: 2.7575731\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16026:\tlearn: 2.7574047\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16027:\tlearn: 2.7572691\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16028:\tlearn: 2.7571890\ttotal: 5m 47s\tremaining: 2m 31s\n",
      "16029:\tlearn: 2.7570626\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16030:\tlearn: 2.7569801\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16031:\tlearn: 2.7568500\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16032:\tlearn: 2.7567434\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16033:\tlearn: 2.7566644\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16034:\tlearn: 2.7564929\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16035:\tlearn: 2.7563663\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16036:\tlearn: 2.7562804\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16037:\tlearn: 2.7560583\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16038:\tlearn: 2.7559517\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16039:\tlearn: 2.7558531\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16040:\tlearn: 2.7557990\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16041:\tlearn: 2.7556353\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16042:\tlearn: 2.7554732\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16043:\tlearn: 2.7553771\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16044:\tlearn: 2.7552629\ttotal: 5m 48s\tremaining: 2m 31s\n",
      "16045:\tlearn: 2.7551967\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16046:\tlearn: 2.7551551\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16047:\tlearn: 2.7550749\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16048:\tlearn: 2.7549429\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16049:\tlearn: 2.7547852\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16050:\tlearn: 2.7547433\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16051:\tlearn: 2.7546580\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16052:\tlearn: 2.7545268\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16053:\tlearn: 2.7545254\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16054:\tlearn: 2.7545081\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16055:\tlearn: 2.7544107\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16056:\tlearn: 2.7542815\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16057:\tlearn: 2.7541971\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16058:\tlearn: 2.7540678\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16059:\tlearn: 2.7539002\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16060:\tlearn: 2.7538499\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16061:\tlearn: 2.7537689\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16062:\tlearn: 2.7536478\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16063:\tlearn: 2.7535565\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16064:\tlearn: 2.7534509\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16065:\tlearn: 2.7533828\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16066:\tlearn: 2.7532582\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16067:\tlearn: 2.7531658\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16068:\tlearn: 2.7529800\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16069:\tlearn: 2.7528086\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16070:\tlearn: 2.7526821\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16071:\tlearn: 2.7525559\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16072:\tlearn: 2.7524143\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "16073:\tlearn: 2.7522952\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16074:\tlearn: 2.7521551\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16075:\tlearn: 2.7520733\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16076:\tlearn: 2.7519270\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16077:\tlearn: 2.7518120\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16078:\tlearn: 2.7516643\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16079:\tlearn: 2.7515387\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16080:\tlearn: 2.7514191\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16081:\tlearn: 2.7514177\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16082:\tlearn: 2.7512981\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16083:\tlearn: 2.7511758\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16084:\tlearn: 2.7509680\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16085:\tlearn: 2.7508325\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16086:\tlearn: 2.7506898\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16087:\tlearn: 2.7505486\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16088:\tlearn: 2.7504650\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16089:\tlearn: 2.7503231\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16090:\tlearn: 2.7502465\ttotal: 5m 49s\tremaining: 2m 30s\n",
      "16091:\tlearn: 2.7501436\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16092:\tlearn: 2.7500328\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16093:\tlearn: 2.7499448\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16094:\tlearn: 2.7498053\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16095:\tlearn: 2.7497297\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16096:\tlearn: 2.7496711\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16097:\tlearn: 2.7494820\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16098:\tlearn: 2.7493676\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16099:\tlearn: 2.7492825\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16100:\tlearn: 2.7491865\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16101:\tlearn: 2.7490215\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16102:\tlearn: 2.7489070\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16103:\tlearn: 2.7488089\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16104:\tlearn: 2.7487809\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16105:\tlearn: 2.7487791\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16106:\tlearn: 2.7486376\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16107:\tlearn: 2.7485397\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16108:\tlearn: 2.7484314\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16109:\tlearn: 2.7483229\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16110:\tlearn: 2.7482607\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16111:\tlearn: 2.7481247\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16112:\tlearn: 2.7480453\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16113:\tlearn: 2.7479451\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16114:\tlearn: 2.7478333\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16115:\tlearn: 2.7477823\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16116:\tlearn: 2.7476670\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16117:\tlearn: 2.7475583\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16118:\tlearn: 2.7473969\ttotal: 5m 49s\tremaining: 2m 29s\n",
      "16119:\tlearn: 2.7473264\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16120:\tlearn: 2.7471744\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16121:\tlearn: 2.7470618\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16122:\tlearn: 2.7469420\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16123:\tlearn: 2.7468716\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16124:\tlearn: 2.7467922\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16125:\tlearn: 2.7466328\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16126:\tlearn: 2.7465312\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16127:\tlearn: 2.7464613\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16128:\tlearn: 2.7463783\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16129:\tlearn: 2.7461736\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16130:\tlearn: 2.7460413\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16131:\tlearn: 2.7458890\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16132:\tlearn: 2.7457536\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16133:\tlearn: 2.7456460\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16134:\tlearn: 2.7455134\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16135:\tlearn: 2.7453631\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16136:\tlearn: 2.7452846\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16137:\tlearn: 2.7452016\ttotal: 5m 50s\tremaining: 2m 29s\n",
      "16138:\tlearn: 2.7451193\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16139:\tlearn: 2.7449929\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16140:\tlearn: 2.7449554\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16141:\tlearn: 2.7448971\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16142:\tlearn: 2.7447946\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16143:\tlearn: 2.7446898\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16144:\tlearn: 2.7445561\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16145:\tlearn: 2.7444989\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16146:\tlearn: 2.7444971\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16147:\tlearn: 2.7444603\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16148:\tlearn: 2.7443909\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16149:\tlearn: 2.7443065\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16150:\tlearn: 2.7442029\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16151:\tlearn: 2.7440405\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16152:\tlearn: 2.7438981\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16153:\tlearn: 2.7438315\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16154:\tlearn: 2.7437306\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16155:\tlearn: 2.7436297\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16156:\tlearn: 2.7434824\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16157:\tlearn: 2.7432579\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16158:\tlearn: 2.7432039\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16159:\tlearn: 2.7431459\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16160:\tlearn: 2.7430157\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16161:\tlearn: 2.7428824\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16162:\tlearn: 2.7427325\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16163:\tlearn: 2.7427310\ttotal: 5m 50s\tremaining: 2m 28s\n",
      "16164:\tlearn: 2.7425964\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16165:\tlearn: 2.7424829\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16166:\tlearn: 2.7423462\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16167:\tlearn: 2.7422363\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16168:\tlearn: 2.7420727\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16169:\tlearn: 2.7419404\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16170:\tlearn: 2.7417396\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16171:\tlearn: 2.7416561\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16172:\tlearn: 2.7416078\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16173:\tlearn: 2.7415180\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16174:\tlearn: 2.7413433\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16175:\tlearn: 2.7412559\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16176:\tlearn: 2.7411908\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16177:\tlearn: 2.7410755\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16178:\tlearn: 2.7410174\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16179:\tlearn: 2.7408897\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16180:\tlearn: 2.7407947\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16181:\tlearn: 2.7407054\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16182:\tlearn: 2.7405555\ttotal: 5m 51s\tremaining: 2m 28s\n",
      "16183:\tlearn: 2.7405004\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16184:\tlearn: 2.7404465\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16185:\tlearn: 2.7403386\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16186:\tlearn: 2.7402477\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16187:\tlearn: 2.7401211\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16188:\tlearn: 2.7401198\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16189:\tlearn: 2.7400052\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16190:\tlearn: 2.7399481\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16191:\tlearn: 2.7398716\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16192:\tlearn: 2.7398330\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16193:\tlearn: 2.7398309\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16194:\tlearn: 2.7396913\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16195:\tlearn: 2.7396021\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16196:\tlearn: 2.7396002\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16197:\tlearn: 2.7395006\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16198:\tlearn: 2.7394267\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16199:\tlearn: 2.7393371\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16200:\tlearn: 2.7392239\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16201:\tlearn: 2.7392227\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16202:\tlearn: 2.7391706\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16203:\tlearn: 2.7390197\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16204:\tlearn: 2.7388350\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16205:\tlearn: 2.7387049\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16206:\tlearn: 2.7386403\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16207:\tlearn: 2.7385223\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16208:\tlearn: 2.7384181\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16209:\tlearn: 2.7383303\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16210:\tlearn: 2.7381698\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16211:\tlearn: 2.7380114\ttotal: 5m 51s\tremaining: 2m 27s\n",
      "16212:\tlearn: 2.7379393\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16213:\tlearn: 2.7378037\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16214:\tlearn: 2.7376224\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16215:\tlearn: 2.7374481\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16216:\tlearn: 2.7373338\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16217:\tlearn: 2.7372249\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16218:\tlearn: 2.7371208\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16219:\tlearn: 2.7369857\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16220:\tlearn: 2.7368674\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16221:\tlearn: 2.7367562\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16222:\tlearn: 2.7366227\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16223:\tlearn: 2.7365435\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16224:\tlearn: 2.7364216\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16225:\tlearn: 2.7363326\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16226:\tlearn: 2.7362312\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16227:\tlearn: 2.7361223\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16228:\tlearn: 2.7360074\ttotal: 5m 52s\tremaining: 2m 27s\n",
      "16229:\tlearn: 2.7359340\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16230:\tlearn: 2.7358644\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16231:\tlearn: 2.7357917\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16232:\tlearn: 2.7357509\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16233:\tlearn: 2.7355881\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16234:\tlearn: 2.7354693\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16235:\tlearn: 2.7353294\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16236:\tlearn: 2.7351649\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16237:\tlearn: 2.7350049\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16238:\tlearn: 2.7349050\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16239:\tlearn: 2.7346884\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16240:\tlearn: 2.7345915\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16241:\tlearn: 2.7345297\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16242:\tlearn: 2.7344265\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16243:\tlearn: 2.7343665\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16244:\tlearn: 2.7342326\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16245:\tlearn: 2.7342310\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16246:\tlearn: 2.7341135\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16247:\tlearn: 2.7339976\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16248:\tlearn: 2.7339371\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16249:\tlearn: 2.7338075\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16250:\tlearn: 2.7337125\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16251:\tlearn: 2.7335838\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16252:\tlearn: 2.7334554\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16253:\tlearn: 2.7333307\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16254:\tlearn: 2.7331809\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16255:\tlearn: 2.7330300\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16256:\tlearn: 2.7329219\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16257:\tlearn: 2.7328193\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16258:\tlearn: 2.7328181\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16259:\tlearn: 2.7327435\ttotal: 5m 52s\tremaining: 2m 26s\n",
      "16260:\tlearn: 2.7325398\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16261:\tlearn: 2.7324179\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16262:\tlearn: 2.7323094\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16263:\tlearn: 2.7321769\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16264:\tlearn: 2.7321291\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16265:\tlearn: 2.7320512\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16266:\tlearn: 2.7319640\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16267:\tlearn: 2.7318096\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16268:\tlearn: 2.7317299\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16269:\tlearn: 2.7315478\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16270:\tlearn: 2.7314624\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16271:\tlearn: 2.7314150\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16272:\tlearn: 2.7312866\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16273:\tlearn: 2.7311227\ttotal: 5m 53s\tremaining: 2m 26s\n",
      "16274:\tlearn: 2.7311207\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16275:\tlearn: 2.7310212\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16276:\tlearn: 2.7308900\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16277:\tlearn: 2.7307776\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16278:\tlearn: 2.7307242\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16279:\tlearn: 2.7305928\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16280:\tlearn: 2.7304701\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16281:\tlearn: 2.7303777\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16282:\tlearn: 2.7302839\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16283:\tlearn: 2.7302175\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16284:\tlearn: 2.7301268\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16285:\tlearn: 2.7300685\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16286:\tlearn: 2.7299729\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16287:\tlearn: 2.7299163\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16288:\tlearn: 2.7297686\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16289:\tlearn: 2.7297046\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16290:\tlearn: 2.7294855\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16291:\tlearn: 2.7294114\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16292:\tlearn: 2.7292895\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16293:\tlearn: 2.7291623\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16294:\tlearn: 2.7289605\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16295:\tlearn: 2.7288154\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16296:\tlearn: 2.7287010\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16297:\tlearn: 2.7286105\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16298:\tlearn: 2.7285098\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16299:\tlearn: 2.7285083\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16300:\tlearn: 2.7284044\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16301:\tlearn: 2.7283021\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16302:\tlearn: 2.7282162\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16303:\tlearn: 2.7281265\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16304:\tlearn: 2.7280284\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16305:\tlearn: 2.7279189\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16306:\tlearn: 2.7278361\ttotal: 5m 53s\tremaining: 2m 25s\n",
      "16307:\tlearn: 2.7277097\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16308:\tlearn: 2.7275454\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16309:\tlearn: 2.7274514\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16310:\tlearn: 2.7273272\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16311:\tlearn: 2.7272678\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16312:\tlearn: 2.7272017\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16313:\tlearn: 2.7271394\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16314:\tlearn: 2.7270508\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16315:\tlearn: 2.7268415\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16316:\tlearn: 2.7267271\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16317:\tlearn: 2.7266236\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16318:\tlearn: 2.7264587\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16319:\tlearn: 2.7263619\ttotal: 5m 54s\tremaining: 2m 25s\n",
      "16320:\tlearn: 2.7263565\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16321:\tlearn: 2.7263535\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16322:\tlearn: 2.7262593\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16323:\tlearn: 2.7261408\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16324:\tlearn: 2.7261395\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16325:\tlearn: 2.7260264\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16326:\tlearn: 2.7259269\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16327:\tlearn: 2.7257725\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16328:\tlearn: 2.7256501\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16329:\tlearn: 2.7255187\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16330:\tlearn: 2.7253560\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16331:\tlearn: 2.7251994\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16332:\tlearn: 2.7250955\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16333:\tlearn: 2.7249620\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16334:\tlearn: 2.7249170\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16335:\tlearn: 2.7248578\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16336:\tlearn: 2.7247267\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16337:\tlearn: 2.7246259\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16338:\tlearn: 2.7244914\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16339:\tlearn: 2.7243752\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16340:\tlearn: 2.7242701\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16341:\tlearn: 2.7241203\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16342:\tlearn: 2.7240301\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16343:\tlearn: 2.7238410\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16344:\tlearn: 2.7237419\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16345:\tlearn: 2.7236780\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16346:\tlearn: 2.7236159\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16347:\tlearn: 2.7235875\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16348:\tlearn: 2.7234850\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16349:\tlearn: 2.7233654\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16350:\tlearn: 2.7231989\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16351:\tlearn: 2.7230730\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16352:\tlearn: 2.7229532\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16353:\tlearn: 2.7228719\ttotal: 5m 54s\tremaining: 2m 24s\n",
      "16354:\tlearn: 2.7227279\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16355:\tlearn: 2.7225715\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16356:\tlearn: 2.7224597\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16357:\tlearn: 2.7223241\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16358:\tlearn: 2.7222067\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16359:\tlearn: 2.7220682\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16360:\tlearn: 2.7219394\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16361:\tlearn: 2.7218738\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16362:\tlearn: 2.7217853\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16363:\tlearn: 2.7217142\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16364:\tlearn: 2.7216330\ttotal: 5m 55s\tremaining: 2m 24s\n",
      "16365:\tlearn: 2.7214949\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16366:\tlearn: 2.7213708\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16367:\tlearn: 2.7213112\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16368:\tlearn: 2.7212225\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16369:\tlearn: 2.7211349\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16370:\tlearn: 2.7210260\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16371:\tlearn: 2.7208583\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16372:\tlearn: 2.7207448\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16373:\tlearn: 2.7206205\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16374:\tlearn: 2.7204707\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16375:\tlearn: 2.7203664\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16376:\tlearn: 2.7202353\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16377:\tlearn: 2.7201614\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16378:\tlearn: 2.7200471\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16379:\tlearn: 2.7199858\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16380:\tlearn: 2.7199157\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16381:\tlearn: 2.7198365\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16382:\tlearn: 2.7197435\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16383:\tlearn: 2.7196912\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16384:\tlearn: 2.7195872\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16385:\tlearn: 2.7194712\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16386:\tlearn: 2.7193722\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16387:\tlearn: 2.7192583\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16388:\tlearn: 2.7191790\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16389:\tlearn: 2.7191764\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16390:\tlearn: 2.7190941\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16391:\tlearn: 2.7189995\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16392:\tlearn: 2.7188959\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16393:\tlearn: 2.7188040\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16394:\tlearn: 2.7187185\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16395:\tlearn: 2.7185653\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16396:\tlearn: 2.7184084\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16397:\tlearn: 2.7183433\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16398:\tlearn: 2.7181837\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16399:\tlearn: 2.7180929\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16400:\tlearn: 2.7180049\ttotal: 5m 55s\tremaining: 2m 23s\n",
      "16401:\tlearn: 2.7178969\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16402:\tlearn: 2.7177823\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16403:\tlearn: 2.7176990\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16404:\tlearn: 2.7175717\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16405:\tlearn: 2.7175092\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16406:\tlearn: 2.7174217\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16407:\tlearn: 2.7173439\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16408:\tlearn: 2.7172303\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16409:\tlearn: 2.7171219\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16410:\tlearn: 2.7170185\ttotal: 5m 56s\tremaining: 2m 23s\n",
      "16411:\tlearn: 2.7169549\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16412:\tlearn: 2.7169134\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16413:\tlearn: 2.7168340\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16414:\tlearn: 2.7167418\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16415:\tlearn: 2.7165649\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16416:\tlearn: 2.7164335\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16417:\tlearn: 2.7162782\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16418:\tlearn: 2.7161995\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16419:\tlearn: 2.7160728\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16420:\tlearn: 2.7159474\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16421:\tlearn: 2.7158318\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16422:\tlearn: 2.7157455\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16423:\tlearn: 2.7156316\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16424:\tlearn: 2.7155343\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16425:\tlearn: 2.7155034\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16426:\tlearn: 2.7154445\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16427:\tlearn: 2.7152832\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16428:\tlearn: 2.7151620\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16429:\tlearn: 2.7150485\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16430:\tlearn: 2.7148712\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16431:\tlearn: 2.7147647\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16432:\tlearn: 2.7146501\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16433:\tlearn: 2.7145624\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16434:\tlearn: 2.7144777\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16435:\tlearn: 2.7143923\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16436:\tlearn: 2.7142501\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16437:\tlearn: 2.7141980\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16438:\tlearn: 2.7140809\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16439:\tlearn: 2.7140073\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16440:\tlearn: 2.7139629\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16441:\tlearn: 2.7138189\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16442:\tlearn: 2.7137457\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16443:\tlearn: 2.7136974\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16444:\tlearn: 2.7135657\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16445:\tlearn: 2.7134308\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16446:\tlearn: 2.7133212\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16447:\tlearn: 2.7131438\ttotal: 5m 56s\tremaining: 2m 22s\n",
      "16448:\tlearn: 2.7130319\ttotal: 5m 57s\tremaining: 2m 22s\n",
      "16449:\tlearn: 2.7129168\ttotal: 5m 57s\tremaining: 2m 22s\n",
      "16450:\tlearn: 2.7128181\ttotal: 5m 57s\tremaining: 2m 22s\n",
      "16451:\tlearn: 2.7126202\ttotal: 5m 57s\tremaining: 2m 22s\n",
      "16452:\tlearn: 2.7125676\ttotal: 5m 57s\tremaining: 2m 22s\n",
      "16453:\tlearn: 2.7124347\ttotal: 5m 57s\tremaining: 2m 22s\n",
      "16454:\tlearn: 2.7123501\ttotal: 5m 57s\tremaining: 2m 22s\n",
      "16455:\tlearn: 2.7122178\ttotal: 5m 57s\tremaining: 2m 22s\n",
      "16456:\tlearn: 2.7119994\ttotal: 5m 57s\tremaining: 2m 22s\n",
      "16457:\tlearn: 2.7119014\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16458:\tlearn: 2.7117830\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16459:\tlearn: 2.7116455\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16460:\tlearn: 2.7115265\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16461:\tlearn: 2.7114008\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16462:\tlearn: 2.7113421\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16463:\tlearn: 2.7110885\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16464:\tlearn: 2.7109814\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16465:\tlearn: 2.7108939\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16466:\tlearn: 2.7108038\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16467:\tlearn: 2.7106566\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16468:\tlearn: 2.7104938\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16469:\tlearn: 2.7104139\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16470:\tlearn: 2.7103117\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16471:\tlearn: 2.7102037\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16472:\tlearn: 2.7101113\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16473:\tlearn: 2.7100260\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16474:\tlearn: 2.7099011\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16475:\tlearn: 2.7098063\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16476:\tlearn: 2.7096568\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16477:\tlearn: 2.7095393\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16478:\tlearn: 2.7093927\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16479:\tlearn: 2.7093915\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16480:\tlearn: 2.7093039\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16481:\tlearn: 2.7092236\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16482:\tlearn: 2.7090845\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16483:\tlearn: 2.7090086\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16484:\tlearn: 2.7089264\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16485:\tlearn: 2.7088679\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16486:\tlearn: 2.7088100\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16487:\tlearn: 2.7086112\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16488:\tlearn: 2.7085402\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16489:\tlearn: 2.7083915\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16490:\tlearn: 2.7083641\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16491:\tlearn: 2.7082366\ttotal: 5m 57s\tremaining: 2m 21s\n",
      "16492:\tlearn: 2.7081499\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16493:\tlearn: 2.7080165\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16494:\tlearn: 2.7079303\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16495:\tlearn: 2.7078541\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16496:\tlearn: 2.7077607\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16497:\tlearn: 2.7075967\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16498:\tlearn: 2.7075469\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16499:\tlearn: 2.7074000\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16500:\tlearn: 2.7072445\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16501:\tlearn: 2.7071375\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16502:\tlearn: 2.7069491\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16503:\tlearn: 2.7068170\ttotal: 5m 58s\tremaining: 2m 21s\n",
      "16504:\tlearn: 2.7067015\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16505:\tlearn: 2.7064758\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16506:\tlearn: 2.7063634\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16507:\tlearn: 2.7062683\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16508:\tlearn: 2.7061476\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16509:\tlearn: 2.7060198\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16510:\tlearn: 2.7059344\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16511:\tlearn: 2.7057588\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16512:\tlearn: 2.7056314\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16513:\tlearn: 2.7055360\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16514:\tlearn: 2.7054443\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16515:\tlearn: 2.7053258\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16516:\tlearn: 2.7052146\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16517:\tlearn: 2.7051085\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16518:\tlearn: 2.7050065\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16519:\tlearn: 2.7049030\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16520:\tlearn: 2.7047898\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16521:\tlearn: 2.7046716\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16522:\tlearn: 2.7045005\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16523:\tlearn: 2.7044298\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16524:\tlearn: 2.7043636\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16525:\tlearn: 2.7043619\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16526:\tlearn: 2.7043196\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16527:\tlearn: 2.7041960\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16528:\tlearn: 2.7041246\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16529:\tlearn: 2.7039924\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16530:\tlearn: 2.7038119\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16531:\tlearn: 2.7036438\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16532:\tlearn: 2.7034671\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16533:\tlearn: 2.7033362\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16534:\tlearn: 2.7031999\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16535:\tlearn: 2.7031967\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16536:\tlearn: 2.7030691\ttotal: 5m 58s\tremaining: 2m 20s\n",
      "16537:\tlearn: 2.7029902\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16538:\tlearn: 2.7028543\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16539:\tlearn: 2.7027684\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16540:\tlearn: 2.7026030\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16541:\tlearn: 2.7024662\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16542:\tlearn: 2.7023395\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16543:\tlearn: 2.7022246\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16544:\tlearn: 2.7021046\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16545:\tlearn: 2.7019347\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16546:\tlearn: 2.7018447\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16547:\tlearn: 2.7017474\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16548:\tlearn: 2.7016439\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16549:\tlearn: 2.7015516\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16550:\tlearn: 2.7014178\ttotal: 5m 59s\tremaining: 2m 20s\n",
      "16551:\tlearn: 2.7013045\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16552:\tlearn: 2.7012385\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16553:\tlearn: 2.7011412\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16554:\tlearn: 2.7010498\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16555:\tlearn: 2.7009313\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16556:\tlearn: 2.7008396\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16557:\tlearn: 2.7006430\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16558:\tlearn: 2.7005753\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16559:\tlearn: 2.7005242\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16560:\tlearn: 2.7005223\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16561:\tlearn: 2.7003850\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16562:\tlearn: 2.7002999\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16563:\tlearn: 2.7002478\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16564:\tlearn: 2.7002075\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16565:\tlearn: 2.7001999\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16566:\tlearn: 2.7000821\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16567:\tlearn: 2.6999529\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16568:\tlearn: 2.6998215\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16569:\tlearn: 2.6997429\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16570:\tlearn: 2.6995823\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16571:\tlearn: 2.6994469\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16572:\tlearn: 2.6993089\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16573:\tlearn: 2.6991980\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16574:\tlearn: 2.6990490\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16575:\tlearn: 2.6989237\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16576:\tlearn: 2.6988035\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16577:\tlearn: 2.6987067\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16578:\tlearn: 2.6986794\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16579:\tlearn: 2.6986780\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16580:\tlearn: 2.6985791\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16581:\tlearn: 2.6984658\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16582:\tlearn: 2.6983095\ttotal: 5m 59s\tremaining: 2m 19s\n",
      "16583:\tlearn: 2.6981979\ttotal: 6m\tremaining: 2m 19s\n",
      "16584:\tlearn: 2.6980309\ttotal: 6m\tremaining: 2m 19s\n",
      "16585:\tlearn: 2.6979292\ttotal: 6m\tremaining: 2m 19s\n",
      "16586:\tlearn: 2.6978460\ttotal: 6m\tremaining: 2m 19s\n",
      "16587:\tlearn: 2.6976353\ttotal: 6m\tremaining: 2m 19s\n",
      "16588:\tlearn: 2.6974864\ttotal: 6m\tremaining: 2m 19s\n",
      "16589:\tlearn: 2.6973461\ttotal: 6m\tremaining: 2m 19s\n",
      "16590:\tlearn: 2.6972889\ttotal: 6m\tremaining: 2m 19s\n",
      "16591:\tlearn: 2.6971470\ttotal: 6m\tremaining: 2m 19s\n",
      "16592:\tlearn: 2.6970639\ttotal: 6m\tremaining: 2m 19s\n",
      "16593:\tlearn: 2.6969051\ttotal: 6m\tremaining: 2m 19s\n",
      "16594:\tlearn: 2.6968560\ttotal: 6m\tremaining: 2m 19s\n",
      "16595:\tlearn: 2.6967691\ttotal: 6m\tremaining: 2m 19s\n",
      "16596:\tlearn: 2.6966702\ttotal: 6m\tremaining: 2m 19s\n",
      "16597:\tlearn: 2.6966579\ttotal: 6m\tremaining: 2m 18s\n",
      "16598:\tlearn: 2.6965240\ttotal: 6m\tremaining: 2m 18s\n",
      "16599:\tlearn: 2.6964425\ttotal: 6m\tremaining: 2m 18s\n",
      "16600:\tlearn: 2.6962919\ttotal: 6m\tremaining: 2m 18s\n",
      "16601:\tlearn: 2.6962097\ttotal: 6m\tremaining: 2m 18s\n",
      "16602:\tlearn: 2.6960282\ttotal: 6m\tremaining: 2m 18s\n",
      "16603:\tlearn: 2.6959323\ttotal: 6m\tremaining: 2m 18s\n",
      "16604:\tlearn: 2.6958334\ttotal: 6m\tremaining: 2m 18s\n",
      "16605:\tlearn: 2.6957172\ttotal: 6m\tremaining: 2m 18s\n",
      "16606:\tlearn: 2.6956571\ttotal: 6m\tremaining: 2m 18s\n",
      "16607:\tlearn: 2.6955680\ttotal: 6m\tremaining: 2m 18s\n",
      "16608:\tlearn: 2.6954122\ttotal: 6m\tremaining: 2m 18s\n",
      "16609:\tlearn: 2.6953582\ttotal: 6m\tremaining: 2m 18s\n",
      "16610:\tlearn: 2.6952852\ttotal: 6m\tremaining: 2m 18s\n",
      "16611:\tlearn: 2.6951560\ttotal: 6m\tremaining: 2m 18s\n",
      "16612:\tlearn: 2.6950420\ttotal: 6m\tremaining: 2m 18s\n",
      "16613:\tlearn: 2.6949520\ttotal: 6m\tremaining: 2m 18s\n",
      "16614:\tlearn: 2.6948458\ttotal: 6m\tremaining: 2m 18s\n",
      "16615:\tlearn: 2.6947386\ttotal: 6m\tremaining: 2m 18s\n",
      "16616:\tlearn: 2.6945893\ttotal: 6m\tremaining: 2m 18s\n",
      "16617:\tlearn: 2.6944996\ttotal: 6m\tremaining: 2m 18s\n",
      "16618:\tlearn: 2.6944270\ttotal: 6m\tremaining: 2m 18s\n",
      "16619:\tlearn: 2.6943314\ttotal: 6m\tremaining: 2m 18s\n",
      "16620:\tlearn: 2.6942470\ttotal: 6m\tremaining: 2m 18s\n",
      "16621:\tlearn: 2.6941976\ttotal: 6m\tremaining: 2m 18s\n",
      "16622:\tlearn: 2.6940496\ttotal: 6m\tremaining: 2m 18s\n",
      "16623:\tlearn: 2.6938976\ttotal: 6m\tremaining: 2m 18s\n",
      "16624:\tlearn: 2.6937894\ttotal: 6m\tremaining: 2m 18s\n",
      "16625:\tlearn: 2.6936540\ttotal: 6m\tremaining: 2m 18s\n",
      "16626:\tlearn: 2.6935269\ttotal: 6m\tremaining: 2m 18s\n",
      "16627:\tlearn: 2.6934400\ttotal: 6m\tremaining: 2m 18s\n",
      "16628:\tlearn: 2.6933267\ttotal: 6m\tremaining: 2m 18s\n",
      "16629:\tlearn: 2.6932543\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16630:\tlearn: 2.6931605\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16631:\tlearn: 2.6930460\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16632:\tlearn: 2.6928852\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16633:\tlearn: 2.6926989\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16634:\tlearn: 2.6925584\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16635:\tlearn: 2.6924955\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16636:\tlearn: 2.6924573\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16637:\tlearn: 2.6923643\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16638:\tlearn: 2.6922518\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16639:\tlearn: 2.6921650\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16640:\tlearn: 2.6920559\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16641:\tlearn: 2.6919976\ttotal: 6m 1s\tremaining: 2m 18s\n",
      "16642:\tlearn: 2.6918770\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16643:\tlearn: 2.6917933\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16644:\tlearn: 2.6916816\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16645:\tlearn: 2.6915381\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16646:\tlearn: 2.6914137\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16647:\tlearn: 2.6913169\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16648:\tlearn: 2.6912734\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16649:\tlearn: 2.6911559\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16650:\tlearn: 2.6911533\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16651:\tlearn: 2.6909877\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16652:\tlearn: 2.6909205\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16653:\tlearn: 2.6908363\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16654:\tlearn: 2.6907456\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16655:\tlearn: 2.6906522\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16656:\tlearn: 2.6906319\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16657:\tlearn: 2.6905002\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16658:\tlearn: 2.6903945\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16659:\tlearn: 2.6902543\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16660:\tlearn: 2.6901293\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16661:\tlearn: 2.6898491\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16662:\tlearn: 2.6897834\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16663:\tlearn: 2.6896982\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16664:\tlearn: 2.6895798\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16665:\tlearn: 2.6895289\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16666:\tlearn: 2.6894045\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16667:\tlearn: 2.6892924\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16668:\tlearn: 2.6890910\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16669:\tlearn: 2.6889729\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16670:\tlearn: 2.6888676\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16671:\tlearn: 2.6887644\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16672:\tlearn: 2.6886481\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16673:\tlearn: 2.6886046\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16674:\tlearn: 2.6885729\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16675:\tlearn: 2.6884787\ttotal: 6m 1s\tremaining: 2m 17s\n",
      "16676:\tlearn: 2.6883624\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16677:\tlearn: 2.6882654\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16678:\tlearn: 2.6881815\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16679:\tlearn: 2.6880657\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16680:\tlearn: 2.6879599\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16681:\tlearn: 2.6878833\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16682:\tlearn: 2.6878092\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16683:\tlearn: 2.6876477\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16684:\tlearn: 2.6874843\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16685:\tlearn: 2.6874189\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16686:\tlearn: 2.6872690\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16687:\tlearn: 2.6871679\ttotal: 6m 2s\tremaining: 2m 17s\n",
      "16688:\tlearn: 2.6870692\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16689:\tlearn: 2.6869200\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16690:\tlearn: 2.6868464\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16691:\tlearn: 2.6867322\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16692:\tlearn: 2.6866521\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16693:\tlearn: 2.6865420\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16694:\tlearn: 2.6864638\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16695:\tlearn: 2.6863519\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16696:\tlearn: 2.6862522\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16697:\tlearn: 2.6861479\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16698:\tlearn: 2.6860127\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16699:\tlearn: 2.6858730\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16700:\tlearn: 2.6857755\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16701:\tlearn: 2.6856845\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16702:\tlearn: 2.6855753\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16703:\tlearn: 2.6854615\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16704:\tlearn: 2.6853288\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16705:\tlearn: 2.6851447\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16706:\tlearn: 2.6850660\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16707:\tlearn: 2.6849455\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16708:\tlearn: 2.6848761\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16709:\tlearn: 2.6847824\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16710:\tlearn: 2.6846915\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16711:\tlearn: 2.6846084\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16712:\tlearn: 2.6845331\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16713:\tlearn: 2.6845310\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16714:\tlearn: 2.6844263\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16715:\tlearn: 2.6844243\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16716:\tlearn: 2.6843315\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16717:\tlearn: 2.6843287\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16718:\tlearn: 2.6843268\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16719:\tlearn: 2.6842247\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16720:\tlearn: 2.6840968\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16721:\tlearn: 2.6840247\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16722:\tlearn: 2.6839631\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16723:\tlearn: 2.6838385\ttotal: 6m 2s\tremaining: 2m 16s\n",
      "16724:\tlearn: 2.6837300\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16725:\tlearn: 2.6836708\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16726:\tlearn: 2.6835821\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16727:\tlearn: 2.6835288\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16728:\tlearn: 2.6833874\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16729:\tlearn: 2.6832655\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16730:\tlearn: 2.6831774\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16731:\tlearn: 2.6830962\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16732:\tlearn: 2.6829932\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16733:\tlearn: 2.6829351\ttotal: 6m 3s\tremaining: 2m 16s\n",
      "16734:\tlearn: 2.6829011\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16735:\tlearn: 2.6828059\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16736:\tlearn: 2.6826858\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16737:\tlearn: 2.6825085\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16738:\tlearn: 2.6823751\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16739:\tlearn: 2.6822966\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16740:\tlearn: 2.6821851\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16741:\tlearn: 2.6820854\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16742:\tlearn: 2.6819914\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16743:\tlearn: 2.6818874\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16744:\tlearn: 2.6816815\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16745:\tlearn: 2.6815877\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16746:\tlearn: 2.6815004\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16747:\tlearn: 2.6813409\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16748:\tlearn: 2.6811939\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16749:\tlearn: 2.6811007\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16750:\tlearn: 2.6809798\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16751:\tlearn: 2.6808656\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16752:\tlearn: 2.6807779\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16753:\tlearn: 2.6807260\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16754:\tlearn: 2.6806375\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16755:\tlearn: 2.6805640\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16756:\tlearn: 2.6804454\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16757:\tlearn: 2.6803496\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16758:\tlearn: 2.6802824\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16759:\tlearn: 2.6802025\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16760:\tlearn: 2.6801196\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16761:\tlearn: 2.6800026\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16762:\tlearn: 2.6799790\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16763:\tlearn: 2.6798725\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16764:\tlearn: 2.6798533\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16765:\tlearn: 2.6797213\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16766:\tlearn: 2.6795939\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16767:\tlearn: 2.6793995\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16768:\tlearn: 2.6792980\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16769:\tlearn: 2.6791997\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16770:\tlearn: 2.6791145\ttotal: 6m 3s\tremaining: 2m 15s\n",
      "16771:\tlearn: 2.6789546\ttotal: 6m 4s\tremaining: 2m 15s\n",
      "16772:\tlearn: 2.6787607\ttotal: 6m 4s\tremaining: 2m 15s\n",
      "16773:\tlearn: 2.6786734\ttotal: 6m 4s\tremaining: 2m 15s\n",
      "16774:\tlearn: 2.6786142\ttotal: 6m 4s\tremaining: 2m 15s\n",
      "16775:\tlearn: 2.6786118\ttotal: 6m 4s\tremaining: 2m 15s\n",
      "16776:\tlearn: 2.6784912\ttotal: 6m 4s\tremaining: 2m 15s\n",
      "16777:\tlearn: 2.6783597\ttotal: 6m 4s\tremaining: 2m 15s\n",
      "16778:\tlearn: 2.6783058\ttotal: 6m 4s\tremaining: 2m 15s\n",
      "16779:\tlearn: 2.6781925\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16780:\tlearn: 2.6781306\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16781:\tlearn: 2.6779525\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16782:\tlearn: 2.6778669\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16783:\tlearn: 2.6777568\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16784:\tlearn: 2.6776858\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16785:\tlearn: 2.6775869\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16786:\tlearn: 2.6774750\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16787:\tlearn: 2.6773896\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16788:\tlearn: 2.6773230\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16789:\tlearn: 2.6772447\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16790:\tlearn: 2.6770887\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16791:\tlearn: 2.6769768\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16792:\tlearn: 2.6768256\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16793:\tlearn: 2.6767287\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16794:\tlearn: 2.6766061\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16795:\tlearn: 2.6765353\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16796:\tlearn: 2.6763195\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16797:\tlearn: 2.6762498\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16798:\tlearn: 2.6761715\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16799:\tlearn: 2.6760994\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16800:\tlearn: 2.6759581\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16801:\tlearn: 2.6758330\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16802:\tlearn: 2.6757274\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16803:\tlearn: 2.6755636\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16804:\tlearn: 2.6753820\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16805:\tlearn: 2.6752929\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16806:\tlearn: 2.6752899\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16807:\tlearn: 2.6752119\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16808:\tlearn: 2.6751360\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16809:\tlearn: 2.6750081\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16810:\tlearn: 2.6748118\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16811:\tlearn: 2.6747251\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16812:\tlearn: 2.6746787\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16813:\tlearn: 2.6745595\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16814:\tlearn: 2.6744766\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16815:\tlearn: 2.6743443\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16816:\tlearn: 2.6742688\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16817:\tlearn: 2.6741679\ttotal: 6m 4s\tremaining: 2m 14s\n",
      "16818:\tlearn: 2.6740838\ttotal: 6m 5s\tremaining: 2m 14s\n",
      "16819:\tlearn: 2.6739450\ttotal: 6m 5s\tremaining: 2m 14s\n",
      "16820:\tlearn: 2.6738533\ttotal: 6m 5s\tremaining: 2m 14s\n",
      "16821:\tlearn: 2.6738230\ttotal: 6m 5s\tremaining: 2m 14s\n",
      "16822:\tlearn: 2.6737691\ttotal: 6m 5s\tremaining: 2m 14s\n",
      "16823:\tlearn: 2.6736528\ttotal: 6m 5s\tremaining: 2m 14s\n",
      "16824:\tlearn: 2.6735486\ttotal: 6m 5s\tremaining: 2m 14s\n",
      "16825:\tlearn: 2.6734635\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16826:\tlearn: 2.6733136\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16827:\tlearn: 2.6732006\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16828:\tlearn: 2.6730883\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16829:\tlearn: 2.6729348\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16830:\tlearn: 2.6728232\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16831:\tlearn: 2.6727233\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16832:\tlearn: 2.6726324\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16833:\tlearn: 2.6726024\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16834:\tlearn: 2.6724670\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16835:\tlearn: 2.6723605\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16836:\tlearn: 2.6722484\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16837:\tlearn: 2.6721080\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16838:\tlearn: 2.6719020\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16839:\tlearn: 2.6719000\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16840:\tlearn: 2.6718200\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16841:\tlearn: 2.6717609\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16842:\tlearn: 2.6716765\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16843:\tlearn: 2.6715297\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16844:\tlearn: 2.6713737\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16845:\tlearn: 2.6712648\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16846:\tlearn: 2.6710876\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16847:\tlearn: 2.6709933\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16848:\tlearn: 2.6709047\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16849:\tlearn: 2.6708380\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16850:\tlearn: 2.6707859\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16851:\tlearn: 2.6706604\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16852:\tlearn: 2.6705329\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16853:\tlearn: 2.6704684\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16854:\tlearn: 2.6702872\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16855:\tlearn: 2.6702106\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16856:\tlearn: 2.6701397\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16857:\tlearn: 2.6700274\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16858:\tlearn: 2.6699683\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16859:\tlearn: 2.6698566\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16860:\tlearn: 2.6697553\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16861:\tlearn: 2.6695595\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16862:\tlearn: 2.6694502\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "16863:\tlearn: 2.6694079\ttotal: 6m 6s\tremaining: 2m 13s\n",
      "16864:\tlearn: 2.6692748\ttotal: 6m 6s\tremaining: 2m 13s\n",
      "16865:\tlearn: 2.6692248\ttotal: 6m 6s\tremaining: 2m 13s\n",
      "16866:\tlearn: 2.6690947\ttotal: 6m 6s\tremaining: 2m 13s\n",
      "16867:\tlearn: 2.6688993\ttotal: 6m 6s\tremaining: 2m 13s\n",
      "16868:\tlearn: 2.6687906\ttotal: 6m 6s\tremaining: 2m 13s\n",
      "16869:\tlearn: 2.6686712\ttotal: 6m 6s\tremaining: 2m 13s\n",
      "16870:\tlearn: 2.6685277\ttotal: 6m 6s\tremaining: 2m 13s\n",
      "16871:\tlearn: 2.6684171\ttotal: 6m 6s\tremaining: 2m 13s\n",
      "16872:\tlearn: 2.6683032\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16873:\tlearn: 2.6681284\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16874:\tlearn: 2.6680260\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16875:\tlearn: 2.6679255\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16876:\tlearn: 2.6678389\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16877:\tlearn: 2.6677533\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16878:\tlearn: 2.6676730\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16879:\tlearn: 2.6676065\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16880:\tlearn: 2.6675266\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16881:\tlearn: 2.6674402\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16882:\tlearn: 2.6673061\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16883:\tlearn: 2.6672003\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16884:\tlearn: 2.6670559\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16885:\tlearn: 2.6669260\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16886:\tlearn: 2.6667827\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16887:\tlearn: 2.6666809\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16888:\tlearn: 2.6666440\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16889:\tlearn: 2.6665746\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16890:\tlearn: 2.6664980\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16891:\tlearn: 2.6663982\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16892:\tlearn: 2.6663344\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16893:\tlearn: 2.6663318\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16894:\tlearn: 2.6662258\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16895:\tlearn: 2.6661362\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16896:\tlearn: 2.6660644\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16897:\tlearn: 2.6659908\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16898:\tlearn: 2.6658627\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16899:\tlearn: 2.6657387\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16900:\tlearn: 2.6656465\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16901:\tlearn: 2.6655529\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16902:\tlearn: 2.6654444\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16903:\tlearn: 2.6654146\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16904:\tlearn: 2.6653311\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16905:\tlearn: 2.6652504\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16906:\tlearn: 2.6650654\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16907:\tlearn: 2.6648799\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16908:\tlearn: 2.6647898\ttotal: 6m 6s\tremaining: 2m 12s\n",
      "16909:\tlearn: 2.6647409\ttotal: 6m 7s\tremaining: 2m 12s\n",
      "16910:\tlearn: 2.6646509\ttotal: 6m 7s\tremaining: 2m 12s\n",
      "16911:\tlearn: 2.6645846\ttotal: 6m 7s\tremaining: 2m 12s\n",
      "16912:\tlearn: 2.6644846\ttotal: 6m 7s\tremaining: 2m 12s\n",
      "16913:\tlearn: 2.6644038\ttotal: 6m 7s\tremaining: 2m 12s\n",
      "16914:\tlearn: 2.6642394\ttotal: 6m 7s\tremaining: 2m 12s\n",
      "16915:\tlearn: 2.6641026\ttotal: 6m 7s\tremaining: 2m 12s\n",
      "16916:\tlearn: 2.6639700\ttotal: 6m 7s\tremaining: 2m 12s\n",
      "16917:\tlearn: 2.6638852\ttotal: 6m 7s\tremaining: 2m 12s\n",
      "16918:\tlearn: 2.6638114\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16919:\tlearn: 2.6636824\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16920:\tlearn: 2.6635580\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16921:\tlearn: 2.6633762\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16922:\tlearn: 2.6632977\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16923:\tlearn: 2.6632388\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16924:\tlearn: 2.6631635\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16925:\tlearn: 2.6630660\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16926:\tlearn: 2.6629883\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16927:\tlearn: 2.6628756\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16928:\tlearn: 2.6627203\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16929:\tlearn: 2.6626841\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16930:\tlearn: 2.6625726\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16931:\tlearn: 2.6624119\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16932:\tlearn: 2.6622544\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16933:\tlearn: 2.6621686\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16934:\tlearn: 2.6621126\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16935:\tlearn: 2.6619909\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16936:\tlearn: 2.6618996\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16937:\tlearn: 2.6617511\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16938:\tlearn: 2.6615991\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16939:\tlearn: 2.6615364\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16940:\tlearn: 2.6615043\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16941:\tlearn: 2.6613588\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16942:\tlearn: 2.6612398\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16943:\tlearn: 2.6611486\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16944:\tlearn: 2.6610541\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16945:\tlearn: 2.6609766\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16946:\tlearn: 2.6607798\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16947:\tlearn: 2.6606686\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16948:\tlearn: 2.6605452\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16949:\tlearn: 2.6603166\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16950:\tlearn: 2.6601327\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16951:\tlearn: 2.6600112\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16952:\tlearn: 2.6598910\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16953:\tlearn: 2.6597693\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16954:\tlearn: 2.6596792\ttotal: 6m 7s\tremaining: 2m 11s\n",
      "16955:\tlearn: 2.6595566\ttotal: 6m 8s\tremaining: 2m 11s\n",
      "16956:\tlearn: 2.6594931\ttotal: 6m 8s\tremaining: 2m 11s\n",
      "16957:\tlearn: 2.6593627\ttotal: 6m 8s\tremaining: 2m 11s\n",
      "16958:\tlearn: 2.6593177\ttotal: 6m 8s\tremaining: 2m 11s\n",
      "16959:\tlearn: 2.6592672\ttotal: 6m 8s\tremaining: 2m 11s\n",
      "16960:\tlearn: 2.6591691\ttotal: 6m 8s\tremaining: 2m 11s\n",
      "16961:\tlearn: 2.6590810\ttotal: 6m 8s\tremaining: 2m 11s\n",
      "16962:\tlearn: 2.6589280\ttotal: 6m 8s\tremaining: 2m 11s\n",
      "16963:\tlearn: 2.6587849\ttotal: 6m 8s\tremaining: 2m 11s\n",
      "16964:\tlearn: 2.6586597\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16965:\tlearn: 2.6585601\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16966:\tlearn: 2.6584605\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16967:\tlearn: 2.6583823\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16968:\tlearn: 2.6582762\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16969:\tlearn: 2.6582086\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16970:\tlearn: 2.6580691\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16971:\tlearn: 2.6580014\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16972:\tlearn: 2.6578888\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16973:\tlearn: 2.6578298\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16974:\tlearn: 2.6577763\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16975:\tlearn: 2.6577169\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16976:\tlearn: 2.6576217\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16977:\tlearn: 2.6575593\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16978:\tlearn: 2.6574770\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16979:\tlearn: 2.6574417\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16980:\tlearn: 2.6573184\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16981:\tlearn: 2.6572197\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16982:\tlearn: 2.6571058\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16983:\tlearn: 2.6569957\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16984:\tlearn: 2.6569005\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16985:\tlearn: 2.6568287\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16986:\tlearn: 2.6567345\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16987:\tlearn: 2.6566679\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16988:\tlearn: 2.6565685\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16989:\tlearn: 2.6564880\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16990:\tlearn: 2.6563700\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16991:\tlearn: 2.6563557\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16992:\tlearn: 2.6562784\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16993:\tlearn: 2.6561807\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16994:\tlearn: 2.6561143\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16995:\tlearn: 2.6560213\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16996:\tlearn: 2.6559211\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16997:\tlearn: 2.6558888\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16998:\tlearn: 2.6558027\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "16999:\tlearn: 2.6557530\ttotal: 6m 8s\tremaining: 2m 10s\n",
      "17000:\tlearn: 2.6556516\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17001:\tlearn: 2.6555151\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17002:\tlearn: 2.6554504\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17003:\tlearn: 2.6553269\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17004:\tlearn: 2.6552211\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17005:\tlearn: 2.6550874\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17006:\tlearn: 2.6549861\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17007:\tlearn: 2.6548922\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17008:\tlearn: 2.6548099\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17009:\tlearn: 2.6547096\ttotal: 6m 9s\tremaining: 2m 10s\n",
      "17010:\tlearn: 2.6545721\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17011:\tlearn: 2.6544662\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17012:\tlearn: 2.6543965\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17013:\tlearn: 2.6542682\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17014:\tlearn: 2.6541605\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17015:\tlearn: 2.6540723\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17016:\tlearn: 2.6540165\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17017:\tlearn: 2.6539169\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17018:\tlearn: 2.6537760\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17019:\tlearn: 2.6536357\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17020:\tlearn: 2.6535010\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17021:\tlearn: 2.6533617\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17022:\tlearn: 2.6532394\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17023:\tlearn: 2.6531070\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17024:\tlearn: 2.6530246\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17025:\tlearn: 2.6529691\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17026:\tlearn: 2.6528799\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17027:\tlearn: 2.6528306\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17028:\tlearn: 2.6527342\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17029:\tlearn: 2.6526189\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17030:\tlearn: 2.6525090\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17031:\tlearn: 2.6524498\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17032:\tlearn: 2.6523445\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17033:\tlearn: 2.6523419\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17034:\tlearn: 2.6522312\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17035:\tlearn: 2.6520831\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17036:\tlearn: 2.6519454\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17037:\tlearn: 2.6518558\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17038:\tlearn: 2.6517250\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17039:\tlearn: 2.6515996\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17040:\tlearn: 2.6515018\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17041:\tlearn: 2.6513310\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17042:\tlearn: 2.6511709\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17043:\tlearn: 2.6510245\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17044:\tlearn: 2.6509449\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17045:\tlearn: 2.6508408\ttotal: 6m 9s\tremaining: 2m 9s\n",
      "17046:\tlearn: 2.6507399\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17047:\tlearn: 2.6505855\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17048:\tlearn: 2.6505352\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17049:\tlearn: 2.6504828\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17050:\tlearn: 2.6503335\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17051:\tlearn: 2.6502850\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17052:\tlearn: 2.6501851\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17053:\tlearn: 2.6500284\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17054:\tlearn: 2.6498478\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17055:\tlearn: 2.6497792\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17056:\tlearn: 2.6496906\ttotal: 6m 10s\tremaining: 2m 9s\n",
      "17057:\tlearn: 2.6496206\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17058:\tlearn: 2.6495320\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17059:\tlearn: 2.6493803\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17060:\tlearn: 2.6493078\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17061:\tlearn: 2.6491248\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17062:\tlearn: 2.6490562\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17063:\tlearn: 2.6489645\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17064:\tlearn: 2.6489065\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17065:\tlearn: 2.6487764\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17066:\tlearn: 2.6487225\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17067:\tlearn: 2.6486444\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17068:\tlearn: 2.6486423\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17069:\tlearn: 2.6485014\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17070:\tlearn: 2.6484303\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17071:\tlearn: 2.6483815\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17072:\tlearn: 2.6483221\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17073:\tlearn: 2.6481747\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17074:\tlearn: 2.6480851\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17075:\tlearn: 2.6480118\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17076:\tlearn: 2.6478846\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17077:\tlearn: 2.6477638\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17078:\tlearn: 2.6476804\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17079:\tlearn: 2.6476342\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17080:\tlearn: 2.6476045\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17081:\tlearn: 2.6474799\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17082:\tlearn: 2.6473825\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17083:\tlearn: 2.6473135\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17084:\tlearn: 2.6472481\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17085:\tlearn: 2.6471634\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17086:\tlearn: 2.6470747\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17087:\tlearn: 2.6470353\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17088:\tlearn: 2.6469529\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17089:\tlearn: 2.6468321\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17090:\tlearn: 2.6467185\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17091:\tlearn: 2.6466664\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "17092:\tlearn: 2.6465985\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17093:\tlearn: 2.6465061\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17094:\tlearn: 2.6463610\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17095:\tlearn: 2.6462769\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17096:\tlearn: 2.6461737\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17097:\tlearn: 2.6461047\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17098:\tlearn: 2.6459906\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17099:\tlearn: 2.6459176\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17100:\tlearn: 2.6458640\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17101:\tlearn: 2.6457278\ttotal: 6m 11s\tremaining: 2m 8s\n",
      "17102:\tlearn: 2.6456673\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17103:\tlearn: 2.6455318\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17104:\tlearn: 2.6454214\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17105:\tlearn: 2.6453349\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17106:\tlearn: 2.6452768\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17107:\tlearn: 2.6452274\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17108:\tlearn: 2.6450975\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17109:\tlearn: 2.6449110\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17110:\tlearn: 2.6447284\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17111:\tlearn: 2.6446324\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17112:\tlearn: 2.6445423\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17113:\tlearn: 2.6444692\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17114:\tlearn: 2.6443833\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17115:\tlearn: 2.6443015\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17116:\tlearn: 2.6442275\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17117:\tlearn: 2.6441435\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17118:\tlearn: 2.6440338\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17119:\tlearn: 2.6438183\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17120:\tlearn: 2.6437044\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17121:\tlearn: 2.6436143\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17122:\tlearn: 2.6434936\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17123:\tlearn: 2.6434118\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17124:\tlearn: 2.6433503\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17125:\tlearn: 2.6432322\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17126:\tlearn: 2.6431868\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17127:\tlearn: 2.6431204\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17128:\tlearn: 2.6430301\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17129:\tlearn: 2.6429180\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17130:\tlearn: 2.6428611\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17131:\tlearn: 2.6428007\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17132:\tlearn: 2.6426297\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17133:\tlearn: 2.6425185\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17134:\tlearn: 2.6424034\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17135:\tlearn: 2.6422754\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17136:\tlearn: 2.6421892\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17137:\tlearn: 2.6420512\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "17138:\tlearn: 2.6419521\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17139:\tlearn: 2.6419494\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17140:\tlearn: 2.6418626\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17141:\tlearn: 2.6417123\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17142:\tlearn: 2.6416105\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17143:\tlearn: 2.6415223\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17144:\tlearn: 2.6413779\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17145:\tlearn: 2.6412867\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17146:\tlearn: 2.6411885\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17147:\tlearn: 2.6410907\ttotal: 6m 12s\tremaining: 2m 7s\n",
      "17148:\tlearn: 2.6410194\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17149:\tlearn: 2.6408798\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17150:\tlearn: 2.6407615\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17151:\tlearn: 2.6406958\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17152:\tlearn: 2.6405789\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17153:\tlearn: 2.6404880\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17154:\tlearn: 2.6404063\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17155:\tlearn: 2.6402596\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17156:\tlearn: 2.6401968\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17157:\tlearn: 2.6401361\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17158:\tlearn: 2.6400117\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17159:\tlearn: 2.6399563\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17160:\tlearn: 2.6398614\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17161:\tlearn: 2.6397081\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17162:\tlearn: 2.6395985\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17163:\tlearn: 2.6394785\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17164:\tlearn: 2.6393911\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17165:\tlearn: 2.6392127\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17166:\tlearn: 2.6391618\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17167:\tlearn: 2.6390519\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17168:\tlearn: 2.6389585\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17169:\tlearn: 2.6388081\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17170:\tlearn: 2.6387113\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17171:\tlearn: 2.6385586\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17172:\tlearn: 2.6384946\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17173:\tlearn: 2.6383640\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17174:\tlearn: 2.6382884\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17175:\tlearn: 2.6381469\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17176:\tlearn: 2.6380289\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17177:\tlearn: 2.6379150\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17178:\tlearn: 2.6378610\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17179:\tlearn: 2.6378577\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17180:\tlearn: 2.6378048\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17181:\tlearn: 2.6377880\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17182:\tlearn: 2.6376964\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17183:\tlearn: 2.6375634\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17184:\tlearn: 2.6374629\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17185:\tlearn: 2.6373514\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "17186:\tlearn: 2.6371945\ttotal: 6m 13s\tremaining: 2m 6s\n",
      "17187:\tlearn: 2.6370600\ttotal: 6m 13s\tremaining: 2m 6s\n",
      "17188:\tlearn: 2.6369306\ttotal: 6m 13s\tremaining: 2m 6s\n",
      "17189:\tlearn: 2.6368093\ttotal: 6m 13s\tremaining: 2m 6s\n",
      "17190:\tlearn: 2.6367134\ttotal: 6m 13s\tremaining: 2m 6s\n",
      "17191:\tlearn: 2.6365757\ttotal: 6m 13s\tremaining: 2m 6s\n",
      "17192:\tlearn: 2.6364140\ttotal: 6m 13s\tremaining: 2m 6s\n",
      "17193:\tlearn: 2.6362455\ttotal: 6m 13s\tremaining: 2m 6s\n",
      "17194:\tlearn: 2.6360805\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17195:\tlearn: 2.6359286\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17196:\tlearn: 2.6358001\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17197:\tlearn: 2.6357300\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17198:\tlearn: 2.6357273\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17199:\tlearn: 2.6356647\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17200:\tlearn: 2.6355743\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17201:\tlearn: 2.6354864\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17202:\tlearn: 2.6353028\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17203:\tlearn: 2.6352191\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17204:\tlearn: 2.6350548\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17205:\tlearn: 2.6349630\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17206:\tlearn: 2.6348423\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17207:\tlearn: 2.6346980\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17208:\tlearn: 2.6346211\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17209:\tlearn: 2.6345424\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17210:\tlearn: 2.6344211\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17211:\tlearn: 2.6343416\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17212:\tlearn: 2.6341492\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17213:\tlearn: 2.6339909\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17214:\tlearn: 2.6338589\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17215:\tlearn: 2.6337572\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17216:\tlearn: 2.6335962\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17217:\tlearn: 2.6335125\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17218:\tlearn: 2.6334099\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17219:\tlearn: 2.6332520\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17220:\tlearn: 2.6331339\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17221:\tlearn: 2.6330165\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17222:\tlearn: 2.6329075\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17223:\tlearn: 2.6327888\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17224:\tlearn: 2.6327371\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17225:\tlearn: 2.6326902\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17226:\tlearn: 2.6325994\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17227:\tlearn: 2.6324682\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17228:\tlearn: 2.6322748\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17229:\tlearn: 2.6321991\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17230:\tlearn: 2.6321029\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17231:\tlearn: 2.6320586\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "17232:\tlearn: 2.6319619\ttotal: 6m 14s\tremaining: 2m 5s\n",
      "17233:\tlearn: 2.6318934\ttotal: 6m 14s\tremaining: 2m 5s\n",
      "17234:\tlearn: 2.6318033\ttotal: 6m 14s\tremaining: 2m 5s\n",
      "17235:\tlearn: 2.6316890\ttotal: 6m 14s\tremaining: 2m 5s\n",
      "17236:\tlearn: 2.6316588\ttotal: 6m 14s\tremaining: 2m 5s\n",
      "17237:\tlearn: 2.6314795\ttotal: 6m 14s\tremaining: 2m 5s\n",
      "17238:\tlearn: 2.6314270\ttotal: 6m 14s\tremaining: 2m 5s\n",
      "17239:\tlearn: 2.6312776\ttotal: 6m 14s\tremaining: 2m 5s\n",
      "17240:\tlearn: 2.6311441\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17241:\tlearn: 2.6310724\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17242:\tlearn: 2.6309645\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17243:\tlearn: 2.6308316\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17244:\tlearn: 2.6308108\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17245:\tlearn: 2.6307255\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17246:\tlearn: 2.6306387\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17247:\tlearn: 2.6305737\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17248:\tlearn: 2.6304557\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17249:\tlearn: 2.6303620\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17250:\tlearn: 2.6302313\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17251:\tlearn: 2.6301297\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17252:\tlearn: 2.6300463\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17253:\tlearn: 2.6299706\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17254:\tlearn: 2.6298757\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17255:\tlearn: 2.6297982\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17256:\tlearn: 2.6296962\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17257:\tlearn: 2.6296555\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17258:\tlearn: 2.6295617\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17259:\tlearn: 2.6294884\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17260:\tlearn: 2.6293894\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17261:\tlearn: 2.6292544\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17262:\tlearn: 2.6291168\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17263:\tlearn: 2.6290357\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17264:\tlearn: 2.6289743\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17265:\tlearn: 2.6288909\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17266:\tlearn: 2.6288448\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17267:\tlearn: 2.6287904\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17268:\tlearn: 2.6286985\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17269:\tlearn: 2.6285974\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17270:\tlearn: 2.6284770\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17271:\tlearn: 2.6284220\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17272:\tlearn: 2.6283223\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17273:\tlearn: 2.6282031\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17274:\tlearn: 2.6281330\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17275:\tlearn: 2.6280582\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17276:\tlearn: 2.6279049\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17277:\tlearn: 2.6278379\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17278:\tlearn: 2.6277154\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "17279:\tlearn: 2.6276529\ttotal: 6m 15s\tremaining: 2m 4s\n",
      "17280:\tlearn: 2.6275263\ttotal: 6m 15s\tremaining: 2m 4s\n",
      "17281:\tlearn: 2.6273984\ttotal: 6m 15s\tremaining: 2m 4s\n",
      "17282:\tlearn: 2.6273345\ttotal: 6m 15s\tremaining: 2m 4s\n",
      "17283:\tlearn: 2.6272285\ttotal: 6m 15s\tremaining: 2m 4s\n",
      "17284:\tlearn: 2.6271744\ttotal: 6m 15s\tremaining: 2m 4s\n",
      "17285:\tlearn: 2.6270615\ttotal: 6m 15s\tremaining: 2m 4s\n",
      "17286:\tlearn: 2.6269894\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17287:\tlearn: 2.6269110\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17288:\tlearn: 2.6268454\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17289:\tlearn: 2.6267800\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17290:\tlearn: 2.6267780\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17291:\tlearn: 2.6266529\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17292:\tlearn: 2.6265197\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17293:\tlearn: 2.6263790\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17294:\tlearn: 2.6262815\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17295:\tlearn: 2.6261734\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17296:\tlearn: 2.6260783\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17297:\tlearn: 2.6259314\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17298:\tlearn: 2.6258502\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17299:\tlearn: 2.6257656\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17300:\tlearn: 2.6256315\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17301:\tlearn: 2.6255398\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17302:\tlearn: 2.6254602\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17303:\tlearn: 2.6254046\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17304:\tlearn: 2.6253229\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17305:\tlearn: 2.6252667\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17306:\tlearn: 2.6251445\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17307:\tlearn: 2.6250525\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17308:\tlearn: 2.6249824\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17309:\tlearn: 2.6248667\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17310:\tlearn: 2.6246855\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17311:\tlearn: 2.6246129\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17312:\tlearn: 2.6244376\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17313:\tlearn: 2.6243377\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17314:\tlearn: 2.6242619\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17315:\tlearn: 2.6241718\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17316:\tlearn: 2.6239988\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17317:\tlearn: 2.6239510\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17318:\tlearn: 2.6238655\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17319:\tlearn: 2.6237553\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17320:\tlearn: 2.6237003\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17321:\tlearn: 2.6236133\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17322:\tlearn: 2.6234817\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17323:\tlearn: 2.6234000\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17324:\tlearn: 2.6232958\ttotal: 6m 15s\tremaining: 2m 3s\n",
      "17325:\tlearn: 2.6231997\ttotal: 6m 16s\tremaining: 2m 3s\n",
      "17326:\tlearn: 2.6230975\ttotal: 6m 16s\tremaining: 2m 3s\n",
      "17327:\tlearn: 2.6230945\ttotal: 6m 16s\tremaining: 2m 3s\n",
      "17328:\tlearn: 2.6229231\ttotal: 6m 16s\tremaining: 2m 3s\n",
      "17329:\tlearn: 2.6227371\ttotal: 6m 16s\tremaining: 2m 3s\n",
      "17330:\tlearn: 2.6225663\ttotal: 6m 16s\tremaining: 2m 3s\n",
      "17331:\tlearn: 2.6225166\ttotal: 6m 16s\tremaining: 2m 3s\n",
      "17332:\tlearn: 2.6224230\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17333:\tlearn: 2.6223611\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17334:\tlearn: 2.6222542\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17335:\tlearn: 2.6222009\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17336:\tlearn: 2.6220454\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17337:\tlearn: 2.6218524\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17338:\tlearn: 2.6217260\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17339:\tlearn: 2.6216830\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17340:\tlearn: 2.6215701\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17341:\tlearn: 2.6214100\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17342:\tlearn: 2.6212963\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17343:\tlearn: 2.6211982\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17344:\tlearn: 2.6211607\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17345:\tlearn: 2.6211091\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17346:\tlearn: 2.6210479\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17347:\tlearn: 2.6209008\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17348:\tlearn: 2.6207910\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17349:\tlearn: 2.6206515\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17350:\tlearn: 2.6204681\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17351:\tlearn: 2.6203604\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17352:\tlearn: 2.6202353\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17353:\tlearn: 2.6201138\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17354:\tlearn: 2.6199621\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17355:\tlearn: 2.6198608\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17356:\tlearn: 2.6197872\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17357:\tlearn: 2.6195888\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17358:\tlearn: 2.6194805\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17359:\tlearn: 2.6194795\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17360:\tlearn: 2.6193648\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17361:\tlearn: 2.6193099\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17362:\tlearn: 2.6192111\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17363:\tlearn: 2.6190184\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17364:\tlearn: 2.6189128\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17365:\tlearn: 2.6188057\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17366:\tlearn: 2.6187426\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17367:\tlearn: 2.6186091\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17368:\tlearn: 2.6185236\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17369:\tlearn: 2.6184575\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17370:\tlearn: 2.6183426\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17371:\tlearn: 2.6182571\ttotal: 6m 16s\tremaining: 2m 2s\n",
      "17372:\tlearn: 2.6181700\ttotal: 6m 17s\tremaining: 2m 2s\n",
      "17373:\tlearn: 2.6180698\ttotal: 6m 17s\tremaining: 2m 2s\n",
      "17374:\tlearn: 2.6179792\ttotal: 6m 17s\tremaining: 2m 2s\n",
      "17375:\tlearn: 2.6179778\ttotal: 6m 17s\tremaining: 2m 2s\n",
      "17376:\tlearn: 2.6178684\ttotal: 6m 17s\tremaining: 2m 2s\n",
      "17377:\tlearn: 2.6177663\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17378:\tlearn: 2.6176891\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17379:\tlearn: 2.6175650\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17380:\tlearn: 2.6173590\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17381:\tlearn: 2.6172790\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17382:\tlearn: 2.6171743\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17383:\tlearn: 2.6171027\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17384:\tlearn: 2.6170156\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17385:\tlearn: 2.6167867\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17386:\tlearn: 2.6166644\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17387:\tlearn: 2.6165404\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17388:\tlearn: 2.6164722\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17389:\tlearn: 2.6163502\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17390:\tlearn: 2.6161578\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17391:\tlearn: 2.6161557\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17392:\tlearn: 2.6160228\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17393:\tlearn: 2.6159337\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17394:\tlearn: 2.6159302\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17395:\tlearn: 2.6158476\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17396:\tlearn: 2.6158049\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17397:\tlearn: 2.6156042\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17398:\tlearn: 2.6155151\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17399:\tlearn: 2.6154007\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17400:\tlearn: 2.6152586\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17401:\tlearn: 2.6151274\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17402:\tlearn: 2.6150495\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17403:\tlearn: 2.6149375\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17404:\tlearn: 2.6148486\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17405:\tlearn: 2.6148380\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17406:\tlearn: 2.6147096\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17407:\tlearn: 2.6145724\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17408:\tlearn: 2.6144626\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17409:\tlearn: 2.6144166\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17410:\tlearn: 2.6142585\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17411:\tlearn: 2.6141718\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17412:\tlearn: 2.6140718\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17413:\tlearn: 2.6139341\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17414:\tlearn: 2.6138256\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17415:\tlearn: 2.6137563\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17416:\tlearn: 2.6136408\ttotal: 6m 17s\tremaining: 2m 1s\n",
      "17417:\tlearn: 2.6135415\ttotal: 6m 18s\tremaining: 2m 1s\n",
      "17418:\tlearn: 2.6134456\ttotal: 6m 18s\tremaining: 2m 1s\n",
      "17419:\tlearn: 2.6133459\ttotal: 6m 18s\tremaining: 2m 1s\n",
      "17420:\tlearn: 2.6131924\ttotal: 6m 18s\tremaining: 2m 1s\n",
      "17421:\tlearn: 2.6130912\ttotal: 6m 18s\tremaining: 2m 1s\n",
      "17422:\tlearn: 2.6129808\ttotal: 6m 18s\tremaining: 2m 1s\n",
      "17423:\tlearn: 2.6129208\ttotal: 6m 18s\tremaining: 2m 1s\n",
      "17424:\tlearn: 2.6128475\ttotal: 6m 18s\tremaining: 2m\n",
      "17425:\tlearn: 2.6127997\ttotal: 6m 18s\tremaining: 2m\n",
      "17426:\tlearn: 2.6126737\ttotal: 6m 18s\tremaining: 2m\n",
      "17427:\tlearn: 2.6125647\ttotal: 6m 18s\tremaining: 2m\n",
      "17428:\tlearn: 2.6125279\ttotal: 6m 18s\tremaining: 2m\n",
      "17429:\tlearn: 2.6124598\ttotal: 6m 18s\tremaining: 2m\n",
      "17430:\tlearn: 2.6123817\ttotal: 6m 18s\tremaining: 2m\n",
      "17431:\tlearn: 2.6122439\ttotal: 6m 18s\tremaining: 2m\n",
      "17432:\tlearn: 2.6120764\ttotal: 6m 18s\tremaining: 2m\n",
      "17433:\tlearn: 2.6119792\ttotal: 6m 18s\tremaining: 2m\n",
      "17434:\tlearn: 2.6118749\ttotal: 6m 18s\tremaining: 2m\n",
      "17435:\tlearn: 2.6118324\ttotal: 6m 18s\tremaining: 2m\n",
      "17436:\tlearn: 2.6117341\ttotal: 6m 18s\tremaining: 2m\n",
      "17437:\tlearn: 2.6116354\ttotal: 6m 18s\tremaining: 2m\n",
      "17438:\tlearn: 2.6115198\ttotal: 6m 18s\tremaining: 2m\n",
      "17439:\tlearn: 2.6114494\ttotal: 6m 18s\tremaining: 2m\n",
      "17440:\tlearn: 2.6113430\ttotal: 6m 18s\tremaining: 2m\n",
      "17441:\tlearn: 2.6112452\ttotal: 6m 18s\tremaining: 2m\n",
      "17442:\tlearn: 2.6111600\ttotal: 6m 18s\tremaining: 2m\n",
      "17443:\tlearn: 2.6110946\ttotal: 6m 18s\tremaining: 2m\n",
      "17444:\tlearn: 2.6110078\ttotal: 6m 18s\tremaining: 2m\n",
      "17445:\tlearn: 2.6109590\ttotal: 6m 18s\tremaining: 2m\n",
      "17446:\tlearn: 2.6108567\ttotal: 6m 18s\tremaining: 2m\n",
      "17447:\tlearn: 2.6107068\ttotal: 6m 18s\tremaining: 2m\n",
      "17448:\tlearn: 2.6105997\ttotal: 6m 18s\tremaining: 2m\n",
      "17449:\tlearn: 2.6105254\ttotal: 6m 18s\tremaining: 2m\n",
      "17450:\tlearn: 2.6103763\ttotal: 6m 18s\tremaining: 2m\n",
      "17451:\tlearn: 2.6103010\ttotal: 6m 18s\tremaining: 2m\n",
      "17452:\tlearn: 2.6102092\ttotal: 6m 18s\tremaining: 2m\n",
      "17453:\tlearn: 2.6101195\ttotal: 6m 18s\tremaining: 2m\n",
      "17454:\tlearn: 2.6100157\ttotal: 6m 18s\tremaining: 2m\n",
      "17455:\tlearn: 2.6098530\ttotal: 6m 18s\tremaining: 2m\n",
      "17456:\tlearn: 2.6097356\ttotal: 6m 18s\tremaining: 2m\n",
      "17457:\tlearn: 2.6096556\ttotal: 6m 18s\tremaining: 2m\n",
      "17458:\tlearn: 2.6095383\ttotal: 6m 18s\tremaining: 2m\n",
      "17459:\tlearn: 2.6094496\ttotal: 6m 18s\tremaining: 2m\n",
      "17460:\tlearn: 2.6093300\ttotal: 6m 18s\tremaining: 2m\n",
      "17461:\tlearn: 2.6092549\ttotal: 6m 18s\tremaining: 2m\n",
      "17462:\tlearn: 2.6091724\ttotal: 6m 18s\tremaining: 2m\n",
      "17463:\tlearn: 2.6090820\ttotal: 6m 18s\tremaining: 2m\n",
      "17464:\tlearn: 2.6089504\ttotal: 6m 19s\tremaining: 2m\n",
      "17465:\tlearn: 2.6088505\ttotal: 6m 19s\tremaining: 2m\n",
      "17466:\tlearn: 2.6087437\ttotal: 6m 19s\tremaining: 2m\n",
      "17467:\tlearn: 2.6086596\ttotal: 6m 19s\tremaining: 2m\n",
      "17468:\tlearn: 2.6085628\ttotal: 6m 19s\tremaining: 2m\n",
      "17469:\tlearn: 2.6084703\ttotal: 6m 19s\tremaining: 2m\n",
      "17470:\tlearn: 2.6083503\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17471:\tlearn: 2.6082932\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17472:\tlearn: 2.6082076\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17473:\tlearn: 2.6081533\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17474:\tlearn: 2.6081139\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17475:\tlearn: 2.6080700\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17476:\tlearn: 2.6080232\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17477:\tlearn: 2.6079973\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17478:\tlearn: 2.6078070\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17479:\tlearn: 2.6076843\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17480:\tlearn: 2.6076084\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17481:\tlearn: 2.6075659\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17482:\tlearn: 2.6074537\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17483:\tlearn: 2.6073314\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17484:\tlearn: 2.6073107\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17485:\tlearn: 2.6072475\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17486:\tlearn: 2.6072465\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17487:\tlearn: 2.6071865\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17488:\tlearn: 2.6070877\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17489:\tlearn: 2.6070271\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17490:\tlearn: 2.6069112\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17491:\tlearn: 2.6068097\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17492:\tlearn: 2.6066977\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17493:\tlearn: 2.6066312\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17494:\tlearn: 2.6064885\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17495:\tlearn: 2.6063941\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17496:\tlearn: 2.6063436\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17497:\tlearn: 2.6062834\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17498:\tlearn: 2.6061802\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17499:\tlearn: 2.6060812\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17500:\tlearn: 2.6059358\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17501:\tlearn: 2.6058165\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17502:\tlearn: 2.6056984\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17503:\tlearn: 2.6055096\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17504:\tlearn: 2.6053977\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17505:\tlearn: 2.6053372\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17506:\tlearn: 2.6052074\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17507:\tlearn: 2.6051183\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17508:\tlearn: 2.6049823\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17509:\tlearn: 2.6048761\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17510:\tlearn: 2.6047781\ttotal: 6m 19s\tremaining: 1m 59s\n",
      "17511:\tlearn: 2.6046907\ttotal: 6m 20s\tremaining: 1m 59s\n",
      "17512:\tlearn: 2.6046024\ttotal: 6m 20s\tremaining: 1m 59s\n",
      "17513:\tlearn: 2.6045032\ttotal: 6m 20s\tremaining: 1m 59s\n",
      "17514:\tlearn: 2.6043989\ttotal: 6m 20s\tremaining: 1m 59s\n",
      "17515:\tlearn: 2.6043182\ttotal: 6m 20s\tremaining: 1m 59s\n",
      "17516:\tlearn: 2.6042463\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17517:\tlearn: 2.6042087\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17518:\tlearn: 2.6040764\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17519:\tlearn: 2.6040744\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17520:\tlearn: 2.6039841\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17521:\tlearn: 2.6039034\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17522:\tlearn: 2.6038019\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17523:\tlearn: 2.6037546\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17524:\tlearn: 2.6037506\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17525:\tlearn: 2.6036592\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17526:\tlearn: 2.6035138\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17527:\tlearn: 2.6034197\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17528:\tlearn: 2.6033554\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17529:\tlearn: 2.6031951\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17530:\tlearn: 2.6031594\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17531:\tlearn: 2.6030158\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17532:\tlearn: 2.6028637\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17533:\tlearn: 2.6027689\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17534:\tlearn: 2.6025900\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17535:\tlearn: 2.6024686\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17536:\tlearn: 2.6024174\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17537:\tlearn: 2.6022993\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17538:\tlearn: 2.6021435\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17539:\tlearn: 2.6021130\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17540:\tlearn: 2.6020618\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17541:\tlearn: 2.6019565\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17542:\tlearn: 2.6018081\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17543:\tlearn: 2.6016901\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17544:\tlearn: 2.6016096\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17545:\tlearn: 2.6015184\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17546:\tlearn: 2.6013645\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17547:\tlearn: 2.6012436\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17548:\tlearn: 2.6011781\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17549:\tlearn: 2.6010210\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17550:\tlearn: 2.6009698\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17551:\tlearn: 2.6008674\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17552:\tlearn: 2.6007627\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17553:\tlearn: 2.6007284\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17554:\tlearn: 2.6006274\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17555:\tlearn: 2.6004835\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17556:\tlearn: 2.6003778\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17557:\tlearn: 2.6003074\ttotal: 6m 20s\tremaining: 1m 58s\n",
      "17558:\tlearn: 2.6002114\ttotal: 6m 21s\tremaining: 1m 58s\n",
      "17559:\tlearn: 2.6001365\ttotal: 6m 21s\tremaining: 1m 58s\n",
      "17560:\tlearn: 2.6000272\ttotal: 6m 21s\tremaining: 1m 58s\n",
      "17561:\tlearn: 2.5998886\ttotal: 6m 21s\tremaining: 1m 58s\n",
      "17562:\tlearn: 2.5998395\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17563:\tlearn: 2.5997257\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17564:\tlearn: 2.5996023\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17565:\tlearn: 2.5994996\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17566:\tlearn: 2.5994107\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17567:\tlearn: 2.5992961\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17568:\tlearn: 2.5992065\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17569:\tlearn: 2.5990883\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17570:\tlearn: 2.5990350\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17571:\tlearn: 2.5989726\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17572:\tlearn: 2.5988580\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17573:\tlearn: 2.5987088\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17574:\tlearn: 2.5986337\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17575:\tlearn: 2.5985584\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17576:\tlearn: 2.5984333\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17577:\tlearn: 2.5983111\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17578:\tlearn: 2.5981405\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17579:\tlearn: 2.5979321\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17580:\tlearn: 2.5978300\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17581:\tlearn: 2.5977520\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17582:\tlearn: 2.5976664\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17583:\tlearn: 2.5975952\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17584:\tlearn: 2.5975481\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17585:\tlearn: 2.5974131\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17586:\tlearn: 2.5973056\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17587:\tlearn: 2.5972124\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17588:\tlearn: 2.5970995\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17589:\tlearn: 2.5969456\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17590:\tlearn: 2.5967824\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17591:\tlearn: 2.5967172\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17592:\tlearn: 2.5966181\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17593:\tlearn: 2.5965261\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17594:\tlearn: 2.5963798\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17595:\tlearn: 2.5962104\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17596:\tlearn: 2.5960932\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17597:\tlearn: 2.5960184\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17598:\tlearn: 2.5959272\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17599:\tlearn: 2.5959252\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17600:\tlearn: 2.5958763\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17601:\tlearn: 2.5957403\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17602:\tlearn: 2.5956424\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17603:\tlearn: 2.5955810\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17604:\tlearn: 2.5955178\ttotal: 6m 21s\tremaining: 1m 57s\n",
      "17605:\tlearn: 2.5954503\ttotal: 6m 22s\tremaining: 1m 57s\n",
      "17606:\tlearn: 2.5953452\ttotal: 6m 22s\tremaining: 1m 57s\n",
      "17607:\tlearn: 2.5953252\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17608:\tlearn: 2.5952003\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17609:\tlearn: 2.5951179\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17610:\tlearn: 2.5949830\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17611:\tlearn: 2.5949815\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17612:\tlearn: 2.5949073\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17613:\tlearn: 2.5948306\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17614:\tlearn: 2.5947090\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17615:\tlearn: 2.5946243\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17616:\tlearn: 2.5945443\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17617:\tlearn: 2.5943984\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17618:\tlearn: 2.5942743\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17619:\tlearn: 2.5941650\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17620:\tlearn: 2.5940758\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17621:\tlearn: 2.5940715\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17622:\tlearn: 2.5939711\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17623:\tlearn: 2.5938380\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17624:\tlearn: 2.5937460\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17625:\tlearn: 2.5936374\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17626:\tlearn: 2.5935083\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17627:\tlearn: 2.5934506\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17628:\tlearn: 2.5933226\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17629:\tlearn: 2.5932074\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17630:\tlearn: 2.5930700\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17631:\tlearn: 2.5930265\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17632:\tlearn: 2.5929662\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17633:\tlearn: 2.5928438\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17634:\tlearn: 2.5927837\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17635:\tlearn: 2.5926997\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17636:\tlearn: 2.5925775\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17637:\tlearn: 2.5924275\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17638:\tlearn: 2.5923728\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17639:\tlearn: 2.5922759\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17640:\tlearn: 2.5921553\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17641:\tlearn: 2.5920979\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17642:\tlearn: 2.5920079\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17643:\tlearn: 2.5919299\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17644:\tlearn: 2.5918472\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17645:\tlearn: 2.5917533\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17646:\tlearn: 2.5917042\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17647:\tlearn: 2.5916086\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17648:\tlearn: 2.5914496\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17649:\tlearn: 2.5913633\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17650:\tlearn: 2.5912707\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17651:\tlearn: 2.5911783\ttotal: 6m 22s\tremaining: 1m 56s\n",
      "17652:\tlearn: 2.5910293\ttotal: 6m 23s\tremaining: 1m 56s\n",
      "17653:\tlearn: 2.5909167\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17654:\tlearn: 2.5908120\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17655:\tlearn: 2.5907384\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17656:\tlearn: 2.5905122\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17657:\tlearn: 2.5904765\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17658:\tlearn: 2.5903526\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17659:\tlearn: 2.5902466\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17660:\tlearn: 2.5900553\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17661:\tlearn: 2.5899017\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17662:\tlearn: 2.5897775\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17663:\tlearn: 2.5896803\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17664:\tlearn: 2.5895332\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17665:\tlearn: 2.5894283\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17666:\tlearn: 2.5893151\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17667:\tlearn: 2.5892618\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17668:\tlearn: 2.5892100\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17669:\tlearn: 2.5890712\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17670:\tlearn: 2.5889946\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17671:\tlearn: 2.5889047\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17672:\tlearn: 2.5888264\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17673:\tlearn: 2.5887605\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17674:\tlearn: 2.5886551\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17675:\tlearn: 2.5885260\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17676:\tlearn: 2.5885244\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17677:\tlearn: 2.5884626\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17678:\tlearn: 2.5883665\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17679:\tlearn: 2.5882705\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17680:\tlearn: 2.5881221\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17681:\tlearn: 2.5879709\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17682:\tlearn: 2.5878577\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17683:\tlearn: 2.5878560\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17684:\tlearn: 2.5877210\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17685:\tlearn: 2.5875907\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17686:\tlearn: 2.5874907\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17687:\tlearn: 2.5874587\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17688:\tlearn: 2.5873566\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17689:\tlearn: 2.5872677\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17690:\tlearn: 2.5871744\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17691:\tlearn: 2.5870508\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17692:\tlearn: 2.5869139\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17693:\tlearn: 2.5868074\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17694:\tlearn: 2.5867127\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17695:\tlearn: 2.5865942\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17696:\tlearn: 2.5865422\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17697:\tlearn: 2.5864727\ttotal: 6m 23s\tremaining: 1m 55s\n",
      "17698:\tlearn: 2.5863443\ttotal: 6m 24s\tremaining: 1m 55s\n",
      "17699:\tlearn: 2.5862269\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17700:\tlearn: 2.5860897\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17701:\tlearn: 2.5860449\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17702:\tlearn: 2.5859682\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17703:\tlearn: 2.5858715\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17704:\tlearn: 2.5857324\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17705:\tlearn: 2.5856301\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17706:\tlearn: 2.5855143\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17707:\tlearn: 2.5853617\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17708:\tlearn: 2.5851947\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17709:\tlearn: 2.5850693\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17710:\tlearn: 2.5849314\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17711:\tlearn: 2.5848472\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17712:\tlearn: 2.5847889\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17713:\tlearn: 2.5846964\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17714:\tlearn: 2.5846171\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17715:\tlearn: 2.5846156\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17716:\tlearn: 2.5845644\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17717:\tlearn: 2.5845289\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17718:\tlearn: 2.5844253\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17719:\tlearn: 2.5843428\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17720:\tlearn: 2.5842181\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17721:\tlearn: 2.5841216\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17722:\tlearn: 2.5840509\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17723:\tlearn: 2.5839866\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17724:\tlearn: 2.5838313\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17725:\tlearn: 2.5837616\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17726:\tlearn: 2.5836752\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17727:\tlearn: 2.5836293\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17728:\tlearn: 2.5835626\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17729:\tlearn: 2.5833941\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17730:\tlearn: 2.5832585\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17731:\tlearn: 2.5832171\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17732:\tlearn: 2.5831067\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17733:\tlearn: 2.5830148\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17734:\tlearn: 2.5829149\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17735:\tlearn: 2.5828332\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17736:\tlearn: 2.5827475\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17737:\tlearn: 2.5826321\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17738:\tlearn: 2.5825305\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17739:\tlearn: 2.5824899\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17740:\tlearn: 2.5822821\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17741:\tlearn: 2.5821833\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17742:\tlearn: 2.5819913\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17743:\tlearn: 2.5819120\ttotal: 6m 24s\tremaining: 1m 54s\n",
      "17744:\tlearn: 2.5817457\ttotal: 6m 25s\tremaining: 1m 54s\n",
      "17745:\tlearn: 2.5815856\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17746:\tlearn: 2.5814961\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17747:\tlearn: 2.5814242\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17748:\tlearn: 2.5813803\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17749:\tlearn: 2.5812866\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17750:\tlearn: 2.5811887\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17751:\tlearn: 2.5811079\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17752:\tlearn: 2.5810635\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17753:\tlearn: 2.5809311\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17754:\tlearn: 2.5808026\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17755:\tlearn: 2.5806505\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17756:\tlearn: 2.5805929\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17757:\tlearn: 2.5804699\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17758:\tlearn: 2.5803953\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17759:\tlearn: 2.5803076\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17760:\tlearn: 2.5801663\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17761:\tlearn: 2.5800376\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17762:\tlearn: 2.5800356\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17763:\tlearn: 2.5798684\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17764:\tlearn: 2.5796719\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17765:\tlearn: 2.5795064\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17766:\tlearn: 2.5794082\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17767:\tlearn: 2.5793884\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17768:\tlearn: 2.5793154\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17769:\tlearn: 2.5792628\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17770:\tlearn: 2.5791684\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17771:\tlearn: 2.5789853\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17772:\tlearn: 2.5788404\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17773:\tlearn: 2.5786968\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17774:\tlearn: 2.5786132\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17775:\tlearn: 2.5785219\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17776:\tlearn: 2.5783244\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17777:\tlearn: 2.5781967\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17778:\tlearn: 2.5781181\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17779:\tlearn: 2.5780229\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17780:\tlearn: 2.5779312\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17781:\tlearn: 2.5777920\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17782:\tlearn: 2.5777335\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17783:\tlearn: 2.5776205\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17784:\tlearn: 2.5775281\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17785:\tlearn: 2.5773439\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17786:\tlearn: 2.5772095\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17787:\tlearn: 2.5771345\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17788:\tlearn: 2.5770881\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17789:\tlearn: 2.5770513\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17790:\tlearn: 2.5770489\ttotal: 6m 25s\tremaining: 1m 53s\n",
      "17791:\tlearn: 2.5768906\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17792:\tlearn: 2.5767946\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17793:\tlearn: 2.5766651\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17794:\tlearn: 2.5765603\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17795:\tlearn: 2.5764117\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17796:\tlearn: 2.5762880\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17797:\tlearn: 2.5762345\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17798:\tlearn: 2.5760545\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17799:\tlearn: 2.5759636\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17800:\tlearn: 2.5758959\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17801:\tlearn: 2.5758337\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17802:\tlearn: 2.5757896\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17803:\tlearn: 2.5757023\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17804:\tlearn: 2.5756296\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17805:\tlearn: 2.5754869\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17806:\tlearn: 2.5754180\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17807:\tlearn: 2.5753105\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17808:\tlearn: 2.5751984\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17809:\tlearn: 2.5750110\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17810:\tlearn: 2.5748983\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17811:\tlearn: 2.5747753\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17812:\tlearn: 2.5747732\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17813:\tlearn: 2.5746565\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17814:\tlearn: 2.5745348\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17815:\tlearn: 2.5743559\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17816:\tlearn: 2.5742760\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17817:\tlearn: 2.5741797\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17818:\tlearn: 2.5741095\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17819:\tlearn: 2.5740137\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17820:\tlearn: 2.5739207\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17821:\tlearn: 2.5738000\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17822:\tlearn: 2.5737517\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17823:\tlearn: 2.5737493\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17824:\tlearn: 2.5736731\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17825:\tlearn: 2.5735234\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17826:\tlearn: 2.5734462\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17827:\tlearn: 2.5733718\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17828:\tlearn: 2.5732538\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17829:\tlearn: 2.5731695\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17830:\tlearn: 2.5730603\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17831:\tlearn: 2.5730401\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17832:\tlearn: 2.5729255\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17833:\tlearn: 2.5728457\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17834:\tlearn: 2.5727401\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17835:\tlearn: 2.5726433\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17836:\tlearn: 2.5724571\ttotal: 6m 26s\tremaining: 1m 52s\n",
      "17837:\tlearn: 2.5723727\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17838:\tlearn: 2.5722529\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17839:\tlearn: 2.5721608\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17840:\tlearn: 2.5721038\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17841:\tlearn: 2.5719811\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17842:\tlearn: 2.5718096\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17843:\tlearn: 2.5717038\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17844:\tlearn: 2.5716140\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17845:\tlearn: 2.5714901\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17846:\tlearn: 2.5713617\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17847:\tlearn: 2.5712448\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17848:\tlearn: 2.5712431\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17849:\tlearn: 2.5711305\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17850:\tlearn: 2.5710549\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17851:\tlearn: 2.5710145\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17852:\tlearn: 2.5708825\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17853:\tlearn: 2.5707913\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17854:\tlearn: 2.5706967\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17855:\tlearn: 2.5705786\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17856:\tlearn: 2.5705468\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17857:\tlearn: 2.5704070\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17858:\tlearn: 2.5703296\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17859:\tlearn: 2.5701552\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17860:\tlearn: 2.5701086\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17861:\tlearn: 2.5700100\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17862:\tlearn: 2.5699429\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17863:\tlearn: 2.5698747\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17864:\tlearn: 2.5698101\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17865:\tlearn: 2.5696493\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17866:\tlearn: 2.5695591\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17867:\tlearn: 2.5695307\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17868:\tlearn: 2.5694229\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17869:\tlearn: 2.5693202\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17870:\tlearn: 2.5691521\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17871:\tlearn: 2.5690766\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17872:\tlearn: 2.5689518\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17873:\tlearn: 2.5688924\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17874:\tlearn: 2.5687824\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17875:\tlearn: 2.5686502\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17876:\tlearn: 2.5685411\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17877:\tlearn: 2.5683988\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17878:\tlearn: 2.5682914\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17879:\tlearn: 2.5681937\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17880:\tlearn: 2.5681237\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17881:\tlearn: 2.5680301\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17882:\tlearn: 2.5679600\ttotal: 6m 27s\tremaining: 1m 51s\n",
      "17883:\tlearn: 2.5679083\ttotal: 6m 27s\tremaining: 1m 50s\n",
      "17884:\tlearn: 2.5678654\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17885:\tlearn: 2.5677533\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17886:\tlearn: 2.5676481\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17887:\tlearn: 2.5674893\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17888:\tlearn: 2.5673950\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17889:\tlearn: 2.5673070\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17890:\tlearn: 2.5672331\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17891:\tlearn: 2.5671559\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17892:\tlearn: 2.5670694\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17893:\tlearn: 2.5669116\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17894:\tlearn: 2.5667790\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17895:\tlearn: 2.5666392\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17896:\tlearn: 2.5665663\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17897:\tlearn: 2.5664371\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17898:\tlearn: 2.5663542\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17899:\tlearn: 2.5662480\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17900:\tlearn: 2.5661410\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17901:\tlearn: 2.5660579\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17902:\tlearn: 2.5659352\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17903:\tlearn: 2.5658622\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17904:\tlearn: 2.5657591\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17905:\tlearn: 2.5656671\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17906:\tlearn: 2.5655847\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17907:\tlearn: 2.5654056\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17908:\tlearn: 2.5653312\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17909:\tlearn: 2.5652523\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17910:\tlearn: 2.5651715\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17911:\tlearn: 2.5650917\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17912:\tlearn: 2.5649632\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17913:\tlearn: 2.5647924\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17914:\tlearn: 2.5646456\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17915:\tlearn: 2.5645099\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17916:\tlearn: 2.5644574\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17917:\tlearn: 2.5643449\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17918:\tlearn: 2.5643193\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17919:\tlearn: 2.5642283\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17920:\tlearn: 2.5641120\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17921:\tlearn: 2.5640423\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17922:\tlearn: 2.5639873\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17923:\tlearn: 2.5638914\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17924:\tlearn: 2.5638071\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17925:\tlearn: 2.5636819\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17926:\tlearn: 2.5636359\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17927:\tlearn: 2.5635166\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17928:\tlearn: 2.5633786\ttotal: 6m 28s\tremaining: 1m 50s\n",
      "17929:\tlearn: 2.5632631\ttotal: 6m 28s\tremaining: 1m 49s\n",
      "17930:\tlearn: 2.5631173\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17931:\tlearn: 2.5630017\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17932:\tlearn: 2.5628440\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17933:\tlearn: 2.5628070\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17934:\tlearn: 2.5627248\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17935:\tlearn: 2.5626060\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17936:\tlearn: 2.5624360\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17937:\tlearn: 2.5623096\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17938:\tlearn: 2.5621971\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17939:\tlearn: 2.5621169\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17940:\tlearn: 2.5620301\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17941:\tlearn: 2.5619196\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17942:\tlearn: 2.5618025\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17943:\tlearn: 2.5616401\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17944:\tlearn: 2.5614781\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17945:\tlearn: 2.5614236\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17946:\tlearn: 2.5612989\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17947:\tlearn: 2.5612032\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17948:\tlearn: 2.5611212\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17949:\tlearn: 2.5610768\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17950:\tlearn: 2.5609876\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17951:\tlearn: 2.5608526\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17952:\tlearn: 2.5607816\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17953:\tlearn: 2.5607041\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17954:\tlearn: 2.5605934\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17955:\tlearn: 2.5605044\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17956:\tlearn: 2.5604342\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17957:\tlearn: 2.5603182\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17958:\tlearn: 2.5601772\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17959:\tlearn: 2.5600730\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17960:\tlearn: 2.5598872\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17961:\tlearn: 2.5597820\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17962:\tlearn: 2.5597218\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17963:\tlearn: 2.5595737\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17964:\tlearn: 2.5594374\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17965:\tlearn: 2.5594361\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17966:\tlearn: 2.5593346\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17967:\tlearn: 2.5592351\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17968:\tlearn: 2.5591595\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17969:\tlearn: 2.5590871\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17970:\tlearn: 2.5589916\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17971:\tlearn: 2.5589000\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17972:\tlearn: 2.5587603\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17973:\tlearn: 2.5586282\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17974:\tlearn: 2.5585783\ttotal: 6m 29s\tremaining: 1m 49s\n",
      "17975:\tlearn: 2.5584685\ttotal: 6m 29s\tremaining: 1m 48s\n",
      "17976:\tlearn: 2.5584009\ttotal: 6m 29s\tremaining: 1m 48s\n",
      "17977:\tlearn: 2.5582838\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17978:\tlearn: 2.5581891\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17979:\tlearn: 2.5581120\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17980:\tlearn: 2.5580501\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17981:\tlearn: 2.5580478\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17982:\tlearn: 2.5579600\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17983:\tlearn: 2.5578867\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17984:\tlearn: 2.5577738\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17985:\tlearn: 2.5576998\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17986:\tlearn: 2.5575956\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17987:\tlearn: 2.5574464\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17988:\tlearn: 2.5572610\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17989:\tlearn: 2.5571851\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17990:\tlearn: 2.5571507\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17991:\tlearn: 2.5570969\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17992:\tlearn: 2.5570220\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17993:\tlearn: 2.5569196\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17994:\tlearn: 2.5568350\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17995:\tlearn: 2.5567299\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17996:\tlearn: 2.5566157\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17997:\tlearn: 2.5565100\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17998:\tlearn: 2.5563786\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "17999:\tlearn: 2.5563095\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18000:\tlearn: 2.5562100\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18001:\tlearn: 2.5560776\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18002:\tlearn: 2.5559826\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18003:\tlearn: 2.5558125\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18004:\tlearn: 2.5557588\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18005:\tlearn: 2.5556972\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18006:\tlearn: 2.5556129\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18007:\tlearn: 2.5555193\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18008:\tlearn: 2.5554278\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18009:\tlearn: 2.5553544\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18010:\tlearn: 2.5552880\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18011:\tlearn: 2.5552078\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18012:\tlearn: 2.5551121\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18013:\tlearn: 2.5550285\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18014:\tlearn: 2.5549328\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18015:\tlearn: 2.5548096\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18016:\tlearn: 2.5547548\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18017:\tlearn: 2.5546718\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18018:\tlearn: 2.5545821\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18019:\tlearn: 2.5544291\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18020:\tlearn: 2.5543292\ttotal: 6m 30s\tremaining: 1m 48s\n",
      "18021:\tlearn: 2.5542214\ttotal: 6m 30s\tremaining: 1m 47s\n",
      "18022:\tlearn: 2.5540822\ttotal: 6m 30s\tremaining: 1m 47s\n",
      "18023:\tlearn: 2.5539834\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18024:\tlearn: 2.5538657\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18025:\tlearn: 2.5537743\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18026:\tlearn: 2.5536562\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18027:\tlearn: 2.5535708\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18028:\tlearn: 2.5534801\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18029:\tlearn: 2.5533378\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18030:\tlearn: 2.5532729\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18031:\tlearn: 2.5531641\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18032:\tlearn: 2.5531047\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18033:\tlearn: 2.5529590\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18034:\tlearn: 2.5528637\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18035:\tlearn: 2.5527529\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18036:\tlearn: 2.5525679\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18037:\tlearn: 2.5525081\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18038:\tlearn: 2.5524423\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18039:\tlearn: 2.5523371\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18040:\tlearn: 2.5522482\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18041:\tlearn: 2.5521600\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18042:\tlearn: 2.5520711\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18043:\tlearn: 2.5519884\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18044:\tlearn: 2.5518658\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18045:\tlearn: 2.5517607\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18046:\tlearn: 2.5516321\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18047:\tlearn: 2.5514441\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18048:\tlearn: 2.5513256\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18049:\tlearn: 2.5512427\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18050:\tlearn: 2.5510498\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18051:\tlearn: 2.5509575\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18052:\tlearn: 2.5508909\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18053:\tlearn: 2.5508131\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18054:\tlearn: 2.5507561\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18055:\tlearn: 2.5506757\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18056:\tlearn: 2.5505966\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18057:\tlearn: 2.5505280\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18058:\tlearn: 2.5503943\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18059:\tlearn: 2.5503174\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18060:\tlearn: 2.5502295\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18061:\tlearn: 2.5501144\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18062:\tlearn: 2.5500181\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18063:\tlearn: 2.5499735\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18064:\tlearn: 2.5498968\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18065:\tlearn: 2.5497920\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18066:\tlearn: 2.5496862\ttotal: 6m 31s\tremaining: 1m 47s\n",
      "18067:\tlearn: 2.5496085\ttotal: 6m 31s\tremaining: 1m 46s\n",
      "18068:\tlearn: 2.5495376\ttotal: 6m 31s\tremaining: 1m 46s\n",
      "18069:\tlearn: 2.5493987\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18070:\tlearn: 2.5493035\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18071:\tlearn: 2.5491464\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18072:\tlearn: 2.5490416\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18073:\tlearn: 2.5489280\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18074:\tlearn: 2.5488636\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18075:\tlearn: 2.5487929\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18076:\tlearn: 2.5486257\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18077:\tlearn: 2.5485381\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18078:\tlearn: 2.5484424\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18079:\tlearn: 2.5483028\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18080:\tlearn: 2.5482445\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18081:\tlearn: 2.5481101\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18082:\tlearn: 2.5480575\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18083:\tlearn: 2.5480058\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18084:\tlearn: 2.5479112\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18085:\tlearn: 2.5478391\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18086:\tlearn: 2.5477022\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18087:\tlearn: 2.5475871\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18088:\tlearn: 2.5474577\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18089:\tlearn: 2.5474063\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18090:\tlearn: 2.5473526\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18091:\tlearn: 2.5472270\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18092:\tlearn: 2.5471446\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18093:\tlearn: 2.5470784\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18094:\tlearn: 2.5469468\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18095:\tlearn: 2.5468885\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18096:\tlearn: 2.5468019\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18097:\tlearn: 2.5467155\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18098:\tlearn: 2.5466296\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18099:\tlearn: 2.5466286\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18100:\tlearn: 2.5465768\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18101:\tlearn: 2.5465218\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18102:\tlearn: 2.5464139\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18103:\tlearn: 2.5463290\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18104:\tlearn: 2.5462277\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18105:\tlearn: 2.5461702\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18106:\tlearn: 2.5461224\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18107:\tlearn: 2.5460239\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18108:\tlearn: 2.5459591\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18109:\tlearn: 2.5458625\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18110:\tlearn: 2.5457760\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18111:\tlearn: 2.5456708\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18112:\tlearn: 2.5456691\ttotal: 6m 32s\tremaining: 1m 46s\n",
      "18113:\tlearn: 2.5455901\ttotal: 6m 32s\tremaining: 1m 45s\n",
      "18114:\tlearn: 2.5454292\ttotal: 6m 32s\tremaining: 1m 45s\n",
      "18115:\tlearn: 2.5453149\ttotal: 6m 32s\tremaining: 1m 45s\n",
      "18116:\tlearn: 2.5452209\ttotal: 6m 32s\tremaining: 1m 45s\n",
      "18117:\tlearn: 2.5451557\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18118:\tlearn: 2.5451540\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18119:\tlearn: 2.5450613\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18120:\tlearn: 2.5449712\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18121:\tlearn: 2.5447850\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18122:\tlearn: 2.5446227\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18123:\tlearn: 2.5445265\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18124:\tlearn: 2.5444684\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18125:\tlearn: 2.5443432\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18126:\tlearn: 2.5441642\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18127:\tlearn: 2.5441032\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18128:\tlearn: 2.5440205\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18129:\tlearn: 2.5439795\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18130:\tlearn: 2.5439264\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18131:\tlearn: 2.5438257\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18132:\tlearn: 2.5437249\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18133:\tlearn: 2.5436310\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18134:\tlearn: 2.5436269\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18135:\tlearn: 2.5435203\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18136:\tlearn: 2.5433615\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18137:\tlearn: 2.5432810\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18138:\tlearn: 2.5431782\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18139:\tlearn: 2.5430738\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18140:\tlearn: 2.5429472\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18141:\tlearn: 2.5428914\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18142:\tlearn: 2.5427635\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18143:\tlearn: 2.5426704\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18144:\tlearn: 2.5425822\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18145:\tlearn: 2.5424670\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18146:\tlearn: 2.5423828\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18147:\tlearn: 2.5422509\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18148:\tlearn: 2.5421772\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18149:\tlearn: 2.5420916\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18150:\tlearn: 2.5420350\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18151:\tlearn: 2.5419279\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18152:\tlearn: 2.5418399\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18153:\tlearn: 2.5417495\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18154:\tlearn: 2.5417481\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18155:\tlearn: 2.5416507\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18156:\tlearn: 2.5415186\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18157:\tlearn: 2.5414363\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18158:\tlearn: 2.5413601\ttotal: 6m 33s\tremaining: 1m 45s\n",
      "18159:\tlearn: 2.5411919\ttotal: 6m 33s\tremaining: 1m 44s\n",
      "18160:\tlearn: 2.5411034\ttotal: 6m 33s\tremaining: 1m 44s\n",
      "18161:\tlearn: 2.5410326\ttotal: 6m 33s\tremaining: 1m 44s\n",
      "18162:\tlearn: 2.5409486\ttotal: 6m 33s\tremaining: 1m 44s\n",
      "18163:\tlearn: 2.5408270\ttotal: 6m 33s\tremaining: 1m 44s\n",
      "18164:\tlearn: 2.5407332\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18165:\tlearn: 2.5406899\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18166:\tlearn: 2.5405414\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18167:\tlearn: 2.5404916\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18168:\tlearn: 2.5404472\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18169:\tlearn: 2.5403238\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18170:\tlearn: 2.5402512\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18171:\tlearn: 2.5401626\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18172:\tlearn: 2.5400494\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18173:\tlearn: 2.5399711\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18174:\tlearn: 2.5398917\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18175:\tlearn: 2.5397603\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18176:\tlearn: 2.5396726\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18177:\tlearn: 2.5396168\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18178:\tlearn: 2.5395579\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18179:\tlearn: 2.5394173\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18180:\tlearn: 2.5393104\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18181:\tlearn: 2.5391611\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18182:\tlearn: 2.5390833\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18183:\tlearn: 2.5390334\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18184:\tlearn: 2.5389361\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18185:\tlearn: 2.5388912\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18186:\tlearn: 2.5387952\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18187:\tlearn: 2.5386718\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18188:\tlearn: 2.5385541\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18189:\tlearn: 2.5384718\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18190:\tlearn: 2.5383303\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18191:\tlearn: 2.5382764\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18192:\tlearn: 2.5381150\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18193:\tlearn: 2.5380250\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18194:\tlearn: 2.5379135\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18195:\tlearn: 2.5378583\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18196:\tlearn: 2.5377636\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18197:\tlearn: 2.5376020\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18198:\tlearn: 2.5375242\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18199:\tlearn: 2.5374435\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18200:\tlearn: 2.5373107\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18201:\tlearn: 2.5371331\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18202:\tlearn: 2.5370538\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18203:\tlearn: 2.5369592\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18204:\tlearn: 2.5368368\ttotal: 6m 34s\tremaining: 1m 44s\n",
      "18205:\tlearn: 2.5366900\ttotal: 6m 34s\tremaining: 1m 43s\n",
      "18206:\tlearn: 2.5366374\ttotal: 6m 34s\tremaining: 1m 43s\n",
      "18207:\tlearn: 2.5365823\ttotal: 6m 34s\tremaining: 1m 43s\n",
      "18208:\tlearn: 2.5365320\ttotal: 6m 34s\tremaining: 1m 43s\n",
      "18209:\tlearn: 2.5364767\ttotal: 6m 34s\tremaining: 1m 43s\n",
      "18210:\tlearn: 2.5364080\ttotal: 6m 34s\tremaining: 1m 43s\n",
      "18211:\tlearn: 2.5362820\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18212:\tlearn: 2.5362204\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18213:\tlearn: 2.5360883\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18214:\tlearn: 2.5360047\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18215:\tlearn: 2.5359634\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18216:\tlearn: 2.5359024\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18217:\tlearn: 2.5358760\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18218:\tlearn: 2.5357117\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18219:\tlearn: 2.5356550\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18220:\tlearn: 2.5355794\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18221:\tlearn: 2.5354530\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18222:\tlearn: 2.5354157\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18223:\tlearn: 2.5353480\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18224:\tlearn: 2.5352453\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18225:\tlearn: 2.5351328\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18226:\tlearn: 2.5350831\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18227:\tlearn: 2.5349885\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18228:\tlearn: 2.5349659\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18229:\tlearn: 2.5349010\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18230:\tlearn: 2.5348569\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18231:\tlearn: 2.5347424\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18232:\tlearn: 2.5346340\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18233:\tlearn: 2.5345684\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18234:\tlearn: 2.5344539\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18235:\tlearn: 2.5342941\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18236:\tlearn: 2.5342229\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18237:\tlearn: 2.5340873\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18238:\tlearn: 2.5340291\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18239:\tlearn: 2.5339705\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18240:\tlearn: 2.5338880\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18241:\tlearn: 2.5338639\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18242:\tlearn: 2.5337715\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18243:\tlearn: 2.5336749\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18244:\tlearn: 2.5335769\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18245:\tlearn: 2.5334372\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18246:\tlearn: 2.5334207\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18247:\tlearn: 2.5333290\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18248:\tlearn: 2.5332917\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18249:\tlearn: 2.5331998\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18250:\tlearn: 2.5330657\ttotal: 6m 35s\tremaining: 1m 43s\n",
      "18251:\tlearn: 2.5329158\ttotal: 6m 35s\tremaining: 1m 42s\n",
      "18252:\tlearn: 2.5328169\ttotal: 6m 35s\tremaining: 1m 42s\n",
      "18253:\tlearn: 2.5327615\ttotal: 6m 35s\tremaining: 1m 42s\n",
      "18254:\tlearn: 2.5326838\ttotal: 6m 35s\tremaining: 1m 42s\n",
      "18255:\tlearn: 2.5325966\ttotal: 6m 35s\tremaining: 1m 42s\n",
      "18256:\tlearn: 2.5324838\ttotal: 6m 35s\tremaining: 1m 42s\n",
      "18257:\tlearn: 2.5324197\ttotal: 6m 35s\tremaining: 1m 42s\n",
      "18258:\tlearn: 2.5323054\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18259:\tlearn: 2.5322106\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18260:\tlearn: 2.5321314\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18261:\tlearn: 2.5320790\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18262:\tlearn: 2.5319659\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18263:\tlearn: 2.5318244\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18264:\tlearn: 2.5317521\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18265:\tlearn: 2.5316201\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18266:\tlearn: 2.5315026\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18267:\tlearn: 2.5313776\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18268:\tlearn: 2.5312620\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18269:\tlearn: 2.5312229\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18270:\tlearn: 2.5310643\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18271:\tlearn: 2.5310346\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18272:\tlearn: 2.5309828\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18273:\tlearn: 2.5308733\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18274:\tlearn: 2.5307876\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18275:\tlearn: 2.5306798\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18276:\tlearn: 2.5306110\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18277:\tlearn: 2.5305239\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18278:\tlearn: 2.5304456\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18279:\tlearn: 2.5303881\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18280:\tlearn: 2.5302997\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18281:\tlearn: 2.5302325\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18282:\tlearn: 2.5301799\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18283:\tlearn: 2.5300138\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18284:\tlearn: 2.5298833\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18285:\tlearn: 2.5297935\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18286:\tlearn: 2.5296815\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18287:\tlearn: 2.5295970\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18288:\tlearn: 2.5294826\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18289:\tlearn: 2.5293796\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18290:\tlearn: 2.5293101\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18291:\tlearn: 2.5291545\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18292:\tlearn: 2.5290974\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18293:\tlearn: 2.5290094\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18294:\tlearn: 2.5288561\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18295:\tlearn: 2.5288154\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18296:\tlearn: 2.5287380\ttotal: 6m 36s\tremaining: 1m 42s\n",
      "18297:\tlearn: 2.5287361\ttotal: 6m 36s\tremaining: 1m 41s\n",
      "18298:\tlearn: 2.5286470\ttotal: 6m 36s\tremaining: 1m 41s\n",
      "18299:\tlearn: 2.5285152\ttotal: 6m 36s\tremaining: 1m 41s\n",
      "18300:\tlearn: 2.5284357\ttotal: 6m 36s\tremaining: 1m 41s\n",
      "18301:\tlearn: 2.5283904\ttotal: 6m 36s\tremaining: 1m 41s\n",
      "18302:\tlearn: 2.5282802\ttotal: 6m 36s\tremaining: 1m 41s\n",
      "18303:\tlearn: 2.5281089\ttotal: 6m 36s\tremaining: 1m 41s\n",
      "18304:\tlearn: 2.5279811\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18305:\tlearn: 2.5279199\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18306:\tlearn: 2.5277673\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18307:\tlearn: 2.5276265\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18308:\tlearn: 2.5274995\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18309:\tlearn: 2.5274152\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18310:\tlearn: 2.5273286\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18311:\tlearn: 2.5272462\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18312:\tlearn: 2.5272010\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18313:\tlearn: 2.5270994\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18314:\tlearn: 2.5269820\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18315:\tlearn: 2.5268854\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18316:\tlearn: 2.5268070\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18317:\tlearn: 2.5267234\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18318:\tlearn: 2.5265868\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18319:\tlearn: 2.5265029\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18320:\tlearn: 2.5264030\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18321:\tlearn: 2.5263334\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18322:\tlearn: 2.5262796\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18323:\tlearn: 2.5261689\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18324:\tlearn: 2.5260722\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18325:\tlearn: 2.5260037\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18326:\tlearn: 2.5259397\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18327:\tlearn: 2.5259386\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18328:\tlearn: 2.5258002\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18329:\tlearn: 2.5256745\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18330:\tlearn: 2.5255544\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18331:\tlearn: 2.5254829\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18332:\tlearn: 2.5253638\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18333:\tlearn: 2.5252360\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18334:\tlearn: 2.5251179\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18335:\tlearn: 2.5250135\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18336:\tlearn: 2.5249023\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18337:\tlearn: 2.5248516\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18338:\tlearn: 2.5247562\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18339:\tlearn: 2.5246167\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18340:\tlearn: 2.5245374\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18341:\tlearn: 2.5244482\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18342:\tlearn: 2.5244102\ttotal: 6m 37s\tremaining: 1m 41s\n",
      "18343:\tlearn: 2.5243601\ttotal: 6m 37s\tremaining: 1m 40s\n",
      "18344:\tlearn: 2.5243495\ttotal: 6m 37s\tremaining: 1m 40s\n",
      "18345:\tlearn: 2.5243117\ttotal: 6m 37s\tremaining: 1m 40s\n",
      "18346:\tlearn: 2.5241687\ttotal: 6m 37s\tremaining: 1m 40s\n",
      "18347:\tlearn: 2.5240653\ttotal: 6m 37s\tremaining: 1m 40s\n",
      "18348:\tlearn: 2.5239887\ttotal: 6m 37s\tremaining: 1m 40s\n",
      "18349:\tlearn: 2.5238566\ttotal: 6m 37s\tremaining: 1m 40s\n",
      "18350:\tlearn: 2.5237044\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18351:\tlearn: 2.5237024\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18352:\tlearn: 2.5236632\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18353:\tlearn: 2.5235989\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18354:\tlearn: 2.5234721\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18355:\tlearn: 2.5233816\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18356:\tlearn: 2.5232804\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18357:\tlearn: 2.5231980\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18358:\tlearn: 2.5230959\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18359:\tlearn: 2.5229711\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18360:\tlearn: 2.5228851\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18361:\tlearn: 2.5227773\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18362:\tlearn: 2.5226810\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18363:\tlearn: 2.5226800\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18364:\tlearn: 2.5226121\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18365:\tlearn: 2.5224897\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18366:\tlearn: 2.5223949\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18367:\tlearn: 2.5223105\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18368:\tlearn: 2.5222050\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18369:\tlearn: 2.5220937\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18370:\tlearn: 2.5220464\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18371:\tlearn: 2.5219963\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18372:\tlearn: 2.5218173\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18373:\tlearn: 2.5217211\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18374:\tlearn: 2.5216088\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18375:\tlearn: 2.5214652\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18376:\tlearn: 2.5213424\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18377:\tlearn: 2.5212911\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18378:\tlearn: 2.5212896\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18379:\tlearn: 2.5212184\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18380:\tlearn: 2.5211308\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18381:\tlearn: 2.5210371\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18382:\tlearn: 2.5209710\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18383:\tlearn: 2.5208519\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18384:\tlearn: 2.5207497\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18385:\tlearn: 2.5206918\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18386:\tlearn: 2.5206389\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18387:\tlearn: 2.5205737\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18388:\tlearn: 2.5205026\ttotal: 6m 38s\tremaining: 1m 40s\n",
      "18389:\tlearn: 2.5203895\ttotal: 6m 38s\tremaining: 1m 39s\n",
      "18390:\tlearn: 2.5203036\ttotal: 6m 38s\tremaining: 1m 39s\n",
      "18391:\tlearn: 2.5202699\ttotal: 6m 38s\tremaining: 1m 39s\n",
      "18392:\tlearn: 2.5201790\ttotal: 6m 38s\tremaining: 1m 39s\n",
      "18393:\tlearn: 2.5200864\ttotal: 6m 38s\tremaining: 1m 39s\n",
      "18394:\tlearn: 2.5199631\ttotal: 6m 38s\tremaining: 1m 39s\n",
      "18395:\tlearn: 2.5198165\ttotal: 6m 38s\tremaining: 1m 39s\n",
      "18396:\tlearn: 2.5197631\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18397:\tlearn: 2.5196870\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18398:\tlearn: 2.5196137\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18399:\tlearn: 2.5195257\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18400:\tlearn: 2.5194547\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18401:\tlearn: 2.5192901\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18402:\tlearn: 2.5192039\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18403:\tlearn: 2.5190994\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18404:\tlearn: 2.5190206\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18405:\tlearn: 2.5189474\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18406:\tlearn: 2.5188748\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18407:\tlearn: 2.5187865\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18408:\tlearn: 2.5186187\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18409:\tlearn: 2.5185474\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18410:\tlearn: 2.5184350\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18411:\tlearn: 2.5182581\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18412:\tlearn: 2.5181260\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18413:\tlearn: 2.5180279\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18414:\tlearn: 2.5179106\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18415:\tlearn: 2.5178683\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18416:\tlearn: 2.5177775\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18417:\tlearn: 2.5176529\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18418:\tlearn: 2.5175489\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18419:\tlearn: 2.5174735\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18420:\tlearn: 2.5173123\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18421:\tlearn: 2.5171511\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18422:\tlearn: 2.5170711\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18423:\tlearn: 2.5169051\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18424:\tlearn: 2.5167818\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18425:\tlearn: 2.5166948\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18426:\tlearn: 2.5165437\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18427:\tlearn: 2.5164785\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18428:\tlearn: 2.5163663\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18429:\tlearn: 2.5161923\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18430:\tlearn: 2.5161036\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18431:\tlearn: 2.5160035\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18432:\tlearn: 2.5158826\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18433:\tlearn: 2.5158270\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18434:\tlearn: 2.5157539\ttotal: 6m 39s\tremaining: 1m 39s\n",
      "18435:\tlearn: 2.5156072\ttotal: 6m 39s\tremaining: 1m 38s\n",
      "18436:\tlearn: 2.5154769\ttotal: 6m 39s\tremaining: 1m 38s\n",
      "18437:\tlearn: 2.5153873\ttotal: 6m 39s\tremaining: 1m 38s\n",
      "18438:\tlearn: 2.5151967\ttotal: 6m 39s\tremaining: 1m 38s\n",
      "18439:\tlearn: 2.5150987\ttotal: 6m 39s\tremaining: 1m 38s\n",
      "18440:\tlearn: 2.5150444\ttotal: 6m 39s\tremaining: 1m 38s\n",
      "18441:\tlearn: 2.5149401\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18442:\tlearn: 2.5147914\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18443:\tlearn: 2.5146822\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18444:\tlearn: 2.5145794\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18445:\tlearn: 2.5145137\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18446:\tlearn: 2.5144099\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18447:\tlearn: 2.5143381\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18448:\tlearn: 2.5142913\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18449:\tlearn: 2.5141657\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18450:\tlearn: 2.5140332\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18451:\tlearn: 2.5139563\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18452:\tlearn: 2.5138758\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18453:\tlearn: 2.5138737\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18454:\tlearn: 2.5137076\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18455:\tlearn: 2.5136336\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18456:\tlearn: 2.5135563\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18457:\tlearn: 2.5134280\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18458:\tlearn: 2.5133037\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18459:\tlearn: 2.5132133\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18460:\tlearn: 2.5131249\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18461:\tlearn: 2.5130805\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18462:\tlearn: 2.5129955\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18463:\tlearn: 2.5129039\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18464:\tlearn: 2.5127826\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18465:\tlearn: 2.5126976\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18466:\tlearn: 2.5126308\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18467:\tlearn: 2.5125663\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18468:\tlearn: 2.5124922\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18469:\tlearn: 2.5124212\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18470:\tlearn: 2.5123595\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18471:\tlearn: 2.5122985\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18472:\tlearn: 2.5121529\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18473:\tlearn: 2.5120666\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18474:\tlearn: 2.5119698\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18475:\tlearn: 2.5118612\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18476:\tlearn: 2.5117973\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18477:\tlearn: 2.5117395\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18478:\tlearn: 2.5117367\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18479:\tlearn: 2.5116964\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18480:\tlearn: 2.5115725\ttotal: 6m 40s\tremaining: 1m 38s\n",
      "18481:\tlearn: 2.5115707\ttotal: 6m 40s\tremaining: 1m 37s\n",
      "18482:\tlearn: 2.5114774\ttotal: 6m 40s\tremaining: 1m 37s\n",
      "18483:\tlearn: 2.5113491\ttotal: 6m 40s\tremaining: 1m 37s\n",
      "18484:\tlearn: 2.5112511\ttotal: 6m 40s\tremaining: 1m 37s\n",
      "18485:\tlearn: 2.5111699\ttotal: 6m 40s\tremaining: 1m 37s\n",
      "18486:\tlearn: 2.5110779\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18487:\tlearn: 2.5109807\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18488:\tlearn: 2.5108777\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18489:\tlearn: 2.5107866\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18490:\tlearn: 2.5106877\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18491:\tlearn: 2.5106557\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18492:\tlearn: 2.5106024\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18493:\tlearn: 2.5105370\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18494:\tlearn: 2.5104357\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18495:\tlearn: 2.5103640\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18496:\tlearn: 2.5103184\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18497:\tlearn: 2.5102529\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18498:\tlearn: 2.5102001\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18499:\tlearn: 2.5101082\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18500:\tlearn: 2.5100474\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18501:\tlearn: 2.5100197\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18502:\tlearn: 2.5099404\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18503:\tlearn: 2.5098433\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18504:\tlearn: 2.5097902\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18505:\tlearn: 2.5097217\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18506:\tlearn: 2.5096108\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18507:\tlearn: 2.5095417\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18508:\tlearn: 2.5094106\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18509:\tlearn: 2.5093365\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18510:\tlearn: 2.5092738\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18511:\tlearn: 2.5091496\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18512:\tlearn: 2.5090159\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18513:\tlearn: 2.5089445\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18514:\tlearn: 2.5089089\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18515:\tlearn: 2.5087981\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18516:\tlearn: 2.5086777\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18517:\tlearn: 2.5086292\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18518:\tlearn: 2.5086277\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18519:\tlearn: 2.5084920\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18520:\tlearn: 2.5083807\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18521:\tlearn: 2.5082302\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18522:\tlearn: 2.5081820\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18523:\tlearn: 2.5080771\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18524:\tlearn: 2.5079583\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18525:\tlearn: 2.5078290\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18526:\tlearn: 2.5076979\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18527:\tlearn: 2.5076225\ttotal: 6m 41s\tremaining: 1m 37s\n",
      "18528:\tlearn: 2.5075676\ttotal: 6m 41s\tremaining: 1m 36s\n",
      "18529:\tlearn: 2.5074831\ttotal: 6m 41s\tremaining: 1m 36s\n",
      "18530:\tlearn: 2.5073695\ttotal: 6m 41s\tremaining: 1m 36s\n",
      "18531:\tlearn: 2.5072454\ttotal: 6m 41s\tremaining: 1m 36s\n",
      "18532:\tlearn: 2.5071572\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18533:\tlearn: 2.5070862\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18534:\tlearn: 2.5069660\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18535:\tlearn: 2.5068413\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18536:\tlearn: 2.5067442\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18537:\tlearn: 2.5066911\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18538:\tlearn: 2.5065788\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18539:\tlearn: 2.5064852\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18540:\tlearn: 2.5063713\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18541:\tlearn: 2.5062476\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18542:\tlearn: 2.5061217\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18543:\tlearn: 2.5060245\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18544:\tlearn: 2.5058957\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18545:\tlearn: 2.5057962\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18546:\tlearn: 2.5057223\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18547:\tlearn: 2.5056280\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18548:\tlearn: 2.5054954\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18549:\tlearn: 2.5054189\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18550:\tlearn: 2.5053512\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18551:\tlearn: 2.5052536\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18552:\tlearn: 2.5051385\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18553:\tlearn: 2.5049920\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18554:\tlearn: 2.5048995\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18555:\tlearn: 2.5048003\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18556:\tlearn: 2.5046266\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18557:\tlearn: 2.5045390\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18558:\tlearn: 2.5043757\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18559:\tlearn: 2.5042851\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18560:\tlearn: 2.5041725\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18561:\tlearn: 2.5040704\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18562:\tlearn: 2.5039762\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18563:\tlearn: 2.5038998\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18564:\tlearn: 2.5037886\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18565:\tlearn: 2.5036991\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18566:\tlearn: 2.5035892\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18567:\tlearn: 2.5035276\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18568:\tlearn: 2.5033377\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18569:\tlearn: 2.5033076\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18570:\tlearn: 2.5031828\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18571:\tlearn: 2.5031048\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18572:\tlearn: 2.5030041\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18573:\tlearn: 2.5029323\ttotal: 6m 42s\tremaining: 1m 36s\n",
      "18574:\tlearn: 2.5028069\ttotal: 6m 42s\tremaining: 1m 35s\n",
      "18575:\tlearn: 2.5027414\ttotal: 6m 42s\tremaining: 1m 35s\n",
      "18576:\tlearn: 2.5026194\ttotal: 6m 42s\tremaining: 1m 35s\n",
      "18577:\tlearn: 2.5025570\ttotal: 6m 42s\tremaining: 1m 35s\n",
      "18578:\tlearn: 2.5025221\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18579:\tlearn: 2.5024623\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18580:\tlearn: 2.5024227\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18581:\tlearn: 2.5023406\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18582:\tlearn: 2.5022450\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18583:\tlearn: 2.5021533\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18584:\tlearn: 2.5020540\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18585:\tlearn: 2.5019550\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18586:\tlearn: 2.5018262\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18587:\tlearn: 2.5017201\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18588:\tlearn: 2.5016051\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18589:\tlearn: 2.5015132\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18590:\tlearn: 2.5014060\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18591:\tlearn: 2.5013099\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18592:\tlearn: 2.5011750\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18593:\tlearn: 2.5010978\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18594:\tlearn: 2.5009949\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18595:\tlearn: 2.5009161\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18596:\tlearn: 2.5008115\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18597:\tlearn: 2.5007141\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18598:\tlearn: 2.5006295\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18599:\tlearn: 2.5005943\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18600:\tlearn: 2.5005424\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18601:\tlearn: 2.5003886\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18602:\tlearn: 2.5002851\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18603:\tlearn: 2.5002151\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18604:\tlearn: 2.5001311\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18605:\tlearn: 2.5000284\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18606:\tlearn: 2.4999703\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18607:\tlearn: 2.4999690\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18608:\tlearn: 2.4999107\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18609:\tlearn: 2.4998417\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18610:\tlearn: 2.4997946\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18611:\tlearn: 2.4997171\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18612:\tlearn: 2.4995463\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18613:\tlearn: 2.4994127\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18614:\tlearn: 2.4993707\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18615:\tlearn: 2.4992807\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18616:\tlearn: 2.4991813\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18617:\tlearn: 2.4990975\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18618:\tlearn: 2.4990593\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18619:\tlearn: 2.4989953\ttotal: 6m 43s\tremaining: 1m 35s\n",
      "18620:\tlearn: 2.4989218\ttotal: 6m 43s\tremaining: 1m 34s\n",
      "18621:\tlearn: 2.4988225\ttotal: 6m 43s\tremaining: 1m 34s\n",
      "18622:\tlearn: 2.4987307\ttotal: 6m 43s\tremaining: 1m 34s\n",
      "18623:\tlearn: 2.4986700\ttotal: 6m 43s\tremaining: 1m 34s\n",
      "18624:\tlearn: 2.4985918\ttotal: 6m 43s\tremaining: 1m 34s\n",
      "18625:\tlearn: 2.4984799\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18626:\tlearn: 2.4984679\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18627:\tlearn: 2.4983845\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18628:\tlearn: 2.4981791\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18629:\tlearn: 2.4981285\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18630:\tlearn: 2.4980069\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18631:\tlearn: 2.4979252\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18632:\tlearn: 2.4978907\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18633:\tlearn: 2.4977964\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18634:\tlearn: 2.4977136\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18635:\tlearn: 2.4976388\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18636:\tlearn: 2.4975680\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18637:\tlearn: 2.4974699\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18638:\tlearn: 2.4973560\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18639:\tlearn: 2.4973124\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18640:\tlearn: 2.4972209\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18641:\tlearn: 2.4971091\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18642:\tlearn: 2.4969314\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18643:\tlearn: 2.4968837\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18644:\tlearn: 2.4966991\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18645:\tlearn: 2.4965883\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18646:\tlearn: 2.4965244\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18647:\tlearn: 2.4964554\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18648:\tlearn: 2.4964032\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18649:\tlearn: 2.4963142\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18650:\tlearn: 2.4962433\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18651:\tlearn: 2.4961581\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18652:\tlearn: 2.4959920\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18653:\tlearn: 2.4959136\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18654:\tlearn: 2.4957993\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18655:\tlearn: 2.4956897\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18656:\tlearn: 2.4955798\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18657:\tlearn: 2.4955132\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18658:\tlearn: 2.4953790\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18659:\tlearn: 2.4952075\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18660:\tlearn: 2.4951433\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18661:\tlearn: 2.4950686\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18662:\tlearn: 2.4949275\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18663:\tlearn: 2.4948566\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18664:\tlearn: 2.4947204\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18665:\tlearn: 2.4945685\ttotal: 6m 44s\tremaining: 1m 34s\n",
      "18666:\tlearn: 2.4945268\ttotal: 6m 44s\tremaining: 1m 33s\n",
      "18667:\tlearn: 2.4944784\ttotal: 6m 44s\tremaining: 1m 33s\n",
      "18668:\tlearn: 2.4944177\ttotal: 6m 44s\tremaining: 1m 33s\n",
      "18669:\tlearn: 2.4943404\ttotal: 6m 44s\tremaining: 1m 33s\n",
      "18670:\tlearn: 2.4942000\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18671:\tlearn: 2.4940184\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18672:\tlearn: 2.4939518\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18673:\tlearn: 2.4938823\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18674:\tlearn: 2.4937999\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18675:\tlearn: 2.4937254\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18676:\tlearn: 2.4935963\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18677:\tlearn: 2.4935158\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18678:\tlearn: 2.4934032\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18679:\tlearn: 2.4932529\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18680:\tlearn: 2.4931899\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18681:\tlearn: 2.4930807\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18682:\tlearn: 2.4929678\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18683:\tlearn: 2.4929230\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18684:\tlearn: 2.4928221\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18685:\tlearn: 2.4927118\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18686:\tlearn: 2.4925956\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18687:\tlearn: 2.4924760\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18688:\tlearn: 2.4923217\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18689:\tlearn: 2.4922467\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18690:\tlearn: 2.4922092\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18691:\tlearn: 2.4920200\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18692:\tlearn: 2.4919137\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18693:\tlearn: 2.4918300\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18694:\tlearn: 2.4917108\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18695:\tlearn: 2.4916094\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18696:\tlearn: 2.4914900\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18697:\tlearn: 2.4914165\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18698:\tlearn: 2.4912753\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18699:\tlearn: 2.4912735\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18700:\tlearn: 2.4911611\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18701:\tlearn: 2.4910804\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18702:\tlearn: 2.4910177\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18703:\tlearn: 2.4909641\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18704:\tlearn: 2.4908265\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18705:\tlearn: 2.4908173\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18706:\tlearn: 2.4907202\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18707:\tlearn: 2.4905903\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18708:\tlearn: 2.4904532\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18709:\tlearn: 2.4904517\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18710:\tlearn: 2.4903750\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18711:\tlearn: 2.4903022\ttotal: 6m 45s\tremaining: 1m 33s\n",
      "18712:\tlearn: 2.4902542\ttotal: 6m 45s\tremaining: 1m 32s\n",
      "18713:\tlearn: 2.4902157\ttotal: 6m 45s\tremaining: 1m 32s\n",
      "18714:\tlearn: 2.4901584\ttotal: 6m 45s\tremaining: 1m 32s\n",
      "18715:\tlearn: 2.4900915\ttotal: 6m 45s\tremaining: 1m 32s\n",
      "18716:\tlearn: 2.4899455\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18717:\tlearn: 2.4898721\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18718:\tlearn: 2.4897556\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18719:\tlearn: 2.4896208\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18720:\tlearn: 2.4895480\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18721:\tlearn: 2.4894667\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18722:\tlearn: 2.4893791\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18723:\tlearn: 2.4892892\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18724:\tlearn: 2.4892143\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18725:\tlearn: 2.4890954\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18726:\tlearn: 2.4889628\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18727:\tlearn: 2.4888228\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18728:\tlearn: 2.4887765\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18729:\tlearn: 2.4886900\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18730:\tlearn: 2.4886874\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18731:\tlearn: 2.4885671\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18732:\tlearn: 2.4884855\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18733:\tlearn: 2.4884077\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18734:\tlearn: 2.4883676\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18735:\tlearn: 2.4883012\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18736:\tlearn: 2.4882994\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18737:\tlearn: 2.4882288\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18738:\tlearn: 2.4881115\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18739:\tlearn: 2.4880339\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18740:\tlearn: 2.4880040\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18741:\tlearn: 2.4879145\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18742:\tlearn: 2.4878106\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18743:\tlearn: 2.4878079\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18744:\tlearn: 2.4877020\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18745:\tlearn: 2.4876676\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18746:\tlearn: 2.4875347\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18747:\tlearn: 2.4874743\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18748:\tlearn: 2.4873849\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18749:\tlearn: 2.4872765\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18750:\tlearn: 2.4872204\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18751:\tlearn: 2.4871420\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18752:\tlearn: 2.4870880\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18753:\tlearn: 2.4869266\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18754:\tlearn: 2.4868196\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18755:\tlearn: 2.4867570\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18756:\tlearn: 2.4865636\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18757:\tlearn: 2.4864385\ttotal: 6m 46s\tremaining: 1m 32s\n",
      "18758:\tlearn: 2.4863618\ttotal: 6m 46s\tremaining: 1m 31s\n",
      "18759:\tlearn: 2.4862988\ttotal: 6m 46s\tremaining: 1m 31s\n",
      "18760:\tlearn: 2.4862763\ttotal: 6m 46s\tremaining: 1m 31s\n",
      "18761:\tlearn: 2.4862247\ttotal: 6m 46s\tremaining: 1m 31s\n",
      "18762:\tlearn: 2.4861866\ttotal: 6m 46s\tremaining: 1m 31s\n",
      "18763:\tlearn: 2.4861065\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18764:\tlearn: 2.4860299\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18765:\tlearn: 2.4859146\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18766:\tlearn: 2.4858609\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18767:\tlearn: 2.4857575\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18768:\tlearn: 2.4856362\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18769:\tlearn: 2.4854801\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18770:\tlearn: 2.4853586\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18771:\tlearn: 2.4852341\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18772:\tlearn: 2.4851531\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18773:\tlearn: 2.4850661\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18774:\tlearn: 2.4850043\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18775:\tlearn: 2.4849112\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18776:\tlearn: 2.4848419\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18777:\tlearn: 2.4847731\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18778:\tlearn: 2.4846958\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18779:\tlearn: 2.4846564\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18780:\tlearn: 2.4845828\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18781:\tlearn: 2.4845330\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18782:\tlearn: 2.4843969\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18783:\tlearn: 2.4841935\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18784:\tlearn: 2.4840551\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18785:\tlearn: 2.4839995\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18786:\tlearn: 2.4839498\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18787:\tlearn: 2.4838320\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18788:\tlearn: 2.4836985\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18789:\tlearn: 2.4836624\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18790:\tlearn: 2.4835831\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18791:\tlearn: 2.4834958\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18792:\tlearn: 2.4833678\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18793:\tlearn: 2.4832748\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18794:\tlearn: 2.4832137\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18795:\tlearn: 2.4831242\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18796:\tlearn: 2.4830032\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18797:\tlearn: 2.4828908\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18798:\tlearn: 2.4828065\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18799:\tlearn: 2.4827257\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18800:\tlearn: 2.4826580\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18801:\tlearn: 2.4824993\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18802:\tlearn: 2.4823814\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18803:\tlearn: 2.4823795\ttotal: 6m 47s\tremaining: 1m 31s\n",
      "18804:\tlearn: 2.4822458\ttotal: 6m 47s\tremaining: 1m 30s\n",
      "18805:\tlearn: 2.4821660\ttotal: 6m 47s\tremaining: 1m 30s\n",
      "18806:\tlearn: 2.4820435\ttotal: 6m 47s\tremaining: 1m 30s\n",
      "18807:\tlearn: 2.4819701\ttotal: 6m 47s\tremaining: 1m 30s\n",
      "18808:\tlearn: 2.4819685\ttotal: 6m 47s\tremaining: 1m 30s\n",
      "18809:\tlearn: 2.4818584\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18810:\tlearn: 2.4817443\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18811:\tlearn: 2.4816403\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18812:\tlearn: 2.4815744\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18813:\tlearn: 2.4815027\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18814:\tlearn: 2.4814206\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18815:\tlearn: 2.4813040\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18816:\tlearn: 2.4812156\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18817:\tlearn: 2.4810677\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18818:\tlearn: 2.4808511\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18819:\tlearn: 2.4807493\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18820:\tlearn: 2.4806623\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18821:\tlearn: 2.4805576\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18822:\tlearn: 2.4804544\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18823:\tlearn: 2.4803886\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18824:\tlearn: 2.4803236\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18825:\tlearn: 2.4802068\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18826:\tlearn: 2.4801598\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18827:\tlearn: 2.4801134\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18828:\tlearn: 2.4799824\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18829:\tlearn: 2.4798884\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18830:\tlearn: 2.4797741\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18831:\tlearn: 2.4796136\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18832:\tlearn: 2.4795460\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18833:\tlearn: 2.4794523\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18834:\tlearn: 2.4793629\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18835:\tlearn: 2.4792624\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18836:\tlearn: 2.4791693\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18837:\tlearn: 2.4791079\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18838:\tlearn: 2.4790601\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18839:\tlearn: 2.4789172\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18840:\tlearn: 2.4788701\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18841:\tlearn: 2.4788079\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18842:\tlearn: 2.4787415\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18843:\tlearn: 2.4786097\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18844:\tlearn: 2.4785539\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18845:\tlearn: 2.4784683\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18846:\tlearn: 2.4782888\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18847:\tlearn: 2.4781658\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18848:\tlearn: 2.4780711\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18849:\tlearn: 2.4779390\ttotal: 6m 48s\tremaining: 1m 30s\n",
      "18850:\tlearn: 2.4778126\ttotal: 6m 48s\tremaining: 1m 29s\n",
      "18851:\tlearn: 2.4777319\ttotal: 6m 48s\tremaining: 1m 29s\n",
      "18852:\tlearn: 2.4776160\ttotal: 6m 48s\tremaining: 1m 29s\n",
      "18853:\tlearn: 2.4774955\ttotal: 6m 48s\tremaining: 1m 29s\n",
      "18854:\tlearn: 2.4774365\ttotal: 6m 48s\tremaining: 1m 29s\n",
      "18855:\tlearn: 2.4773478\ttotal: 6m 48s\tremaining: 1m 29s\n",
      "18856:\tlearn: 2.4772793\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18857:\tlearn: 2.4772450\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18858:\tlearn: 2.4771482\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18859:\tlearn: 2.4770195\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18860:\tlearn: 2.4769433\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18861:\tlearn: 2.4767699\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18862:\tlearn: 2.4766966\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18863:\tlearn: 2.4765802\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18864:\tlearn: 2.4764583\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18865:\tlearn: 2.4763888\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18866:\tlearn: 2.4763343\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18867:\tlearn: 2.4762698\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18868:\tlearn: 2.4761534\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18869:\tlearn: 2.4760227\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18870:\tlearn: 2.4759465\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18871:\tlearn: 2.4759438\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18872:\tlearn: 2.4758537\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18873:\tlearn: 2.4758002\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18874:\tlearn: 2.4757353\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18875:\tlearn: 2.4756377\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18876:\tlearn: 2.4755672\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18877:\tlearn: 2.4754953\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18878:\tlearn: 2.4754278\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18879:\tlearn: 2.4753271\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18880:\tlearn: 2.4752396\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18881:\tlearn: 2.4751582\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18882:\tlearn: 2.4750916\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18883:\tlearn: 2.4750311\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18884:\tlearn: 2.4749346\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18885:\tlearn: 2.4748663\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18886:\tlearn: 2.4748229\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18887:\tlearn: 2.4747198\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18888:\tlearn: 2.4746377\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18889:\tlearn: 2.4745283\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18890:\tlearn: 2.4745264\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18891:\tlearn: 2.4743707\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18892:\tlearn: 2.4742533\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18893:\tlearn: 2.4741232\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18894:\tlearn: 2.4741224\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18895:\tlearn: 2.4740325\ttotal: 6m 49s\tremaining: 1m 29s\n",
      "18896:\tlearn: 2.4739094\ttotal: 6m 49s\tremaining: 1m 28s\n",
      "18897:\tlearn: 2.4738018\ttotal: 6m 49s\tremaining: 1m 28s\n",
      "18898:\tlearn: 2.4736760\ttotal: 6m 49s\tremaining: 1m 28s\n",
      "18899:\tlearn: 2.4735705\ttotal: 6m 49s\tremaining: 1m 28s\n",
      "18900:\tlearn: 2.4735243\ttotal: 6m 49s\tremaining: 1m 28s\n",
      "18901:\tlearn: 2.4734124\ttotal: 6m 49s\tremaining: 1m 28s\n",
      "18902:\tlearn: 2.4732619\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18903:\tlearn: 2.4731467\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18904:\tlearn: 2.4730449\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18905:\tlearn: 2.4729598\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18906:\tlearn: 2.4728223\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18907:\tlearn: 2.4727600\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18908:\tlearn: 2.4725540\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18909:\tlearn: 2.4725030\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18910:\tlearn: 2.4723794\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18911:\tlearn: 2.4723015\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18912:\tlearn: 2.4721954\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18913:\tlearn: 2.4720938\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18914:\tlearn: 2.4720433\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18915:\tlearn: 2.4719612\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18916:\tlearn: 2.4718867\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18917:\tlearn: 2.4718546\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18918:\tlearn: 2.4717860\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18919:\tlearn: 2.4716725\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18920:\tlearn: 2.4715914\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18921:\tlearn: 2.4714544\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18922:\tlearn: 2.4713709\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18923:\tlearn: 2.4712230\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18924:\tlearn: 2.4710790\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18925:\tlearn: 2.4710095\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18926:\tlearn: 2.4708822\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18927:\tlearn: 2.4708065\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18928:\tlearn: 2.4707798\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18929:\tlearn: 2.4707462\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18930:\tlearn: 2.4706190\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18931:\tlearn: 2.4705603\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18932:\tlearn: 2.4704394\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18933:\tlearn: 2.4703586\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18934:\tlearn: 2.4701836\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18935:\tlearn: 2.4700450\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18936:\tlearn: 2.4699949\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18937:\tlearn: 2.4698919\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18938:\tlearn: 2.4698271\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18939:\tlearn: 2.4697154\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18940:\tlearn: 2.4695918\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18941:\tlearn: 2.4695103\ttotal: 6m 50s\tremaining: 1m 28s\n",
      "18942:\tlearn: 2.4693755\ttotal: 6m 50s\tremaining: 1m 27s\n",
      "18943:\tlearn: 2.4692331\ttotal: 6m 50s\tremaining: 1m 27s\n",
      "18944:\tlearn: 2.4690998\ttotal: 6m 50s\tremaining: 1m 27s\n",
      "18945:\tlearn: 2.4689934\ttotal: 6m 50s\tremaining: 1m 27s\n",
      "18946:\tlearn: 2.4688939\ttotal: 6m 50s\tremaining: 1m 27s\n",
      "18947:\tlearn: 2.4688341\ttotal: 6m 50s\tremaining: 1m 27s\n",
      "18948:\tlearn: 2.4687670\ttotal: 6m 50s\tremaining: 1m 27s\n",
      "18949:\tlearn: 2.4686605\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18950:\tlearn: 2.4685876\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18951:\tlearn: 2.4683792\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18952:\tlearn: 2.4682935\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18953:\tlearn: 2.4682586\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18954:\tlearn: 2.4681339\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18955:\tlearn: 2.4680724\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18956:\tlearn: 2.4679710\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18957:\tlearn: 2.4679085\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18958:\tlearn: 2.4678577\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18959:\tlearn: 2.4678129\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18960:\tlearn: 2.4677337\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18961:\tlearn: 2.4676794\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18962:\tlearn: 2.4675904\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18963:\tlearn: 2.4675102\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18964:\tlearn: 2.4673711\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18965:\tlearn: 2.4672700\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18966:\tlearn: 2.4672395\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18967:\tlearn: 2.4671607\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18968:\tlearn: 2.4671172\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18969:\tlearn: 2.4670335\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18970:\tlearn: 2.4668913\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18971:\tlearn: 2.4668159\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18972:\tlearn: 2.4667476\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18973:\tlearn: 2.4666692\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18974:\tlearn: 2.4665857\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18975:\tlearn: 2.4664477\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18976:\tlearn: 2.4663414\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18977:\tlearn: 2.4662363\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18978:\tlearn: 2.4662353\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18979:\tlearn: 2.4661163\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18980:\tlearn: 2.4660661\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18981:\tlearn: 2.4659619\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18982:\tlearn: 2.4658844\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18983:\tlearn: 2.4657623\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18984:\tlearn: 2.4657258\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18985:\tlearn: 2.4656095\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18986:\tlearn: 2.4655620\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18987:\tlearn: 2.4654636\ttotal: 6m 51s\tremaining: 1m 27s\n",
      "18988:\tlearn: 2.4653986\ttotal: 6m 51s\tremaining: 1m 26s\n",
      "18989:\tlearn: 2.4652879\ttotal: 6m 51s\tremaining: 1m 26s\n",
      "18990:\tlearn: 2.4652066\ttotal: 6m 51s\tremaining: 1m 26s\n",
      "18991:\tlearn: 2.4650657\ttotal: 6m 51s\tremaining: 1m 26s\n",
      "18992:\tlearn: 2.4649470\ttotal: 6m 51s\tremaining: 1m 26s\n",
      "18993:\tlearn: 2.4648126\ttotal: 6m 51s\tremaining: 1m 26s\n",
      "18994:\tlearn: 2.4647251\ttotal: 6m 51s\tremaining: 1m 26s\n",
      "18995:\tlearn: 2.4646651\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "18996:\tlearn: 2.4645803\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "18997:\tlearn: 2.4645375\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "18998:\tlearn: 2.4644331\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "18999:\tlearn: 2.4643813\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19000:\tlearn: 2.4642059\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19001:\tlearn: 2.4641537\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19002:\tlearn: 2.4640619\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19003:\tlearn: 2.4640040\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19004:\tlearn: 2.4638886\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19005:\tlearn: 2.4637878\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19006:\tlearn: 2.4637708\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19007:\tlearn: 2.4636957\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19008:\tlearn: 2.4636177\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19009:\tlearn: 2.4635113\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19010:\tlearn: 2.4634085\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19011:\tlearn: 2.4633165\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19012:\tlearn: 2.4632103\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19013:\tlearn: 2.4630651\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19014:\tlearn: 2.4630108\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19015:\tlearn: 2.4628573\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19016:\tlearn: 2.4627743\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19017:\tlearn: 2.4626801\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19018:\tlearn: 2.4626015\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19019:\tlearn: 2.4625015\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19020:\tlearn: 2.4624110\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19021:\tlearn: 2.4622996\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19022:\tlearn: 2.4622434\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19023:\tlearn: 2.4621679\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19024:\tlearn: 2.4621001\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19025:\tlearn: 2.4620147\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19026:\tlearn: 2.4619166\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19027:\tlearn: 2.4618229\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19028:\tlearn: 2.4618219\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19029:\tlearn: 2.4617501\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19030:\tlearn: 2.4616320\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19031:\tlearn: 2.4615457\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19032:\tlearn: 2.4614989\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19033:\tlearn: 2.4614443\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19034:\tlearn: 2.4613629\ttotal: 6m 52s\tremaining: 1m 26s\n",
      "19035:\tlearn: 2.4612524\ttotal: 6m 52s\tremaining: 1m 25s\n",
      "19036:\tlearn: 2.4611733\ttotal: 6m 52s\tremaining: 1m 25s\n",
      "19037:\tlearn: 2.4610607\ttotal: 6m 52s\tremaining: 1m 25s\n",
      "19038:\tlearn: 2.4609767\ttotal: 6m 52s\tremaining: 1m 25s\n",
      "19039:\tlearn: 2.4608991\ttotal: 6m 52s\tremaining: 1m 25s\n",
      "19040:\tlearn: 2.4607948\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19041:\tlearn: 2.4606897\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19042:\tlearn: 2.4605908\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19043:\tlearn: 2.4605264\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19044:\tlearn: 2.4605119\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19045:\tlearn: 2.4604752\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19046:\tlearn: 2.4604366\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19047:\tlearn: 2.4603401\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19048:\tlearn: 2.4603059\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19049:\tlearn: 2.4602349\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19050:\tlearn: 2.4601795\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19051:\tlearn: 2.4600637\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19052:\tlearn: 2.4599427\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19053:\tlearn: 2.4597966\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19054:\tlearn: 2.4597052\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19055:\tlearn: 2.4596050\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19056:\tlearn: 2.4595089\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19057:\tlearn: 2.4593731\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19058:\tlearn: 2.4592188\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19059:\tlearn: 2.4591367\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19060:\tlearn: 2.4590663\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19061:\tlearn: 2.4590021\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19062:\tlearn: 2.4589071\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19063:\tlearn: 2.4588445\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19064:\tlearn: 2.4587779\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19065:\tlearn: 2.4586806\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19066:\tlearn: 2.4586798\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19067:\tlearn: 2.4586203\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19068:\tlearn: 2.4585181\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19069:\tlearn: 2.4585163\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19070:\tlearn: 2.4584416\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19071:\tlearn: 2.4583364\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19072:\tlearn: 2.4582959\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19073:\tlearn: 2.4582105\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19074:\tlearn: 2.4581414\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19075:\tlearn: 2.4580320\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19076:\tlearn: 2.4579674\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19077:\tlearn: 2.4579043\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19078:\tlearn: 2.4578388\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19079:\tlearn: 2.4577607\ttotal: 6m 53s\tremaining: 1m 25s\n",
      "19080:\tlearn: 2.4576847\ttotal: 6m 53s\tremaining: 1m 24s\n",
      "19081:\tlearn: 2.4575928\ttotal: 6m 53s\tremaining: 1m 24s\n",
      "19082:\tlearn: 2.4574852\ttotal: 6m 53s\tremaining: 1m 24s\n",
      "19083:\tlearn: 2.4574064\ttotal: 6m 53s\tremaining: 1m 24s\n",
      "19084:\tlearn: 2.4573126\ttotal: 6m 53s\tremaining: 1m 24s\n",
      "19085:\tlearn: 2.4572805\ttotal: 6m 53s\tremaining: 1m 24s\n",
      "19086:\tlearn: 2.4572193\ttotal: 6m 53s\tremaining: 1m 24s\n",
      "19087:\tlearn: 2.4570891\ttotal: 6m 53s\tremaining: 1m 24s\n",
      "19088:\tlearn: 2.4570109\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19089:\tlearn: 2.4569241\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19090:\tlearn: 2.4568714\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19091:\tlearn: 2.4567230\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19092:\tlearn: 2.4566167\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19093:\tlearn: 2.4565507\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19094:\tlearn: 2.4564884\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19095:\tlearn: 2.4563998\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19096:\tlearn: 2.4562745\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19097:\tlearn: 2.4561264\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19098:\tlearn: 2.4560494\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19099:\tlearn: 2.4559842\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19100:\tlearn: 2.4559830\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19101:\tlearn: 2.4558770\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19102:\tlearn: 2.4557394\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19103:\tlearn: 2.4556545\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19104:\tlearn: 2.4555712\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19105:\tlearn: 2.4554817\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19106:\tlearn: 2.4554316\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19107:\tlearn: 2.4552981\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19108:\tlearn: 2.4550765\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19109:\tlearn: 2.4549093\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19110:\tlearn: 2.4548771\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19111:\tlearn: 2.4547893\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19112:\tlearn: 2.4547055\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19113:\tlearn: 2.4546149\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19114:\tlearn: 2.4545449\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19115:\tlearn: 2.4544580\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19116:\tlearn: 2.4543462\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19117:\tlearn: 2.4542830\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19118:\tlearn: 2.4542361\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19119:\tlearn: 2.4541824\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19120:\tlearn: 2.4541301\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19121:\tlearn: 2.4540067\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19122:\tlearn: 2.4538482\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19123:\tlearn: 2.4537512\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19124:\tlearn: 2.4536196\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19125:\tlearn: 2.4535386\ttotal: 6m 54s\tremaining: 1m 24s\n",
      "19126:\tlearn: 2.4535004\ttotal: 6m 54s\tremaining: 1m 23s\n",
      "19127:\tlearn: 2.4534401\ttotal: 6m 54s\tremaining: 1m 23s\n",
      "19128:\tlearn: 2.4533792\ttotal: 6m 54s\tremaining: 1m 23s\n",
      "19129:\tlearn: 2.4532302\ttotal: 6m 54s\tremaining: 1m 23s\n",
      "19130:\tlearn: 2.4530870\ttotal: 6m 54s\tremaining: 1m 23s\n",
      "19131:\tlearn: 2.4530446\ttotal: 6m 54s\tremaining: 1m 23s\n",
      "19132:\tlearn: 2.4529608\ttotal: 6m 54s\tremaining: 1m 23s\n",
      "19133:\tlearn: 2.4528124\ttotal: 6m 54s\tremaining: 1m 23s\n",
      "19134:\tlearn: 2.4527028\ttotal: 6m 54s\tremaining: 1m 23s\n",
      "19135:\tlearn: 2.4525965\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19136:\tlearn: 2.4524625\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19137:\tlearn: 2.4524147\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19138:\tlearn: 2.4523110\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19139:\tlearn: 2.4522576\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19140:\tlearn: 2.4521699\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19141:\tlearn: 2.4521000\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19142:\tlearn: 2.4519879\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19143:\tlearn: 2.4519574\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19144:\tlearn: 2.4519005\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19145:\tlearn: 2.4517894\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19146:\tlearn: 2.4517263\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19147:\tlearn: 2.4516285\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19148:\tlearn: 2.4515526\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19149:\tlearn: 2.4514568\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19150:\tlearn: 2.4513745\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19151:\tlearn: 2.4512821\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19152:\tlearn: 2.4512134\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19153:\tlearn: 2.4510815\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19154:\tlearn: 2.4509963\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19155:\tlearn: 2.4509953\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19156:\tlearn: 2.4509371\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19157:\tlearn: 2.4508338\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19158:\tlearn: 2.4508322\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19159:\tlearn: 2.4507369\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19160:\tlearn: 2.4506335\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19161:\tlearn: 2.4505295\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19162:\tlearn: 2.4504684\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19163:\tlearn: 2.4503734\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19164:\tlearn: 2.4502979\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19165:\tlearn: 2.4502010\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19166:\tlearn: 2.4501443\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19167:\tlearn: 2.4500705\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19168:\tlearn: 2.4500064\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19169:\tlearn: 2.4499684\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19170:\tlearn: 2.4498752\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19171:\tlearn: 2.4498006\ttotal: 6m 55s\tremaining: 1m 23s\n",
      "19172:\tlearn: 2.4497249\ttotal: 6m 55s\tremaining: 1m 22s\n",
      "19173:\tlearn: 2.4496221\ttotal: 6m 55s\tremaining: 1m 22s\n",
      "19174:\tlearn: 2.4496013\ttotal: 6m 55s\tremaining: 1m 22s\n",
      "19175:\tlearn: 2.4494919\ttotal: 6m 55s\tremaining: 1m 22s\n",
      "19176:\tlearn: 2.4493540\ttotal: 6m 55s\tremaining: 1m 22s\n",
      "19177:\tlearn: 2.4491969\ttotal: 6m 55s\tremaining: 1m 22s\n",
      "19178:\tlearn: 2.4490927\ttotal: 6m 55s\tremaining: 1m 22s\n",
      "19179:\tlearn: 2.4490379\ttotal: 6m 55s\tremaining: 1m 22s\n",
      "19180:\tlearn: 2.4489915\ttotal: 6m 55s\tremaining: 1m 22s\n",
      "19181:\tlearn: 2.4488499\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19182:\tlearn: 2.4487359\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19183:\tlearn: 2.4487338\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19184:\tlearn: 2.4486769\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19185:\tlearn: 2.4485592\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19186:\tlearn: 2.4484509\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19187:\tlearn: 2.4483889\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19188:\tlearn: 2.4483871\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19189:\tlearn: 2.4483638\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19190:\tlearn: 2.4482887\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19191:\tlearn: 2.4481778\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19192:\tlearn: 2.4480733\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19193:\tlearn: 2.4479929\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19194:\tlearn: 2.4479227\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19195:\tlearn: 2.4478639\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19196:\tlearn: 2.4477995\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19197:\tlearn: 2.4477284\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19198:\tlearn: 2.4476819\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19199:\tlearn: 2.4475896\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19200:\tlearn: 2.4475884\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19201:\tlearn: 2.4475169\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19202:\tlearn: 2.4474217\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19203:\tlearn: 2.4473490\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19204:\tlearn: 2.4471653\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19205:\tlearn: 2.4470402\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19206:\tlearn: 2.4469445\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19207:\tlearn: 2.4469107\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19208:\tlearn: 2.4467417\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19209:\tlearn: 2.4466495\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19210:\tlearn: 2.4465512\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19211:\tlearn: 2.4464828\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19212:\tlearn: 2.4464578\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19213:\tlearn: 2.4463383\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19214:\tlearn: 2.4462450\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19215:\tlearn: 2.4461669\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19216:\tlearn: 2.4461175\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19217:\tlearn: 2.4460460\ttotal: 6m 56s\tremaining: 1m 22s\n",
      "19218:\tlearn: 2.4459171\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19219:\tlearn: 2.4458572\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19220:\tlearn: 2.4458108\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19221:\tlearn: 2.4457206\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19222:\tlearn: 2.4456456\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19223:\tlearn: 2.4454771\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19224:\tlearn: 2.4453680\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19225:\tlearn: 2.4452908\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19226:\tlearn: 2.4452584\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19227:\tlearn: 2.4451772\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19228:\tlearn: 2.4451061\ttotal: 6m 56s\tremaining: 1m 21s\n",
      "19229:\tlearn: 2.4450116\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19230:\tlearn: 2.4449583\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19231:\tlearn: 2.4448280\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19232:\tlearn: 2.4447684\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19233:\tlearn: 2.4447139\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19234:\tlearn: 2.4446470\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19235:\tlearn: 2.4446131\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19236:\tlearn: 2.4445790\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19237:\tlearn: 2.4445130\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19238:\tlearn: 2.4444246\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19239:\tlearn: 2.4443852\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19240:\tlearn: 2.4443186\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19241:\tlearn: 2.4442175\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19242:\tlearn: 2.4440360\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19243:\tlearn: 2.4439376\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19244:\tlearn: 2.4437962\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19245:\tlearn: 2.4437375\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19246:\tlearn: 2.4436444\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19247:\tlearn: 2.4435237\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19248:\tlearn: 2.4434250\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19249:\tlearn: 2.4433756\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19250:\tlearn: 2.4433659\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19251:\tlearn: 2.4432910\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19252:\tlearn: 2.4431997\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19253:\tlearn: 2.4431491\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19254:\tlearn: 2.4429947\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19255:\tlearn: 2.4429157\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19256:\tlearn: 2.4428541\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19257:\tlearn: 2.4427470\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19258:\tlearn: 2.4426815\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19259:\tlearn: 2.4425796\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19260:\tlearn: 2.4425066\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19261:\tlearn: 2.4423755\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19262:\tlearn: 2.4423025\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19263:\tlearn: 2.4421883\ttotal: 6m 57s\tremaining: 1m 21s\n",
      "19264:\tlearn: 2.4421351\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19265:\tlearn: 2.4420440\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19266:\tlearn: 2.4419550\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19267:\tlearn: 2.4418850\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19268:\tlearn: 2.4418205\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19269:\tlearn: 2.4416509\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19270:\tlearn: 2.4415527\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19271:\tlearn: 2.4415503\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19272:\tlearn: 2.4415321\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19273:\tlearn: 2.4414769\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19274:\tlearn: 2.4413951\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19275:\tlearn: 2.4413150\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "19276:\tlearn: 2.4412193\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19277:\tlearn: 2.4410961\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19278:\tlearn: 2.4410946\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19279:\tlearn: 2.4410531\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19280:\tlearn: 2.4409711\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19281:\tlearn: 2.4408199\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19282:\tlearn: 2.4406896\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19283:\tlearn: 2.4406297\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19284:\tlearn: 2.4405536\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19285:\tlearn: 2.4404986\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19286:\tlearn: 2.4404415\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19287:\tlearn: 2.4403733\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19288:\tlearn: 2.4402515\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19289:\tlearn: 2.4401895\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19290:\tlearn: 2.4400863\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19291:\tlearn: 2.4400075\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19292:\tlearn: 2.4399624\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19293:\tlearn: 2.4398912\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19294:\tlearn: 2.4397639\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19295:\tlearn: 2.4396655\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19296:\tlearn: 2.4395758\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19297:\tlearn: 2.4395019\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19298:\tlearn: 2.4393964\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19299:\tlearn: 2.4392909\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19300:\tlearn: 2.4391364\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19301:\tlearn: 2.4390425\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19302:\tlearn: 2.4389710\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19303:\tlearn: 2.4388689\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19304:\tlearn: 2.4387816\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19305:\tlearn: 2.4387090\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19306:\tlearn: 2.4386308\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19307:\tlearn: 2.4385167\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19308:\tlearn: 2.4384492\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19309:\tlearn: 2.4383736\ttotal: 6m 58s\tremaining: 1m 20s\n",
      "19310:\tlearn: 2.4382678\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19311:\tlearn: 2.4381332\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19312:\tlearn: 2.4380693\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19313:\tlearn: 2.4379896\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19314:\tlearn: 2.4379627\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19315:\tlearn: 2.4379306\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19316:\tlearn: 2.4378328\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19317:\tlearn: 2.4377493\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19318:\tlearn: 2.4376858\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19319:\tlearn: 2.4376365\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19320:\tlearn: 2.4375221\ttotal: 6m 58s\tremaining: 1m 19s\n",
      "19321:\tlearn: 2.4374070\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19322:\tlearn: 2.4372936\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19323:\tlearn: 2.4372162\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19324:\tlearn: 2.4370855\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19325:\tlearn: 2.4370264\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19326:\tlearn: 2.4369034\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19327:\tlearn: 2.4367685\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19328:\tlearn: 2.4366808\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19329:\tlearn: 2.4366246\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19330:\tlearn: 2.4365715\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19331:\tlearn: 2.4364907\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19332:\tlearn: 2.4364155\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19333:\tlearn: 2.4363406\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19334:\tlearn: 2.4362624\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19335:\tlearn: 2.4361649\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19336:\tlearn: 2.4360675\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19337:\tlearn: 2.4360249\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19338:\tlearn: 2.4358937\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19339:\tlearn: 2.4357961\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19340:\tlearn: 2.4357506\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19341:\tlearn: 2.4356646\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19342:\tlearn: 2.4355509\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19343:\tlearn: 2.4354843\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19344:\tlearn: 2.4353657\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19345:\tlearn: 2.4353028\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19346:\tlearn: 2.4352200\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19347:\tlearn: 2.4351353\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19348:\tlearn: 2.4350529\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19349:\tlearn: 2.4349754\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19350:\tlearn: 2.4348991\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19351:\tlearn: 2.4347942\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19352:\tlearn: 2.4347590\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19353:\tlearn: 2.4347279\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19354:\tlearn: 2.4346560\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19355:\tlearn: 2.4345648\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19356:\tlearn: 2.4344590\ttotal: 6m 59s\tremaining: 1m 19s\n",
      "19357:\tlearn: 2.4343260\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19358:\tlearn: 2.4342369\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19359:\tlearn: 2.4340643\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19360:\tlearn: 2.4339708\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19361:\tlearn: 2.4339217\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19362:\tlearn: 2.4338480\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19363:\tlearn: 2.4337844\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19364:\tlearn: 2.4337137\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19365:\tlearn: 2.4336436\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19366:\tlearn: 2.4335789\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19367:\tlearn: 2.4334114\ttotal: 6m 59s\tremaining: 1m 18s\n",
      "19368:\tlearn: 2.4333646\ttotal: 7m\tremaining: 1m 18s\n",
      "19369:\tlearn: 2.4332304\ttotal: 7m\tremaining: 1m 18s\n",
      "19370:\tlearn: 2.4331787\ttotal: 7m\tremaining: 1m 18s\n",
      "19371:\tlearn: 2.4330767\ttotal: 7m\tremaining: 1m 18s\n",
      "19372:\tlearn: 2.4329592\ttotal: 7m\tremaining: 1m 18s\n",
      "19373:\tlearn: 2.4328529\ttotal: 7m\tremaining: 1m 18s\n",
      "19374:\tlearn: 2.4327889\ttotal: 7m\tremaining: 1m 18s\n",
      "19375:\tlearn: 2.4327076\ttotal: 7m\tremaining: 1m 18s\n",
      "19376:\tlearn: 2.4326355\ttotal: 7m\tremaining: 1m 18s\n",
      "19377:\tlearn: 2.4325662\ttotal: 7m\tremaining: 1m 18s\n",
      "19378:\tlearn: 2.4325340\ttotal: 7m\tremaining: 1m 18s\n",
      "19379:\tlearn: 2.4324348\ttotal: 7m\tremaining: 1m 18s\n",
      "19380:\tlearn: 2.4323476\ttotal: 7m\tremaining: 1m 18s\n",
      "19381:\tlearn: 2.4322250\ttotal: 7m\tremaining: 1m 18s\n",
      "19382:\tlearn: 2.4320664\ttotal: 7m\tremaining: 1m 18s\n",
      "19383:\tlearn: 2.4320246\ttotal: 7m\tremaining: 1m 18s\n",
      "19384:\tlearn: 2.4319329\ttotal: 7m\tremaining: 1m 18s\n",
      "19385:\tlearn: 2.4317884\ttotal: 7m\tremaining: 1m 18s\n",
      "19386:\tlearn: 2.4316874\ttotal: 7m\tremaining: 1m 18s\n",
      "19387:\tlearn: 2.4315966\ttotal: 7m\tremaining: 1m 18s\n",
      "19388:\tlearn: 2.4315019\ttotal: 7m\tremaining: 1m 18s\n",
      "19389:\tlearn: 2.4314435\ttotal: 7m\tremaining: 1m 18s\n",
      "19390:\tlearn: 2.4313492\ttotal: 7m\tremaining: 1m 18s\n",
      "19391:\tlearn: 2.4312784\ttotal: 7m\tremaining: 1m 18s\n",
      "19392:\tlearn: 2.4311892\ttotal: 7m\tremaining: 1m 18s\n",
      "19393:\tlearn: 2.4310931\ttotal: 7m\tremaining: 1m 18s\n",
      "19394:\tlearn: 2.4310153\ttotal: 7m\tremaining: 1m 18s\n",
      "19395:\tlearn: 2.4309370\ttotal: 7m\tremaining: 1m 18s\n",
      "19396:\tlearn: 2.4308323\ttotal: 7m\tremaining: 1m 18s\n",
      "19397:\tlearn: 2.4307673\ttotal: 7m\tremaining: 1m 18s\n",
      "19398:\tlearn: 2.4306796\ttotal: 7m\tremaining: 1m 18s\n",
      "19399:\tlearn: 2.4305988\ttotal: 7m\tremaining: 1m 18s\n",
      "19400:\tlearn: 2.4305180\ttotal: 7m\tremaining: 1m 18s\n",
      "19401:\tlearn: 2.4304141\ttotal: 7m\tremaining: 1m 18s\n",
      "19402:\tlearn: 2.4303108\ttotal: 7m\tremaining: 1m 17s\n",
      "19403:\tlearn: 2.4302753\ttotal: 7m\tremaining: 1m 17s\n",
      "19404:\tlearn: 2.4301301\ttotal: 7m\tremaining: 1m 17s\n",
      "19405:\tlearn: 2.4300549\ttotal: 7m\tremaining: 1m 17s\n",
      "19406:\tlearn: 2.4299701\ttotal: 7m\tremaining: 1m 17s\n",
      "19407:\tlearn: 2.4299068\ttotal: 7m\tremaining: 1m 17s\n",
      "19408:\tlearn: 2.4298452\ttotal: 7m\tremaining: 1m 17s\n",
      "19409:\tlearn: 2.4296917\ttotal: 7m\tremaining: 1m 17s\n",
      "19410:\tlearn: 2.4296240\ttotal: 7m\tremaining: 1m 17s\n",
      "19411:\tlearn: 2.4295544\ttotal: 7m\tremaining: 1m 17s\n",
      "19412:\tlearn: 2.4294430\ttotal: 7m\tremaining: 1m 17s\n",
      "19413:\tlearn: 2.4293438\ttotal: 7m\tremaining: 1m 17s\n",
      "19414:\tlearn: 2.4291661\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19415:\tlearn: 2.4291264\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19416:\tlearn: 2.4290349\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19417:\tlearn: 2.4288945\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19418:\tlearn: 2.4287494\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19419:\tlearn: 2.4286832\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19420:\tlearn: 2.4285638\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19421:\tlearn: 2.4284582\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19422:\tlearn: 2.4283819\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19423:\tlearn: 2.4283172\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19424:\tlearn: 2.4282257\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19425:\tlearn: 2.4281721\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19426:\tlearn: 2.4281019\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19427:\tlearn: 2.4280060\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19428:\tlearn: 2.4279246\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19429:\tlearn: 2.4278286\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19430:\tlearn: 2.4277536\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19431:\tlearn: 2.4277064\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19432:\tlearn: 2.4276334\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19433:\tlearn: 2.4275665\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19434:\tlearn: 2.4274617\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19435:\tlearn: 2.4274117\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19436:\tlearn: 2.4273565\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19437:\tlearn: 2.4272907\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19438:\tlearn: 2.4271756\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19439:\tlearn: 2.4270894\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19440:\tlearn: 2.4269934\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19441:\tlearn: 2.4269011\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19442:\tlearn: 2.4268190\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19443:\tlearn: 2.4267297\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19444:\tlearn: 2.4266332\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19445:\tlearn: 2.4264875\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19446:\tlearn: 2.4264129\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19447:\tlearn: 2.4263206\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19448:\tlearn: 2.4262457\ttotal: 7m 1s\tremaining: 1m 17s\n",
      "19449:\tlearn: 2.4262004\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19450:\tlearn: 2.4260796\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19451:\tlearn: 2.4259847\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19452:\tlearn: 2.4258992\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19453:\tlearn: 2.4258281\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19454:\tlearn: 2.4257751\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19455:\tlearn: 2.4256982\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19456:\tlearn: 2.4256355\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19457:\tlearn: 2.4255246\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19458:\tlearn: 2.4254826\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19459:\tlearn: 2.4254377\ttotal: 7m 1s\tremaining: 1m 16s\n",
      "19460:\tlearn: 2.4253896\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19461:\tlearn: 2.4252784\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19462:\tlearn: 2.4251655\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19463:\tlearn: 2.4250122\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19464:\tlearn: 2.4249105\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19465:\tlearn: 2.4248292\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19466:\tlearn: 2.4247408\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19467:\tlearn: 2.4246742\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19468:\tlearn: 2.4245527\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19469:\tlearn: 2.4244832\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19470:\tlearn: 2.4244344\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19471:\tlearn: 2.4243759\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19472:\tlearn: 2.4242908\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19473:\tlearn: 2.4242068\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19474:\tlearn: 2.4241056\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19475:\tlearn: 2.4240363\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19476:\tlearn: 2.4239536\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19477:\tlearn: 2.4238518\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19478:\tlearn: 2.4237753\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19479:\tlearn: 2.4236761\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19480:\tlearn: 2.4235691\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19481:\tlearn: 2.4234441\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19482:\tlearn: 2.4233644\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19483:\tlearn: 2.4232590\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19484:\tlearn: 2.4231402\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19485:\tlearn: 2.4230116\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19486:\tlearn: 2.4229480\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19487:\tlearn: 2.4228769\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19488:\tlearn: 2.4227847\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19489:\tlearn: 2.4227051\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19490:\tlearn: 2.4225781\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19491:\tlearn: 2.4225048\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19492:\tlearn: 2.4223994\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19493:\tlearn: 2.4223215\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19494:\tlearn: 2.4221992\ttotal: 7m 2s\tremaining: 1m 16s\n",
      "19495:\tlearn: 2.4221358\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19496:\tlearn: 2.4220184\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19497:\tlearn: 2.4219429\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19498:\tlearn: 2.4218169\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19499:\tlearn: 2.4217383\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19500:\tlearn: 2.4216427\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19501:\tlearn: 2.4215747\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19502:\tlearn: 2.4215028\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19503:\tlearn: 2.4213888\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19504:\tlearn: 2.4213284\ttotal: 7m 2s\tremaining: 1m 15s\n",
      "19505:\tlearn: 2.4212551\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19506:\tlearn: 2.4211098\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19507:\tlearn: 2.4210072\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19508:\tlearn: 2.4208752\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19509:\tlearn: 2.4208299\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19510:\tlearn: 2.4207414\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19511:\tlearn: 2.4207290\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19512:\tlearn: 2.4206425\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19513:\tlearn: 2.4205853\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19514:\tlearn: 2.4204646\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19515:\tlearn: 2.4204408\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19516:\tlearn: 2.4203698\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19517:\tlearn: 2.4203012\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19518:\tlearn: 2.4202055\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19519:\tlearn: 2.4201092\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19520:\tlearn: 2.4199778\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19521:\tlearn: 2.4198867\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19522:\tlearn: 2.4198586\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19523:\tlearn: 2.4197332\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19524:\tlearn: 2.4196939\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19525:\tlearn: 2.4196495\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19526:\tlearn: 2.4195602\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19527:\tlearn: 2.4194949\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19528:\tlearn: 2.4193898\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19529:\tlearn: 2.4192915\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19530:\tlearn: 2.4192089\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19531:\tlearn: 2.4191482\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19532:\tlearn: 2.4190798\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19533:\tlearn: 2.4190178\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19534:\tlearn: 2.4189357\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19535:\tlearn: 2.4188236\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19536:\tlearn: 2.4187723\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19537:\tlearn: 2.4187165\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19538:\tlearn: 2.4186509\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19539:\tlearn: 2.4185407\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19540:\tlearn: 2.4184427\ttotal: 7m 3s\tremaining: 1m 15s\n",
      "19541:\tlearn: 2.4183883\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19542:\tlearn: 2.4183022\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19543:\tlearn: 2.4182494\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19544:\tlearn: 2.4181506\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19545:\tlearn: 2.4180550\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19546:\tlearn: 2.4179782\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19547:\tlearn: 2.4179659\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19548:\tlearn: 2.4178445\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19549:\tlearn: 2.4177343\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19550:\tlearn: 2.4176633\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19551:\tlearn: 2.4175914\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19552:\tlearn: 2.4175103\ttotal: 7m 3s\tremaining: 1m 14s\n",
      "19553:\tlearn: 2.4174079\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19554:\tlearn: 2.4172773\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19555:\tlearn: 2.4171346\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19556:\tlearn: 2.4170623\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19557:\tlearn: 2.4169964\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19558:\tlearn: 2.4169245\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19559:\tlearn: 2.4167603\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19560:\tlearn: 2.4166795\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19561:\tlearn: 2.4165945\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19562:\tlearn: 2.4165272\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19563:\tlearn: 2.4165264\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19564:\tlearn: 2.4163879\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19565:\tlearn: 2.4162524\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19566:\tlearn: 2.4161074\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19567:\tlearn: 2.4160122\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19568:\tlearn: 2.4159301\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19569:\tlearn: 2.4159285\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19570:\tlearn: 2.4158321\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19571:\tlearn: 2.4157659\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19572:\tlearn: 2.4156400\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19573:\tlearn: 2.4155412\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19574:\tlearn: 2.4154052\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19575:\tlearn: 2.4153102\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19576:\tlearn: 2.4152053\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19577:\tlearn: 2.4150357\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19578:\tlearn: 2.4149485\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19579:\tlearn: 2.4149468\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19580:\tlearn: 2.4148550\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19581:\tlearn: 2.4147642\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19582:\tlearn: 2.4147162\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19583:\tlearn: 2.4146535\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19584:\tlearn: 2.4146166\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19585:\tlearn: 2.4145145\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19586:\tlearn: 2.4143940\ttotal: 7m 4s\tremaining: 1m 14s\n",
      "19587:\tlearn: 2.4142911\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19588:\tlearn: 2.4141987\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19589:\tlearn: 2.4140844\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19590:\tlearn: 2.4139911\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19591:\tlearn: 2.4139394\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19592:\tlearn: 2.4138428\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19593:\tlearn: 2.4137732\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19594:\tlearn: 2.4136842\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19595:\tlearn: 2.4136373\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19596:\tlearn: 2.4135859\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19597:\tlearn: 2.4135320\ttotal: 7m 4s\tremaining: 1m 13s\n",
      "19598:\tlearn: 2.4134850\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19599:\tlearn: 2.4133681\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19600:\tlearn: 2.4133658\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19601:\tlearn: 2.4132690\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19602:\tlearn: 2.4131053\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19603:\tlearn: 2.4129809\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19604:\tlearn: 2.4128626\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19605:\tlearn: 2.4127567\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19606:\tlearn: 2.4126226\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19607:\tlearn: 2.4125382\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19608:\tlearn: 2.4123897\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19609:\tlearn: 2.4123348\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19610:\tlearn: 2.4122156\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19611:\tlearn: 2.4121045\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19612:\tlearn: 2.4120221\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19613:\tlearn: 2.4119646\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19614:\tlearn: 2.4119298\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19615:\tlearn: 2.4117926\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19616:\tlearn: 2.4117354\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19617:\tlearn: 2.4116849\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19618:\tlearn: 2.4115601\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19619:\tlearn: 2.4114431\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19620:\tlearn: 2.4113368\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19621:\tlearn: 2.4112519\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19622:\tlearn: 2.4111808\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19623:\tlearn: 2.4111791\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19624:\tlearn: 2.4111086\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19625:\tlearn: 2.4109836\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19626:\tlearn: 2.4109181\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19627:\tlearn: 2.4108137\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19628:\tlearn: 2.4106421\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19629:\tlearn: 2.4105806\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19630:\tlearn: 2.4104650\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19631:\tlearn: 2.4102710\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19632:\tlearn: 2.4101751\ttotal: 7m 5s\tremaining: 1m 13s\n",
      "19633:\tlearn: 2.4100898\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19634:\tlearn: 2.4100358\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19635:\tlearn: 2.4099995\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19636:\tlearn: 2.4099225\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19637:\tlearn: 2.4097893\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19638:\tlearn: 2.4096735\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19639:\tlearn: 2.4096117\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19640:\tlearn: 2.4095627\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19641:\tlearn: 2.4095252\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19642:\tlearn: 2.4094032\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19643:\tlearn: 2.4092977\ttotal: 7m 5s\tremaining: 1m 12s\n",
      "19644:\tlearn: 2.4092196\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19645:\tlearn: 2.4091144\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19646:\tlearn: 2.4090644\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19647:\tlearn: 2.4089552\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19648:\tlearn: 2.4088890\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19649:\tlearn: 2.4087789\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19650:\tlearn: 2.4087777\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19651:\tlearn: 2.4087008\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19652:\tlearn: 2.4086524\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19653:\tlearn: 2.4085667\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19654:\tlearn: 2.4084136\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19655:\tlearn: 2.4083151\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19656:\tlearn: 2.4081934\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19657:\tlearn: 2.4081478\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19658:\tlearn: 2.4080751\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19659:\tlearn: 2.4079466\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19660:\tlearn: 2.4078668\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19661:\tlearn: 2.4077563\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19662:\tlearn: 2.4076558\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19663:\tlearn: 2.4075873\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19664:\tlearn: 2.4075270\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19665:\tlearn: 2.4074760\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19666:\tlearn: 2.4073801\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19667:\tlearn: 2.4073222\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19668:\tlearn: 2.4072442\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19669:\tlearn: 2.4071688\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19670:\tlearn: 2.4070904\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19671:\tlearn: 2.4070384\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19672:\tlearn: 2.4069999\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19673:\tlearn: 2.4069163\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19674:\tlearn: 2.4067729\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19675:\tlearn: 2.4066388\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19676:\tlearn: 2.4066196\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19677:\tlearn: 2.4065250\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19678:\tlearn: 2.4064884\ttotal: 7m 6s\tremaining: 1m 12s\n",
      "19679:\tlearn: 2.4064303\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19680:\tlearn: 2.4063764\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19681:\tlearn: 2.4062500\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19682:\tlearn: 2.4060849\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19683:\tlearn: 2.4060143\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19684:\tlearn: 2.4059167\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19685:\tlearn: 2.4058145\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19686:\tlearn: 2.4057307\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19687:\tlearn: 2.4056982\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19688:\tlearn: 2.4055918\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19689:\tlearn: 2.4055179\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19690:\tlearn: 2.4054164\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19691:\tlearn: 2.4053854\ttotal: 7m 6s\tremaining: 1m 11s\n",
      "19692:\tlearn: 2.4052915\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19693:\tlearn: 2.4052058\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19694:\tlearn: 2.4050715\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19695:\tlearn: 2.4049595\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19696:\tlearn: 2.4049189\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19697:\tlearn: 2.4048603\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19698:\tlearn: 2.4048261\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19699:\tlearn: 2.4046667\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19700:\tlearn: 2.4045560\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19701:\tlearn: 2.4044743\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19702:\tlearn: 2.4044271\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19703:\tlearn: 2.4042371\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19704:\tlearn: 2.4041055\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19705:\tlearn: 2.4040350\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19706:\tlearn: 2.4039528\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19707:\tlearn: 2.4038666\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19708:\tlearn: 2.4037672\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19709:\tlearn: 2.4037054\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19710:\tlearn: 2.4036625\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19711:\tlearn: 2.4035685\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19712:\tlearn: 2.4035163\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19713:\tlearn: 2.4034349\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19714:\tlearn: 2.4033856\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19715:\tlearn: 2.4033080\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19716:\tlearn: 2.4032189\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19717:\tlearn: 2.4031111\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19718:\tlearn: 2.4030676\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19719:\tlearn: 2.4029789\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19720:\tlearn: 2.4029271\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19721:\tlearn: 2.4028355\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19722:\tlearn: 2.4027217\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19723:\tlearn: 2.4026605\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19724:\tlearn: 2.4025992\ttotal: 7m 7s\tremaining: 1m 11s\n",
      "19725:\tlearn: 2.4025023\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19726:\tlearn: 2.4024509\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19727:\tlearn: 2.4024031\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19728:\tlearn: 2.4022793\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19729:\tlearn: 2.4021785\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19730:\tlearn: 2.4021617\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19731:\tlearn: 2.4020877\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19732:\tlearn: 2.4020298\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19733:\tlearn: 2.4019477\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19734:\tlearn: 2.4018638\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19735:\tlearn: 2.4017752\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19736:\tlearn: 2.4016977\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19737:\tlearn: 2.4016409\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19738:\tlearn: 2.4015752\ttotal: 7m 7s\tremaining: 1m 10s\n",
      "19739:\tlearn: 2.4014320\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19740:\tlearn: 2.4013488\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19741:\tlearn: 2.4012680\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19742:\tlearn: 2.4011923\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19743:\tlearn: 2.4011062\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19744:\tlearn: 2.4010812\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19745:\tlearn: 2.4010418\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19746:\tlearn: 2.4009597\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19747:\tlearn: 2.4008695\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19748:\tlearn: 2.4008039\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19749:\tlearn: 2.4007083\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19750:\tlearn: 2.4005923\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19751:\tlearn: 2.4005287\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19752:\tlearn: 2.4005262\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19753:\tlearn: 2.4004741\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19754:\tlearn: 2.4004002\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19755:\tlearn: 2.4003328\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19756:\tlearn: 2.4002730\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19757:\tlearn: 2.4001836\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19758:\tlearn: 2.4000865\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19759:\tlearn: 2.3999888\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19760:\tlearn: 2.3998979\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19761:\tlearn: 2.3998588\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19762:\tlearn: 2.3997777\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19763:\tlearn: 2.3996567\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19764:\tlearn: 2.3996299\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19765:\tlearn: 2.3994894\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19766:\tlearn: 2.3993871\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19767:\tlearn: 2.3993299\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19768:\tlearn: 2.3992846\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19769:\tlearn: 2.3991462\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19770:\tlearn: 2.3990369\ttotal: 7m 8s\tremaining: 1m 10s\n",
      "19771:\tlearn: 2.3989578\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19772:\tlearn: 2.3989083\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19773:\tlearn: 2.3988365\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19774:\tlearn: 2.3988193\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19775:\tlearn: 2.3987911\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19776:\tlearn: 2.3987622\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19777:\tlearn: 2.3986889\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19778:\tlearn: 2.3986093\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19779:\tlearn: 2.3985702\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19780:\tlearn: 2.3984684\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19781:\tlearn: 2.3984114\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19782:\tlearn: 2.3982324\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19783:\tlearn: 2.3981547\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19784:\tlearn: 2.3981088\ttotal: 7m 8s\tremaining: 1m 9s\n",
      "19785:\tlearn: 2.3979104\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19786:\tlearn: 2.3978197\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19787:\tlearn: 2.3976558\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19788:\tlearn: 2.3975791\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19789:\tlearn: 2.3974343\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19790:\tlearn: 2.3973148\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19791:\tlearn: 2.3972430\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19792:\tlearn: 2.3971921\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19793:\tlearn: 2.3970608\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19794:\tlearn: 2.3969801\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19795:\tlearn: 2.3969148\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19796:\tlearn: 2.3968088\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19797:\tlearn: 2.3966756\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19798:\tlearn: 2.3965343\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19799:\tlearn: 2.3964442\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19800:\tlearn: 2.3963819\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19801:\tlearn: 2.3963223\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19802:\tlearn: 2.3962627\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19803:\tlearn: 2.3962011\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19804:\tlearn: 2.3961372\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19805:\tlearn: 2.3960369\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19806:\tlearn: 2.3959659\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19807:\tlearn: 2.3959310\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19808:\tlearn: 2.3959006\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19809:\tlearn: 2.3958790\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19810:\tlearn: 2.3957930\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19811:\tlearn: 2.3957522\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19812:\tlearn: 2.3957510\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19813:\tlearn: 2.3956408\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19814:\tlearn: 2.3955489\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19815:\tlearn: 2.3954902\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19816:\tlearn: 2.3953818\ttotal: 7m 9s\tremaining: 1m 9s\n",
      "19817:\tlearn: 2.3953762\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19818:\tlearn: 2.3953392\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19819:\tlearn: 2.3952324\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19820:\tlearn: 2.3951733\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19821:\tlearn: 2.3950951\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19822:\tlearn: 2.3950070\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19823:\tlearn: 2.3948888\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19824:\tlearn: 2.3948158\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19825:\tlearn: 2.3946613\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19826:\tlearn: 2.3945848\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19827:\tlearn: 2.3944291\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19828:\tlearn: 2.3943510\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19829:\tlearn: 2.3942791\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19830:\tlearn: 2.3942381\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19831:\tlearn: 2.3941385\ttotal: 7m 9s\tremaining: 1m 8s\n",
      "19832:\tlearn: 2.3940501\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19833:\tlearn: 2.3939186\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19834:\tlearn: 2.3938427\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19835:\tlearn: 2.3937689\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19836:\tlearn: 2.3936730\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19837:\tlearn: 2.3936262\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19838:\tlearn: 2.3935390\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19839:\tlearn: 2.3934842\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19840:\tlearn: 2.3933740\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19841:\tlearn: 2.3932784\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19842:\tlearn: 2.3932119\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19843:\tlearn: 2.3931514\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19844:\tlearn: 2.3930866\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19845:\tlearn: 2.3929641\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19846:\tlearn: 2.3928851\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19847:\tlearn: 2.3928358\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19848:\tlearn: 2.3927202\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19849:\tlearn: 2.3926837\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19850:\tlearn: 2.3925152\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19851:\tlearn: 2.3923863\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19852:\tlearn: 2.3922883\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19853:\tlearn: 2.3922310\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19854:\tlearn: 2.3920901\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19855:\tlearn: 2.3919781\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19856:\tlearn: 2.3918856\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19857:\tlearn: 2.3917987\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19858:\tlearn: 2.3917423\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19859:\tlearn: 2.3916732\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19860:\tlearn: 2.3915829\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19861:\tlearn: 2.3914486\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19862:\tlearn: 2.3913722\ttotal: 7m 10s\tremaining: 1m 8s\n",
      "19863:\tlearn: 2.3913050\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19864:\tlearn: 2.3912240\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19865:\tlearn: 2.3911164\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19866:\tlearn: 2.3910109\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19867:\tlearn: 2.3909420\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19868:\tlearn: 2.3908630\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19869:\tlearn: 2.3908008\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19870:\tlearn: 2.3907600\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19871:\tlearn: 2.3906438\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19872:\tlearn: 2.3905479\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19873:\tlearn: 2.3904928\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19874:\tlearn: 2.3903785\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19875:\tlearn: 2.3903084\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19876:\tlearn: 2.3901652\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19877:\tlearn: 2.3900962\ttotal: 7m 10s\tremaining: 1m 7s\n",
      "19878:\tlearn: 2.3899897\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19879:\tlearn: 2.3899831\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19880:\tlearn: 2.3898806\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19881:\tlearn: 2.3898065\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19882:\tlearn: 2.3896919\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19883:\tlearn: 2.3896519\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19884:\tlearn: 2.3896426\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19885:\tlearn: 2.3895457\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19886:\tlearn: 2.3894836\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19887:\tlearn: 2.3894357\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19888:\tlearn: 2.3893667\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19889:\tlearn: 2.3892886\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19890:\tlearn: 2.3891625\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19891:\tlearn: 2.3891058\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19892:\tlearn: 2.3890512\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19893:\tlearn: 2.3889232\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19894:\tlearn: 2.3888630\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19895:\tlearn: 2.3887829\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19896:\tlearn: 2.3887452\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19897:\tlearn: 2.3886160\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19898:\tlearn: 2.3885152\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19899:\tlearn: 2.3884076\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19900:\tlearn: 2.3883135\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19901:\tlearn: 2.3881723\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19902:\tlearn: 2.3880177\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19903:\tlearn: 2.3879298\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19904:\tlearn: 2.3878631\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19905:\tlearn: 2.3877944\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19906:\tlearn: 2.3876963\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19907:\tlearn: 2.3876255\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19908:\tlearn: 2.3875572\ttotal: 7m 11s\tremaining: 1m 7s\n",
      "19909:\tlearn: 2.3874643\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19910:\tlearn: 2.3874108\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19911:\tlearn: 2.3872908\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19912:\tlearn: 2.3872093\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19913:\tlearn: 2.3872077\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19914:\tlearn: 2.3871180\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19915:\tlearn: 2.3870770\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19916:\tlearn: 2.3869727\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19917:\tlearn: 2.3868525\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19918:\tlearn: 2.3868117\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19919:\tlearn: 2.3867191\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19920:\tlearn: 2.3866324\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19921:\tlearn: 2.3865476\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19922:\tlearn: 2.3864809\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19923:\tlearn: 2.3863884\ttotal: 7m 11s\tremaining: 1m 6s\n",
      "19924:\tlearn: 2.3862907\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19925:\tlearn: 2.3861850\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19926:\tlearn: 2.3860731\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19927:\tlearn: 2.3859489\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19928:\tlearn: 2.3858658\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19929:\tlearn: 2.3858012\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19930:\tlearn: 2.3857250\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19931:\tlearn: 2.3856074\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19932:\tlearn: 2.3854898\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19933:\tlearn: 2.3854415\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19934:\tlearn: 2.3853657\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19935:\tlearn: 2.3853517\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19936:\tlearn: 2.3852606\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19937:\tlearn: 2.3851920\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19938:\tlearn: 2.3850625\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19939:\tlearn: 2.3849790\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19940:\tlearn: 2.3848789\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19941:\tlearn: 2.3847556\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19942:\tlearn: 2.3847379\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19943:\tlearn: 2.3846105\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19944:\tlearn: 2.3845496\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19945:\tlearn: 2.3844294\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19946:\tlearn: 2.3843958\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19947:\tlearn: 2.3843126\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19948:\tlearn: 2.3842464\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19949:\tlearn: 2.3842009\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19950:\tlearn: 2.3841114\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19951:\tlearn: 2.3840603\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19952:\tlearn: 2.3839862\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19953:\tlearn: 2.3838755\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19954:\tlearn: 2.3837844\ttotal: 7m 12s\tremaining: 1m 6s\n",
      "19955:\tlearn: 2.3837068\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19956:\tlearn: 2.3836308\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19957:\tlearn: 2.3835303\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19958:\tlearn: 2.3834775\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19959:\tlearn: 2.3833854\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19960:\tlearn: 2.3833022\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19961:\tlearn: 2.3832111\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19962:\tlearn: 2.3831290\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19963:\tlearn: 2.3829983\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19964:\tlearn: 2.3829235\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19965:\tlearn: 2.3828356\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19966:\tlearn: 2.3828109\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19967:\tlearn: 2.3827567\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19968:\tlearn: 2.3826512\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19969:\tlearn: 2.3825874\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19970:\tlearn: 2.3825178\ttotal: 7m 12s\tremaining: 1m 5s\n",
      "19971:\tlearn: 2.3824439\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19972:\tlearn: 2.3823645\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19973:\tlearn: 2.3822268\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19974:\tlearn: 2.3821164\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19975:\tlearn: 2.3820620\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19976:\tlearn: 2.3819366\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19977:\tlearn: 2.3818467\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19978:\tlearn: 2.3817810\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19979:\tlearn: 2.3816748\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19980:\tlearn: 2.3816073\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19981:\tlearn: 2.3816059\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19982:\tlearn: 2.3815332\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19983:\tlearn: 2.3814407\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19984:\tlearn: 2.3813792\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19985:\tlearn: 2.3813272\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19986:\tlearn: 2.3812296\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19987:\tlearn: 2.3811122\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19988:\tlearn: 2.3810440\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19989:\tlearn: 2.3809990\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19990:\tlearn: 2.3809412\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19991:\tlearn: 2.3808352\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19992:\tlearn: 2.3807844\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19993:\tlearn: 2.3807090\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19994:\tlearn: 2.3806696\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19995:\tlearn: 2.3806330\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19996:\tlearn: 2.3805110\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19997:\tlearn: 2.3804636\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19998:\tlearn: 2.3803561\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "19999:\tlearn: 2.3802649\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "20000:\tlearn: 2.3802488\ttotal: 7m 13s\tremaining: 1m 5s\n",
      "20001:\tlearn: 2.3801423\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20002:\tlearn: 2.3800302\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20003:\tlearn: 2.3799152\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20004:\tlearn: 2.3798118\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20005:\tlearn: 2.3797079\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20006:\tlearn: 2.3796753\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20007:\tlearn: 2.3795705\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20008:\tlearn: 2.3795183\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20009:\tlearn: 2.3794843\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20010:\tlearn: 2.3794042\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20011:\tlearn: 2.3793007\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20012:\tlearn: 2.3792082\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20013:\tlearn: 2.3791283\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20014:\tlearn: 2.3790481\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20015:\tlearn: 2.3789895\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20016:\tlearn: 2.3789206\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20017:\tlearn: 2.3788084\ttotal: 7m 13s\tremaining: 1m 4s\n",
      "20018:\tlearn: 2.3787770\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20019:\tlearn: 2.3787754\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20020:\tlearn: 2.3786277\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20021:\tlearn: 2.3785200\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20022:\tlearn: 2.3784633\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20023:\tlearn: 2.3784060\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20024:\tlearn: 2.3783148\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20025:\tlearn: 2.3782679\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20026:\tlearn: 2.3781558\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20027:\tlearn: 2.3780571\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20028:\tlearn: 2.3779489\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20029:\tlearn: 2.3778179\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20030:\tlearn: 2.3777416\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20031:\tlearn: 2.3776520\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20032:\tlearn: 2.3775925\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20033:\tlearn: 2.3775637\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20034:\tlearn: 2.3774714\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20035:\tlearn: 2.3773887\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20036:\tlearn: 2.3773569\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20037:\tlearn: 2.3772891\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20038:\tlearn: 2.3772065\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20039:\tlearn: 2.3771311\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20040:\tlearn: 2.3770402\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20041:\tlearn: 2.3769655\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20042:\tlearn: 2.3768966\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20043:\tlearn: 2.3768435\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20044:\tlearn: 2.3767892\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20045:\tlearn: 2.3767849\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20046:\tlearn: 2.3767198\ttotal: 7m 14s\tremaining: 1m 4s\n",
      "20047:\tlearn: 2.3766633\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20048:\tlearn: 2.3765974\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20049:\tlearn: 2.3764862\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20050:\tlearn: 2.3763731\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20051:\tlearn: 2.3762820\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20052:\tlearn: 2.3762302\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20053:\tlearn: 2.3761225\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20054:\tlearn: 2.3760484\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20055:\tlearn: 2.3759743\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20056:\tlearn: 2.3758962\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20057:\tlearn: 2.3758027\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20058:\tlearn: 2.3756244\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20059:\tlearn: 2.3755285\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20060:\tlearn: 2.3754361\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20061:\tlearn: 2.3753746\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20062:\tlearn: 2.3753303\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20063:\tlearn: 2.3753295\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20064:\tlearn: 2.3752500\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20065:\tlearn: 2.3751731\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "20066:\tlearn: 2.3751128\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20067:\tlearn: 2.3750343\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20068:\tlearn: 2.3749724\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20069:\tlearn: 2.3748808\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20070:\tlearn: 2.3748118\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20071:\tlearn: 2.3747141\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20072:\tlearn: 2.3745997\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20073:\tlearn: 2.3745111\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20074:\tlearn: 2.3744270\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20075:\tlearn: 2.3743628\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20076:\tlearn: 2.3743276\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20077:\tlearn: 2.3742846\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20078:\tlearn: 2.3742170\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20079:\tlearn: 2.3741489\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20080:\tlearn: 2.3740823\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20081:\tlearn: 2.3740456\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20082:\tlearn: 2.3739073\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20083:\tlearn: 2.3737852\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20084:\tlearn: 2.3737228\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20085:\tlearn: 2.3735957\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20086:\tlearn: 2.3735520\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20087:\tlearn: 2.3735132\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20088:\tlearn: 2.3734322\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20089:\tlearn: 2.3733569\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20090:\tlearn: 2.3732745\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20091:\tlearn: 2.3732298\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20092:\tlearn: 2.3731817\ttotal: 7m 15s\tremaining: 1m 3s\n",
      "20093:\tlearn: 2.3731009\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20094:\tlearn: 2.3729755\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20095:\tlearn: 2.3729272\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20096:\tlearn: 2.3728528\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20097:\tlearn: 2.3727479\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20098:\tlearn: 2.3726839\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20099:\tlearn: 2.3726123\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20100:\tlearn: 2.3725079\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20101:\tlearn: 2.3724186\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20102:\tlearn: 2.3723624\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20103:\tlearn: 2.3723082\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20104:\tlearn: 2.3722389\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20105:\tlearn: 2.3721566\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20106:\tlearn: 2.3720460\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20107:\tlearn: 2.3719723\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20108:\tlearn: 2.3719709\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20109:\tlearn: 2.3718652\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20110:\tlearn: 2.3717936\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20111:\tlearn: 2.3717130\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20112:\tlearn: 2.3716240\ttotal: 7m 15s\tremaining: 1m 2s\n",
      "20113:\tlearn: 2.3715024\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20114:\tlearn: 2.3714017\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20115:\tlearn: 2.3712956\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20116:\tlearn: 2.3711966\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20117:\tlearn: 2.3711132\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20118:\tlearn: 2.3709984\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20119:\tlearn: 2.3708508\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20120:\tlearn: 2.3707878\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20121:\tlearn: 2.3707408\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20122:\tlearn: 2.3706361\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20123:\tlearn: 2.3705101\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20124:\tlearn: 2.3703793\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20125:\tlearn: 2.3702615\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20126:\tlearn: 2.3701915\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20127:\tlearn: 2.3701431\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20128:\tlearn: 2.3700768\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20129:\tlearn: 2.3700292\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20130:\tlearn: 2.3699827\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20131:\tlearn: 2.3699226\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20132:\tlearn: 2.3698210\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20133:\tlearn: 2.3697117\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20134:\tlearn: 2.3696629\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20135:\tlearn: 2.3696012\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20136:\tlearn: 2.3695008\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20137:\tlearn: 2.3694507\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20138:\tlearn: 2.3693855\ttotal: 7m 16s\tremaining: 1m 2s\n",
      "20139:\tlearn: 2.3692700\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20140:\tlearn: 2.3691453\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20141:\tlearn: 2.3690435\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20142:\tlearn: 2.3689563\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20143:\tlearn: 2.3688901\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20144:\tlearn: 2.3688087\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20145:\tlearn: 2.3687532\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20146:\tlearn: 2.3687042\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20147:\tlearn: 2.3686297\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20148:\tlearn: 2.3685367\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20149:\tlearn: 2.3684567\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20150:\tlearn: 2.3683630\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20151:\tlearn: 2.3682533\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20152:\tlearn: 2.3682122\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20153:\tlearn: 2.3681356\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20154:\tlearn: 2.3680295\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20155:\tlearn: 2.3679573\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20156:\tlearn: 2.3679082\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20157:\tlearn: 2.3678089\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20158:\tlearn: 2.3677058\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "20159:\tlearn: 2.3676950\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20160:\tlearn: 2.3675835\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20161:\tlearn: 2.3675081\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20162:\tlearn: 2.3674448\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20163:\tlearn: 2.3673143\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20164:\tlearn: 2.3671877\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20165:\tlearn: 2.3671464\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20166:\tlearn: 2.3670733\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20167:\tlearn: 2.3670188\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20168:\tlearn: 2.3669635\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20169:\tlearn: 2.3668821\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20170:\tlearn: 2.3667716\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20171:\tlearn: 2.3667707\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20172:\tlearn: 2.3666503\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20173:\tlearn: 2.3665550\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20174:\tlearn: 2.3665537\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20175:\tlearn: 2.3664695\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20176:\tlearn: 2.3663511\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20177:\tlearn: 2.3662765\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20178:\tlearn: 2.3661834\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20179:\tlearn: 2.3661274\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20180:\tlearn: 2.3659999\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20181:\tlearn: 2.3659231\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20182:\tlearn: 2.3658022\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20183:\tlearn: 2.3657199\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20184:\tlearn: 2.3656546\ttotal: 7m 17s\tremaining: 1m 1s\n",
      "20185:\tlearn: 2.3655799\ttotal: 7m 17s\tremaining: 1m\n",
      "20186:\tlearn: 2.3655200\ttotal: 7m 17s\tremaining: 1m\n",
      "20187:\tlearn: 2.3654838\ttotal: 7m 17s\tremaining: 1m\n",
      "20188:\tlearn: 2.3653624\ttotal: 7m 17s\tremaining: 1m\n",
      "20189:\tlearn: 2.3652994\ttotal: 7m 17s\tremaining: 1m\n",
      "20190:\tlearn: 2.3652274\ttotal: 7m 17s\tremaining: 1m\n",
      "20191:\tlearn: 2.3651219\ttotal: 7m 17s\tremaining: 1m\n",
      "20192:\tlearn: 2.3650304\ttotal: 7m 17s\tremaining: 1m\n",
      "20193:\tlearn: 2.3649603\ttotal: 7m 17s\tremaining: 1m\n",
      "20194:\tlearn: 2.3648620\ttotal: 7m 17s\tremaining: 1m\n",
      "20195:\tlearn: 2.3648139\ttotal: 7m 17s\tremaining: 1m\n",
      "20196:\tlearn: 2.3647599\ttotal: 7m 17s\tremaining: 1m\n",
      "20197:\tlearn: 2.3646973\ttotal: 7m 17s\tremaining: 1m\n",
      "20198:\tlearn: 2.3646343\ttotal: 7m 17s\tremaining: 1m\n",
      "20199:\tlearn: 2.3645632\ttotal: 7m 17s\tremaining: 1m\n",
      "20200:\tlearn: 2.3644951\ttotal: 7m 17s\tremaining: 1m\n",
      "20201:\tlearn: 2.3643469\ttotal: 7m 17s\tremaining: 1m\n",
      "20202:\tlearn: 2.3642337\ttotal: 7m 17s\tremaining: 1m\n",
      "20203:\tlearn: 2.3641235\ttotal: 7m 17s\tremaining: 1m\n",
      "20204:\tlearn: 2.3640409\ttotal: 7m 17s\tremaining: 1m\n",
      "20205:\tlearn: 2.3639352\ttotal: 7m 18s\tremaining: 1m\n",
      "20206:\tlearn: 2.3639063\ttotal: 7m 18s\tremaining: 1m\n",
      "20207:\tlearn: 2.3638190\ttotal: 7m 18s\tremaining: 1m\n",
      "20208:\tlearn: 2.3637652\ttotal: 7m 18s\tremaining: 1m\n",
      "20209:\tlearn: 2.3636566\ttotal: 7m 18s\tremaining: 1m\n",
      "20210:\tlearn: 2.3635337\ttotal: 7m 18s\tremaining: 1m\n",
      "20211:\tlearn: 2.3634596\ttotal: 7m 18s\tremaining: 1m\n",
      "20212:\tlearn: 2.3633720\ttotal: 7m 18s\tremaining: 1m\n",
      "20213:\tlearn: 2.3632530\ttotal: 7m 18s\tremaining: 1m\n",
      "20214:\tlearn: 2.3631380\ttotal: 7m 18s\tremaining: 1m\n",
      "20215:\tlearn: 2.3630262\ttotal: 7m 18s\tremaining: 1m\n",
      "20216:\tlearn: 2.3629652\ttotal: 7m 18s\tremaining: 1m\n",
      "20217:\tlearn: 2.3629290\ttotal: 7m 18s\tremaining: 1m\n",
      "20218:\tlearn: 2.3627804\ttotal: 7m 18s\tremaining: 1m\n",
      "20219:\tlearn: 2.3626562\ttotal: 7m 18s\tremaining: 1m\n",
      "20220:\tlearn: 2.3625600\ttotal: 7m 18s\tremaining: 1m\n",
      "20221:\tlearn: 2.3623975\ttotal: 7m 18s\tremaining: 1m\n",
      "20222:\tlearn: 2.3623186\ttotal: 7m 18s\tremaining: 1m\n",
      "20223:\tlearn: 2.3621589\ttotal: 7m 18s\tremaining: 1m\n",
      "20224:\tlearn: 2.3620859\ttotal: 7m 18s\tremaining: 1m\n",
      "20225:\tlearn: 2.3619521\ttotal: 7m 18s\tremaining: 1m\n",
      "20226:\tlearn: 2.3618858\ttotal: 7m 18s\tremaining: 1m\n",
      "20227:\tlearn: 2.3617831\ttotal: 7m 18s\tremaining: 1m\n",
      "20228:\tlearn: 2.3617355\ttotal: 7m 18s\tremaining: 1m\n",
      "20229:\tlearn: 2.3616604\ttotal: 7m 18s\tremaining: 1m\n",
      "20230:\tlearn: 2.3615930\ttotal: 7m 18s\tremaining: 1m\n",
      "20231:\tlearn: 2.3615220\ttotal: 7m 18s\tremaining: 1m\n",
      "20232:\tlearn: 2.3614371\ttotal: 7m 18s\tremaining: 60s\n",
      "20233:\tlearn: 2.3612879\ttotal: 7m 18s\tremaining: 60s\n",
      "20234:\tlearn: 2.3611830\ttotal: 7m 18s\tremaining: 59.9s\n",
      "20235:\tlearn: 2.3611195\ttotal: 7m 18s\tremaining: 59.9s\n",
      "20236:\tlearn: 2.3610549\ttotal: 7m 18s\tremaining: 59.9s\n",
      "20237:\tlearn: 2.3609826\ttotal: 7m 18s\tremaining: 59.9s\n",
      "20238:\tlearn: 2.3609178\ttotal: 7m 18s\tremaining: 59.9s\n",
      "20239:\tlearn: 2.3608547\ttotal: 7m 18s\tremaining: 59.8s\n",
      "20240:\tlearn: 2.3607786\ttotal: 7m 18s\tremaining: 59.8s\n",
      "20241:\tlearn: 2.3607164\ttotal: 7m 18s\tremaining: 59.8s\n",
      "20242:\tlearn: 2.3606549\ttotal: 7m 18s\tremaining: 59.8s\n",
      "20243:\tlearn: 2.3605858\ttotal: 7m 18s\tremaining: 59.7s\n",
      "20244:\tlearn: 2.3605152\ttotal: 7m 18s\tremaining: 59.7s\n",
      "20245:\tlearn: 2.3604688\ttotal: 7m 18s\tremaining: 59.7s\n",
      "20246:\tlearn: 2.3603967\ttotal: 7m 18s\tremaining: 59.7s\n",
      "20247:\tlearn: 2.3603001\ttotal: 7m 18s\tremaining: 59.7s\n",
      "20248:\tlearn: 2.3602111\ttotal: 7m 18s\tremaining: 59.6s\n",
      "20249:\tlearn: 2.3601627\ttotal: 7m 18s\tremaining: 59.6s\n",
      "20250:\tlearn: 2.3600684\ttotal: 7m 18s\tremaining: 59.6s\n",
      "20251:\tlearn: 2.3599875\ttotal: 7m 19s\tremaining: 59.6s\n",
      "20252:\tlearn: 2.3598306\ttotal: 7m 19s\tremaining: 59.5s\n",
      "20253:\tlearn: 2.3597180\ttotal: 7m 19s\tremaining: 59.5s\n",
      "20254:\tlearn: 2.3595604\ttotal: 7m 19s\tremaining: 59.5s\n",
      "20255:\tlearn: 2.3594588\ttotal: 7m 19s\tremaining: 59.5s\n",
      "20256:\tlearn: 2.3593843\ttotal: 7m 19s\tremaining: 59.5s\n",
      "20257:\tlearn: 2.3592866\ttotal: 7m 19s\tremaining: 59.4s\n",
      "20258:\tlearn: 2.3592419\ttotal: 7m 19s\tremaining: 59.4s\n",
      "20259:\tlearn: 2.3591540\ttotal: 7m 19s\tremaining: 59.4s\n",
      "20260:\tlearn: 2.3590736\ttotal: 7m 19s\tremaining: 59.4s\n",
      "20261:\tlearn: 2.3589348\ttotal: 7m 19s\tremaining: 59.4s\n",
      "20262:\tlearn: 2.3588157\ttotal: 7m 19s\tremaining: 59.3s\n",
      "20263:\tlearn: 2.3587303\ttotal: 7m 19s\tremaining: 59.3s\n",
      "20264:\tlearn: 2.3586196\ttotal: 7m 19s\tremaining: 59.3s\n",
      "20265:\tlearn: 2.3585124\ttotal: 7m 19s\tremaining: 59.3s\n",
      "20266:\tlearn: 2.3584447\ttotal: 7m 19s\tremaining: 59.2s\n",
      "20267:\tlearn: 2.3583399\ttotal: 7m 19s\tremaining: 59.2s\n",
      "20268:\tlearn: 2.3582678\ttotal: 7m 19s\tremaining: 59.2s\n",
      "20269:\tlearn: 2.3581946\ttotal: 7m 19s\tremaining: 59.2s\n",
      "20270:\tlearn: 2.3581172\ttotal: 7m 19s\tremaining: 59.2s\n",
      "20271:\tlearn: 2.3579737\ttotal: 7m 19s\tremaining: 59.1s\n",
      "20272:\tlearn: 2.3578811\ttotal: 7m 19s\tremaining: 59.1s\n",
      "20273:\tlearn: 2.3578080\ttotal: 7m 19s\tremaining: 59.1s\n",
      "20274:\tlearn: 2.3576948\ttotal: 7m 19s\tremaining: 59.1s\n",
      "20275:\tlearn: 2.3576230\ttotal: 7m 19s\tremaining: 59s\n",
      "20276:\tlearn: 2.3575190\ttotal: 7m 19s\tremaining: 59s\n",
      "20277:\tlearn: 2.3574631\ttotal: 7m 19s\tremaining: 59s\n",
      "20278:\tlearn: 2.3573581\ttotal: 7m 19s\tremaining: 59s\n",
      "20279:\tlearn: 2.3572909\ttotal: 7m 19s\tremaining: 59s\n",
      "20280:\tlearn: 2.3572401\ttotal: 7m 19s\tremaining: 58.9s\n",
      "20281:\tlearn: 2.3571179\ttotal: 7m 19s\tremaining: 58.9s\n",
      "20282:\tlearn: 2.3570604\ttotal: 7m 19s\tremaining: 58.9s\n",
      "20283:\tlearn: 2.3569176\ttotal: 7m 19s\tremaining: 58.9s\n",
      "20284:\tlearn: 2.3568418\ttotal: 7m 19s\tremaining: 58.9s\n",
      "20285:\tlearn: 2.3567791\ttotal: 7m 19s\tremaining: 58.8s\n",
      "20286:\tlearn: 2.3567132\ttotal: 7m 19s\tremaining: 58.8s\n",
      "20287:\tlearn: 2.3566214\ttotal: 7m 19s\tremaining: 58.8s\n",
      "20288:\tlearn: 2.3565405\ttotal: 7m 19s\tremaining: 58.8s\n",
      "20289:\tlearn: 2.3564578\ttotal: 7m 19s\tremaining: 58.7s\n",
      "20290:\tlearn: 2.3563987\ttotal: 7m 19s\tremaining: 58.7s\n",
      "20291:\tlearn: 2.3563104\ttotal: 7m 19s\tremaining: 58.7s\n",
      "20292:\tlearn: 2.3562151\ttotal: 7m 19s\tremaining: 58.7s\n",
      "20293:\tlearn: 2.3560834\ttotal: 7m 19s\tremaining: 58.7s\n",
      "20294:\tlearn: 2.3560146\ttotal: 7m 19s\tremaining: 58.6s\n",
      "20295:\tlearn: 2.3559618\ttotal: 7m 19s\tremaining: 58.6s\n",
      "20296:\tlearn: 2.3558606\ttotal: 7m 19s\tremaining: 58.6s\n",
      "20297:\tlearn: 2.3557188\ttotal: 7m 19s\tremaining: 58.6s\n",
      "20298:\tlearn: 2.3556526\ttotal: 7m 20s\tremaining: 58.5s\n",
      "20299:\tlearn: 2.3555767\ttotal: 7m 20s\tremaining: 58.5s\n",
      "20300:\tlearn: 2.3554884\ttotal: 7m 20s\tremaining: 58.5s\n",
      "20301:\tlearn: 2.3553880\ttotal: 7m 20s\tremaining: 58.5s\n",
      "20302:\tlearn: 2.3553187\ttotal: 7m 20s\tremaining: 58.5s\n",
      "20303:\tlearn: 2.3552413\ttotal: 7m 20s\tremaining: 58.4s\n",
      "20304:\tlearn: 2.3551939\ttotal: 7m 20s\tremaining: 58.4s\n",
      "20305:\tlearn: 2.3551526\ttotal: 7m 20s\tremaining: 58.4s\n",
      "20306:\tlearn: 2.3550698\ttotal: 7m 20s\tremaining: 58.4s\n",
      "20307:\tlearn: 2.3550012\ttotal: 7m 20s\tremaining: 58.4s\n",
      "20308:\tlearn: 2.3549103\ttotal: 7m 20s\tremaining: 58.3s\n",
      "20309:\tlearn: 2.3548151\ttotal: 7m 20s\tremaining: 58.3s\n",
      "20310:\tlearn: 2.3547313\ttotal: 7m 20s\tremaining: 58.3s\n",
      "20311:\tlearn: 2.3546443\ttotal: 7m 20s\tremaining: 58.3s\n",
      "20312:\tlearn: 2.3545542\ttotal: 7m 20s\tremaining: 58.2s\n",
      "20313:\tlearn: 2.3544754\ttotal: 7m 20s\tremaining: 58.2s\n",
      "20314:\tlearn: 2.3544228\ttotal: 7m 20s\tremaining: 58.2s\n",
      "20315:\tlearn: 2.3542800\ttotal: 7m 20s\tremaining: 58.2s\n",
      "20316:\tlearn: 2.3542055\ttotal: 7m 20s\tremaining: 58.2s\n",
      "20317:\tlearn: 2.3541197\ttotal: 7m 20s\tremaining: 58.1s\n",
      "20318:\tlearn: 2.3540009\ttotal: 7m 20s\tremaining: 58.1s\n",
      "20319:\tlearn: 2.3539056\ttotal: 7m 20s\tremaining: 58.1s\n",
      "20320:\tlearn: 2.3538379\ttotal: 7m 20s\tremaining: 58.1s\n",
      "20321:\tlearn: 2.3537605\ttotal: 7m 20s\tremaining: 58.1s\n",
      "20322:\tlearn: 2.3537280\ttotal: 7m 20s\tremaining: 58s\n",
      "20323:\tlearn: 2.3536346\ttotal: 7m 20s\tremaining: 58s\n",
      "20324:\tlearn: 2.3535927\ttotal: 7m 20s\tremaining: 58s\n",
      "20325:\tlearn: 2.3535185\ttotal: 7m 20s\tremaining: 58s\n",
      "20326:\tlearn: 2.3534465\ttotal: 7m 20s\tremaining: 57.9s\n",
      "20327:\tlearn: 2.3533719\ttotal: 7m 20s\tremaining: 57.9s\n",
      "20328:\tlearn: 2.3532941\ttotal: 7m 20s\tremaining: 57.9s\n",
      "20329:\tlearn: 2.3532262\ttotal: 7m 20s\tremaining: 57.9s\n",
      "20330:\tlearn: 2.3531310\ttotal: 7m 20s\tremaining: 57.9s\n",
      "20331:\tlearn: 2.3530956\ttotal: 7m 20s\tremaining: 57.8s\n",
      "20332:\tlearn: 2.3530122\ttotal: 7m 20s\tremaining: 57.8s\n",
      "20333:\tlearn: 2.3529742\ttotal: 7m 20s\tremaining: 57.8s\n",
      "20334:\tlearn: 2.3529656\ttotal: 7m 20s\tremaining: 57.8s\n",
      "20335:\tlearn: 2.3528304\ttotal: 7m 20s\tremaining: 57.7s\n",
      "20336:\tlearn: 2.3527771\ttotal: 7m 20s\tremaining: 57.7s\n",
      "20337:\tlearn: 2.3526611\ttotal: 7m 20s\tremaining: 57.7s\n",
      "20338:\tlearn: 2.3525460\ttotal: 7m 20s\tremaining: 57.7s\n",
      "20339:\tlearn: 2.3523553\ttotal: 7m 20s\tremaining: 57.7s\n",
      "20340:\tlearn: 2.3522922\ttotal: 7m 20s\tremaining: 57.6s\n",
      "20341:\tlearn: 2.3521862\ttotal: 7m 20s\tremaining: 57.6s\n",
      "20342:\tlearn: 2.3521195\ttotal: 7m 20s\tremaining: 57.6s\n",
      "20343:\tlearn: 2.3520442\ttotal: 7m 20s\tremaining: 57.6s\n",
      "20344:\tlearn: 2.3519803\ttotal: 7m 21s\tremaining: 57.6s\n",
      "20345:\tlearn: 2.3518957\ttotal: 7m 21s\tremaining: 57.5s\n",
      "20346:\tlearn: 2.3518340\ttotal: 7m 21s\tremaining: 57.5s\n",
      "20347:\tlearn: 2.3517341\ttotal: 7m 21s\tremaining: 57.5s\n",
      "20348:\tlearn: 2.3516635\ttotal: 7m 21s\tremaining: 57.5s\n",
      "20349:\tlearn: 2.3515772\ttotal: 7m 21s\tremaining: 57.4s\n",
      "20350:\tlearn: 2.3515083\ttotal: 7m 21s\tremaining: 57.4s\n",
      "20351:\tlearn: 2.3514353\ttotal: 7m 21s\tremaining: 57.4s\n",
      "20352:\tlearn: 2.3512953\ttotal: 7m 21s\tremaining: 57.4s\n",
      "20353:\tlearn: 2.3511968\ttotal: 7m 21s\tremaining: 57.4s\n",
      "20354:\tlearn: 2.3511244\ttotal: 7m 21s\tremaining: 57.3s\n",
      "20355:\tlearn: 2.3510356\ttotal: 7m 21s\tremaining: 57.3s\n",
      "20356:\tlearn: 2.3509425\ttotal: 7m 21s\tremaining: 57.3s\n",
      "20357:\tlearn: 2.3508660\ttotal: 7m 21s\tremaining: 57.3s\n",
      "20358:\tlearn: 2.3507774\ttotal: 7m 21s\tremaining: 57.2s\n",
      "20359:\tlearn: 2.3506898\ttotal: 7m 21s\tremaining: 57.2s\n",
      "20360:\tlearn: 2.3506271\ttotal: 7m 21s\tremaining: 57.2s\n",
      "20361:\tlearn: 2.3505351\ttotal: 7m 21s\tremaining: 57.2s\n",
      "20362:\tlearn: 2.3504615\ttotal: 7m 21s\tremaining: 57.2s\n",
      "20363:\tlearn: 2.3503391\ttotal: 7m 21s\tremaining: 57.1s\n",
      "20364:\tlearn: 2.3502557\ttotal: 7m 21s\tremaining: 57.1s\n",
      "20365:\tlearn: 2.3501861\ttotal: 7m 21s\tremaining: 57.1s\n",
      "20366:\tlearn: 2.3501006\ttotal: 7m 21s\tremaining: 57.1s\n",
      "20367:\tlearn: 2.3500147\ttotal: 7m 21s\tremaining: 57.1s\n",
      "20368:\tlearn: 2.3499650\ttotal: 7m 21s\tremaining: 57s\n",
      "20369:\tlearn: 2.3498766\ttotal: 7m 21s\tremaining: 57s\n",
      "20370:\tlearn: 2.3497935\ttotal: 7m 21s\tremaining: 57s\n",
      "20371:\tlearn: 2.3497091\ttotal: 7m 21s\tremaining: 57s\n",
      "20372:\tlearn: 2.3496204\ttotal: 7m 21s\tremaining: 56.9s\n",
      "20373:\tlearn: 2.3494897\ttotal: 7m 21s\tremaining: 56.9s\n",
      "20374:\tlearn: 2.3493895\ttotal: 7m 21s\tremaining: 56.9s\n",
      "20375:\tlearn: 2.3492335\ttotal: 7m 21s\tremaining: 56.9s\n",
      "20376:\tlearn: 2.3491603\ttotal: 7m 21s\tremaining: 56.9s\n",
      "20377:\tlearn: 2.3491109\ttotal: 7m 21s\tremaining: 56.8s\n",
      "20378:\tlearn: 2.3489959\ttotal: 7m 21s\tremaining: 56.8s\n",
      "20379:\tlearn: 2.3489234\ttotal: 7m 21s\tremaining: 56.8s\n",
      "20380:\tlearn: 2.3488366\ttotal: 7m 21s\tremaining: 56.8s\n",
      "20381:\tlearn: 2.3487330\ttotal: 7m 21s\tremaining: 56.8s\n",
      "20382:\tlearn: 2.3486720\ttotal: 7m 21s\tremaining: 56.7s\n",
      "20383:\tlearn: 2.3485999\ttotal: 7m 21s\tremaining: 56.7s\n",
      "20384:\tlearn: 2.3485284\ttotal: 7m 21s\tremaining: 56.7s\n",
      "20385:\tlearn: 2.3484432\ttotal: 7m 21s\tremaining: 56.7s\n",
      "20386:\tlearn: 2.3483550\ttotal: 7m 21s\tremaining: 56.6s\n",
      "20387:\tlearn: 2.3482416\ttotal: 7m 21s\tremaining: 56.6s\n",
      "20388:\tlearn: 2.3482141\ttotal: 7m 21s\tremaining: 56.6s\n",
      "20389:\tlearn: 2.3481510\ttotal: 7m 21s\tremaining: 56.6s\n",
      "20390:\tlearn: 2.3480518\ttotal: 7m 22s\tremaining: 56.6s\n",
      "20391:\tlearn: 2.3479392\ttotal: 7m 22s\tremaining: 56.5s\n",
      "20392:\tlearn: 2.3478416\ttotal: 7m 22s\tremaining: 56.5s\n",
      "20393:\tlearn: 2.3477518\ttotal: 7m 22s\tremaining: 56.5s\n",
      "20394:\tlearn: 2.3476588\ttotal: 7m 22s\tremaining: 56.5s\n",
      "20395:\tlearn: 2.3475436\ttotal: 7m 22s\tremaining: 56.4s\n",
      "20396:\tlearn: 2.3474728\ttotal: 7m 22s\tremaining: 56.4s\n",
      "20397:\tlearn: 2.3474405\ttotal: 7m 22s\tremaining: 56.4s\n",
      "20398:\tlearn: 2.3473009\ttotal: 7m 22s\tremaining: 56.4s\n",
      "20399:\tlearn: 2.3472092\ttotal: 7m 22s\tremaining: 56.4s\n",
      "20400:\tlearn: 2.3471120\ttotal: 7m 22s\tremaining: 56.3s\n",
      "20401:\tlearn: 2.3470495\ttotal: 7m 22s\tremaining: 56.3s\n",
      "20402:\tlearn: 2.3469117\ttotal: 7m 22s\tremaining: 56.3s\n",
      "20403:\tlearn: 2.3468097\ttotal: 7m 22s\tremaining: 56.3s\n",
      "20404:\tlearn: 2.3467327\ttotal: 7m 22s\tremaining: 56.3s\n",
      "20405:\tlearn: 2.3466563\ttotal: 7m 22s\tremaining: 56.2s\n",
      "20406:\tlearn: 2.3465402\ttotal: 7m 22s\tremaining: 56.2s\n",
      "20407:\tlearn: 2.3465387\ttotal: 7m 22s\tremaining: 56.2s\n",
      "20408:\tlearn: 2.3464957\ttotal: 7m 22s\tremaining: 56.2s\n",
      "20409:\tlearn: 2.3463620\ttotal: 7m 22s\tremaining: 56.1s\n",
      "20410:\tlearn: 2.3463012\ttotal: 7m 22s\tremaining: 56.1s\n",
      "20411:\tlearn: 2.3461821\ttotal: 7m 22s\tremaining: 56.1s\n",
      "20412:\tlearn: 2.3460862\ttotal: 7m 22s\tremaining: 56.1s\n",
      "20413:\tlearn: 2.3459940\ttotal: 7m 22s\tremaining: 56.1s\n",
      "20414:\tlearn: 2.3459265\ttotal: 7m 22s\tremaining: 56s\n",
      "20415:\tlearn: 2.3458883\ttotal: 7m 22s\tremaining: 56s\n",
      "20416:\tlearn: 2.3457645\ttotal: 7m 22s\tremaining: 56s\n",
      "20417:\tlearn: 2.3456807\ttotal: 7m 22s\tremaining: 56s\n",
      "20418:\tlearn: 2.3456237\ttotal: 7m 22s\tremaining: 55.9s\n",
      "20419:\tlearn: 2.3455868\ttotal: 7m 22s\tremaining: 55.9s\n",
      "20420:\tlearn: 2.3454356\ttotal: 7m 22s\tremaining: 55.9s\n",
      "20421:\tlearn: 2.3453667\ttotal: 7m 22s\tremaining: 55.9s\n",
      "20422:\tlearn: 2.3453202\ttotal: 7m 22s\tremaining: 55.9s\n",
      "20423:\tlearn: 2.3451553\ttotal: 7m 22s\tremaining: 55.8s\n",
      "20424:\tlearn: 2.3451148\ttotal: 7m 22s\tremaining: 55.8s\n",
      "20425:\tlearn: 2.3450246\ttotal: 7m 22s\tremaining: 55.8s\n",
      "20426:\tlearn: 2.3449572\ttotal: 7m 22s\tremaining: 55.8s\n",
      "20427:\tlearn: 2.3448723\ttotal: 7m 22s\tremaining: 55.8s\n",
      "20428:\tlearn: 2.3447812\ttotal: 7m 22s\tremaining: 55.7s\n",
      "20429:\tlearn: 2.3447209\ttotal: 7m 22s\tremaining: 55.7s\n",
      "20430:\tlearn: 2.3445851\ttotal: 7m 22s\tremaining: 55.7s\n",
      "20431:\tlearn: 2.3445466\ttotal: 7m 22s\tremaining: 55.7s\n",
      "20432:\tlearn: 2.3444788\ttotal: 7m 22s\tremaining: 55.6s\n",
      "20433:\tlearn: 2.3443976\ttotal: 7m 22s\tremaining: 55.6s\n",
      "20434:\tlearn: 2.3443227\ttotal: 7m 22s\tremaining: 55.6s\n",
      "20435:\tlearn: 2.3442491\ttotal: 7m 23s\tremaining: 55.6s\n",
      "20436:\tlearn: 2.3441440\ttotal: 7m 23s\tremaining: 55.6s\n",
      "20437:\tlearn: 2.3441001\ttotal: 7m 23s\tremaining: 55.5s\n",
      "20438:\tlearn: 2.3440108\ttotal: 7m 23s\tremaining: 55.5s\n",
      "20439:\tlearn: 2.3439025\ttotal: 7m 23s\tremaining: 55.5s\n",
      "20440:\tlearn: 2.3438393\ttotal: 7m 23s\tremaining: 55.5s\n",
      "20441:\tlearn: 2.3437517\ttotal: 7m 23s\tremaining: 55.5s\n",
      "20442:\tlearn: 2.3436772\ttotal: 7m 23s\tremaining: 55.4s\n",
      "20443:\tlearn: 2.3435834\ttotal: 7m 23s\tremaining: 55.4s\n",
      "20444:\tlearn: 2.3434795\ttotal: 7m 23s\tremaining: 55.4s\n",
      "20445:\tlearn: 2.3433511\ttotal: 7m 23s\tremaining: 55.4s\n",
      "20446:\tlearn: 2.3432174\ttotal: 7m 23s\tremaining: 55.3s\n",
      "20447:\tlearn: 2.3431386\ttotal: 7m 23s\tremaining: 55.3s\n",
      "20448:\tlearn: 2.3430768\ttotal: 7m 23s\tremaining: 55.3s\n",
      "20449:\tlearn: 2.3429468\ttotal: 7m 23s\tremaining: 55.3s\n",
      "20450:\tlearn: 2.3429446\ttotal: 7m 23s\tremaining: 55.3s\n",
      "20451:\tlearn: 2.3429142\ttotal: 7m 23s\tremaining: 55.2s\n",
      "20452:\tlearn: 2.3428039\ttotal: 7m 23s\tremaining: 55.2s\n",
      "20453:\tlearn: 2.3427326\ttotal: 7m 23s\tremaining: 55.2s\n",
      "20454:\tlearn: 2.3426753\ttotal: 7m 23s\tremaining: 55.2s\n",
      "20455:\tlearn: 2.3426226\ttotal: 7m 23s\tremaining: 55.1s\n",
      "20456:\tlearn: 2.3425704\ttotal: 7m 23s\tremaining: 55.1s\n",
      "20457:\tlearn: 2.3424800\ttotal: 7m 23s\tremaining: 55.1s\n",
      "20458:\tlearn: 2.3424113\ttotal: 7m 23s\tremaining: 55.1s\n",
      "20459:\tlearn: 2.3423456\ttotal: 7m 23s\tremaining: 55.1s\n",
      "20460:\tlearn: 2.3422641\ttotal: 7m 23s\tremaining: 55s\n",
      "20461:\tlearn: 2.3421884\ttotal: 7m 23s\tremaining: 55s\n",
      "20462:\tlearn: 2.3420927\ttotal: 7m 23s\tremaining: 55s\n",
      "20463:\tlearn: 2.3420381\ttotal: 7m 23s\tremaining: 55s\n",
      "20464:\tlearn: 2.3419803\ttotal: 7m 23s\tremaining: 55s\n",
      "20465:\tlearn: 2.3419229\ttotal: 7m 23s\tremaining: 54.9s\n",
      "20466:\tlearn: 2.3418226\ttotal: 7m 23s\tremaining: 54.9s\n",
      "20467:\tlearn: 2.3417397\ttotal: 7m 23s\tremaining: 54.9s\n",
      "20468:\tlearn: 2.3416262\ttotal: 7m 23s\tremaining: 54.9s\n",
      "20469:\tlearn: 2.3415281\ttotal: 7m 23s\tremaining: 54.8s\n",
      "20470:\tlearn: 2.3414525\ttotal: 7m 23s\tremaining: 54.8s\n",
      "20471:\tlearn: 2.3413516\ttotal: 7m 23s\tremaining: 54.8s\n",
      "20472:\tlearn: 2.3412519\ttotal: 7m 23s\tremaining: 54.8s\n",
      "20473:\tlearn: 2.3411686\ttotal: 7m 23s\tremaining: 54.8s\n",
      "20474:\tlearn: 2.3411671\ttotal: 7m 23s\tremaining: 54.7s\n",
      "20475:\tlearn: 2.3410855\ttotal: 7m 23s\tremaining: 54.7s\n",
      "20476:\tlearn: 2.3410124\ttotal: 7m 23s\tremaining: 54.7s\n",
      "20477:\tlearn: 2.3409281\ttotal: 7m 23s\tremaining: 54.7s\n",
      "20478:\tlearn: 2.3408736\ttotal: 7m 23s\tremaining: 54.6s\n",
      "20479:\tlearn: 2.3407695\ttotal: 7m 23s\tremaining: 54.6s\n",
      "20480:\tlearn: 2.3407212\ttotal: 7m 23s\tremaining: 54.6s\n",
      "20481:\tlearn: 2.3406642\ttotal: 7m 24s\tremaining: 54.6s\n",
      "20482:\tlearn: 2.3405896\ttotal: 7m 24s\tremaining: 54.6s\n",
      "20483:\tlearn: 2.3404907\ttotal: 7m 24s\tremaining: 54.5s\n",
      "20484:\tlearn: 2.3404097\ttotal: 7m 24s\tremaining: 54.5s\n",
      "20485:\tlearn: 2.3402787\ttotal: 7m 24s\tremaining: 54.5s\n",
      "20486:\tlearn: 2.3401515\ttotal: 7m 24s\tremaining: 54.5s\n",
      "20487:\tlearn: 2.3400627\ttotal: 7m 24s\tremaining: 54.5s\n",
      "20488:\tlearn: 2.3399882\ttotal: 7m 24s\tremaining: 54.4s\n",
      "20489:\tlearn: 2.3399058\ttotal: 7m 24s\tremaining: 54.4s\n",
      "20490:\tlearn: 2.3398279\ttotal: 7m 24s\tremaining: 54.4s\n",
      "20491:\tlearn: 2.3398050\ttotal: 7m 24s\tremaining: 54.4s\n",
      "20492:\tlearn: 2.3397200\ttotal: 7m 24s\tremaining: 54.3s\n",
      "20493:\tlearn: 2.3396169\ttotal: 7m 24s\tremaining: 54.3s\n",
      "20494:\tlearn: 2.3395249\ttotal: 7m 24s\tremaining: 54.3s\n",
      "20495:\tlearn: 2.3394325\ttotal: 7m 24s\tremaining: 54.3s\n",
      "20496:\tlearn: 2.3394318\ttotal: 7m 24s\tremaining: 54.3s\n",
      "20497:\tlearn: 2.3392979\ttotal: 7m 24s\tremaining: 54.2s\n",
      "20498:\tlearn: 2.3392220\ttotal: 7m 24s\tremaining: 54.2s\n",
      "20499:\tlearn: 2.3391965\ttotal: 7m 24s\tremaining: 54.2s\n",
      "20500:\tlearn: 2.3391392\ttotal: 7m 24s\tremaining: 54.2s\n",
      "20501:\tlearn: 2.3389973\ttotal: 7m 24s\tremaining: 54.1s\n",
      "20502:\tlearn: 2.3389646\ttotal: 7m 24s\tremaining: 54.1s\n",
      "20503:\tlearn: 2.3388691\ttotal: 7m 24s\tremaining: 54.1s\n",
      "20504:\tlearn: 2.3387826\ttotal: 7m 24s\tremaining: 54.1s\n",
      "20505:\tlearn: 2.3387058\ttotal: 7m 24s\tremaining: 54.1s\n",
      "20506:\tlearn: 2.3386111\ttotal: 7m 24s\tremaining: 54s\n",
      "20507:\tlearn: 2.3385555\ttotal: 7m 24s\tremaining: 54s\n",
      "20508:\tlearn: 2.3384385\ttotal: 7m 24s\tremaining: 54s\n",
      "20509:\tlearn: 2.3383579\ttotal: 7m 24s\tremaining: 54s\n",
      "20510:\tlearn: 2.3382954\ttotal: 7m 24s\tremaining: 54s\n",
      "20511:\tlearn: 2.3382238\ttotal: 7m 24s\tremaining: 53.9s\n",
      "20512:\tlearn: 2.3381947\ttotal: 7m 24s\tremaining: 53.9s\n",
      "20513:\tlearn: 2.3381044\ttotal: 7m 24s\tremaining: 53.9s\n",
      "20514:\tlearn: 2.3380453\ttotal: 7m 24s\tremaining: 53.9s\n",
      "20515:\tlearn: 2.3379018\ttotal: 7m 24s\tremaining: 53.8s\n",
      "20516:\tlearn: 2.3378334\ttotal: 7m 24s\tremaining: 53.8s\n",
      "20517:\tlearn: 2.3377512\ttotal: 7m 24s\tremaining: 53.8s\n",
      "20518:\tlearn: 2.3376357\ttotal: 7m 24s\tremaining: 53.8s\n",
      "20519:\tlearn: 2.3375445\ttotal: 7m 24s\tremaining: 53.8s\n",
      "20520:\tlearn: 2.3374311\ttotal: 7m 24s\tremaining: 53.7s\n",
      "20521:\tlearn: 2.3373353\ttotal: 7m 24s\tremaining: 53.7s\n",
      "20522:\tlearn: 2.3372652\ttotal: 7m 24s\tremaining: 53.7s\n",
      "20523:\tlearn: 2.3372124\ttotal: 7m 24s\tremaining: 53.7s\n",
      "20524:\tlearn: 2.3372117\ttotal: 7m 24s\tremaining: 53.6s\n",
      "20525:\tlearn: 2.3370297\ttotal: 7m 24s\tremaining: 53.6s\n",
      "20526:\tlearn: 2.3369781\ttotal: 7m 24s\tremaining: 53.6s\n",
      "20527:\tlearn: 2.3369565\ttotal: 7m 24s\tremaining: 53.6s\n",
      "20528:\tlearn: 2.3368578\ttotal: 7m 25s\tremaining: 53.6s\n",
      "20529:\tlearn: 2.3366774\ttotal: 7m 25s\tremaining: 53.5s\n",
      "20530:\tlearn: 2.3365454\ttotal: 7m 25s\tremaining: 53.5s\n",
      "20531:\tlearn: 2.3364842\ttotal: 7m 25s\tremaining: 53.5s\n",
      "20532:\tlearn: 2.3363832\ttotal: 7m 25s\tremaining: 53.5s\n",
      "20533:\tlearn: 2.3363172\ttotal: 7m 25s\tremaining: 53.5s\n",
      "20534:\tlearn: 2.3362157\ttotal: 7m 25s\tremaining: 53.4s\n",
      "20535:\tlearn: 2.3361391\ttotal: 7m 25s\tremaining: 53.4s\n",
      "20536:\tlearn: 2.3361195\ttotal: 7m 25s\tremaining: 53.4s\n",
      "20537:\tlearn: 2.3360372\ttotal: 7m 25s\tremaining: 53.4s\n",
      "20538:\tlearn: 2.3359575\ttotal: 7m 25s\tremaining: 53.3s\n",
      "20539:\tlearn: 2.3358882\ttotal: 7m 25s\tremaining: 53.3s\n",
      "20540:\tlearn: 2.3357879\ttotal: 7m 25s\tremaining: 53.3s\n",
      "20541:\tlearn: 2.3356537\ttotal: 7m 25s\tremaining: 53.3s\n",
      "20542:\tlearn: 2.3355734\ttotal: 7m 25s\tremaining: 53.3s\n",
      "20543:\tlearn: 2.3355347\ttotal: 7m 25s\tremaining: 53.2s\n",
      "20544:\tlearn: 2.3354450\ttotal: 7m 25s\tremaining: 53.2s\n",
      "20545:\tlearn: 2.3353496\ttotal: 7m 25s\tremaining: 53.2s\n",
      "20546:\tlearn: 2.3353146\ttotal: 7m 25s\tremaining: 53.2s\n",
      "20547:\tlearn: 2.3352670\ttotal: 7m 25s\tremaining: 53.2s\n",
      "20548:\tlearn: 2.3351421\ttotal: 7m 25s\tremaining: 53.1s\n",
      "20549:\tlearn: 2.3350643\ttotal: 7m 25s\tremaining: 53.1s\n",
      "20550:\tlearn: 2.3349622\ttotal: 7m 25s\tremaining: 53.1s\n",
      "20551:\tlearn: 2.3349157\ttotal: 7m 25s\tremaining: 53.1s\n",
      "20552:\tlearn: 2.3348410\ttotal: 7m 25s\tremaining: 53s\n",
      "20553:\tlearn: 2.3347580\ttotal: 7m 25s\tremaining: 53s\n",
      "20554:\tlearn: 2.3347212\ttotal: 7m 25s\tremaining: 53s\n",
      "20555:\tlearn: 2.3346354\ttotal: 7m 25s\tremaining: 53s\n",
      "20556:\tlearn: 2.3345347\ttotal: 7m 25s\tremaining: 53s\n",
      "20557:\tlearn: 2.3344761\ttotal: 7m 25s\tremaining: 52.9s\n",
      "20558:\tlearn: 2.3343821\ttotal: 7m 25s\tremaining: 52.9s\n",
      "20559:\tlearn: 2.3342736\ttotal: 7m 25s\tremaining: 52.9s\n",
      "20560:\tlearn: 2.3342069\ttotal: 7m 25s\tremaining: 52.9s\n",
      "20561:\tlearn: 2.3341546\ttotal: 7m 25s\tremaining: 52.8s\n",
      "20562:\tlearn: 2.3340984\ttotal: 7m 25s\tremaining: 52.8s\n",
      "20563:\tlearn: 2.3340385\ttotal: 7m 25s\tremaining: 52.8s\n",
      "20564:\tlearn: 2.3339584\ttotal: 7m 25s\tremaining: 52.8s\n",
      "20565:\tlearn: 2.3339277\ttotal: 7m 25s\tremaining: 52.8s\n",
      "20566:\tlearn: 2.3338602\ttotal: 7m 25s\tremaining: 52.7s\n",
      "20567:\tlearn: 2.3337689\ttotal: 7m 25s\tremaining: 52.7s\n",
      "20568:\tlearn: 2.3336938\ttotal: 7m 25s\tremaining: 52.7s\n",
      "20569:\tlearn: 2.3335983\ttotal: 7m 25s\tremaining: 52.7s\n",
      "20570:\tlearn: 2.3335233\ttotal: 7m 25s\tremaining: 52.7s\n",
      "20571:\tlearn: 2.3334602\ttotal: 7m 25s\tremaining: 52.6s\n",
      "20572:\tlearn: 2.3334281\ttotal: 7m 25s\tremaining: 52.6s\n",
      "20573:\tlearn: 2.3333825\ttotal: 7m 25s\tremaining: 52.6s\n",
      "20574:\tlearn: 2.3332717\ttotal: 7m 25s\tremaining: 52.6s\n",
      "20575:\tlearn: 2.3331767\ttotal: 7m 26s\tremaining: 52.5s\n",
      "20576:\tlearn: 2.3331088\ttotal: 7m 26s\tremaining: 52.5s\n",
      "20577:\tlearn: 2.3330420\ttotal: 7m 26s\tremaining: 52.5s\n",
      "20578:\tlearn: 2.3329914\ttotal: 7m 26s\tremaining: 52.5s\n",
      "20579:\tlearn: 2.3329566\ttotal: 7m 26s\tremaining: 52.5s\n",
      "20580:\tlearn: 2.3329148\ttotal: 7m 26s\tremaining: 52.4s\n",
      "20581:\tlearn: 2.3328321\ttotal: 7m 26s\tremaining: 52.4s\n",
      "20582:\tlearn: 2.3326726\ttotal: 7m 26s\tremaining: 52.4s\n",
      "20583:\tlearn: 2.3326712\ttotal: 7m 26s\tremaining: 52.4s\n",
      "20584:\tlearn: 2.3325567\ttotal: 7m 26s\tremaining: 52.3s\n",
      "20585:\tlearn: 2.3324801\ttotal: 7m 26s\tremaining: 52.3s\n",
      "20586:\tlearn: 2.3323935\ttotal: 7m 26s\tremaining: 52.3s\n",
      "20587:\tlearn: 2.3322825\ttotal: 7m 26s\tremaining: 52.3s\n",
      "20588:\tlearn: 2.3322292\ttotal: 7m 26s\tremaining: 52.3s\n",
      "20589:\tlearn: 2.3321484\ttotal: 7m 26s\tremaining: 52.2s\n",
      "20590:\tlearn: 2.3320583\ttotal: 7m 26s\tremaining: 52.2s\n",
      "20591:\tlearn: 2.3319769\ttotal: 7m 26s\tremaining: 52.2s\n",
      "20592:\tlearn: 2.3318973\ttotal: 7m 26s\tremaining: 52.2s\n",
      "20593:\tlearn: 2.3318320\ttotal: 7m 26s\tremaining: 52.2s\n",
      "20594:\tlearn: 2.3316870\ttotal: 7m 26s\tremaining: 52.1s\n",
      "20595:\tlearn: 2.3316191\ttotal: 7m 26s\tremaining: 52.1s\n",
      "20596:\tlearn: 2.3315677\ttotal: 7m 26s\tremaining: 52.1s\n",
      "20597:\tlearn: 2.3315119\ttotal: 7m 26s\tremaining: 52.1s\n",
      "20598:\tlearn: 2.3314020\ttotal: 7m 26s\tremaining: 52s\n",
      "20599:\tlearn: 2.3313035\ttotal: 7m 26s\tremaining: 52s\n",
      "20600:\tlearn: 2.3312422\ttotal: 7m 26s\tremaining: 52s\n",
      "20601:\tlearn: 2.3311371\ttotal: 7m 26s\tremaining: 52s\n",
      "20602:\tlearn: 2.3310107\ttotal: 7m 26s\tremaining: 52s\n",
      "20603:\tlearn: 2.3309386\ttotal: 7m 26s\tremaining: 51.9s\n",
      "20604:\tlearn: 2.3308225\ttotal: 7m 26s\tremaining: 51.9s\n",
      "20605:\tlearn: 2.3307152\ttotal: 7m 26s\tremaining: 51.9s\n",
      "20606:\tlearn: 2.3306237\ttotal: 7m 26s\tremaining: 51.9s\n",
      "20607:\tlearn: 2.3305879\ttotal: 7m 26s\tremaining: 51.8s\n",
      "20608:\tlearn: 2.3305107\ttotal: 7m 26s\tremaining: 51.8s\n",
      "20609:\tlearn: 2.3304506\ttotal: 7m 26s\tremaining: 51.8s\n",
      "20610:\tlearn: 2.3303668\ttotal: 7m 26s\tremaining: 51.8s\n",
      "20611:\tlearn: 2.3302600\ttotal: 7m 26s\tremaining: 51.8s\n",
      "20612:\tlearn: 2.3302225\ttotal: 7m 26s\tremaining: 51.7s\n",
      "20613:\tlearn: 2.3302018\ttotal: 7m 26s\tremaining: 51.7s\n",
      "20614:\tlearn: 2.3301394\ttotal: 7m 26s\tremaining: 51.7s\n",
      "20615:\tlearn: 2.3300222\ttotal: 7m 26s\tremaining: 51.7s\n",
      "20616:\tlearn: 2.3299652\ttotal: 7m 26s\tremaining: 51.7s\n",
      "20617:\tlearn: 2.3298509\ttotal: 7m 26s\tremaining: 51.6s\n",
      "20618:\tlearn: 2.3297689\ttotal: 7m 26s\tremaining: 51.6s\n",
      "20619:\tlearn: 2.3296734\ttotal: 7m 26s\tremaining: 51.6s\n",
      "20620:\tlearn: 2.3296005\ttotal: 7m 26s\tremaining: 51.6s\n",
      "20621:\tlearn: 2.3294866\ttotal: 7m 27s\tremaining: 51.5s\n",
      "20622:\tlearn: 2.3294179\ttotal: 7m 27s\tremaining: 51.5s\n",
      "20623:\tlearn: 2.3292980\ttotal: 7m 27s\tremaining: 51.5s\n",
      "20624:\tlearn: 2.3291612\ttotal: 7m 27s\tremaining: 51.5s\n",
      "20625:\tlearn: 2.3290097\ttotal: 7m 27s\tremaining: 51.5s\n",
      "20626:\tlearn: 2.3289015\ttotal: 7m 27s\tremaining: 51.4s\n",
      "20627:\tlearn: 2.3287611\ttotal: 7m 27s\tremaining: 51.4s\n",
      "20628:\tlearn: 2.3286870\ttotal: 7m 27s\tremaining: 51.4s\n",
      "20629:\tlearn: 2.3286152\ttotal: 7m 27s\tremaining: 51.4s\n",
      "20630:\tlearn: 2.3285216\ttotal: 7m 27s\tremaining: 51.4s\n",
      "20631:\tlearn: 2.3284731\ttotal: 7m 27s\tremaining: 51.3s\n",
      "20632:\tlearn: 2.3283713\ttotal: 7m 27s\tremaining: 51.3s\n",
      "20633:\tlearn: 2.3283263\ttotal: 7m 27s\tremaining: 51.3s\n",
      "20634:\tlearn: 2.3282486\ttotal: 7m 27s\tremaining: 51.3s\n",
      "20635:\tlearn: 2.3282127\ttotal: 7m 27s\tremaining: 51.2s\n",
      "20636:\tlearn: 2.3281243\ttotal: 7m 27s\tremaining: 51.2s\n",
      "20637:\tlearn: 2.3280192\ttotal: 7m 27s\tremaining: 51.2s\n",
      "20638:\tlearn: 2.3279438\ttotal: 7m 27s\tremaining: 51.2s\n",
      "20639:\tlearn: 2.3278579\ttotal: 7m 27s\tremaining: 51.2s\n",
      "20640:\tlearn: 2.3277673\ttotal: 7m 27s\tremaining: 51.1s\n",
      "20641:\tlearn: 2.3276713\ttotal: 7m 27s\tremaining: 51.1s\n",
      "20642:\tlearn: 2.3275844\ttotal: 7m 27s\tremaining: 51.1s\n",
      "20643:\tlearn: 2.3275048\ttotal: 7m 27s\tremaining: 51.1s\n",
      "20644:\tlearn: 2.3274087\ttotal: 7m 27s\tremaining: 51s\n",
      "20645:\tlearn: 2.3273408\ttotal: 7m 27s\tremaining: 51s\n",
      "20646:\tlearn: 2.3272500\ttotal: 7m 27s\tremaining: 51s\n",
      "20647:\tlearn: 2.3271881\ttotal: 7m 27s\tremaining: 51s\n",
      "20648:\tlearn: 2.3271873\ttotal: 7m 27s\tremaining: 51s\n",
      "20649:\tlearn: 2.3270775\ttotal: 7m 27s\tremaining: 50.9s\n",
      "20650:\tlearn: 2.3270176\ttotal: 7m 27s\tremaining: 50.9s\n",
      "20651:\tlearn: 2.3269338\ttotal: 7m 27s\tremaining: 50.9s\n",
      "20652:\tlearn: 2.3268735\ttotal: 7m 27s\tremaining: 50.9s\n",
      "20653:\tlearn: 2.3267996\ttotal: 7m 27s\tremaining: 50.9s\n",
      "20654:\tlearn: 2.3267269\ttotal: 7m 27s\tremaining: 50.8s\n",
      "20655:\tlearn: 2.3266878\ttotal: 7m 27s\tremaining: 50.8s\n",
      "20656:\tlearn: 2.3265994\ttotal: 7m 27s\tremaining: 50.8s\n",
      "20657:\tlearn: 2.3264515\ttotal: 7m 27s\tremaining: 50.8s\n",
      "20658:\tlearn: 2.3263532\ttotal: 7m 27s\tremaining: 50.7s\n",
      "20659:\tlearn: 2.3262149\ttotal: 7m 27s\tremaining: 50.7s\n",
      "20660:\tlearn: 2.3261303\ttotal: 7m 27s\tremaining: 50.7s\n",
      "20661:\tlearn: 2.3260891\ttotal: 7m 27s\tremaining: 50.7s\n",
      "20662:\tlearn: 2.3259977\ttotal: 7m 27s\tremaining: 50.7s\n",
      "20663:\tlearn: 2.3259475\ttotal: 7m 27s\tremaining: 50.6s\n",
      "20664:\tlearn: 2.3258833\ttotal: 7m 27s\tremaining: 50.6s\n",
      "20665:\tlearn: 2.3258124\ttotal: 7m 27s\tremaining: 50.6s\n",
      "20666:\tlearn: 2.3256983\ttotal: 7m 27s\tremaining: 50.6s\n",
      "20667:\tlearn: 2.3256407\ttotal: 7m 27s\tremaining: 50.5s\n",
      "20668:\tlearn: 2.3255194\ttotal: 7m 28s\tremaining: 50.5s\n",
      "20669:\tlearn: 2.3255178\ttotal: 7m 28s\tremaining: 50.5s\n",
      "20670:\tlearn: 2.3254106\ttotal: 7m 28s\tremaining: 50.5s\n",
      "20671:\tlearn: 2.3253157\ttotal: 7m 28s\tremaining: 50.5s\n",
      "20672:\tlearn: 2.3252647\ttotal: 7m 28s\tremaining: 50.4s\n",
      "20673:\tlearn: 2.3251450\ttotal: 7m 28s\tremaining: 50.4s\n",
      "20674:\tlearn: 2.3250160\ttotal: 7m 28s\tremaining: 50.4s\n",
      "20675:\tlearn: 2.3249452\ttotal: 7m 28s\tremaining: 50.4s\n",
      "20676:\tlearn: 2.3247892\ttotal: 7m 28s\tremaining: 50.4s\n",
      "20677:\tlearn: 2.3246439\ttotal: 7m 28s\tremaining: 50.3s\n",
      "20678:\tlearn: 2.3245923\ttotal: 7m 28s\tremaining: 50.3s\n",
      "20679:\tlearn: 2.3245165\ttotal: 7m 28s\tremaining: 50.3s\n",
      "20680:\tlearn: 2.3243688\ttotal: 7m 28s\tremaining: 50.3s\n",
      "20681:\tlearn: 2.3242830\ttotal: 7m 28s\tremaining: 50.2s\n",
      "20682:\tlearn: 2.3242075\ttotal: 7m 28s\tremaining: 50.2s\n",
      "20683:\tlearn: 2.3240761\ttotal: 7m 28s\tremaining: 50.2s\n",
      "20684:\tlearn: 2.3239697\ttotal: 7m 28s\tremaining: 50.2s\n",
      "20685:\tlearn: 2.3239093\ttotal: 7m 28s\tremaining: 50.2s\n",
      "20686:\tlearn: 2.3238259\ttotal: 7m 28s\tremaining: 50.1s\n",
      "20687:\tlearn: 2.3237426\ttotal: 7m 28s\tremaining: 50.1s\n",
      "20688:\tlearn: 2.3236833\ttotal: 7m 28s\tremaining: 50.1s\n",
      "20689:\tlearn: 2.3236211\ttotal: 7m 28s\tremaining: 50.1s\n",
      "20690:\tlearn: 2.3235399\ttotal: 7m 28s\tremaining: 50s\n",
      "20691:\tlearn: 2.3234944\ttotal: 7m 28s\tremaining: 50s\n",
      "20692:\tlearn: 2.3234557\ttotal: 7m 28s\tremaining: 50s\n",
      "20693:\tlearn: 2.3233555\ttotal: 7m 28s\tremaining: 50s\n",
      "20694:\tlearn: 2.3233541\ttotal: 7m 28s\tremaining: 50s\n",
      "20695:\tlearn: 2.3232620\ttotal: 7m 28s\tremaining: 49.9s\n",
      "20696:\tlearn: 2.3232204\ttotal: 7m 28s\tremaining: 49.9s\n",
      "20697:\tlearn: 2.3231437\ttotal: 7m 28s\tremaining: 49.9s\n",
      "20698:\tlearn: 2.3231414\ttotal: 7m 28s\tremaining: 49.9s\n",
      "20699:\tlearn: 2.3230555\ttotal: 7m 28s\tremaining: 49.9s\n",
      "20700:\tlearn: 2.3229957\ttotal: 7m 28s\tremaining: 49.8s\n",
      "20701:\tlearn: 2.3228918\ttotal: 7m 28s\tremaining: 49.8s\n",
      "20702:\tlearn: 2.3228600\ttotal: 7m 28s\tremaining: 49.8s\n",
      "20703:\tlearn: 2.3228105\ttotal: 7m 28s\tremaining: 49.8s\n",
      "20704:\tlearn: 2.3226721\ttotal: 7m 28s\tremaining: 49.7s\n",
      "20705:\tlearn: 2.3225823\ttotal: 7m 28s\tremaining: 49.7s\n",
      "20706:\tlearn: 2.3225167\ttotal: 7m 28s\tremaining: 49.7s\n",
      "20707:\tlearn: 2.3224762\ttotal: 7m 28s\tremaining: 49.7s\n",
      "20708:\tlearn: 2.3223357\ttotal: 7m 28s\tremaining: 49.7s\n",
      "20709:\tlearn: 2.3222490\ttotal: 7m 28s\tremaining: 49.6s\n",
      "20710:\tlearn: 2.3221814\ttotal: 7m 28s\tremaining: 49.6s\n",
      "20711:\tlearn: 2.3221000\ttotal: 7m 28s\tremaining: 49.6s\n",
      "20712:\tlearn: 2.3220891\ttotal: 7m 28s\tremaining: 49.6s\n",
      "20713:\tlearn: 2.3219916\ttotal: 7m 28s\tremaining: 49.5s\n",
      "20714:\tlearn: 2.3218897\ttotal: 7m 29s\tremaining: 49.5s\n",
      "20715:\tlearn: 2.3218010\ttotal: 7m 29s\tremaining: 49.5s\n",
      "20716:\tlearn: 2.3217229\ttotal: 7m 29s\tremaining: 49.5s\n",
      "20717:\tlearn: 2.3216753\ttotal: 7m 29s\tremaining: 49.5s\n",
      "20718:\tlearn: 2.3216050\ttotal: 7m 29s\tremaining: 49.4s\n",
      "20719:\tlearn: 2.3215518\ttotal: 7m 29s\tremaining: 49.4s\n",
      "20720:\tlearn: 2.3215251\ttotal: 7m 29s\tremaining: 49.4s\n",
      "20721:\tlearn: 2.3214577\ttotal: 7m 29s\tremaining: 49.4s\n",
      "20722:\tlearn: 2.3213677\ttotal: 7m 29s\tremaining: 49.4s\n",
      "20723:\tlearn: 2.3212729\ttotal: 7m 29s\tremaining: 49.3s\n",
      "20724:\tlearn: 2.3212143\ttotal: 7m 29s\tremaining: 49.3s\n",
      "20725:\tlearn: 2.3212124\ttotal: 7m 29s\tremaining: 49.3s\n",
      "20726:\tlearn: 2.3211286\ttotal: 7m 29s\tremaining: 49.3s\n",
      "20727:\tlearn: 2.3210532\ttotal: 7m 29s\tremaining: 49.2s\n",
      "20728:\tlearn: 2.3209644\ttotal: 7m 29s\tremaining: 49.2s\n",
      "20729:\tlearn: 2.3208850\ttotal: 7m 29s\tremaining: 49.2s\n",
      "20730:\tlearn: 2.3207680\ttotal: 7m 29s\tremaining: 49.2s\n",
      "20731:\tlearn: 2.3207168\ttotal: 7m 29s\tremaining: 49.2s\n",
      "20732:\tlearn: 2.3206451\ttotal: 7m 29s\tremaining: 49.1s\n",
      "20733:\tlearn: 2.3205841\ttotal: 7m 29s\tremaining: 49.1s\n",
      "20734:\tlearn: 2.3204428\ttotal: 7m 29s\tremaining: 49.1s\n",
      "20735:\tlearn: 2.3203413\ttotal: 7m 29s\tremaining: 49.1s\n",
      "20736:\tlearn: 2.3202527\ttotal: 7m 29s\tremaining: 49s\n",
      "20737:\tlearn: 2.3201283\ttotal: 7m 29s\tremaining: 49s\n",
      "20738:\tlearn: 2.3200764\ttotal: 7m 29s\tremaining: 49s\n",
      "20739:\tlearn: 2.3199832\ttotal: 7m 29s\tremaining: 49s\n",
      "20740:\tlearn: 2.3199091\ttotal: 7m 29s\tremaining: 49s\n",
      "20741:\tlearn: 2.3198657\ttotal: 7m 29s\tremaining: 48.9s\n",
      "20742:\tlearn: 2.3198056\ttotal: 7m 29s\tremaining: 48.9s\n",
      "20743:\tlearn: 2.3197319\ttotal: 7m 29s\tremaining: 48.9s\n",
      "20744:\tlearn: 2.3196584\ttotal: 7m 29s\tremaining: 48.9s\n",
      "20745:\tlearn: 2.3196567\ttotal: 7m 29s\tremaining: 48.9s\n",
      "20746:\tlearn: 2.3195889\ttotal: 7m 29s\tremaining: 48.8s\n",
      "20747:\tlearn: 2.3195159\ttotal: 7m 29s\tremaining: 48.8s\n",
      "20748:\tlearn: 2.3194237\ttotal: 7m 29s\tremaining: 48.8s\n",
      "20749:\tlearn: 2.3193477\ttotal: 7m 29s\tremaining: 48.8s\n",
      "20750:\tlearn: 2.3192501\ttotal: 7m 29s\tremaining: 48.7s\n",
      "20751:\tlearn: 2.3191699\ttotal: 7m 29s\tremaining: 48.7s\n",
      "20752:\tlearn: 2.3190452\ttotal: 7m 29s\tremaining: 48.7s\n",
      "20753:\tlearn: 2.3189713\ttotal: 7m 29s\tremaining: 48.7s\n",
      "20754:\tlearn: 2.3188854\ttotal: 7m 29s\tremaining: 48.7s\n",
      "20755:\tlearn: 2.3187661\ttotal: 7m 29s\tremaining: 48.6s\n",
      "20756:\tlearn: 2.3185995\ttotal: 7m 29s\tremaining: 48.6s\n",
      "20757:\tlearn: 2.3185099\ttotal: 7m 29s\tremaining: 48.6s\n",
      "20758:\tlearn: 2.3184049\ttotal: 7m 29s\tremaining: 48.6s\n",
      "20759:\tlearn: 2.3183438\ttotal: 7m 29s\tremaining: 48.5s\n",
      "20760:\tlearn: 2.3182998\ttotal: 7m 29s\tremaining: 48.5s\n",
      "20761:\tlearn: 2.3182355\ttotal: 7m 29s\tremaining: 48.5s\n",
      "20762:\tlearn: 2.3181416\ttotal: 7m 30s\tremaining: 48.5s\n",
      "20763:\tlearn: 2.3180571\ttotal: 7m 30s\tremaining: 48.5s\n",
      "20764:\tlearn: 2.3179378\ttotal: 7m 30s\tremaining: 48.4s\n",
      "20765:\tlearn: 2.3178624\ttotal: 7m 30s\tremaining: 48.4s\n",
      "20766:\tlearn: 2.3177139\ttotal: 7m 30s\tremaining: 48.4s\n",
      "20767:\tlearn: 2.3176944\ttotal: 7m 30s\tremaining: 48.4s\n",
      "20768:\tlearn: 2.3176538\ttotal: 7m 30s\tremaining: 48.4s\n",
      "20769:\tlearn: 2.3176290\ttotal: 7m 30s\tremaining: 48.3s\n",
      "20770:\tlearn: 2.3175178\ttotal: 7m 30s\tremaining: 48.3s\n",
      "20771:\tlearn: 2.3173973\ttotal: 7m 30s\tremaining: 48.3s\n",
      "20772:\tlearn: 2.3173573\ttotal: 7m 30s\tremaining: 48.3s\n",
      "20773:\tlearn: 2.3172881\ttotal: 7m 30s\tremaining: 48.2s\n",
      "20774:\tlearn: 2.3171232\ttotal: 7m 30s\tremaining: 48.2s\n",
      "20775:\tlearn: 2.3170203\ttotal: 7m 30s\tremaining: 48.2s\n",
      "20776:\tlearn: 2.3169458\ttotal: 7m 30s\tremaining: 48.2s\n",
      "20777:\tlearn: 2.3168901\ttotal: 7m 30s\tremaining: 48.2s\n",
      "20778:\tlearn: 2.3167912\ttotal: 7m 30s\tremaining: 48.1s\n",
      "20779:\tlearn: 2.3166985\ttotal: 7m 30s\tremaining: 48.1s\n",
      "20780:\tlearn: 2.3166969\ttotal: 7m 30s\tremaining: 48.1s\n",
      "20781:\tlearn: 2.3166076\ttotal: 7m 30s\tremaining: 48.1s\n",
      "20782:\tlearn: 2.3165681\ttotal: 7m 30s\tremaining: 48s\n",
      "20783:\tlearn: 2.3164945\ttotal: 7m 30s\tremaining: 48s\n",
      "20784:\tlearn: 2.3164244\ttotal: 7m 30s\tremaining: 48s\n",
      "20785:\tlearn: 2.3162720\ttotal: 7m 30s\tremaining: 48s\n",
      "20786:\tlearn: 2.3162083\ttotal: 7m 30s\tremaining: 48s\n",
      "20787:\tlearn: 2.3161357\ttotal: 7m 30s\tremaining: 47.9s\n",
      "20788:\tlearn: 2.3160871\ttotal: 7m 30s\tremaining: 47.9s\n",
      "20789:\tlearn: 2.3160408\ttotal: 7m 30s\tremaining: 47.9s\n",
      "20790:\tlearn: 2.3159297\ttotal: 7m 30s\tremaining: 47.9s\n",
      "20791:\tlearn: 2.3158542\ttotal: 7m 30s\tremaining: 47.9s\n",
      "20792:\tlearn: 2.3157669\ttotal: 7m 30s\tremaining: 47.8s\n",
      "20793:\tlearn: 2.3156859\ttotal: 7m 30s\tremaining: 47.8s\n",
      "20794:\tlearn: 2.3156303\ttotal: 7m 30s\tremaining: 47.8s\n",
      "20795:\tlearn: 2.3155638\ttotal: 7m 30s\tremaining: 47.8s\n",
      "20796:\tlearn: 2.3154625\ttotal: 7m 30s\tremaining: 47.7s\n",
      "20797:\tlearn: 2.3153901\ttotal: 7m 30s\tremaining: 47.7s\n",
      "20798:\tlearn: 2.3152743\ttotal: 7m 30s\tremaining: 47.7s\n",
      "20799:\tlearn: 2.3151622\ttotal: 7m 30s\tremaining: 47.7s\n",
      "20800:\tlearn: 2.3150787\ttotal: 7m 30s\tremaining: 47.7s\n",
      "20801:\tlearn: 2.3150336\ttotal: 7m 30s\tremaining: 47.6s\n",
      "20802:\tlearn: 2.3149616\ttotal: 7m 30s\tremaining: 47.6s\n",
      "20803:\tlearn: 2.3148291\ttotal: 7m 30s\tremaining: 47.6s\n",
      "20804:\tlearn: 2.3147505\ttotal: 7m 30s\tremaining: 47.6s\n",
      "20805:\tlearn: 2.3146735\ttotal: 7m 30s\tremaining: 47.6s\n",
      "20806:\tlearn: 2.3146094\ttotal: 7m 30s\tremaining: 47.5s\n",
      "20807:\tlearn: 2.3145465\ttotal: 7m 30s\tremaining: 47.5s\n",
      "20808:\tlearn: 2.3144834\ttotal: 7m 31s\tremaining: 47.5s\n",
      "20809:\tlearn: 2.3144339\ttotal: 7m 31s\tremaining: 47.5s\n",
      "20810:\tlearn: 2.3143770\ttotal: 7m 31s\tremaining: 47.4s\n",
      "20811:\tlearn: 2.3142736\ttotal: 7m 31s\tremaining: 47.4s\n",
      "20812:\tlearn: 2.3141827\ttotal: 7m 31s\tremaining: 47.4s\n",
      "20813:\tlearn: 2.3140793\ttotal: 7m 31s\tremaining: 47.4s\n",
      "20814:\tlearn: 2.3140154\ttotal: 7m 31s\tremaining: 47.4s\n",
      "20815:\tlearn: 2.3139809\ttotal: 7m 31s\tremaining: 47.3s\n",
      "20816:\tlearn: 2.3139044\ttotal: 7m 31s\tremaining: 47.3s\n",
      "20817:\tlearn: 2.3138237\ttotal: 7m 31s\tremaining: 47.3s\n",
      "20818:\tlearn: 2.3137822\ttotal: 7m 31s\tremaining: 47.3s\n",
      "20819:\tlearn: 2.3136579\ttotal: 7m 31s\tremaining: 47.2s\n",
      "20820:\tlearn: 2.3135451\ttotal: 7m 31s\tremaining: 47.2s\n",
      "20821:\tlearn: 2.3134604\ttotal: 7m 31s\tremaining: 47.2s\n",
      "20822:\tlearn: 2.3133868\ttotal: 7m 31s\tremaining: 47.2s\n",
      "20823:\tlearn: 2.3132989\ttotal: 7m 31s\tremaining: 47.2s\n",
      "20824:\tlearn: 2.3132764\ttotal: 7m 31s\tremaining: 47.1s\n",
      "20825:\tlearn: 2.3131915\ttotal: 7m 31s\tremaining: 47.1s\n",
      "20826:\tlearn: 2.3131206\ttotal: 7m 31s\tremaining: 47.1s\n",
      "20827:\tlearn: 2.3130657\ttotal: 7m 31s\tremaining: 47.1s\n",
      "20828:\tlearn: 2.3129188\ttotal: 7m 31s\tremaining: 47.1s\n",
      "20829:\tlearn: 2.3128384\ttotal: 7m 31s\tremaining: 47s\n",
      "20830:\tlearn: 2.3127804\ttotal: 7m 31s\tremaining: 47s\n",
      "20831:\tlearn: 2.3126771\ttotal: 7m 31s\tremaining: 47s\n",
      "20832:\tlearn: 2.3125579\ttotal: 7m 31s\tremaining: 47s\n",
      "20833:\tlearn: 2.3124547\ttotal: 7m 31s\tremaining: 46.9s\n",
      "20834:\tlearn: 2.3123360\ttotal: 7m 31s\tremaining: 46.9s\n",
      "20835:\tlearn: 2.3122368\ttotal: 7m 31s\tremaining: 46.9s\n",
      "20836:\tlearn: 2.3122358\ttotal: 7m 31s\tremaining: 46.9s\n",
      "20837:\tlearn: 2.3121550\ttotal: 7m 31s\tremaining: 46.9s\n",
      "20838:\tlearn: 2.3120321\ttotal: 7m 31s\tremaining: 46.8s\n",
      "20839:\tlearn: 2.3119298\ttotal: 7m 31s\tremaining: 46.8s\n",
      "20840:\tlearn: 2.3118249\ttotal: 7m 31s\tremaining: 46.8s\n",
      "20841:\tlearn: 2.3117356\ttotal: 7m 31s\tremaining: 46.8s\n",
      "20842:\tlearn: 2.3116755\ttotal: 7m 31s\tremaining: 46.8s\n",
      "20843:\tlearn: 2.3116014\ttotal: 7m 31s\tremaining: 46.7s\n",
      "20844:\tlearn: 2.3115290\ttotal: 7m 31s\tremaining: 46.7s\n",
      "20845:\tlearn: 2.3114459\ttotal: 7m 31s\tremaining: 46.7s\n",
      "20846:\tlearn: 2.3113358\ttotal: 7m 31s\tremaining: 46.7s\n",
      "20847:\tlearn: 2.3112717\ttotal: 7m 31s\tremaining: 46.6s\n",
      "20848:\tlearn: 2.3112182\ttotal: 7m 31s\tremaining: 46.6s\n",
      "20849:\tlearn: 2.3111144\ttotal: 7m 31s\tremaining: 46.6s\n",
      "20850:\tlearn: 2.3110498\ttotal: 7m 31s\tremaining: 46.6s\n",
      "20851:\tlearn: 2.3109613\ttotal: 7m 31s\tremaining: 46.6s\n",
      "20852:\tlearn: 2.3109094\ttotal: 7m 31s\tremaining: 46.5s\n",
      "20853:\tlearn: 2.3108632\ttotal: 7m 31s\tremaining: 46.5s\n",
      "20854:\tlearn: 2.3108091\ttotal: 7m 32s\tremaining: 46.5s\n",
      "20855:\tlearn: 2.3107623\ttotal: 7m 32s\tremaining: 46.5s\n",
      "20856:\tlearn: 2.3106493\ttotal: 7m 32s\tremaining: 46.4s\n",
      "20857:\tlearn: 2.3106059\ttotal: 7m 32s\tremaining: 46.4s\n",
      "20858:\tlearn: 2.3105732\ttotal: 7m 32s\tremaining: 46.4s\n",
      "20859:\tlearn: 2.3104630\ttotal: 7m 32s\tremaining: 46.4s\n",
      "20860:\tlearn: 2.3103903\ttotal: 7m 32s\tremaining: 46.4s\n",
      "20861:\tlearn: 2.3103221\ttotal: 7m 32s\tremaining: 46.3s\n",
      "20862:\tlearn: 2.3102189\ttotal: 7m 32s\tremaining: 46.3s\n",
      "20863:\tlearn: 2.3101539\ttotal: 7m 32s\tremaining: 46.3s\n",
      "20864:\tlearn: 2.3100678\ttotal: 7m 32s\tremaining: 46.3s\n",
      "20865:\tlearn: 2.3099837\ttotal: 7m 32s\tremaining: 46.3s\n",
      "20866:\tlearn: 2.3099312\ttotal: 7m 32s\tremaining: 46.2s\n",
      "20867:\tlearn: 2.3098098\ttotal: 7m 32s\tremaining: 46.2s\n",
      "20868:\tlearn: 2.3097939\ttotal: 7m 32s\tremaining: 46.2s\n",
      "20869:\tlearn: 2.3097166\ttotal: 7m 32s\tremaining: 46.2s\n",
      "20870:\tlearn: 2.3096593\ttotal: 7m 32s\tremaining: 46.1s\n",
      "20871:\tlearn: 2.3095792\ttotal: 7m 32s\tremaining: 46.1s\n",
      "20872:\tlearn: 2.3094907\ttotal: 7m 32s\tremaining: 46.1s\n",
      "20873:\tlearn: 2.3093854\ttotal: 7m 32s\tremaining: 46.1s\n",
      "20874:\tlearn: 2.3093293\ttotal: 7m 32s\tremaining: 46.1s\n",
      "20875:\tlearn: 2.3092169\ttotal: 7m 32s\tremaining: 46s\n",
      "20876:\tlearn: 2.3091409\ttotal: 7m 32s\tremaining: 46s\n",
      "20877:\tlearn: 2.3090524\ttotal: 7m 32s\tremaining: 46s\n",
      "20878:\tlearn: 2.3089898\ttotal: 7m 32s\tremaining: 46s\n",
      "20879:\tlearn: 2.3089357\ttotal: 7m 32s\tremaining: 45.9s\n",
      "20880:\tlearn: 2.3088841\ttotal: 7m 32s\tremaining: 45.9s\n",
      "20881:\tlearn: 2.3088086\ttotal: 7m 32s\tremaining: 45.9s\n",
      "20882:\tlearn: 2.3087375\ttotal: 7m 32s\tremaining: 45.9s\n",
      "20883:\tlearn: 2.3086963\ttotal: 7m 32s\tremaining: 45.9s\n",
      "20884:\tlearn: 2.3086356\ttotal: 7m 32s\tremaining: 45.8s\n",
      "20885:\tlearn: 2.3084967\ttotal: 7m 32s\tremaining: 45.8s\n",
      "20886:\tlearn: 2.3083956\ttotal: 7m 32s\tremaining: 45.8s\n",
      "20887:\tlearn: 2.3083924\ttotal: 7m 32s\tremaining: 45.8s\n",
      "20888:\tlearn: 2.3082453\ttotal: 7m 32s\tremaining: 45.8s\n",
      "20889:\tlearn: 2.3081317\ttotal: 7m 32s\tremaining: 45.7s\n",
      "20890:\tlearn: 2.3080527\ttotal: 7m 32s\tremaining: 45.7s\n",
      "20891:\tlearn: 2.3080093\ttotal: 7m 32s\tremaining: 45.7s\n",
      "20892:\tlearn: 2.3079515\ttotal: 7m 32s\tremaining: 45.7s\n",
      "20893:\tlearn: 2.3078616\ttotal: 7m 32s\tremaining: 45.6s\n",
      "20894:\tlearn: 2.3078391\ttotal: 7m 32s\tremaining: 45.6s\n",
      "20895:\tlearn: 2.3077870\ttotal: 7m 32s\tremaining: 45.6s\n",
      "20896:\tlearn: 2.3077613\ttotal: 7m 32s\tremaining: 45.6s\n",
      "20897:\tlearn: 2.3076877\ttotal: 7m 32s\tremaining: 45.6s\n",
      "20898:\tlearn: 2.3075811\ttotal: 7m 32s\tremaining: 45.5s\n",
      "20899:\tlearn: 2.3075249\ttotal: 7m 32s\tremaining: 45.5s\n",
      "20900:\tlearn: 2.3074427\ttotal: 7m 32s\tremaining: 45.5s\n",
      "20901:\tlearn: 2.3073179\ttotal: 7m 32s\tremaining: 45.5s\n",
      "20902:\tlearn: 2.3072440\ttotal: 7m 33s\tremaining: 45.4s\n",
      "20903:\tlearn: 2.3071894\ttotal: 7m 33s\tremaining: 45.4s\n",
      "20904:\tlearn: 2.3071279\ttotal: 7m 33s\tremaining: 45.4s\n",
      "20905:\tlearn: 2.3070243\ttotal: 7m 33s\tremaining: 45.4s\n",
      "20906:\tlearn: 2.3069155\ttotal: 7m 33s\tremaining: 45.4s\n",
      "20907:\tlearn: 2.3068670\ttotal: 7m 33s\tremaining: 45.3s\n",
      "20908:\tlearn: 2.3067747\ttotal: 7m 33s\tremaining: 45.3s\n",
      "20909:\tlearn: 2.3067493\ttotal: 7m 33s\tremaining: 45.3s\n",
      "20910:\tlearn: 2.3066610\ttotal: 7m 33s\tremaining: 45.3s\n",
      "20911:\tlearn: 2.3065923\ttotal: 7m 33s\tremaining: 45.3s\n",
      "20912:\tlearn: 2.3065362\ttotal: 7m 33s\tremaining: 45.2s\n",
      "20913:\tlearn: 2.3064659\ttotal: 7m 33s\tremaining: 45.2s\n",
      "20914:\tlearn: 2.3064564\ttotal: 7m 33s\tremaining: 45.2s\n",
      "20915:\tlearn: 2.3063649\ttotal: 7m 33s\tremaining: 45.2s\n",
      "20916:\tlearn: 2.3062828\ttotal: 7m 33s\tremaining: 45.1s\n",
      "20917:\tlearn: 2.3062293\ttotal: 7m 33s\tremaining: 45.1s\n",
      "20918:\tlearn: 2.3060919\ttotal: 7m 33s\tremaining: 45.1s\n",
      "20919:\tlearn: 2.3059969\ttotal: 7m 33s\tremaining: 45.1s\n",
      "20920:\tlearn: 2.3058823\ttotal: 7m 33s\tremaining: 45.1s\n",
      "20921:\tlearn: 2.3057642\ttotal: 7m 33s\tremaining: 45s\n",
      "20922:\tlearn: 2.3057100\ttotal: 7m 33s\tremaining: 45s\n",
      "20923:\tlearn: 2.3056612\ttotal: 7m 33s\tremaining: 45s\n",
      "20924:\tlearn: 2.3055670\ttotal: 7m 33s\tremaining: 45s\n",
      "20925:\tlearn: 2.3055386\ttotal: 7m 33s\tremaining: 44.9s\n",
      "20926:\tlearn: 2.3054393\ttotal: 7m 33s\tremaining: 44.9s\n",
      "20927:\tlearn: 2.3053225\ttotal: 7m 33s\tremaining: 44.9s\n",
      "20928:\tlearn: 2.3052793\ttotal: 7m 33s\tremaining: 44.9s\n",
      "20929:\tlearn: 2.3052263\ttotal: 7m 33s\tremaining: 44.9s\n",
      "20930:\tlearn: 2.3051199\ttotal: 7m 33s\tremaining: 44.8s\n",
      "20931:\tlearn: 2.3050431\ttotal: 7m 33s\tremaining: 44.8s\n",
      "20932:\tlearn: 2.3049920\ttotal: 7m 33s\tremaining: 44.8s\n",
      "20933:\tlearn: 2.3049158\ttotal: 7m 33s\tremaining: 44.8s\n",
      "20934:\tlearn: 2.3048511\ttotal: 7m 33s\tremaining: 44.8s\n",
      "20935:\tlearn: 2.3047684\ttotal: 7m 33s\tremaining: 44.7s\n",
      "20936:\tlearn: 2.3046992\ttotal: 7m 33s\tremaining: 44.7s\n",
      "20937:\tlearn: 2.3046699\ttotal: 7m 33s\tremaining: 44.7s\n",
      "20938:\tlearn: 2.3046355\ttotal: 7m 33s\tremaining: 44.7s\n",
      "20939:\tlearn: 2.3045575\ttotal: 7m 33s\tremaining: 44.6s\n",
      "20940:\tlearn: 2.3044538\ttotal: 7m 33s\tremaining: 44.6s\n",
      "20941:\tlearn: 2.3043608\ttotal: 7m 33s\tremaining: 44.6s\n",
      "20942:\tlearn: 2.3042702\ttotal: 7m 33s\tremaining: 44.6s\n",
      "20943:\tlearn: 2.3041772\ttotal: 7m 33s\tremaining: 44.6s\n",
      "20944:\tlearn: 2.3041021\ttotal: 7m 33s\tremaining: 44.5s\n",
      "20945:\tlearn: 2.3040795\ttotal: 7m 33s\tremaining: 44.5s\n",
      "20946:\tlearn: 2.3040277\ttotal: 7m 33s\tremaining: 44.5s\n",
      "20947:\tlearn: 2.3039330\ttotal: 7m 33s\tremaining: 44.5s\n",
      "20948:\tlearn: 2.3037835\ttotal: 7m 33s\tremaining: 44.4s\n",
      "20949:\tlearn: 2.3036945\ttotal: 7m 34s\tremaining: 44.4s\n",
      "20950:\tlearn: 2.3036262\ttotal: 7m 34s\tremaining: 44.4s\n",
      "20951:\tlearn: 2.3035641\ttotal: 7m 34s\tremaining: 44.4s\n",
      "20952:\tlearn: 2.3035146\ttotal: 7m 34s\tremaining: 44.4s\n",
      "20953:\tlearn: 2.3034323\ttotal: 7m 34s\tremaining: 44.3s\n",
      "20954:\tlearn: 2.3033047\ttotal: 7m 34s\tremaining: 44.3s\n",
      "20955:\tlearn: 2.3032261\ttotal: 7m 34s\tremaining: 44.3s\n",
      "20956:\tlearn: 2.3031423\ttotal: 7m 34s\tremaining: 44.3s\n",
      "20957:\tlearn: 2.3030230\ttotal: 7m 34s\tremaining: 44.3s\n",
      "20958:\tlearn: 2.3030204\ttotal: 7m 34s\tremaining: 44.2s\n",
      "20959:\tlearn: 2.3029375\ttotal: 7m 34s\tremaining: 44.2s\n",
      "20960:\tlearn: 2.3028809\ttotal: 7m 34s\tremaining: 44.2s\n",
      "20961:\tlearn: 2.3028016\ttotal: 7m 34s\tremaining: 44.2s\n",
      "20962:\tlearn: 2.3026774\ttotal: 7m 34s\tremaining: 44.1s\n",
      "20963:\tlearn: 2.3025883\ttotal: 7m 34s\tremaining: 44.1s\n",
      "20964:\tlearn: 2.3024791\ttotal: 7m 34s\tremaining: 44.1s\n",
      "20965:\tlearn: 2.3023565\ttotal: 7m 34s\tremaining: 44.1s\n",
      "20966:\tlearn: 2.3022886\ttotal: 7m 34s\tremaining: 44.1s\n",
      "20967:\tlearn: 2.3022319\ttotal: 7m 34s\tremaining: 44s\n",
      "20968:\tlearn: 2.3021364\ttotal: 7m 34s\tremaining: 44s\n",
      "20969:\tlearn: 2.3020695\ttotal: 7m 34s\tremaining: 44s\n",
      "20970:\tlearn: 2.3020003\ttotal: 7m 34s\tremaining: 44s\n",
      "20971:\tlearn: 2.3019109\ttotal: 7m 34s\tremaining: 44s\n",
      "20972:\tlearn: 2.3017826\ttotal: 7m 34s\tremaining: 43.9s\n",
      "20973:\tlearn: 2.3016754\ttotal: 7m 34s\tremaining: 43.9s\n",
      "20974:\tlearn: 2.3015952\ttotal: 7m 34s\tremaining: 43.9s\n",
      "20975:\tlearn: 2.3014923\ttotal: 7m 34s\tremaining: 43.9s\n",
      "20976:\tlearn: 2.3014333\ttotal: 7m 34s\tremaining: 43.8s\n",
      "20977:\tlearn: 2.3013508\ttotal: 7m 34s\tremaining: 43.8s\n",
      "20978:\tlearn: 2.3012519\ttotal: 7m 34s\tremaining: 43.8s\n",
      "20979:\tlearn: 2.3012047\ttotal: 7m 34s\tremaining: 43.8s\n",
      "20980:\tlearn: 2.3011414\ttotal: 7m 34s\tremaining: 43.8s\n",
      "20981:\tlearn: 2.3010397\ttotal: 7m 34s\tremaining: 43.7s\n",
      "20982:\tlearn: 2.3010022\ttotal: 7m 34s\tremaining: 43.7s\n",
      "20983:\tlearn: 2.3009245\ttotal: 7m 34s\tremaining: 43.7s\n",
      "20984:\tlearn: 2.3008457\ttotal: 7m 34s\tremaining: 43.7s\n",
      "20985:\tlearn: 2.3007926\ttotal: 7m 34s\tremaining: 43.6s\n",
      "20986:\tlearn: 2.3007159\ttotal: 7m 34s\tremaining: 43.6s\n",
      "20987:\tlearn: 2.3006458\ttotal: 7m 34s\tremaining: 43.6s\n",
      "20988:\tlearn: 2.3005646\ttotal: 7m 34s\tremaining: 43.6s\n",
      "20989:\tlearn: 2.3004956\ttotal: 7m 34s\tremaining: 43.6s\n",
      "20990:\tlearn: 2.3003592\ttotal: 7m 34s\tremaining: 43.5s\n",
      "20991:\tlearn: 2.3003037\ttotal: 7m 34s\tremaining: 43.5s\n",
      "20992:\tlearn: 2.3002340\ttotal: 7m 34s\tremaining: 43.5s\n",
      "20993:\tlearn: 2.3002011\ttotal: 7m 34s\tremaining: 43.5s\n",
      "20994:\tlearn: 2.3000477\ttotal: 7m 35s\tremaining: 43.5s\n",
      "20995:\tlearn: 2.2999570\ttotal: 7m 35s\tremaining: 43.4s\n",
      "20996:\tlearn: 2.2998602\ttotal: 7m 35s\tremaining: 43.4s\n",
      "20997:\tlearn: 2.2997347\ttotal: 7m 35s\tremaining: 43.4s\n",
      "20998:\tlearn: 2.2996390\ttotal: 7m 35s\tremaining: 43.4s\n",
      "20999:\tlearn: 2.2996346\ttotal: 7m 35s\tremaining: 43.3s\n",
      "21000:\tlearn: 2.2995949\ttotal: 7m 35s\tremaining: 43.3s\n",
      "21001:\tlearn: 2.2994984\ttotal: 7m 35s\tremaining: 43.3s\n",
      "21002:\tlearn: 2.2994102\ttotal: 7m 35s\tremaining: 43.3s\n",
      "21003:\tlearn: 2.2993575\ttotal: 7m 35s\tremaining: 43.3s\n",
      "21004:\tlearn: 2.2992750\ttotal: 7m 35s\tremaining: 43.2s\n",
      "21005:\tlearn: 2.2991952\ttotal: 7m 35s\tremaining: 43.2s\n",
      "21006:\tlearn: 2.2990935\ttotal: 7m 35s\tremaining: 43.2s\n",
      "21007:\tlearn: 2.2989854\ttotal: 7m 35s\tremaining: 43.2s\n",
      "21008:\tlearn: 2.2989833\ttotal: 7m 35s\tremaining: 43.1s\n",
      "21009:\tlearn: 2.2989122\ttotal: 7m 35s\tremaining: 43.1s\n",
      "21010:\tlearn: 2.2988037\ttotal: 7m 35s\tremaining: 43.1s\n",
      "21011:\tlearn: 2.2987212\ttotal: 7m 35s\tremaining: 43.1s\n",
      "21012:\tlearn: 2.2986653\ttotal: 7m 35s\tremaining: 43.1s\n",
      "21013:\tlearn: 2.2986217\ttotal: 7m 35s\tremaining: 43s\n",
      "21014:\tlearn: 2.2985447\ttotal: 7m 35s\tremaining: 43s\n",
      "21015:\tlearn: 2.2984936\ttotal: 7m 35s\tremaining: 43s\n",
      "21016:\tlearn: 2.2983945\ttotal: 7m 35s\tremaining: 43s\n",
      "21017:\tlearn: 2.2983230\ttotal: 7m 35s\tremaining: 43s\n",
      "21018:\tlearn: 2.2982422\ttotal: 7m 35s\tremaining: 42.9s\n",
      "21019:\tlearn: 2.2981861\ttotal: 7m 35s\tremaining: 42.9s\n",
      "21020:\tlearn: 2.2981311\ttotal: 7m 35s\tremaining: 42.9s\n",
      "21021:\tlearn: 2.2980346\ttotal: 7m 35s\tremaining: 42.9s\n",
      "21022:\tlearn: 2.2979626\ttotal: 7m 35s\tremaining: 42.8s\n",
      "21023:\tlearn: 2.2978932\ttotal: 7m 35s\tremaining: 42.8s\n",
      "21024:\tlearn: 2.2978669\ttotal: 7m 35s\tremaining: 42.8s\n",
      "21025:\tlearn: 2.2977680\ttotal: 7m 35s\tremaining: 42.8s\n",
      "21026:\tlearn: 2.2976999\ttotal: 7m 35s\tremaining: 42.8s\n",
      "21027:\tlearn: 2.2976110\ttotal: 7m 35s\tremaining: 42.7s\n",
      "21028:\tlearn: 2.2975753\ttotal: 7m 35s\tremaining: 42.7s\n",
      "21029:\tlearn: 2.2975088\ttotal: 7m 35s\tremaining: 42.7s\n",
      "21030:\tlearn: 2.2974012\ttotal: 7m 35s\tremaining: 42.7s\n",
      "21031:\tlearn: 2.2973520\ttotal: 7m 35s\tremaining: 42.6s\n",
      "21032:\tlearn: 2.2972183\ttotal: 7m 35s\tremaining: 42.6s\n",
      "21033:\tlearn: 2.2970878\ttotal: 7m 35s\tremaining: 42.6s\n",
      "21034:\tlearn: 2.2970198\ttotal: 7m 35s\tremaining: 42.6s\n",
      "21035:\tlearn: 2.2969383\ttotal: 7m 35s\tremaining: 42.6s\n",
      "21036:\tlearn: 2.2967915\ttotal: 7m 35s\tremaining: 42.5s\n",
      "21037:\tlearn: 2.2967157\ttotal: 7m 35s\tremaining: 42.5s\n",
      "21038:\tlearn: 2.2966193\ttotal: 7m 35s\tremaining: 42.5s\n",
      "21039:\tlearn: 2.2965612\ttotal: 7m 35s\tremaining: 42.5s\n",
      "21040:\tlearn: 2.2964552\ttotal: 7m 36s\tremaining: 42.5s\n",
      "21041:\tlearn: 2.2963834\ttotal: 7m 36s\tremaining: 42.4s\n",
      "21042:\tlearn: 2.2962738\ttotal: 7m 36s\tremaining: 42.4s\n",
      "21043:\tlearn: 2.2961950\ttotal: 7m 36s\tremaining: 42.4s\n",
      "21044:\tlearn: 2.2961186\ttotal: 7m 36s\tremaining: 42.4s\n",
      "21045:\tlearn: 2.2960711\ttotal: 7m 36s\tremaining: 42.3s\n",
      "21046:\tlearn: 2.2960297\ttotal: 7m 36s\tremaining: 42.3s\n",
      "21047:\tlearn: 2.2959613\ttotal: 7m 36s\tremaining: 42.3s\n",
      "21048:\tlearn: 2.2958835\ttotal: 7m 36s\tremaining: 42.3s\n",
      "21049:\tlearn: 2.2958405\ttotal: 7m 36s\tremaining: 42.3s\n",
      "21050:\tlearn: 2.2957267\ttotal: 7m 36s\tremaining: 42.2s\n",
      "21051:\tlearn: 2.2956390\ttotal: 7m 36s\tremaining: 42.2s\n",
      "21052:\tlearn: 2.2955246\ttotal: 7m 36s\tremaining: 42.2s\n",
      "21053:\tlearn: 2.2955226\ttotal: 7m 36s\tremaining: 42.2s\n",
      "21054:\tlearn: 2.2954201\ttotal: 7m 36s\tremaining: 42.2s\n",
      "21055:\tlearn: 2.2953838\ttotal: 7m 36s\tremaining: 42.1s\n",
      "21056:\tlearn: 2.2953348\ttotal: 7m 36s\tremaining: 42.1s\n",
      "21057:\tlearn: 2.2952599\ttotal: 7m 36s\tremaining: 42.1s\n",
      "21058:\tlearn: 2.2952327\ttotal: 7m 36s\tremaining: 42.1s\n",
      "21059:\tlearn: 2.2951887\ttotal: 7m 36s\tremaining: 42s\n",
      "21060:\tlearn: 2.2950654\ttotal: 7m 36s\tremaining: 42s\n",
      "21061:\tlearn: 2.2950638\ttotal: 7m 36s\tremaining: 42s\n",
      "21062:\tlearn: 2.2949689\ttotal: 7m 36s\tremaining: 42s\n",
      "21063:\tlearn: 2.2948397\ttotal: 7m 36s\tremaining: 42s\n",
      "21064:\tlearn: 2.2947568\ttotal: 7m 36s\tremaining: 41.9s\n",
      "21065:\tlearn: 2.2946438\ttotal: 7m 36s\tremaining: 41.9s\n",
      "21066:\tlearn: 2.2945237\ttotal: 7m 36s\tremaining: 41.9s\n",
      "21067:\tlearn: 2.2944196\ttotal: 7m 36s\tremaining: 41.9s\n",
      "21068:\tlearn: 2.2942858\ttotal: 7m 36s\tremaining: 41.8s\n",
      "21069:\tlearn: 2.2942124\ttotal: 7m 36s\tremaining: 41.8s\n",
      "21070:\tlearn: 2.2941336\ttotal: 7m 36s\tremaining: 41.8s\n",
      "21071:\tlearn: 2.2940749\ttotal: 7m 36s\tremaining: 41.8s\n",
      "21072:\tlearn: 2.2940286\ttotal: 7m 36s\tremaining: 41.8s\n",
      "21073:\tlearn: 2.2939594\ttotal: 7m 36s\tremaining: 41.7s\n",
      "21074:\tlearn: 2.2939304\ttotal: 7m 36s\tremaining: 41.7s\n",
      "21075:\tlearn: 2.2938653\ttotal: 7m 36s\tremaining: 41.7s\n",
      "21076:\tlearn: 2.2938333\ttotal: 7m 36s\tremaining: 41.7s\n",
      "21077:\tlearn: 2.2937709\ttotal: 7m 36s\tremaining: 41.7s\n",
      "21078:\tlearn: 2.2937090\ttotal: 7m 36s\tremaining: 41.6s\n",
      "21079:\tlearn: 2.2936192\ttotal: 7m 36s\tremaining: 41.6s\n",
      "21080:\tlearn: 2.2935110\ttotal: 7m 36s\tremaining: 41.6s\n",
      "21081:\tlearn: 2.2934523\ttotal: 7m 36s\tremaining: 41.6s\n",
      "21082:\tlearn: 2.2933528\ttotal: 7m 36s\tremaining: 41.5s\n",
      "21083:\tlearn: 2.2932866\ttotal: 7m 36s\tremaining: 41.5s\n",
      "21084:\tlearn: 2.2931814\ttotal: 7m 36s\tremaining: 41.5s\n",
      "21085:\tlearn: 2.2930472\ttotal: 7m 36s\tremaining: 41.5s\n",
      "21086:\tlearn: 2.2929764\ttotal: 7m 36s\tremaining: 41.5s\n",
      "21087:\tlearn: 2.2928881\ttotal: 7m 37s\tremaining: 41.4s\n",
      "21088:\tlearn: 2.2927763\ttotal: 7m 37s\tremaining: 41.4s\n",
      "21089:\tlearn: 2.2927154\ttotal: 7m 37s\tremaining: 41.4s\n",
      "21090:\tlearn: 2.2926733\ttotal: 7m 37s\tremaining: 41.4s\n",
      "21091:\tlearn: 2.2925653\ttotal: 7m 37s\tremaining: 41.3s\n",
      "21092:\tlearn: 2.2924822\ttotal: 7m 37s\tremaining: 41.3s\n",
      "21093:\tlearn: 2.2924080\ttotal: 7m 37s\tremaining: 41.3s\n",
      "21094:\tlearn: 2.2923276\ttotal: 7m 37s\tremaining: 41.3s\n",
      "21095:\tlearn: 2.2922095\ttotal: 7m 37s\tremaining: 41.3s\n",
      "21096:\tlearn: 2.2921698\ttotal: 7m 37s\tremaining: 41.2s\n",
      "21097:\tlearn: 2.2921400\ttotal: 7m 37s\tremaining: 41.2s\n",
      "21098:\tlearn: 2.2920916\ttotal: 7m 37s\tremaining: 41.2s\n",
      "21099:\tlearn: 2.2920310\ttotal: 7m 37s\tremaining: 41.2s\n",
      "21100:\tlearn: 2.2919566\ttotal: 7m 37s\tremaining: 41.2s\n",
      "21101:\tlearn: 2.2918830\ttotal: 7m 37s\tremaining: 41.1s\n",
      "21102:\tlearn: 2.2917674\ttotal: 7m 37s\tremaining: 41.1s\n",
      "21103:\tlearn: 2.2916179\ttotal: 7m 37s\tremaining: 41.1s\n",
      "21104:\tlearn: 2.2915496\ttotal: 7m 37s\tremaining: 41.1s\n",
      "21105:\tlearn: 2.2914737\ttotal: 7m 37s\tremaining: 41s\n",
      "21106:\tlearn: 2.2913757\ttotal: 7m 37s\tremaining: 41s\n",
      "21107:\tlearn: 2.2913117\ttotal: 7m 37s\tremaining: 41s\n",
      "21108:\tlearn: 2.2912558\ttotal: 7m 37s\tremaining: 41s\n",
      "21109:\tlearn: 2.2911705\ttotal: 7m 37s\tremaining: 41s\n",
      "21110:\tlearn: 2.2910853\ttotal: 7m 37s\tremaining: 40.9s\n",
      "21111:\tlearn: 2.2909861\ttotal: 7m 37s\tremaining: 40.9s\n",
      "21112:\tlearn: 2.2908982\ttotal: 7m 37s\tremaining: 40.9s\n",
      "21113:\tlearn: 2.2908267\ttotal: 7m 37s\tremaining: 40.9s\n",
      "21114:\tlearn: 2.2907671\ttotal: 7m 37s\tremaining: 40.9s\n",
      "21115:\tlearn: 2.2907088\ttotal: 7m 37s\tremaining: 40.8s\n",
      "21116:\tlearn: 2.2906085\ttotal: 7m 37s\tremaining: 40.8s\n",
      "21117:\tlearn: 2.2905367\ttotal: 7m 37s\tremaining: 40.8s\n",
      "21118:\tlearn: 2.2904737\ttotal: 7m 37s\tremaining: 40.8s\n",
      "21119:\tlearn: 2.2904098\ttotal: 7m 37s\tremaining: 40.7s\n",
      "21120:\tlearn: 2.2903343\ttotal: 7m 37s\tremaining: 40.7s\n",
      "21121:\tlearn: 2.2902180\ttotal: 7m 37s\tremaining: 40.7s\n",
      "21122:\tlearn: 2.2901298\ttotal: 7m 37s\tremaining: 40.7s\n",
      "21123:\tlearn: 2.2900609\ttotal: 7m 37s\tremaining: 40.7s\n",
      "21124:\tlearn: 2.2900244\ttotal: 7m 37s\tremaining: 40.6s\n",
      "21125:\tlearn: 2.2899202\ttotal: 7m 37s\tremaining: 40.6s\n",
      "21126:\tlearn: 2.2898937\ttotal: 7m 37s\tremaining: 40.6s\n",
      "21127:\tlearn: 2.2897753\ttotal: 7m 37s\tremaining: 40.6s\n",
      "21128:\tlearn: 2.2896905\ttotal: 7m 37s\tremaining: 40.5s\n",
      "21129:\tlearn: 2.2896212\ttotal: 7m 37s\tremaining: 40.5s\n",
      "21130:\tlearn: 2.2895513\ttotal: 7m 37s\tremaining: 40.5s\n",
      "21131:\tlearn: 2.2895016\ttotal: 7m 37s\tremaining: 40.5s\n",
      "21132:\tlearn: 2.2894207\ttotal: 7m 37s\tremaining: 40.5s\n",
      "21133:\tlearn: 2.2893791\ttotal: 7m 38s\tremaining: 40.4s\n",
      "21134:\tlearn: 2.2892814\ttotal: 7m 38s\tremaining: 40.4s\n",
      "21135:\tlearn: 2.2892123\ttotal: 7m 38s\tremaining: 40.4s\n",
      "21136:\tlearn: 2.2891436\ttotal: 7m 38s\tremaining: 40.4s\n",
      "21137:\tlearn: 2.2890831\ttotal: 7m 38s\tremaining: 40.4s\n",
      "21138:\tlearn: 2.2889838\ttotal: 7m 38s\tremaining: 40.3s\n",
      "21139:\tlearn: 2.2889328\ttotal: 7m 38s\tremaining: 40.3s\n",
      "21140:\tlearn: 2.2888460\ttotal: 7m 38s\tremaining: 40.3s\n",
      "21141:\tlearn: 2.2887588\ttotal: 7m 38s\tremaining: 40.3s\n",
      "21142:\tlearn: 2.2887253\ttotal: 7m 38s\tremaining: 40.2s\n",
      "21143:\tlearn: 2.2886789\ttotal: 7m 38s\tremaining: 40.2s\n",
      "21144:\tlearn: 2.2885976\ttotal: 7m 38s\tremaining: 40.2s\n",
      "21145:\tlearn: 2.2884810\ttotal: 7m 38s\tremaining: 40.2s\n",
      "21146:\tlearn: 2.2884765\ttotal: 7m 38s\tremaining: 40.2s\n",
      "21147:\tlearn: 2.2884042\ttotal: 7m 38s\tremaining: 40.1s\n",
      "21148:\tlearn: 2.2882993\ttotal: 7m 38s\tremaining: 40.1s\n",
      "21149:\tlearn: 2.2882797\ttotal: 7m 38s\tremaining: 40.1s\n",
      "21150:\tlearn: 2.2881844\ttotal: 7m 38s\tremaining: 40.1s\n",
      "21151:\tlearn: 2.2880124\ttotal: 7m 38s\tremaining: 40s\n",
      "21152:\tlearn: 2.2879436\ttotal: 7m 38s\tremaining: 40s\n",
      "21153:\tlearn: 2.2879119\ttotal: 7m 38s\tremaining: 40s\n",
      "21154:\tlearn: 2.2878235\ttotal: 7m 38s\tremaining: 40s\n",
      "21155:\tlearn: 2.2877635\ttotal: 7m 38s\tremaining: 40s\n",
      "21156:\tlearn: 2.2877346\ttotal: 7m 38s\tremaining: 39.9s\n",
      "21157:\tlearn: 2.2876418\ttotal: 7m 38s\tremaining: 39.9s\n",
      "21158:\tlearn: 2.2875995\ttotal: 7m 38s\tremaining: 39.9s\n",
      "21159:\tlearn: 2.2875716\ttotal: 7m 38s\tremaining: 39.9s\n",
      "21160:\tlearn: 2.2874510\ttotal: 7m 38s\tremaining: 39.9s\n",
      "21161:\tlearn: 2.2873968\ttotal: 7m 38s\tremaining: 39.8s\n",
      "21162:\tlearn: 2.2872936\ttotal: 7m 38s\tremaining: 39.8s\n",
      "21163:\tlearn: 2.2872591\ttotal: 7m 38s\tremaining: 39.8s\n",
      "21164:\tlearn: 2.2871571\ttotal: 7m 38s\tremaining: 39.8s\n",
      "21165:\tlearn: 2.2870328\ttotal: 7m 38s\tremaining: 39.7s\n",
      "21166:\tlearn: 2.2869340\ttotal: 7m 38s\tremaining: 39.7s\n",
      "21167:\tlearn: 2.2869317\ttotal: 7m 38s\tremaining: 39.7s\n",
      "21168:\tlearn: 2.2867735\ttotal: 7m 38s\tremaining: 39.7s\n",
      "21169:\tlearn: 2.2867146\ttotal: 7m 38s\tremaining: 39.7s\n",
      "21170:\tlearn: 2.2866146\ttotal: 7m 38s\tremaining: 39.6s\n",
      "21171:\tlearn: 2.2865736\ttotal: 7m 38s\tremaining: 39.6s\n",
      "21172:\tlearn: 2.2865119\ttotal: 7m 38s\tremaining: 39.6s\n",
      "21173:\tlearn: 2.2864615\ttotal: 7m 38s\tremaining: 39.6s\n",
      "21174:\tlearn: 2.2864032\ttotal: 7m 38s\tremaining: 39.6s\n",
      "21175:\tlearn: 2.2863270\ttotal: 7m 38s\tremaining: 39.5s\n",
      "21176:\tlearn: 2.2861666\ttotal: 7m 38s\tremaining: 39.5s\n",
      "21177:\tlearn: 2.2861070\ttotal: 7m 38s\tremaining: 39.5s\n",
      "21178:\tlearn: 2.2860389\ttotal: 7m 39s\tremaining: 39.5s\n",
      "21179:\tlearn: 2.2858977\ttotal: 7m 39s\tremaining: 39.4s\n",
      "21180:\tlearn: 2.2858454\ttotal: 7m 39s\tremaining: 39.4s\n",
      "21181:\tlearn: 2.2857938\ttotal: 7m 39s\tremaining: 39.4s\n",
      "21182:\tlearn: 2.2856876\ttotal: 7m 39s\tremaining: 39.4s\n",
      "21183:\tlearn: 2.2856401\ttotal: 7m 39s\tremaining: 39.4s\n",
      "21184:\tlearn: 2.2856013\ttotal: 7m 39s\tremaining: 39.3s\n",
      "21185:\tlearn: 2.2854752\ttotal: 7m 39s\tremaining: 39.3s\n",
      "21186:\tlearn: 2.2853911\ttotal: 7m 39s\tremaining: 39.3s\n",
      "21187:\tlearn: 2.2852859\ttotal: 7m 39s\tremaining: 39.3s\n",
      "21188:\tlearn: 2.2852437\ttotal: 7m 39s\tremaining: 39.2s\n",
      "21189:\tlearn: 2.2851723\ttotal: 7m 39s\tremaining: 39.2s\n",
      "21190:\tlearn: 2.2850934\ttotal: 7m 39s\tremaining: 39.2s\n",
      "21191:\tlearn: 2.2850447\ttotal: 7m 39s\tremaining: 39.2s\n",
      "21192:\tlearn: 2.2849406\ttotal: 7m 39s\tremaining: 39.2s\n",
      "21193:\tlearn: 2.2848673\ttotal: 7m 39s\tremaining: 39.1s\n",
      "21194:\tlearn: 2.2847665\ttotal: 7m 39s\tremaining: 39.1s\n",
      "21195:\tlearn: 2.2847212\ttotal: 7m 39s\tremaining: 39.1s\n",
      "21196:\tlearn: 2.2846447\ttotal: 7m 39s\tremaining: 39.1s\n",
      "21197:\tlearn: 2.2845315\ttotal: 7m 39s\tremaining: 39.1s\n",
      "21198:\tlearn: 2.2844835\ttotal: 7m 39s\tremaining: 39s\n",
      "21199:\tlearn: 2.2844215\ttotal: 7m 39s\tremaining: 39s\n",
      "21200:\tlearn: 2.2843395\ttotal: 7m 39s\tremaining: 39s\n",
      "21201:\tlearn: 2.2842639\ttotal: 7m 39s\tremaining: 39s\n",
      "21202:\tlearn: 2.2842357\ttotal: 7m 39s\tremaining: 38.9s\n",
      "21203:\tlearn: 2.2841798\ttotal: 7m 39s\tremaining: 38.9s\n",
      "21204:\tlearn: 2.2841192\ttotal: 7m 39s\tremaining: 38.9s\n",
      "21205:\tlearn: 2.2840802\ttotal: 7m 39s\tremaining: 38.9s\n",
      "21206:\tlearn: 2.2840548\ttotal: 7m 39s\tremaining: 38.9s\n",
      "21207:\tlearn: 2.2839748\ttotal: 7m 39s\tremaining: 38.8s\n",
      "21208:\tlearn: 2.2838954\ttotal: 7m 39s\tremaining: 38.8s\n",
      "21209:\tlearn: 2.2838303\ttotal: 7m 39s\tremaining: 38.8s\n",
      "21210:\tlearn: 2.2837589\ttotal: 7m 39s\tremaining: 38.8s\n",
      "21211:\tlearn: 2.2836661\ttotal: 7m 39s\tremaining: 38.8s\n",
      "21212:\tlearn: 2.2836086\ttotal: 7m 39s\tremaining: 38.7s\n",
      "21213:\tlearn: 2.2835147\ttotal: 7m 39s\tremaining: 38.7s\n",
      "21214:\tlearn: 2.2834548\ttotal: 7m 39s\tremaining: 38.7s\n",
      "21215:\tlearn: 2.2833783\ttotal: 7m 39s\tremaining: 38.7s\n",
      "21216:\tlearn: 2.2833242\ttotal: 7m 39s\tremaining: 38.6s\n",
      "21217:\tlearn: 2.2832624\ttotal: 7m 39s\tremaining: 38.6s\n",
      "21218:\tlearn: 2.2832171\ttotal: 7m 39s\tremaining: 38.6s\n",
      "21219:\tlearn: 2.2831399\ttotal: 7m 39s\tremaining: 38.6s\n",
      "21220:\tlearn: 2.2831103\ttotal: 7m 39s\tremaining: 38.6s\n",
      "21221:\tlearn: 2.2830442\ttotal: 7m 39s\tremaining: 38.5s\n",
      "21222:\tlearn: 2.2829701\ttotal: 7m 40s\tremaining: 38.5s\n",
      "21223:\tlearn: 2.2829094\ttotal: 7m 40s\tremaining: 38.5s\n",
      "21224:\tlearn: 2.2828619\ttotal: 7m 40s\tremaining: 38.5s\n",
      "21225:\tlearn: 2.2827640\ttotal: 7m 40s\tremaining: 38.5s\n",
      "21226:\tlearn: 2.2827119\ttotal: 7m 40s\tremaining: 38.4s\n",
      "21227:\tlearn: 2.2826626\ttotal: 7m 40s\tremaining: 38.4s\n",
      "21228:\tlearn: 2.2826369\ttotal: 7m 40s\tremaining: 38.4s\n",
      "21229:\tlearn: 2.2825598\ttotal: 7m 40s\tremaining: 38.4s\n",
      "21230:\tlearn: 2.2825183\ttotal: 7m 40s\tremaining: 38.3s\n",
      "21231:\tlearn: 2.2824525\ttotal: 7m 40s\tremaining: 38.3s\n",
      "21232:\tlearn: 2.2823356\ttotal: 7m 40s\tremaining: 38.3s\n",
      "21233:\tlearn: 2.2822286\ttotal: 7m 40s\tremaining: 38.3s\n",
      "21234:\tlearn: 2.2821525\ttotal: 7m 40s\tremaining: 38.3s\n",
      "21235:\tlearn: 2.2820867\ttotal: 7m 40s\tremaining: 38.2s\n",
      "21236:\tlearn: 2.2820619\ttotal: 7m 40s\tremaining: 38.2s\n",
      "21237:\tlearn: 2.2819754\ttotal: 7m 40s\tremaining: 38.2s\n",
      "21238:\tlearn: 2.2818788\ttotal: 7m 40s\tremaining: 38.2s\n",
      "21239:\tlearn: 2.2818191\ttotal: 7m 40s\tremaining: 38.2s\n",
      "21240:\tlearn: 2.2817497\ttotal: 7m 40s\tremaining: 38.1s\n",
      "21241:\tlearn: 2.2816335\ttotal: 7m 40s\tremaining: 38.1s\n",
      "21242:\tlearn: 2.2815498\ttotal: 7m 40s\tremaining: 38.1s\n",
      "21243:\tlearn: 2.2814686\ttotal: 7m 40s\tremaining: 38.1s\n",
      "21244:\tlearn: 2.2813844\ttotal: 7m 40s\tremaining: 38s\n",
      "21245:\tlearn: 2.2813695\ttotal: 7m 40s\tremaining: 38s\n",
      "21246:\tlearn: 2.2813122\ttotal: 7m 40s\tremaining: 38s\n",
      "21247:\tlearn: 2.2811837\ttotal: 7m 40s\tremaining: 38s\n",
      "21248:\tlearn: 2.2810915\ttotal: 7m 40s\tremaining: 38s\n",
      "21249:\tlearn: 2.2810208\ttotal: 7m 40s\tremaining: 37.9s\n",
      "21250:\tlearn: 2.2809054\ttotal: 7m 40s\tremaining: 37.9s\n",
      "21251:\tlearn: 2.2808108\ttotal: 7m 40s\tremaining: 37.9s\n",
      "21252:\tlearn: 2.2806967\ttotal: 7m 40s\tremaining: 37.9s\n",
      "21253:\tlearn: 2.2806804\ttotal: 7m 40s\tremaining: 37.8s\n",
      "21254:\tlearn: 2.2806019\ttotal: 7m 40s\tremaining: 37.8s\n",
      "21255:\tlearn: 2.2805472\ttotal: 7m 40s\tremaining: 37.8s\n",
      "21256:\tlearn: 2.2804454\ttotal: 7m 40s\tremaining: 37.8s\n",
      "21257:\tlearn: 2.2803919\ttotal: 7m 40s\tremaining: 37.8s\n",
      "21258:\tlearn: 2.2803324\ttotal: 7m 40s\tremaining: 37.7s\n",
      "21259:\tlearn: 2.2802242\ttotal: 7m 40s\tremaining: 37.7s\n",
      "21260:\tlearn: 2.2801960\ttotal: 7m 40s\tremaining: 37.7s\n",
      "21261:\tlearn: 2.2801237\ttotal: 7m 40s\tremaining: 37.7s\n",
      "21262:\tlearn: 2.2800252\ttotal: 7m 40s\tremaining: 37.7s\n",
      "21263:\tlearn: 2.2799494\ttotal: 7m 40s\tremaining: 37.6s\n",
      "21264:\tlearn: 2.2798767\ttotal: 7m 40s\tremaining: 37.6s\n",
      "21265:\tlearn: 2.2798017\ttotal: 7m 40s\tremaining: 37.6s\n",
      "21266:\tlearn: 2.2797578\ttotal: 7m 41s\tremaining: 37.6s\n",
      "21267:\tlearn: 2.2797024\ttotal: 7m 41s\tremaining: 37.5s\n",
      "21268:\tlearn: 2.2796301\ttotal: 7m 41s\tremaining: 37.5s\n",
      "21269:\tlearn: 2.2795584\ttotal: 7m 41s\tremaining: 37.5s\n",
      "21270:\tlearn: 2.2794691\ttotal: 7m 41s\tremaining: 37.5s\n",
      "21271:\tlearn: 2.2794180\ttotal: 7m 41s\tremaining: 37.5s\n",
      "21272:\tlearn: 2.2793243\ttotal: 7m 41s\tremaining: 37.4s\n",
      "21273:\tlearn: 2.2792769\ttotal: 7m 41s\tremaining: 37.4s\n",
      "21274:\tlearn: 2.2792335\ttotal: 7m 41s\tremaining: 37.4s\n",
      "21275:\tlearn: 2.2791447\ttotal: 7m 41s\tremaining: 37.4s\n",
      "21276:\tlearn: 2.2790442\ttotal: 7m 41s\tremaining: 37.4s\n",
      "21277:\tlearn: 2.2789498\ttotal: 7m 41s\tremaining: 37.3s\n",
      "21278:\tlearn: 2.2788609\ttotal: 7m 41s\tremaining: 37.3s\n",
      "21279:\tlearn: 2.2787386\ttotal: 7m 41s\tremaining: 37.3s\n",
      "21280:\tlearn: 2.2786581\ttotal: 7m 41s\tremaining: 37.3s\n",
      "21281:\tlearn: 2.2785980\ttotal: 7m 41s\tremaining: 37.2s\n",
      "21282:\tlearn: 2.2785094\ttotal: 7m 41s\tremaining: 37.2s\n",
      "21283:\tlearn: 2.2784374\ttotal: 7m 41s\tremaining: 37.2s\n",
      "21284:\tlearn: 2.2783664\ttotal: 7m 41s\tremaining: 37.2s\n",
      "21285:\tlearn: 2.2783155\ttotal: 7m 41s\tremaining: 37.2s\n",
      "21286:\tlearn: 2.2781580\ttotal: 7m 41s\tremaining: 37.1s\n",
      "21287:\tlearn: 2.2780939\ttotal: 7m 41s\tremaining: 37.1s\n",
      "21288:\tlearn: 2.2780292\ttotal: 7m 41s\tremaining: 37.1s\n",
      "21289:\tlearn: 2.2779343\ttotal: 7m 41s\tremaining: 37.1s\n",
      "21290:\tlearn: 2.2777954\ttotal: 7m 41s\tremaining: 37s\n",
      "21291:\tlearn: 2.2776846\ttotal: 7m 41s\tremaining: 37s\n",
      "21292:\tlearn: 2.2776292\ttotal: 7m 41s\tremaining: 37s\n",
      "21293:\tlearn: 2.2775270\ttotal: 7m 41s\tremaining: 37s\n",
      "21294:\tlearn: 2.2774555\ttotal: 7m 41s\tremaining: 37s\n",
      "21295:\tlearn: 2.2773564\ttotal: 7m 41s\tremaining: 36.9s\n",
      "21296:\tlearn: 2.2772940\ttotal: 7m 41s\tremaining: 36.9s\n",
      "21297:\tlearn: 2.2772209\ttotal: 7m 41s\tremaining: 36.9s\n",
      "21298:\tlearn: 2.2771986\ttotal: 7m 41s\tremaining: 36.9s\n",
      "21299:\tlearn: 2.2771448\ttotal: 7m 41s\tremaining: 36.9s\n",
      "21300:\tlearn: 2.2770659\ttotal: 7m 41s\tremaining: 36.8s\n",
      "21301:\tlearn: 2.2769850\ttotal: 7m 41s\tremaining: 36.8s\n",
      "21302:\tlearn: 2.2768393\ttotal: 7m 41s\tremaining: 36.8s\n",
      "21303:\tlearn: 2.2767461\ttotal: 7m 41s\tremaining: 36.8s\n",
      "21304:\tlearn: 2.2766496\ttotal: 7m 41s\tremaining: 36.7s\n",
      "21305:\tlearn: 2.2765700\ttotal: 7m 41s\tremaining: 36.7s\n",
      "21306:\tlearn: 2.2764581\ttotal: 7m 41s\tremaining: 36.7s\n",
      "21307:\tlearn: 2.2764106\ttotal: 7m 41s\tremaining: 36.7s\n",
      "21308:\tlearn: 2.2763079\ttotal: 7m 41s\tremaining: 36.7s\n",
      "21309:\tlearn: 2.2762618\ttotal: 7m 42s\tremaining: 36.6s\n",
      "21310:\tlearn: 2.2761823\ttotal: 7m 42s\tremaining: 36.6s\n",
      "21311:\tlearn: 2.2760954\ttotal: 7m 42s\tremaining: 36.6s\n",
      "21312:\tlearn: 2.2760117\ttotal: 7m 42s\tremaining: 36.6s\n",
      "21313:\tlearn: 2.2758848\ttotal: 7m 42s\tremaining: 36.6s\n",
      "21314:\tlearn: 2.2758037\ttotal: 7m 42s\tremaining: 36.5s\n",
      "21315:\tlearn: 2.2757316\ttotal: 7m 42s\tremaining: 36.5s\n",
      "21316:\tlearn: 2.2756128\ttotal: 7m 42s\tremaining: 36.5s\n",
      "21317:\tlearn: 2.2755081\ttotal: 7m 42s\tremaining: 36.5s\n",
      "21318:\tlearn: 2.2754882\ttotal: 7m 42s\tremaining: 36.4s\n",
      "21319:\tlearn: 2.2754412\ttotal: 7m 42s\tremaining: 36.4s\n",
      "21320:\tlearn: 2.2753728\ttotal: 7m 42s\tremaining: 36.4s\n",
      "21321:\tlearn: 2.2753069\ttotal: 7m 42s\tremaining: 36.4s\n",
      "21322:\tlearn: 2.2752073\ttotal: 7m 42s\tremaining: 36.4s\n",
      "21323:\tlearn: 2.2751232\ttotal: 7m 42s\tremaining: 36.3s\n",
      "21324:\tlearn: 2.2750521\ttotal: 7m 42s\tremaining: 36.3s\n",
      "21325:\tlearn: 2.2750088\ttotal: 7m 42s\tremaining: 36.3s\n",
      "21326:\tlearn: 2.2748780\ttotal: 7m 42s\tremaining: 36.3s\n",
      "21327:\tlearn: 2.2748125\ttotal: 7m 42s\tremaining: 36.3s\n",
      "21328:\tlearn: 2.2747093\ttotal: 7m 42s\tremaining: 36.2s\n",
      "21329:\tlearn: 2.2746461\ttotal: 7m 42s\tremaining: 36.2s\n",
      "21330:\tlearn: 2.2745447\ttotal: 7m 42s\tremaining: 36.2s\n",
      "21331:\tlearn: 2.2744764\ttotal: 7m 42s\tremaining: 36.2s\n",
      "21332:\tlearn: 2.2744225\ttotal: 7m 42s\tremaining: 36.1s\n",
      "21333:\tlearn: 2.2743255\ttotal: 7m 42s\tremaining: 36.1s\n",
      "21334:\tlearn: 2.2741909\ttotal: 7m 42s\tremaining: 36.1s\n",
      "21335:\tlearn: 2.2741215\ttotal: 7m 42s\tremaining: 36.1s\n",
      "21336:\tlearn: 2.2740308\ttotal: 7m 42s\tremaining: 36.1s\n",
      "21337:\tlearn: 2.2739182\ttotal: 7m 42s\tremaining: 36s\n",
      "21338:\tlearn: 2.2738727\ttotal: 7m 42s\tremaining: 36s\n",
      "21339:\tlearn: 2.2737906\ttotal: 7m 42s\tremaining: 36s\n",
      "21340:\tlearn: 2.2737022\ttotal: 7m 42s\tremaining: 36s\n",
      "21341:\tlearn: 2.2736308\ttotal: 7m 42s\tremaining: 35.9s\n",
      "21342:\tlearn: 2.2735350\ttotal: 7m 42s\tremaining: 35.9s\n",
      "21343:\tlearn: 2.2734205\ttotal: 7m 42s\tremaining: 35.9s\n",
      "21344:\tlearn: 2.2733569\ttotal: 7m 42s\tremaining: 35.9s\n",
      "21345:\tlearn: 2.2732764\ttotal: 7m 42s\tremaining: 35.9s\n",
      "21346:\tlearn: 2.2732469\ttotal: 7m 42s\tremaining: 35.8s\n",
      "21347:\tlearn: 2.2731404\ttotal: 7m 42s\tremaining: 35.8s\n",
      "21348:\tlearn: 2.2730717\ttotal: 7m 42s\tremaining: 35.8s\n",
      "21349:\tlearn: 2.2729790\ttotal: 7m 42s\tremaining: 35.8s\n",
      "21350:\tlearn: 2.2728842\ttotal: 7m 42s\tremaining: 35.8s\n",
      "21351:\tlearn: 2.2728419\ttotal: 7m 42s\tremaining: 35.7s\n",
      "21352:\tlearn: 2.2727788\ttotal: 7m 42s\tremaining: 35.7s\n",
      "21353:\tlearn: 2.2727185\ttotal: 7m 42s\tremaining: 35.7s\n",
      "21354:\tlearn: 2.2726528\ttotal: 7m 42s\tremaining: 35.7s\n",
      "21355:\tlearn: 2.2726223\ttotal: 7m 43s\tremaining: 35.6s\n",
      "21356:\tlearn: 2.2725391\ttotal: 7m 43s\tremaining: 35.6s\n",
      "21357:\tlearn: 2.2724645\ttotal: 7m 43s\tremaining: 35.6s\n",
      "21358:\tlearn: 2.2724052\ttotal: 7m 43s\tremaining: 35.6s\n",
      "21359:\tlearn: 2.2722812\ttotal: 7m 43s\tremaining: 35.6s\n",
      "21360:\tlearn: 2.2722300\ttotal: 7m 43s\tremaining: 35.5s\n",
      "21361:\tlearn: 2.2721316\ttotal: 7m 43s\tremaining: 35.5s\n",
      "21362:\tlearn: 2.2720129\ttotal: 7m 43s\tremaining: 35.5s\n",
      "21363:\tlearn: 2.2719321\ttotal: 7m 43s\tremaining: 35.5s\n",
      "21364:\tlearn: 2.2718359\ttotal: 7m 43s\tremaining: 35.4s\n",
      "21365:\tlearn: 2.2717479\ttotal: 7m 43s\tremaining: 35.4s\n",
      "21366:\tlearn: 2.2716635\ttotal: 7m 43s\tremaining: 35.4s\n",
      "21367:\tlearn: 2.2715870\ttotal: 7m 43s\tremaining: 35.4s\n",
      "21368:\tlearn: 2.2714976\ttotal: 7m 43s\tremaining: 35.4s\n",
      "21369:\tlearn: 2.2714819\ttotal: 7m 43s\tremaining: 35.3s\n",
      "21370:\tlearn: 2.2713575\ttotal: 7m 43s\tremaining: 35.3s\n",
      "21371:\tlearn: 2.2712616\ttotal: 7m 43s\tremaining: 35.3s\n",
      "21372:\tlearn: 2.2712236\ttotal: 7m 43s\tremaining: 35.3s\n",
      "21373:\tlearn: 2.2711882\ttotal: 7m 43s\tremaining: 35.3s\n",
      "21374:\tlearn: 2.2710794\ttotal: 7m 43s\tremaining: 35.2s\n",
      "21375:\tlearn: 2.2709805\ttotal: 7m 43s\tremaining: 35.2s\n",
      "21376:\tlearn: 2.2709127\ttotal: 7m 43s\tremaining: 35.2s\n",
      "21377:\tlearn: 2.2708632\ttotal: 7m 43s\tremaining: 35.2s\n",
      "21378:\tlearn: 2.2707815\ttotal: 7m 43s\tremaining: 35.1s\n",
      "21379:\tlearn: 2.2707560\ttotal: 7m 43s\tremaining: 35.1s\n",
      "21380:\tlearn: 2.2706843\ttotal: 7m 43s\tremaining: 35.1s\n",
      "21381:\tlearn: 2.2705840\ttotal: 7m 43s\tremaining: 35.1s\n",
      "21382:\tlearn: 2.2705212\ttotal: 7m 43s\tremaining: 35.1s\n",
      "21383:\tlearn: 2.2704677\ttotal: 7m 43s\tremaining: 35s\n",
      "21384:\tlearn: 2.2703195\ttotal: 7m 43s\tremaining: 35s\n",
      "21385:\tlearn: 2.2702469\ttotal: 7m 43s\tremaining: 35s\n",
      "21386:\tlearn: 2.2701586\ttotal: 7m 43s\tremaining: 35s\n",
      "21387:\tlearn: 2.2700760\ttotal: 7m 43s\tremaining: 35s\n",
      "21388:\tlearn: 2.2700305\ttotal: 7m 43s\tremaining: 34.9s\n",
      "21389:\tlearn: 2.2699781\ttotal: 7m 43s\tremaining: 34.9s\n",
      "21390:\tlearn: 2.2698653\ttotal: 7m 43s\tremaining: 34.9s\n",
      "21391:\tlearn: 2.2697689\ttotal: 7m 43s\tremaining: 34.9s\n",
      "21392:\tlearn: 2.2696830\ttotal: 7m 43s\tremaining: 34.8s\n",
      "21393:\tlearn: 2.2696313\ttotal: 7m 43s\tremaining: 34.8s\n",
      "21394:\tlearn: 2.2695424\ttotal: 7m 43s\tremaining: 34.8s\n",
      "21395:\tlearn: 2.2694563\ttotal: 7m 43s\tremaining: 34.8s\n",
      "21396:\tlearn: 2.2694177\ttotal: 7m 44s\tremaining: 34.8s\n",
      "21397:\tlearn: 2.2693330\ttotal: 7m 44s\tremaining: 34.7s\n",
      "21398:\tlearn: 2.2692699\ttotal: 7m 44s\tremaining: 34.7s\n",
      "21399:\tlearn: 2.2691472\ttotal: 7m 44s\tremaining: 34.7s\n",
      "21400:\tlearn: 2.2690715\ttotal: 7m 44s\tremaining: 34.7s\n",
      "21401:\tlearn: 2.2689956\ttotal: 7m 44s\tremaining: 34.7s\n",
      "21402:\tlearn: 2.2689184\ttotal: 7m 44s\tremaining: 34.6s\n",
      "21403:\tlearn: 2.2688182\ttotal: 7m 44s\tremaining: 34.6s\n",
      "21404:\tlearn: 2.2687139\ttotal: 7m 44s\tremaining: 34.6s\n",
      "21405:\tlearn: 2.2686321\ttotal: 7m 44s\tremaining: 34.6s\n",
      "21406:\tlearn: 2.2685396\ttotal: 7m 44s\tremaining: 34.5s\n",
      "21407:\tlearn: 2.2684513\ttotal: 7m 44s\tremaining: 34.5s\n",
      "21408:\tlearn: 2.2684002\ttotal: 7m 44s\tremaining: 34.5s\n",
      "21409:\tlearn: 2.2683691\ttotal: 7m 44s\tremaining: 34.5s\n",
      "21410:\tlearn: 2.2682478\ttotal: 7m 44s\tremaining: 34.5s\n",
      "21411:\tlearn: 2.2682301\ttotal: 7m 44s\tremaining: 34.4s\n",
      "21412:\tlearn: 2.2680707\ttotal: 7m 44s\tremaining: 34.4s\n",
      "21413:\tlearn: 2.2679890\ttotal: 7m 44s\tremaining: 34.4s\n",
      "21414:\tlearn: 2.2679112\ttotal: 7m 44s\tremaining: 34.4s\n",
      "21415:\tlearn: 2.2678091\ttotal: 7m 44s\tremaining: 34.4s\n",
      "21416:\tlearn: 2.2677376\ttotal: 7m 44s\tremaining: 34.3s\n",
      "21417:\tlearn: 2.2676107\ttotal: 7m 44s\tremaining: 34.3s\n",
      "21418:\tlearn: 2.2675451\ttotal: 7m 44s\tremaining: 34.3s\n",
      "21419:\tlearn: 2.2675059\ttotal: 7m 44s\tremaining: 34.3s\n",
      "21420:\tlearn: 2.2673839\ttotal: 7m 44s\tremaining: 34.2s\n",
      "21421:\tlearn: 2.2673587\ttotal: 7m 44s\tremaining: 34.2s\n",
      "21422:\tlearn: 2.2672486\ttotal: 7m 44s\tremaining: 34.2s\n",
      "21423:\tlearn: 2.2671414\ttotal: 7m 44s\tremaining: 34.2s\n",
      "21424:\tlearn: 2.2670766\ttotal: 7m 44s\tremaining: 34.2s\n",
      "21425:\tlearn: 2.2670131\ttotal: 7m 44s\tremaining: 34.1s\n",
      "21426:\tlearn: 2.2669113\ttotal: 7m 44s\tremaining: 34.1s\n",
      "21427:\tlearn: 2.2668245\ttotal: 7m 44s\tremaining: 34.1s\n",
      "21428:\tlearn: 2.2667208\ttotal: 7m 44s\tremaining: 34.1s\n",
      "21429:\tlearn: 2.2666208\ttotal: 7m 44s\tremaining: 34.1s\n",
      "21430:\tlearn: 2.2665258\ttotal: 7m 44s\tremaining: 34s\n",
      "21431:\tlearn: 2.2664828\ttotal: 7m 44s\tremaining: 34s\n",
      "21432:\tlearn: 2.2664133\ttotal: 7m 44s\tremaining: 34s\n",
      "21433:\tlearn: 2.2663761\ttotal: 7m 44s\tremaining: 34s\n",
      "21434:\tlearn: 2.2662689\ttotal: 7m 44s\tremaining: 33.9s\n",
      "21435:\tlearn: 2.2662084\ttotal: 7m 44s\tremaining: 33.9s\n",
      "21436:\tlearn: 2.2661549\ttotal: 7m 44s\tremaining: 33.9s\n",
      "21437:\tlearn: 2.2660734\ttotal: 7m 44s\tremaining: 33.9s\n",
      "21438:\tlearn: 2.2660368\ttotal: 7m 45s\tremaining: 33.9s\n",
      "21439:\tlearn: 2.2659941\ttotal: 7m 45s\tremaining: 33.8s\n",
      "21440:\tlearn: 2.2659272\ttotal: 7m 45s\tremaining: 33.8s\n",
      "21441:\tlearn: 2.2658374\ttotal: 7m 45s\tremaining: 33.8s\n",
      "21442:\tlearn: 2.2657406\ttotal: 7m 45s\tremaining: 33.8s\n",
      "21443:\tlearn: 2.2656884\ttotal: 7m 45s\tremaining: 33.8s\n",
      "21444:\tlearn: 2.2656817\ttotal: 7m 45s\tremaining: 33.7s\n",
      "21445:\tlearn: 2.2656308\ttotal: 7m 45s\tremaining: 33.7s\n",
      "21446:\tlearn: 2.2656152\ttotal: 7m 45s\tremaining: 33.7s\n",
      "21447:\tlearn: 2.2655391\ttotal: 7m 45s\tremaining: 33.7s\n",
      "21448:\tlearn: 2.2654672\ttotal: 7m 45s\tremaining: 33.6s\n",
      "21449:\tlearn: 2.2653482\ttotal: 7m 45s\tremaining: 33.6s\n",
      "21450:\tlearn: 2.2653136\ttotal: 7m 45s\tremaining: 33.6s\n",
      "21451:\tlearn: 2.2652207\ttotal: 7m 45s\tremaining: 33.6s\n",
      "21452:\tlearn: 2.2651697\ttotal: 7m 45s\tremaining: 33.6s\n",
      "21453:\tlearn: 2.2650678\ttotal: 7m 45s\tremaining: 33.5s\n",
      "21454:\tlearn: 2.2650054\ttotal: 7m 45s\tremaining: 33.5s\n",
      "21455:\tlearn: 2.2649154\ttotal: 7m 45s\tremaining: 33.5s\n",
      "21456:\tlearn: 2.2648451\ttotal: 7m 45s\tremaining: 33.5s\n",
      "21457:\tlearn: 2.2647215\ttotal: 7m 45s\tremaining: 33.4s\n",
      "21458:\tlearn: 2.2646394\ttotal: 7m 45s\tremaining: 33.4s\n",
      "21459:\tlearn: 2.2645839\ttotal: 7m 45s\tremaining: 33.4s\n",
      "21460:\tlearn: 2.2645471\ttotal: 7m 45s\tremaining: 33.4s\n",
      "21461:\tlearn: 2.2644886\ttotal: 7m 45s\tremaining: 33.4s\n",
      "21462:\tlearn: 2.2644392\ttotal: 7m 45s\tremaining: 33.3s\n",
      "21463:\tlearn: 2.2643591\ttotal: 7m 45s\tremaining: 33.3s\n",
      "21464:\tlearn: 2.2643168\ttotal: 7m 45s\tremaining: 33.3s\n",
      "21465:\tlearn: 2.2642143\ttotal: 7m 45s\tremaining: 33.3s\n",
      "21466:\tlearn: 2.2641234\ttotal: 7m 45s\tremaining: 33.3s\n",
      "21467:\tlearn: 2.2640398\ttotal: 7m 45s\tremaining: 33.2s\n",
      "21468:\tlearn: 2.2640381\ttotal: 7m 45s\tremaining: 33.2s\n",
      "21469:\tlearn: 2.2640086\ttotal: 7m 45s\tremaining: 33.2s\n",
      "21470:\tlearn: 2.2639303\ttotal: 7m 45s\tremaining: 33.2s\n",
      "21471:\tlearn: 2.2638378\ttotal: 7m 45s\tremaining: 33.1s\n",
      "21472:\tlearn: 2.2637074\ttotal: 7m 45s\tremaining: 33.1s\n",
      "21473:\tlearn: 2.2636199\ttotal: 7m 45s\tremaining: 33.1s\n",
      "21474:\tlearn: 2.2636121\ttotal: 7m 45s\tremaining: 33.1s\n",
      "21475:\tlearn: 2.2635857\ttotal: 7m 45s\tremaining: 33.1s\n",
      "21476:\tlearn: 2.2634353\ttotal: 7m 45s\tremaining: 33s\n",
      "21477:\tlearn: 2.2634255\ttotal: 7m 45s\tremaining: 33s\n",
      "21478:\tlearn: 2.2633302\ttotal: 7m 45s\tremaining: 33s\n",
      "21479:\tlearn: 2.2632748\ttotal: 7m 45s\tremaining: 33s\n",
      "21480:\tlearn: 2.2631929\ttotal: 7m 45s\tremaining: 33s\n",
      "21481:\tlearn: 2.2631583\ttotal: 7m 46s\tremaining: 32.9s\n",
      "21482:\tlearn: 2.2631231\ttotal: 7m 46s\tremaining: 32.9s\n",
      "21483:\tlearn: 2.2630686\ttotal: 7m 46s\tremaining: 32.9s\n",
      "21484:\tlearn: 2.2630231\ttotal: 7m 46s\tremaining: 32.9s\n",
      "21485:\tlearn: 2.2629763\ttotal: 7m 46s\tremaining: 32.8s\n",
      "21486:\tlearn: 2.2628771\ttotal: 7m 46s\tremaining: 32.8s\n",
      "21487:\tlearn: 2.2628624\ttotal: 7m 46s\tremaining: 32.8s\n",
      "21488:\tlearn: 2.2627852\ttotal: 7m 46s\tremaining: 32.8s\n",
      "21489:\tlearn: 2.2626934\ttotal: 7m 46s\tremaining: 32.8s\n",
      "21490:\tlearn: 2.2625488\ttotal: 7m 46s\tremaining: 32.7s\n",
      "21491:\tlearn: 2.2625077\ttotal: 7m 46s\tremaining: 32.7s\n",
      "21492:\tlearn: 2.2624506\ttotal: 7m 46s\tremaining: 32.7s\n",
      "21493:\tlearn: 2.2623799\ttotal: 7m 46s\tremaining: 32.7s\n",
      "21494:\tlearn: 2.2623322\ttotal: 7m 46s\tremaining: 32.6s\n",
      "21495:\tlearn: 2.2623004\ttotal: 7m 46s\tremaining: 32.6s\n",
      "21496:\tlearn: 2.2622247\ttotal: 7m 46s\tremaining: 32.6s\n",
      "21497:\tlearn: 2.2621345\ttotal: 7m 46s\tremaining: 32.6s\n",
      "21498:\tlearn: 2.2620585\ttotal: 7m 46s\tremaining: 32.6s\n",
      "21499:\tlearn: 2.2620263\ttotal: 7m 46s\tremaining: 32.5s\n",
      "21500:\tlearn: 2.2619776\ttotal: 7m 46s\tremaining: 32.5s\n",
      "21501:\tlearn: 2.2618991\ttotal: 7m 46s\tremaining: 32.5s\n",
      "21502:\tlearn: 2.2617942\ttotal: 7m 46s\tremaining: 32.5s\n",
      "21503:\tlearn: 2.2617163\ttotal: 7m 46s\tremaining: 32.5s\n",
      "21504:\tlearn: 2.2616511\ttotal: 7m 46s\tremaining: 32.4s\n",
      "21505:\tlearn: 2.2615748\ttotal: 7m 46s\tremaining: 32.4s\n",
      "21506:\tlearn: 2.2615345\ttotal: 7m 46s\tremaining: 32.4s\n",
      "21507:\tlearn: 2.2614538\ttotal: 7m 46s\tremaining: 32.4s\n",
      "21508:\tlearn: 2.2613849\ttotal: 7m 46s\tremaining: 32.3s\n",
      "21509:\tlearn: 2.2612931\ttotal: 7m 46s\tremaining: 32.3s\n",
      "21510:\tlearn: 2.2611661\ttotal: 7m 46s\tremaining: 32.3s\n",
      "21511:\tlearn: 2.2610935\ttotal: 7m 46s\tremaining: 32.3s\n",
      "21512:\tlearn: 2.2610380\ttotal: 7m 46s\tremaining: 32.3s\n",
      "21513:\tlearn: 2.2609664\ttotal: 7m 46s\tremaining: 32.2s\n",
      "21514:\tlearn: 2.2608945\ttotal: 7m 46s\tremaining: 32.2s\n",
      "21515:\tlearn: 2.2607931\ttotal: 7m 46s\tremaining: 32.2s\n",
      "21516:\tlearn: 2.2606233\ttotal: 7m 46s\tremaining: 32.2s\n",
      "21517:\tlearn: 2.2605651\ttotal: 7m 46s\tremaining: 32.1s\n",
      "21518:\tlearn: 2.2605085\ttotal: 7m 46s\tremaining: 32.1s\n",
      "21519:\tlearn: 2.2605075\ttotal: 7m 46s\tremaining: 32.1s\n",
      "21520:\tlearn: 2.2604384\ttotal: 7m 46s\tremaining: 32.1s\n",
      "21521:\tlearn: 2.2603526\ttotal: 7m 46s\tremaining: 32.1s\n",
      "21522:\tlearn: 2.2602547\ttotal: 7m 46s\tremaining: 32s\n",
      "21523:\tlearn: 2.2602155\ttotal: 7m 46s\tremaining: 32s\n",
      "21524:\tlearn: 2.2601300\ttotal: 7m 46s\tremaining: 32s\n",
      "21525:\tlearn: 2.2600148\ttotal: 7m 46s\tremaining: 32s\n",
      "21526:\tlearn: 2.2599118\ttotal: 7m 47s\tremaining: 32s\n",
      "21527:\tlearn: 2.2598059\ttotal: 7m 47s\tremaining: 31.9s\n",
      "21528:\tlearn: 2.2597529\ttotal: 7m 47s\tremaining: 31.9s\n",
      "21529:\tlearn: 2.2596792\ttotal: 7m 47s\tremaining: 31.9s\n",
      "21530:\tlearn: 2.2595552\ttotal: 7m 47s\tremaining: 31.9s\n",
      "21531:\tlearn: 2.2594814\ttotal: 7m 47s\tremaining: 31.8s\n",
      "21532:\tlearn: 2.2594341\ttotal: 7m 47s\tremaining: 31.8s\n",
      "21533:\tlearn: 2.2593519\ttotal: 7m 47s\tremaining: 31.8s\n",
      "21534:\tlearn: 2.2592909\ttotal: 7m 47s\tremaining: 31.8s\n",
      "21535:\tlearn: 2.2592123\ttotal: 7m 47s\tremaining: 31.8s\n",
      "21536:\tlearn: 2.2590994\ttotal: 7m 47s\tremaining: 31.7s\n",
      "21537:\tlearn: 2.2590500\ttotal: 7m 47s\tremaining: 31.7s\n",
      "21538:\tlearn: 2.2589860\ttotal: 7m 47s\tremaining: 31.7s\n",
      "21539:\tlearn: 2.2589350\ttotal: 7m 47s\tremaining: 31.7s\n",
      "21540:\tlearn: 2.2588395\ttotal: 7m 47s\tremaining: 31.7s\n",
      "21541:\tlearn: 2.2587978\ttotal: 7m 47s\tremaining: 31.6s\n",
      "21542:\tlearn: 2.2586714\ttotal: 7m 47s\tremaining: 31.6s\n",
      "21543:\tlearn: 2.2586385\ttotal: 7m 47s\tremaining: 31.6s\n",
      "21544:\tlearn: 2.2585547\ttotal: 7m 47s\tremaining: 31.6s\n",
      "21545:\tlearn: 2.2584831\ttotal: 7m 47s\tremaining: 31.5s\n",
      "21546:\tlearn: 2.2584486\ttotal: 7m 47s\tremaining: 31.5s\n",
      "21547:\tlearn: 2.2583193\ttotal: 7m 47s\tremaining: 31.5s\n",
      "21548:\tlearn: 2.2582654\ttotal: 7m 47s\tremaining: 31.5s\n",
      "21549:\tlearn: 2.2581799\ttotal: 7m 47s\tremaining: 31.5s\n",
      "21550:\tlearn: 2.2580374\ttotal: 7m 47s\tremaining: 31.4s\n",
      "21551:\tlearn: 2.2579801\ttotal: 7m 47s\tremaining: 31.4s\n",
      "21552:\tlearn: 2.2579029\ttotal: 7m 47s\tremaining: 31.4s\n",
      "21553:\tlearn: 2.2578317\ttotal: 7m 47s\tremaining: 31.4s\n",
      "21554:\tlearn: 2.2577584\ttotal: 7m 47s\tremaining: 31.3s\n",
      "21555:\tlearn: 2.2577148\ttotal: 7m 47s\tremaining: 31.3s\n",
      "21556:\tlearn: 2.2576207\ttotal: 7m 47s\tremaining: 31.3s\n",
      "21557:\tlearn: 2.2575632\ttotal: 7m 47s\tremaining: 31.3s\n",
      "21558:\tlearn: 2.2575119\ttotal: 7m 47s\tremaining: 31.3s\n",
      "21559:\tlearn: 2.2574667\ttotal: 7m 47s\tremaining: 31.2s\n",
      "21560:\tlearn: 2.2573893\ttotal: 7m 47s\tremaining: 31.2s\n",
      "21561:\tlearn: 2.2573355\ttotal: 7m 47s\tremaining: 31.2s\n",
      "21562:\tlearn: 2.2572473\ttotal: 7m 47s\tremaining: 31.2s\n",
      "21563:\tlearn: 2.2571513\ttotal: 7m 47s\tremaining: 31.2s\n",
      "21564:\tlearn: 2.2570827\ttotal: 7m 47s\tremaining: 31.1s\n",
      "21565:\tlearn: 2.2570254\ttotal: 7m 47s\tremaining: 31.1s\n",
      "21566:\tlearn: 2.2569392\ttotal: 7m 47s\tremaining: 31.1s\n",
      "21567:\tlearn: 2.2568878\ttotal: 7m 47s\tremaining: 31.1s\n",
      "21568:\tlearn: 2.2568520\ttotal: 7m 47s\tremaining: 31s\n",
      "21569:\tlearn: 2.2567903\ttotal: 7m 47s\tremaining: 31s\n",
      "21570:\tlearn: 2.2567353\ttotal: 7m 47s\tremaining: 31s\n",
      "21571:\tlearn: 2.2566654\ttotal: 7m 47s\tremaining: 31s\n",
      "21572:\tlearn: 2.2565239\ttotal: 7m 47s\tremaining: 31s\n",
      "21573:\tlearn: 2.2564228\ttotal: 7m 48s\tremaining: 30.9s\n",
      "21574:\tlearn: 2.2563260\ttotal: 7m 48s\tremaining: 30.9s\n",
      "21575:\tlearn: 2.2562289\ttotal: 7m 48s\tremaining: 30.9s\n",
      "21576:\tlearn: 2.2561079\ttotal: 7m 48s\tremaining: 30.9s\n",
      "21577:\tlearn: 2.2561072\ttotal: 7m 48s\tremaining: 30.8s\n",
      "21578:\tlearn: 2.2560247\ttotal: 7m 48s\tremaining: 30.8s\n",
      "21579:\tlearn: 2.2560082\ttotal: 7m 48s\tremaining: 30.8s\n",
      "21580:\tlearn: 2.2559480\ttotal: 7m 48s\tremaining: 30.8s\n",
      "21581:\tlearn: 2.2558567\ttotal: 7m 48s\tremaining: 30.8s\n",
      "21582:\tlearn: 2.2558243\ttotal: 7m 48s\tremaining: 30.7s\n",
      "21583:\tlearn: 2.2557326\ttotal: 7m 48s\tremaining: 30.7s\n",
      "21584:\tlearn: 2.2556863\ttotal: 7m 48s\tremaining: 30.7s\n",
      "21585:\tlearn: 2.2556528\ttotal: 7m 48s\tremaining: 30.7s\n",
      "21586:\tlearn: 2.2555613\ttotal: 7m 48s\tremaining: 30.7s\n",
      "21587:\tlearn: 2.2555239\ttotal: 7m 48s\tremaining: 30.6s\n",
      "21588:\tlearn: 2.2554862\ttotal: 7m 48s\tremaining: 30.6s\n",
      "21589:\tlearn: 2.2554371\ttotal: 7m 48s\tremaining: 30.6s\n",
      "21590:\tlearn: 2.2553443\ttotal: 7m 48s\tremaining: 30.6s\n",
      "21591:\tlearn: 2.2553001\ttotal: 7m 48s\tremaining: 30.5s\n",
      "21592:\tlearn: 2.2552372\ttotal: 7m 48s\tremaining: 30.5s\n",
      "21593:\tlearn: 2.2551296\ttotal: 7m 48s\tremaining: 30.5s\n",
      "21594:\tlearn: 2.2550472\ttotal: 7m 48s\tremaining: 30.5s\n",
      "21595:\tlearn: 2.2550069\ttotal: 7m 48s\tremaining: 30.5s\n",
      "21596:\tlearn: 2.2548481\ttotal: 7m 48s\tremaining: 30.4s\n",
      "21597:\tlearn: 2.2547765\ttotal: 7m 48s\tremaining: 30.4s\n",
      "21598:\tlearn: 2.2547128\ttotal: 7m 48s\tremaining: 30.4s\n",
      "21599:\tlearn: 2.2546515\ttotal: 7m 48s\tremaining: 30.4s\n",
      "21600:\tlearn: 2.2545468\ttotal: 7m 48s\tremaining: 30.3s\n",
      "21601:\tlearn: 2.2544812\ttotal: 7m 48s\tremaining: 30.3s\n",
      "21602:\tlearn: 2.2543924\ttotal: 7m 48s\tremaining: 30.3s\n",
      "21603:\tlearn: 2.2542870\ttotal: 7m 48s\tremaining: 30.3s\n",
      "21604:\tlearn: 2.2542411\ttotal: 7m 48s\tremaining: 30.3s\n",
      "21605:\tlearn: 2.2541911\ttotal: 7m 48s\tremaining: 30.2s\n",
      "21606:\tlearn: 2.2540996\ttotal: 7m 48s\tremaining: 30.2s\n",
      "21607:\tlearn: 2.2540656\ttotal: 7m 48s\tremaining: 30.2s\n",
      "21608:\tlearn: 2.2540142\ttotal: 7m 48s\tremaining: 30.2s\n",
      "21609:\tlearn: 2.2539161\ttotal: 7m 48s\tremaining: 30.2s\n",
      "21610:\tlearn: 2.2538151\ttotal: 7m 48s\tremaining: 30.1s\n",
      "21611:\tlearn: 2.2537708\ttotal: 7m 48s\tremaining: 30.1s\n",
      "21612:\tlearn: 2.2537298\ttotal: 7m 48s\tremaining: 30.1s\n",
      "21613:\tlearn: 2.2535922\ttotal: 7m 48s\tremaining: 30.1s\n",
      "21614:\tlearn: 2.2534962\ttotal: 7m 48s\tremaining: 30s\n",
      "21615:\tlearn: 2.2533776\ttotal: 7m 48s\tremaining: 30s\n",
      "21616:\tlearn: 2.2532710\ttotal: 7m 48s\tremaining: 30s\n",
      "21617:\tlearn: 2.2532055\ttotal: 7m 48s\tremaining: 30s\n",
      "21618:\tlearn: 2.2530567\ttotal: 7m 48s\tremaining: 30s\n",
      "21619:\tlearn: 2.2529328\ttotal: 7m 49s\tremaining: 29.9s\n",
      "21620:\tlearn: 2.2528237\ttotal: 7m 49s\tremaining: 29.9s\n",
      "21621:\tlearn: 2.2527457\ttotal: 7m 49s\tremaining: 29.9s\n",
      "21622:\tlearn: 2.2526156\ttotal: 7m 49s\tremaining: 29.9s\n",
      "21623:\tlearn: 2.2525103\ttotal: 7m 49s\tremaining: 29.9s\n",
      "21624:\tlearn: 2.2524502\ttotal: 7m 49s\tremaining: 29.8s\n",
      "21625:\tlearn: 2.2523964\ttotal: 7m 49s\tremaining: 29.8s\n",
      "21626:\tlearn: 2.2523832\ttotal: 7m 49s\tremaining: 29.8s\n",
      "21627:\tlearn: 2.2523199\ttotal: 7m 49s\tremaining: 29.8s\n",
      "21628:\tlearn: 2.2522678\ttotal: 7m 49s\tremaining: 29.7s\n",
      "21629:\tlearn: 2.2522123\ttotal: 7m 49s\tremaining: 29.7s\n",
      "21630:\tlearn: 2.2521181\ttotal: 7m 49s\tremaining: 29.7s\n",
      "21631:\tlearn: 2.2520764\ttotal: 7m 49s\tremaining: 29.7s\n",
      "21632:\tlearn: 2.2520137\ttotal: 7m 49s\tremaining: 29.7s\n",
      "21633:\tlearn: 2.2519091\ttotal: 7m 49s\tremaining: 29.6s\n",
      "21634:\tlearn: 2.2517976\ttotal: 7m 49s\tremaining: 29.6s\n",
      "21635:\tlearn: 2.2516589\ttotal: 7m 49s\tremaining: 29.6s\n",
      "21636:\tlearn: 2.2515563\ttotal: 7m 49s\tremaining: 29.6s\n",
      "21637:\tlearn: 2.2515215\ttotal: 7m 49s\tremaining: 29.5s\n",
      "21638:\tlearn: 2.2514844\ttotal: 7m 49s\tremaining: 29.5s\n",
      "21639:\tlearn: 2.2513682\ttotal: 7m 49s\tremaining: 29.5s\n",
      "21640:\tlearn: 2.2513647\ttotal: 7m 49s\tremaining: 29.5s\n",
      "21641:\tlearn: 2.2512825\ttotal: 7m 49s\tremaining: 29.5s\n",
      "21642:\tlearn: 2.2512235\ttotal: 7m 49s\tremaining: 29.4s\n",
      "21643:\tlearn: 2.2511347\ttotal: 7m 49s\tremaining: 29.4s\n",
      "21644:\tlearn: 2.2511103\ttotal: 7m 49s\tremaining: 29.4s\n",
      "21645:\tlearn: 2.2510271\ttotal: 7m 49s\tremaining: 29.4s\n",
      "21646:\tlearn: 2.2509264\ttotal: 7m 49s\tremaining: 29.4s\n",
      "21647:\tlearn: 2.2508794\ttotal: 7m 49s\tremaining: 29.3s\n",
      "21648:\tlearn: 2.2508245\ttotal: 7m 49s\tremaining: 29.3s\n",
      "21649:\tlearn: 2.2507902\ttotal: 7m 49s\tremaining: 29.3s\n",
      "21650:\tlearn: 2.2507033\ttotal: 7m 49s\tremaining: 29.3s\n",
      "21651:\tlearn: 2.2505910\ttotal: 7m 49s\tremaining: 29.2s\n",
      "21652:\tlearn: 2.2504841\ttotal: 7m 49s\tremaining: 29.2s\n",
      "21653:\tlearn: 2.2504227\ttotal: 7m 49s\tremaining: 29.2s\n",
      "21654:\tlearn: 2.2503836\ttotal: 7m 49s\tremaining: 29.2s\n",
      "21655:\tlearn: 2.2503258\ttotal: 7m 49s\tremaining: 29.2s\n",
      "21656:\tlearn: 2.2503058\ttotal: 7m 49s\tremaining: 29.1s\n",
      "21657:\tlearn: 2.2502411\ttotal: 7m 49s\tremaining: 29.1s\n",
      "21658:\tlearn: 2.2501413\ttotal: 7m 49s\tremaining: 29.1s\n",
      "21659:\tlearn: 2.2500986\ttotal: 7m 49s\tremaining: 29.1s\n",
      "21660:\tlearn: 2.2500218\ttotal: 7m 49s\tremaining: 29.1s\n",
      "21661:\tlearn: 2.2499755\ttotal: 7m 49s\tremaining: 29s\n",
      "21662:\tlearn: 2.2499236\ttotal: 7m 50s\tremaining: 29s\n",
      "21663:\tlearn: 2.2498401\ttotal: 7m 50s\tremaining: 29s\n",
      "21664:\tlearn: 2.2497697\ttotal: 7m 50s\tremaining: 29s\n",
      "21665:\tlearn: 2.2496985\ttotal: 7m 50s\tremaining: 28.9s\n",
      "21666:\tlearn: 2.2496649\ttotal: 7m 50s\tremaining: 28.9s\n",
      "21667:\tlearn: 2.2495805\ttotal: 7m 50s\tremaining: 28.9s\n",
      "21668:\tlearn: 2.2494459\ttotal: 7m 50s\tremaining: 28.9s\n",
      "21669:\tlearn: 2.2493680\ttotal: 7m 50s\tremaining: 28.9s\n",
      "21670:\tlearn: 2.2492746\ttotal: 7m 50s\tremaining: 28.8s\n",
      "21671:\tlearn: 2.2492566\ttotal: 7m 50s\tremaining: 28.8s\n",
      "21672:\tlearn: 2.2491856\ttotal: 7m 50s\tremaining: 28.8s\n",
      "21673:\tlearn: 2.2490836\ttotal: 7m 50s\tremaining: 28.8s\n",
      "21674:\tlearn: 2.2490060\ttotal: 7m 50s\tremaining: 28.7s\n",
      "21675:\tlearn: 2.2489235\ttotal: 7m 50s\tremaining: 28.7s\n",
      "21676:\tlearn: 2.2488417\ttotal: 7m 50s\tremaining: 28.7s\n",
      "21677:\tlearn: 2.2487257\ttotal: 7m 50s\tremaining: 28.7s\n",
      "21678:\tlearn: 2.2486677\ttotal: 7m 50s\tremaining: 28.7s\n",
      "21679:\tlearn: 2.2485929\ttotal: 7m 50s\tremaining: 28.6s\n",
      "21680:\tlearn: 2.2485462\ttotal: 7m 50s\tremaining: 28.6s\n",
      "21681:\tlearn: 2.2484597\ttotal: 7m 50s\tremaining: 28.6s\n",
      "21682:\tlearn: 2.2484069\ttotal: 7m 50s\tremaining: 28.6s\n",
      "21683:\tlearn: 2.2483202\ttotal: 7m 50s\tremaining: 28.6s\n",
      "21684:\tlearn: 2.2482820\ttotal: 7m 50s\tremaining: 28.5s\n",
      "21685:\tlearn: 2.2481785\ttotal: 7m 50s\tremaining: 28.5s\n",
      "21686:\tlearn: 2.2481195\ttotal: 7m 50s\tremaining: 28.5s\n",
      "21687:\tlearn: 2.2480753\ttotal: 7m 50s\tremaining: 28.5s\n",
      "21688:\tlearn: 2.2480100\ttotal: 7m 50s\tremaining: 28.4s\n",
      "21689:\tlearn: 2.2479408\ttotal: 7m 50s\tremaining: 28.4s\n",
      "21690:\tlearn: 2.2478734\ttotal: 7m 50s\tremaining: 28.4s\n",
      "21691:\tlearn: 2.2478277\ttotal: 7m 50s\tremaining: 28.4s\n",
      "21692:\tlearn: 2.2477260\ttotal: 7m 50s\tremaining: 28.4s\n",
      "21693:\tlearn: 2.2476504\ttotal: 7m 50s\tremaining: 28.3s\n",
      "21694:\tlearn: 2.2475674\ttotal: 7m 50s\tremaining: 28.3s\n",
      "21695:\tlearn: 2.2474968\ttotal: 7m 50s\tremaining: 28.3s\n",
      "21696:\tlearn: 2.2474350\ttotal: 7m 50s\tremaining: 28.3s\n",
      "21697:\tlearn: 2.2473617\ttotal: 7m 50s\tremaining: 28.2s\n",
      "21698:\tlearn: 2.2472678\ttotal: 7m 50s\tremaining: 28.2s\n",
      "21699:\tlearn: 2.2472249\ttotal: 7m 50s\tremaining: 28.2s\n",
      "21700:\tlearn: 2.2471332\ttotal: 7m 50s\tremaining: 28.2s\n",
      "21701:\tlearn: 2.2470547\ttotal: 7m 50s\tremaining: 28.2s\n",
      "21702:\tlearn: 2.2470130\ttotal: 7m 50s\tremaining: 28.1s\n",
      "21703:\tlearn: 2.2469314\ttotal: 7m 50s\tremaining: 28.1s\n",
      "21704:\tlearn: 2.2468966\ttotal: 7m 50s\tremaining: 28.1s\n",
      "21705:\tlearn: 2.2468516\ttotal: 7m 50s\tremaining: 28.1s\n",
      "21706:\tlearn: 2.2467442\ttotal: 7m 50s\tremaining: 28.1s\n",
      "21707:\tlearn: 2.2467003\ttotal: 7m 50s\tremaining: 28s\n",
      "21708:\tlearn: 2.2466056\ttotal: 7m 50s\tremaining: 28s\n",
      "21709:\tlearn: 2.2465073\ttotal: 7m 51s\tremaining: 28s\n",
      "21710:\tlearn: 2.2464533\ttotal: 7m 51s\tremaining: 28s\n",
      "21711:\tlearn: 2.2463662\ttotal: 7m 51s\tremaining: 27.9s\n",
      "21712:\tlearn: 2.2462469\ttotal: 7m 51s\tremaining: 27.9s\n",
      "21713:\tlearn: 2.2461393\ttotal: 7m 51s\tremaining: 27.9s\n",
      "21714:\tlearn: 2.2460279\ttotal: 7m 51s\tremaining: 27.9s\n",
      "21715:\tlearn: 2.2459090\ttotal: 7m 51s\tremaining: 27.9s\n",
      "21716:\tlearn: 2.2458302\ttotal: 7m 51s\tremaining: 27.8s\n",
      "21717:\tlearn: 2.2456731\ttotal: 7m 51s\tremaining: 27.8s\n",
      "21718:\tlearn: 2.2456130\ttotal: 7m 51s\tremaining: 27.8s\n",
      "21719:\tlearn: 2.2455304\ttotal: 7m 51s\tremaining: 27.8s\n",
      "21720:\tlearn: 2.2454430\ttotal: 7m 51s\tremaining: 27.8s\n",
      "21721:\tlearn: 2.2453740\ttotal: 7m 51s\tremaining: 27.7s\n",
      "21722:\tlearn: 2.2453410\ttotal: 7m 51s\tremaining: 27.7s\n",
      "21723:\tlearn: 2.2452630\ttotal: 7m 51s\tremaining: 27.7s\n",
      "21724:\tlearn: 2.2452125\ttotal: 7m 51s\tremaining: 27.7s\n",
      "21725:\tlearn: 2.2451703\ttotal: 7m 51s\tremaining: 27.6s\n",
      "21726:\tlearn: 2.2451242\ttotal: 7m 51s\tremaining: 27.6s\n",
      "21727:\tlearn: 2.2450653\ttotal: 7m 51s\tremaining: 27.6s\n",
      "21728:\tlearn: 2.2449878\ttotal: 7m 51s\tremaining: 27.6s\n",
      "21729:\tlearn: 2.2449562\ttotal: 7m 51s\tremaining: 27.6s\n",
      "21730:\tlearn: 2.2448496\ttotal: 7m 51s\tremaining: 27.5s\n",
      "21731:\tlearn: 2.2447641\ttotal: 7m 51s\tremaining: 27.5s\n",
      "21732:\tlearn: 2.2446962\ttotal: 7m 51s\tremaining: 27.5s\n",
      "21733:\tlearn: 2.2446098\ttotal: 7m 51s\tremaining: 27.5s\n",
      "21734:\tlearn: 2.2445272\ttotal: 7m 51s\tremaining: 27.4s\n",
      "21735:\tlearn: 2.2444304\ttotal: 7m 51s\tremaining: 27.4s\n",
      "21736:\tlearn: 2.2443651\ttotal: 7m 51s\tremaining: 27.4s\n",
      "21737:\tlearn: 2.2442534\ttotal: 7m 51s\tremaining: 27.4s\n",
      "21738:\tlearn: 2.2441841\ttotal: 7m 51s\tremaining: 27.4s\n",
      "21739:\tlearn: 2.2441128\ttotal: 7m 51s\tremaining: 27.3s\n",
      "21740:\tlearn: 2.2440369\ttotal: 7m 51s\tremaining: 27.3s\n",
      "21741:\tlearn: 2.2439657\ttotal: 7m 51s\tremaining: 27.3s\n",
      "21742:\tlearn: 2.2439254\ttotal: 7m 51s\tremaining: 27.3s\n",
      "21743:\tlearn: 2.2438799\ttotal: 7m 51s\tremaining: 27.3s\n",
      "21744:\tlearn: 2.2437761\ttotal: 7m 51s\tremaining: 27.2s\n",
      "21745:\tlearn: 2.2437397\ttotal: 7m 51s\tremaining: 27.2s\n",
      "21746:\tlearn: 2.2436769\ttotal: 7m 51s\tremaining: 27.2s\n",
      "21747:\tlearn: 2.2436310\ttotal: 7m 51s\tremaining: 27.2s\n",
      "21748:\tlearn: 2.2435451\ttotal: 7m 51s\tremaining: 27.1s\n",
      "21749:\tlearn: 2.2434470\ttotal: 7m 51s\tremaining: 27.1s\n",
      "21750:\tlearn: 2.2433470\ttotal: 7m 51s\tremaining: 27.1s\n",
      "21751:\tlearn: 2.2432550\ttotal: 7m 51s\tremaining: 27.1s\n",
      "21752:\tlearn: 2.2431169\ttotal: 7m 52s\tremaining: 27.1s\n",
      "21753:\tlearn: 2.2430533\ttotal: 7m 52s\tremaining: 27s\n",
      "21754:\tlearn: 2.2429622\ttotal: 7m 52s\tremaining: 27s\n",
      "21755:\tlearn: 2.2428840\ttotal: 7m 52s\tremaining: 27s\n",
      "21756:\tlearn: 2.2428126\ttotal: 7m 52s\tremaining: 27s\n",
      "21757:\tlearn: 2.2427659\ttotal: 7m 52s\tremaining: 26.9s\n",
      "21758:\tlearn: 2.2427419\ttotal: 7m 52s\tremaining: 26.9s\n",
      "21759:\tlearn: 2.2426295\ttotal: 7m 52s\tremaining: 26.9s\n",
      "21760:\tlearn: 2.2426275\ttotal: 7m 52s\tremaining: 26.9s\n",
      "21761:\tlearn: 2.2425353\ttotal: 7m 52s\tremaining: 26.9s\n",
      "21762:\tlearn: 2.2424204\ttotal: 7m 52s\tremaining: 26.8s\n",
      "21763:\tlearn: 2.2423621\ttotal: 7m 52s\tremaining: 26.8s\n",
      "21764:\tlearn: 2.2422821\ttotal: 7m 52s\tremaining: 26.8s\n",
      "21765:\tlearn: 2.2422198\ttotal: 7m 52s\tremaining: 26.8s\n",
      "21766:\tlearn: 2.2421979\ttotal: 7m 52s\tremaining: 26.8s\n",
      "21767:\tlearn: 2.2421916\ttotal: 7m 52s\tremaining: 26.7s\n",
      "21768:\tlearn: 2.2421213\ttotal: 7m 52s\tremaining: 26.7s\n",
      "21769:\tlearn: 2.2420535\ttotal: 7m 52s\tremaining: 26.7s\n",
      "21770:\tlearn: 2.2420049\ttotal: 7m 52s\tremaining: 26.7s\n",
      "21771:\tlearn: 2.2419691\ttotal: 7m 52s\tremaining: 26.6s\n",
      "21772:\tlearn: 2.2418954\ttotal: 7m 52s\tremaining: 26.6s\n",
      "21773:\tlearn: 2.2418692\ttotal: 7m 52s\tremaining: 26.6s\n",
      "21774:\tlearn: 2.2417914\ttotal: 7m 52s\tremaining: 26.6s\n",
      "21775:\tlearn: 2.2417113\ttotal: 7m 52s\tremaining: 26.6s\n",
      "21776:\tlearn: 2.2416320\ttotal: 7m 52s\tremaining: 26.5s\n",
      "21777:\tlearn: 2.2416054\ttotal: 7m 52s\tremaining: 26.5s\n",
      "21778:\tlearn: 2.2415506\ttotal: 7m 52s\tremaining: 26.5s\n",
      "21779:\tlearn: 2.2414889\ttotal: 7m 52s\tremaining: 26.5s\n",
      "21780:\tlearn: 2.2414267\ttotal: 7m 52s\tremaining: 26.4s\n",
      "21781:\tlearn: 2.2413541\ttotal: 7m 52s\tremaining: 26.4s\n",
      "21782:\tlearn: 2.2412597\ttotal: 7m 52s\tremaining: 26.4s\n",
      "21783:\tlearn: 2.2410644\ttotal: 7m 52s\tremaining: 26.4s\n",
      "21784:\tlearn: 2.2409768\ttotal: 7m 52s\tremaining: 26.4s\n",
      "21785:\tlearn: 2.2409385\ttotal: 7m 52s\tremaining: 26.3s\n",
      "21786:\tlearn: 2.2408495\ttotal: 7m 52s\tremaining: 26.3s\n",
      "21787:\tlearn: 2.2407585\ttotal: 7m 52s\tremaining: 26.3s\n",
      "21788:\tlearn: 2.2407448\ttotal: 7m 52s\tremaining: 26.3s\n",
      "21789:\tlearn: 2.2406818\ttotal: 7m 52s\tremaining: 26.3s\n",
      "21790:\tlearn: 2.2406181\ttotal: 7m 52s\tremaining: 26.2s\n",
      "21791:\tlearn: 2.2405502\ttotal: 7m 52s\tremaining: 26.2s\n",
      "21792:\tlearn: 2.2404532\ttotal: 7m 52s\tremaining: 26.2s\n",
      "21793:\tlearn: 2.2403817\ttotal: 7m 52s\tremaining: 26.2s\n",
      "21794:\tlearn: 2.2403012\ttotal: 7m 52s\tremaining: 26.1s\n",
      "21795:\tlearn: 2.2402202\ttotal: 7m 52s\tremaining: 26.1s\n",
      "21796:\tlearn: 2.2401538\ttotal: 7m 52s\tremaining: 26.1s\n",
      "21797:\tlearn: 2.2401026\ttotal: 7m 52s\tremaining: 26.1s\n",
      "21798:\tlearn: 2.2399750\ttotal: 7m 53s\tremaining: 26.1s\n",
      "21799:\tlearn: 2.2398824\ttotal: 7m 53s\tremaining: 26s\n",
      "21800:\tlearn: 2.2398099\ttotal: 7m 53s\tremaining: 26s\n",
      "21801:\tlearn: 2.2397659\ttotal: 7m 53s\tremaining: 26s\n",
      "21802:\tlearn: 2.2396267\ttotal: 7m 53s\tremaining: 26s\n",
      "21803:\tlearn: 2.2395735\ttotal: 7m 53s\tremaining: 26s\n",
      "21804:\tlearn: 2.2395039\ttotal: 7m 53s\tremaining: 25.9s\n",
      "21805:\tlearn: 2.2394101\ttotal: 7m 53s\tremaining: 25.9s\n",
      "21806:\tlearn: 2.2393385\ttotal: 7m 53s\tremaining: 25.9s\n",
      "21807:\tlearn: 2.2392464\ttotal: 7m 53s\tremaining: 25.9s\n",
      "21808:\tlearn: 2.2392026\ttotal: 7m 53s\tremaining: 25.8s\n",
      "21809:\tlearn: 2.2391132\ttotal: 7m 53s\tremaining: 25.8s\n",
      "21810:\tlearn: 2.2390441\ttotal: 7m 53s\tremaining: 25.8s\n",
      "21811:\tlearn: 2.2389424\ttotal: 7m 53s\tremaining: 25.8s\n",
      "21812:\tlearn: 2.2388881\ttotal: 7m 53s\tremaining: 25.8s\n",
      "21813:\tlearn: 2.2387978\ttotal: 7m 53s\tremaining: 25.7s\n",
      "21814:\tlearn: 2.2387193\ttotal: 7m 53s\tremaining: 25.7s\n",
      "21815:\tlearn: 2.2385780\ttotal: 7m 53s\tremaining: 25.7s\n",
      "21816:\tlearn: 2.2385544\ttotal: 7m 53s\tremaining: 25.7s\n",
      "21817:\tlearn: 2.2385035\ttotal: 7m 53s\tremaining: 25.6s\n",
      "21818:\tlearn: 2.2384263\ttotal: 7m 53s\tremaining: 25.6s\n",
      "21819:\tlearn: 2.2383602\ttotal: 7m 53s\tremaining: 25.6s\n",
      "21820:\tlearn: 2.2383514\ttotal: 7m 53s\tremaining: 25.6s\n",
      "21821:\tlearn: 2.2383029\ttotal: 7m 53s\tremaining: 25.6s\n",
      "21822:\tlearn: 2.2382149\ttotal: 7m 53s\tremaining: 25.5s\n",
      "21823:\tlearn: 2.2381562\ttotal: 7m 53s\tremaining: 25.5s\n",
      "21824:\tlearn: 2.2381545\ttotal: 7m 53s\tremaining: 25.5s\n",
      "21825:\tlearn: 2.2380940\ttotal: 7m 53s\tremaining: 25.5s\n",
      "21826:\tlearn: 2.2379957\ttotal: 7m 53s\tremaining: 25.5s\n",
      "21827:\tlearn: 2.2378969\ttotal: 7m 53s\tremaining: 25.4s\n",
      "21828:\tlearn: 2.2378106\ttotal: 7m 53s\tremaining: 25.4s\n",
      "21829:\tlearn: 2.2377136\ttotal: 7m 53s\tremaining: 25.4s\n",
      "21830:\tlearn: 2.2375936\ttotal: 7m 53s\tremaining: 25.4s\n",
      "21831:\tlearn: 2.2375315\ttotal: 7m 53s\tremaining: 25.3s\n",
      "21832:\tlearn: 2.2374050\ttotal: 7m 53s\tremaining: 25.3s\n",
      "21833:\tlearn: 2.2373534\ttotal: 7m 53s\tremaining: 25.3s\n",
      "21834:\tlearn: 2.2373091\ttotal: 7m 53s\tremaining: 25.3s\n",
      "21835:\tlearn: 2.2371962\ttotal: 7m 53s\tremaining: 25.3s\n",
      "21836:\tlearn: 2.2370615\ttotal: 7m 53s\tremaining: 25.2s\n",
      "21837:\tlearn: 2.2369547\ttotal: 7m 53s\tremaining: 25.2s\n",
      "21838:\tlearn: 2.2369183\ttotal: 7m 53s\tremaining: 25.2s\n",
      "21839:\tlearn: 2.2368280\ttotal: 7m 53s\tremaining: 25.2s\n",
      "21840:\tlearn: 2.2367656\ttotal: 7m 53s\tremaining: 25.2s\n",
      "21841:\tlearn: 2.2367185\ttotal: 7m 54s\tremaining: 25.1s\n",
      "21842:\tlearn: 2.2366444\ttotal: 7m 54s\tremaining: 25.1s\n",
      "21843:\tlearn: 2.2365408\ttotal: 7m 54s\tremaining: 25.1s\n",
      "21844:\tlearn: 2.2364423\ttotal: 7m 54s\tremaining: 25.1s\n",
      "21845:\tlearn: 2.2363641\ttotal: 7m 54s\tremaining: 25s\n",
      "21846:\tlearn: 2.2363063\ttotal: 7m 54s\tremaining: 25s\n",
      "21847:\tlearn: 2.2362435\ttotal: 7m 54s\tremaining: 25s\n",
      "21848:\tlearn: 2.2361830\ttotal: 7m 54s\tremaining: 25s\n",
      "21849:\tlearn: 2.2361031\ttotal: 7m 54s\tremaining: 25s\n",
      "21850:\tlearn: 2.2360685\ttotal: 7m 54s\tremaining: 24.9s\n",
      "21851:\tlearn: 2.2360111\ttotal: 7m 54s\tremaining: 24.9s\n",
      "21852:\tlearn: 2.2359114\ttotal: 7m 54s\tremaining: 24.9s\n",
      "21853:\tlearn: 2.2358359\ttotal: 7m 54s\tremaining: 24.9s\n",
      "21854:\tlearn: 2.2357753\ttotal: 7m 54s\tremaining: 24.9s\n",
      "21855:\tlearn: 2.2356930\ttotal: 7m 54s\tremaining: 24.8s\n",
      "21856:\tlearn: 2.2355841\ttotal: 7m 54s\tremaining: 24.8s\n",
      "21857:\tlearn: 2.2355163\ttotal: 7m 54s\tremaining: 24.8s\n",
      "21858:\tlearn: 2.2354412\ttotal: 7m 54s\tremaining: 24.8s\n",
      "21859:\tlearn: 2.2353000\ttotal: 7m 54s\tremaining: 24.7s\n",
      "21860:\tlearn: 2.2352202\ttotal: 7m 54s\tremaining: 24.7s\n",
      "21861:\tlearn: 2.2351296\ttotal: 7m 54s\tremaining: 24.7s\n",
      "21862:\tlearn: 2.2350810\ttotal: 7m 54s\tremaining: 24.7s\n",
      "21863:\tlearn: 2.2350030\ttotal: 7m 54s\tremaining: 24.7s\n",
      "21864:\tlearn: 2.2349408\ttotal: 7m 54s\tremaining: 24.6s\n",
      "21865:\tlearn: 2.2348548\ttotal: 7m 54s\tremaining: 24.6s\n",
      "21866:\tlearn: 2.2348174\ttotal: 7m 54s\tremaining: 24.6s\n",
      "21867:\tlearn: 2.2347721\ttotal: 7m 54s\tremaining: 24.6s\n",
      "21868:\tlearn: 2.2347196\ttotal: 7m 54s\tremaining: 24.5s\n",
      "21869:\tlearn: 2.2346565\ttotal: 7m 54s\tremaining: 24.5s\n",
      "21870:\tlearn: 2.2346231\ttotal: 7m 54s\tremaining: 24.5s\n",
      "21871:\tlearn: 2.2344899\ttotal: 7m 54s\tremaining: 24.5s\n",
      "21872:\tlearn: 2.2344883\ttotal: 7m 54s\tremaining: 24.5s\n",
      "21873:\tlearn: 2.2343993\ttotal: 7m 54s\tremaining: 24.4s\n",
      "21874:\tlearn: 2.2343178\ttotal: 7m 54s\tremaining: 24.4s\n",
      "21875:\tlearn: 2.2342473\ttotal: 7m 54s\tremaining: 24.4s\n",
      "21876:\tlearn: 2.2341704\ttotal: 7m 54s\tremaining: 24.4s\n",
      "21877:\tlearn: 2.2341159\ttotal: 7m 54s\tremaining: 24.4s\n",
      "21878:\tlearn: 2.2340410\ttotal: 7m 54s\tremaining: 24.3s\n",
      "21879:\tlearn: 2.2340058\ttotal: 7m 54s\tremaining: 24.3s\n",
      "21880:\tlearn: 2.2339622\ttotal: 7m 54s\tremaining: 24.3s\n",
      "21881:\tlearn: 2.2338905\ttotal: 7m 54s\tremaining: 24.3s\n",
      "21882:\tlearn: 2.2338237\ttotal: 7m 54s\tremaining: 24.2s\n",
      "21883:\tlearn: 2.2337653\ttotal: 7m 55s\tremaining: 24.2s\n",
      "21884:\tlearn: 2.2336968\ttotal: 7m 55s\tremaining: 24.2s\n",
      "21885:\tlearn: 2.2336211\ttotal: 7m 55s\tremaining: 24.2s\n",
      "21886:\tlearn: 2.2335441\ttotal: 7m 55s\tremaining: 24.2s\n",
      "21887:\tlearn: 2.2335359\ttotal: 7m 55s\tremaining: 24.1s\n",
      "21888:\tlearn: 2.2334492\ttotal: 7m 55s\tremaining: 24.1s\n",
      "21889:\tlearn: 2.2333585\ttotal: 7m 55s\tremaining: 24.1s\n",
      "21890:\tlearn: 2.2332782\ttotal: 7m 55s\tremaining: 24.1s\n",
      "21891:\tlearn: 2.2331663\ttotal: 7m 55s\tremaining: 24.1s\n",
      "21892:\tlearn: 2.2330905\ttotal: 7m 55s\tremaining: 24s\n",
      "21893:\tlearn: 2.2330000\ttotal: 7m 55s\tremaining: 24s\n",
      "21894:\tlearn: 2.2329361\ttotal: 7m 55s\tremaining: 24s\n",
      "21895:\tlearn: 2.2328357\ttotal: 7m 55s\tremaining: 24s\n",
      "21896:\tlearn: 2.2327225\ttotal: 7m 55s\tremaining: 23.9s\n",
      "21897:\tlearn: 2.2326459\ttotal: 7m 55s\tremaining: 23.9s\n",
      "21898:\tlearn: 2.2325484\ttotal: 7m 55s\tremaining: 23.9s\n",
      "21899:\tlearn: 2.2324879\ttotal: 7m 55s\tremaining: 23.9s\n",
      "21900:\tlearn: 2.2324304\ttotal: 7m 55s\tremaining: 23.9s\n",
      "21901:\tlearn: 2.2323324\ttotal: 7m 55s\tremaining: 23.8s\n",
      "21902:\tlearn: 2.2322887\ttotal: 7m 55s\tremaining: 23.8s\n",
      "21903:\tlearn: 2.2322029\ttotal: 7m 55s\tremaining: 23.8s\n",
      "21904:\tlearn: 2.2321496\ttotal: 7m 55s\tremaining: 23.8s\n",
      "21905:\tlearn: 2.2320587\ttotal: 7m 55s\tremaining: 23.7s\n",
      "21906:\tlearn: 2.2320323\ttotal: 7m 55s\tremaining: 23.7s\n",
      "21907:\tlearn: 2.2319366\ttotal: 7m 55s\tremaining: 23.7s\n",
      "21908:\tlearn: 2.2318485\ttotal: 7m 55s\tremaining: 23.7s\n",
      "21909:\tlearn: 2.2317984\ttotal: 7m 55s\tremaining: 23.7s\n",
      "21910:\tlearn: 2.2317182\ttotal: 7m 55s\tremaining: 23.6s\n",
      "21911:\tlearn: 2.2316242\ttotal: 7m 55s\tremaining: 23.6s\n",
      "21912:\tlearn: 2.2315213\ttotal: 7m 55s\tremaining: 23.6s\n",
      "21913:\tlearn: 2.2314252\ttotal: 7m 55s\tremaining: 23.6s\n",
      "21914:\tlearn: 2.2312721\ttotal: 7m 55s\tremaining: 23.6s\n",
      "21915:\tlearn: 2.2312204\ttotal: 7m 55s\tremaining: 23.5s\n",
      "21916:\tlearn: 2.2311113\ttotal: 7m 55s\tremaining: 23.5s\n",
      "21917:\tlearn: 2.2310079\ttotal: 7m 55s\tremaining: 23.5s\n",
      "21918:\tlearn: 2.2309479\ttotal: 7m 55s\tremaining: 23.5s\n",
      "21919:\tlearn: 2.2308860\ttotal: 7m 55s\tremaining: 23.4s\n",
      "21920:\tlearn: 2.2308729\ttotal: 7m 55s\tremaining: 23.4s\n",
      "21921:\tlearn: 2.2308021\ttotal: 7m 55s\tremaining: 23.4s\n",
      "21922:\tlearn: 2.2307213\ttotal: 7m 55s\tremaining: 23.4s\n",
      "21923:\tlearn: 2.2306545\ttotal: 7m 55s\tremaining: 23.4s\n",
      "21924:\tlearn: 2.2305867\ttotal: 7m 56s\tremaining: 23.3s\n",
      "21925:\tlearn: 2.2305308\ttotal: 7m 56s\tremaining: 23.3s\n",
      "21926:\tlearn: 2.2304617\ttotal: 7m 56s\tremaining: 23.3s\n",
      "21927:\tlearn: 2.2303720\ttotal: 7m 56s\tremaining: 23.3s\n",
      "21928:\tlearn: 2.2302969\ttotal: 7m 56s\tremaining: 23.3s\n",
      "21929:\tlearn: 2.2301895\ttotal: 7m 56s\tremaining: 23.2s\n",
      "21930:\tlearn: 2.2301078\ttotal: 7m 56s\tremaining: 23.2s\n",
      "21931:\tlearn: 2.2299962\ttotal: 7m 56s\tremaining: 23.2s\n",
      "21932:\tlearn: 2.2299215\ttotal: 7m 56s\tremaining: 23.2s\n",
      "21933:\tlearn: 2.2298536\ttotal: 7m 56s\tremaining: 23.1s\n",
      "21934:\tlearn: 2.2297879\ttotal: 7m 56s\tremaining: 23.1s\n",
      "21935:\tlearn: 2.2297532\ttotal: 7m 56s\tremaining: 23.1s\n",
      "21936:\tlearn: 2.2296817\ttotal: 7m 56s\tremaining: 23.1s\n",
      "21937:\tlearn: 2.2296271\ttotal: 7m 56s\tremaining: 23.1s\n",
      "21938:\tlearn: 2.2295554\ttotal: 7m 56s\tremaining: 23s\n",
      "21939:\tlearn: 2.2294977\ttotal: 7m 56s\tremaining: 23s\n",
      "21940:\tlearn: 2.2294681\ttotal: 7m 56s\tremaining: 23s\n",
      "21941:\tlearn: 2.2294212\ttotal: 7m 56s\tremaining: 23s\n",
      "21942:\tlearn: 2.2293817\ttotal: 7m 56s\tremaining: 22.9s\n",
      "21943:\tlearn: 2.2292943\ttotal: 7m 56s\tremaining: 22.9s\n",
      "21944:\tlearn: 2.2291425\ttotal: 7m 56s\tremaining: 22.9s\n",
      "21945:\tlearn: 2.2290843\ttotal: 7m 56s\tremaining: 22.9s\n",
      "21946:\tlearn: 2.2290307\ttotal: 7m 56s\tremaining: 22.9s\n",
      "21947:\tlearn: 2.2289560\ttotal: 7m 56s\tremaining: 22.8s\n",
      "21948:\tlearn: 2.2288036\ttotal: 7m 56s\tremaining: 22.8s\n",
      "21949:\tlearn: 2.2287140\ttotal: 7m 56s\tremaining: 22.8s\n",
      "21950:\tlearn: 2.2286426\ttotal: 7m 56s\tremaining: 22.8s\n",
      "21951:\tlearn: 2.2285967\ttotal: 7m 56s\tremaining: 22.8s\n",
      "21952:\tlearn: 2.2285150\ttotal: 7m 56s\tremaining: 22.7s\n",
      "21953:\tlearn: 2.2284568\ttotal: 7m 56s\tremaining: 22.7s\n",
      "21954:\tlearn: 2.2283997\ttotal: 7m 56s\tremaining: 22.7s\n",
      "21955:\tlearn: 2.2283312\ttotal: 7m 56s\tremaining: 22.7s\n",
      "21956:\tlearn: 2.2282584\ttotal: 7m 56s\tremaining: 22.6s\n",
      "21957:\tlearn: 2.2282163\ttotal: 7m 56s\tremaining: 22.6s\n",
      "21958:\tlearn: 2.2281417\ttotal: 7m 56s\tremaining: 22.6s\n",
      "21959:\tlearn: 2.2280599\ttotal: 7m 56s\tremaining: 22.6s\n",
      "21960:\tlearn: 2.2279607\ttotal: 7m 56s\tremaining: 22.6s\n",
      "21961:\tlearn: 2.2278897\ttotal: 7m 56s\tremaining: 22.5s\n",
      "21962:\tlearn: 2.2277857\ttotal: 7m 56s\tremaining: 22.5s\n",
      "21963:\tlearn: 2.2277282\ttotal: 7m 56s\tremaining: 22.5s\n",
      "21964:\tlearn: 2.2276478\ttotal: 7m 56s\tremaining: 22.5s\n",
      "21965:\tlearn: 2.2275740\ttotal: 7m 56s\tremaining: 22.4s\n",
      "21966:\tlearn: 2.2274470\ttotal: 7m 56s\tremaining: 22.4s\n",
      "21967:\tlearn: 2.2273798\ttotal: 7m 56s\tremaining: 22.4s\n",
      "21968:\tlearn: 2.2273540\ttotal: 7m 56s\tremaining: 22.4s\n",
      "21969:\tlearn: 2.2272625\ttotal: 7m 57s\tremaining: 22.4s\n",
      "21970:\tlearn: 2.2271896\ttotal: 7m 57s\tremaining: 22.3s\n",
      "21971:\tlearn: 2.2271303\ttotal: 7m 57s\tremaining: 22.3s\n",
      "21972:\tlearn: 2.2270799\ttotal: 7m 57s\tremaining: 22.3s\n",
      "21973:\tlearn: 2.2270297\ttotal: 7m 57s\tremaining: 22.3s\n",
      "21974:\tlearn: 2.2269134\ttotal: 7m 57s\tremaining: 22.3s\n",
      "21975:\tlearn: 2.2268628\ttotal: 7m 57s\tremaining: 22.2s\n",
      "21976:\tlearn: 2.2268002\ttotal: 7m 57s\tremaining: 22.2s\n",
      "21977:\tlearn: 2.2267192\ttotal: 7m 57s\tremaining: 22.2s\n",
      "21978:\tlearn: 2.2266325\ttotal: 7m 57s\tremaining: 22.2s\n",
      "21979:\tlearn: 2.2265988\ttotal: 7m 57s\tremaining: 22.1s\n",
      "21980:\tlearn: 2.2264867\ttotal: 7m 57s\tremaining: 22.1s\n",
      "21981:\tlearn: 2.2263809\ttotal: 7m 57s\tremaining: 22.1s\n",
      "21982:\tlearn: 2.2263263\ttotal: 7m 57s\tremaining: 22.1s\n",
      "21983:\tlearn: 2.2262806\ttotal: 7m 57s\tremaining: 22.1s\n",
      "21984:\tlearn: 2.2262157\ttotal: 7m 57s\tremaining: 22s\n",
      "21985:\tlearn: 2.2261191\ttotal: 7m 57s\tremaining: 22s\n",
      "21986:\tlearn: 2.2260399\ttotal: 7m 57s\tremaining: 22s\n",
      "21987:\tlearn: 2.2259833\ttotal: 7m 57s\tremaining: 22s\n",
      "21988:\tlearn: 2.2259449\ttotal: 7m 57s\tremaining: 22s\n",
      "21989:\tlearn: 2.2258877\ttotal: 7m 57s\tremaining: 21.9s\n",
      "21990:\tlearn: 2.2258113\ttotal: 7m 57s\tremaining: 21.9s\n",
      "21991:\tlearn: 2.2257446\ttotal: 7m 57s\tremaining: 21.9s\n",
      "21992:\tlearn: 2.2257078\ttotal: 7m 57s\tremaining: 21.9s\n",
      "21993:\tlearn: 2.2256717\ttotal: 7m 57s\tremaining: 21.8s\n",
      "21994:\tlearn: 2.2256707\ttotal: 7m 57s\tremaining: 21.8s\n",
      "21995:\tlearn: 2.2256151\ttotal: 7m 57s\tremaining: 21.8s\n",
      "21996:\tlearn: 2.2255721\ttotal: 7m 57s\tremaining: 21.8s\n",
      "21997:\tlearn: 2.2255280\ttotal: 7m 57s\tremaining: 21.8s\n",
      "21998:\tlearn: 2.2254634\ttotal: 7m 57s\tremaining: 21.7s\n",
      "21999:\tlearn: 2.2253794\ttotal: 7m 57s\tremaining: 21.7s\n",
      "22000:\tlearn: 2.2252977\ttotal: 7m 57s\tremaining: 21.7s\n",
      "22001:\tlearn: 2.2252052\ttotal: 7m 57s\tremaining: 21.7s\n",
      "22002:\tlearn: 2.2251411\ttotal: 7m 57s\tremaining: 21.6s\n",
      "22003:\tlearn: 2.2250677\ttotal: 7m 57s\tremaining: 21.6s\n",
      "22004:\tlearn: 2.2249511\ttotal: 7m 57s\tremaining: 21.6s\n",
      "22005:\tlearn: 2.2249488\ttotal: 7m 57s\tremaining: 21.6s\n",
      "22006:\tlearn: 2.2248614\ttotal: 7m 57s\tremaining: 21.6s\n",
      "22007:\tlearn: 2.2248038\ttotal: 7m 57s\tremaining: 21.5s\n",
      "22008:\tlearn: 2.2247527\ttotal: 7m 57s\tremaining: 21.5s\n",
      "22009:\tlearn: 2.2246610\ttotal: 7m 57s\tremaining: 21.5s\n",
      "22010:\tlearn: 2.2245656\ttotal: 7m 57s\tremaining: 21.5s\n",
      "22011:\tlearn: 2.2245127\ttotal: 7m 57s\tremaining: 21.5s\n",
      "22012:\tlearn: 2.2244078\ttotal: 7m 58s\tremaining: 21.4s\n",
      "22013:\tlearn: 2.2243034\ttotal: 7m 58s\tremaining: 21.4s\n",
      "22014:\tlearn: 2.2242113\ttotal: 7m 58s\tremaining: 21.4s\n",
      "22015:\tlearn: 2.2241543\ttotal: 7m 58s\tremaining: 21.4s\n",
      "22016:\tlearn: 2.2240804\ttotal: 7m 58s\tremaining: 21.3s\n",
      "22017:\tlearn: 2.2240124\ttotal: 7m 58s\tremaining: 21.3s\n",
      "22018:\tlearn: 2.2239674\ttotal: 7m 58s\tremaining: 21.3s\n",
      "22019:\tlearn: 2.2238815\ttotal: 7m 58s\tremaining: 21.3s\n",
      "22020:\tlearn: 2.2238666\ttotal: 7m 58s\tremaining: 21.3s\n",
      "22021:\tlearn: 2.2238056\ttotal: 7m 58s\tremaining: 21.2s\n",
      "22022:\tlearn: 2.2237366\ttotal: 7m 58s\tremaining: 21.2s\n",
      "22023:\tlearn: 2.2236774\ttotal: 7m 58s\tremaining: 21.2s\n",
      "22024:\tlearn: 2.2235682\ttotal: 7m 58s\tremaining: 21.2s\n",
      "22025:\tlearn: 2.2235180\ttotal: 7m 58s\tremaining: 21.2s\n",
      "22026:\tlearn: 2.2234513\ttotal: 7m 58s\tremaining: 21.1s\n",
      "22027:\tlearn: 2.2234199\ttotal: 7m 58s\tremaining: 21.1s\n",
      "22028:\tlearn: 2.2233107\ttotal: 7m 58s\tremaining: 21.1s\n",
      "22029:\tlearn: 2.2232654\ttotal: 7m 58s\tremaining: 21.1s\n",
      "22030:\tlearn: 2.2232162\ttotal: 7m 58s\tremaining: 21s\n",
      "22031:\tlearn: 2.2231532\ttotal: 7m 58s\tremaining: 21s\n",
      "22032:\tlearn: 2.2230770\ttotal: 7m 58s\tremaining: 21s\n",
      "22033:\tlearn: 2.2230069\ttotal: 7m 58s\tremaining: 21s\n",
      "22034:\tlearn: 2.2229551\ttotal: 7m 58s\tremaining: 21s\n",
      "22035:\tlearn: 2.2229009\ttotal: 7m 58s\tremaining: 20.9s\n",
      "22036:\tlearn: 2.2228262\ttotal: 7m 58s\tremaining: 20.9s\n",
      "22037:\tlearn: 2.2227689\ttotal: 7m 58s\tremaining: 20.9s\n",
      "22038:\tlearn: 2.2226819\ttotal: 7m 58s\tremaining: 20.9s\n",
      "22039:\tlearn: 2.2226311\ttotal: 7m 58s\tremaining: 20.8s\n",
      "22040:\tlearn: 2.2225089\ttotal: 7m 58s\tremaining: 20.8s\n",
      "22041:\tlearn: 2.2224362\ttotal: 7m 58s\tremaining: 20.8s\n",
      "22042:\tlearn: 2.2223812\ttotal: 7m 58s\tremaining: 20.8s\n",
      "22043:\tlearn: 2.2222889\ttotal: 7m 58s\tremaining: 20.8s\n",
      "22044:\tlearn: 2.2222133\ttotal: 7m 58s\tremaining: 20.7s\n",
      "22045:\tlearn: 2.2221315\ttotal: 7m 58s\tremaining: 20.7s\n",
      "22046:\tlearn: 2.2220923\ttotal: 7m 58s\tremaining: 20.7s\n",
      "22047:\tlearn: 2.2220396\ttotal: 7m 58s\tremaining: 20.7s\n",
      "22048:\tlearn: 2.2219762\ttotal: 7m 58s\tremaining: 20.7s\n",
      "22049:\tlearn: 2.2219205\ttotal: 7m 58s\tremaining: 20.6s\n",
      "22050:\tlearn: 2.2218011\ttotal: 7m 58s\tremaining: 20.6s\n",
      "22051:\tlearn: 2.2217988\ttotal: 7m 58s\tremaining: 20.6s\n",
      "22052:\tlearn: 2.2217523\ttotal: 7m 58s\tremaining: 20.6s\n",
      "22053:\tlearn: 2.2216951\ttotal: 7m 58s\tremaining: 20.5s\n",
      "22054:\tlearn: 2.2215926\ttotal: 7m 58s\tremaining: 20.5s\n",
      "22055:\tlearn: 2.2215172\ttotal: 7m 59s\tremaining: 20.5s\n",
      "22056:\tlearn: 2.2214025\ttotal: 7m 59s\tremaining: 20.5s\n",
      "22057:\tlearn: 2.2213259\ttotal: 7m 59s\tremaining: 20.5s\n",
      "22058:\tlearn: 2.2212414\ttotal: 7m 59s\tremaining: 20.4s\n",
      "22059:\tlearn: 2.2211399\ttotal: 7m 59s\tremaining: 20.4s\n",
      "22060:\tlearn: 2.2210883\ttotal: 7m 59s\tremaining: 20.4s\n",
      "22061:\tlearn: 2.2210050\ttotal: 7m 59s\tremaining: 20.4s\n",
      "22062:\tlearn: 2.2209448\ttotal: 7m 59s\tremaining: 20.4s\n",
      "22063:\tlearn: 2.2208967\ttotal: 7m 59s\tremaining: 20.3s\n",
      "22064:\tlearn: 2.2208517\ttotal: 7m 59s\tremaining: 20.3s\n",
      "22065:\tlearn: 2.2207945\ttotal: 7m 59s\tremaining: 20.3s\n",
      "22066:\tlearn: 2.2206912\ttotal: 7m 59s\tremaining: 20.3s\n",
      "22067:\tlearn: 2.2206177\ttotal: 7m 59s\tremaining: 20.2s\n",
      "22068:\tlearn: 2.2205598\ttotal: 7m 59s\tremaining: 20.2s\n",
      "22069:\tlearn: 2.2204520\ttotal: 7m 59s\tremaining: 20.2s\n",
      "22070:\tlearn: 2.2203673\ttotal: 7m 59s\tremaining: 20.2s\n",
      "22071:\tlearn: 2.2202958\ttotal: 7m 59s\tremaining: 20.2s\n",
      "22072:\tlearn: 2.2201719\ttotal: 7m 59s\tremaining: 20.1s\n",
      "22073:\tlearn: 2.2200839\ttotal: 7m 59s\tremaining: 20.1s\n",
      "22074:\tlearn: 2.2200689\ttotal: 7m 59s\tremaining: 20.1s\n",
      "22075:\tlearn: 2.2199845\ttotal: 7m 59s\tremaining: 20.1s\n",
      "22076:\tlearn: 2.2198860\ttotal: 7m 59s\tremaining: 20s\n",
      "22077:\tlearn: 2.2198084\ttotal: 7m 59s\tremaining: 20s\n",
      "22078:\tlearn: 2.2197591\ttotal: 7m 59s\tremaining: 20s\n",
      "22079:\tlearn: 2.2196918\ttotal: 7m 59s\tremaining: 20s\n",
      "22080:\tlearn: 2.2195885\ttotal: 7m 59s\tremaining: 20s\n",
      "22081:\tlearn: 2.2195250\ttotal: 7m 59s\tremaining: 19.9s\n",
      "22082:\tlearn: 2.2194820\ttotal: 7m 59s\tremaining: 19.9s\n",
      "22083:\tlearn: 2.2194079\ttotal: 7m 59s\tremaining: 19.9s\n",
      "22084:\tlearn: 2.2193220\ttotal: 7m 59s\tremaining: 19.9s\n",
      "22085:\tlearn: 2.2192455\ttotal: 7m 59s\tremaining: 19.9s\n",
      "22086:\tlearn: 2.2191830\ttotal: 7m 59s\tremaining: 19.8s\n",
      "22087:\tlearn: 2.2191205\ttotal: 7m 59s\tremaining: 19.8s\n",
      "22088:\tlearn: 2.2190642\ttotal: 7m 59s\tremaining: 19.8s\n",
      "22089:\tlearn: 2.2189845\ttotal: 7m 59s\tremaining: 19.8s\n",
      "22090:\tlearn: 2.2189310\ttotal: 7m 59s\tremaining: 19.7s\n",
      "22091:\tlearn: 2.2188220\ttotal: 7m 59s\tremaining: 19.7s\n",
      "22092:\tlearn: 2.2187737\ttotal: 7m 59s\tremaining: 19.7s\n",
      "22093:\tlearn: 2.2186471\ttotal: 7m 59s\tremaining: 19.7s\n",
      "22094:\tlearn: 2.2185381\ttotal: 7m 59s\tremaining: 19.7s\n",
      "22095:\tlearn: 2.2184170\ttotal: 7m 59s\tremaining: 19.6s\n",
      "22096:\tlearn: 2.2183281\ttotal: 7m 59s\tremaining: 19.6s\n",
      "22097:\tlearn: 2.2182478\ttotal: 8m\tremaining: 19.6s\n",
      "22098:\tlearn: 2.2181623\ttotal: 8m\tremaining: 19.6s\n",
      "22099:\tlearn: 2.2181338\ttotal: 8m\tremaining: 19.6s\n",
      "22100:\tlearn: 2.2180927\ttotal: 8m\tremaining: 19.5s\n",
      "22101:\tlearn: 2.2179764\ttotal: 8m\tremaining: 19.5s\n",
      "22102:\tlearn: 2.2179178\ttotal: 8m\tremaining: 19.5s\n",
      "22103:\tlearn: 2.2178074\ttotal: 8m\tremaining: 19.5s\n",
      "22104:\tlearn: 2.2177522\ttotal: 8m\tremaining: 19.4s\n",
      "22105:\tlearn: 2.2177146\ttotal: 8m\tremaining: 19.4s\n",
      "22106:\tlearn: 2.2176181\ttotal: 8m\tremaining: 19.4s\n",
      "22107:\tlearn: 2.2175645\ttotal: 8m\tremaining: 19.4s\n",
      "22108:\tlearn: 2.2174895\ttotal: 8m\tremaining: 19.4s\n",
      "22109:\tlearn: 2.2174295\ttotal: 8m\tremaining: 19.3s\n",
      "22110:\tlearn: 2.2173336\ttotal: 8m\tremaining: 19.3s\n",
      "22111:\tlearn: 2.2173049\ttotal: 8m\tremaining: 19.3s\n",
      "22112:\tlearn: 2.2172489\ttotal: 8m\tremaining: 19.3s\n",
      "22113:\tlearn: 2.2171775\ttotal: 8m\tremaining: 19.2s\n",
      "22114:\tlearn: 2.2171352\ttotal: 8m\tremaining: 19.2s\n",
      "22115:\tlearn: 2.2170796\ttotal: 8m\tremaining: 19.2s\n",
      "22116:\tlearn: 2.2170103\ttotal: 8m\tremaining: 19.2s\n",
      "22117:\tlearn: 2.2170025\ttotal: 8m\tremaining: 19.2s\n",
      "22118:\tlearn: 2.2169366\ttotal: 8m\tremaining: 19.1s\n",
      "22119:\tlearn: 2.2168547\ttotal: 8m\tremaining: 19.1s\n",
      "22120:\tlearn: 2.2167408\ttotal: 8m\tremaining: 19.1s\n",
      "22121:\tlearn: 2.2167020\ttotal: 8m\tremaining: 19.1s\n",
      "22122:\tlearn: 2.2166013\ttotal: 8m\tremaining: 19s\n",
      "22123:\tlearn: 2.2165455\ttotal: 8m\tremaining: 19s\n",
      "22124:\tlearn: 2.2165026\ttotal: 8m\tremaining: 19s\n",
      "22125:\tlearn: 2.2164502\ttotal: 8m\tremaining: 19s\n",
      "22126:\tlearn: 2.2163904\ttotal: 8m\tremaining: 19s\n",
      "22127:\tlearn: 2.2163200\ttotal: 8m\tremaining: 18.9s\n",
      "22128:\tlearn: 2.2162853\ttotal: 8m\tremaining: 18.9s\n",
      "22129:\tlearn: 2.2161771\ttotal: 8m\tremaining: 18.9s\n",
      "22130:\tlearn: 2.2161307\ttotal: 8m\tremaining: 18.9s\n",
      "22131:\tlearn: 2.2160243\ttotal: 8m\tremaining: 18.9s\n",
      "22132:\tlearn: 2.2159384\ttotal: 8m\tremaining: 18.8s\n",
      "22133:\tlearn: 2.2158583\ttotal: 8m\tremaining: 18.8s\n",
      "22134:\tlearn: 2.2157858\ttotal: 8m\tremaining: 18.8s\n",
      "22135:\tlearn: 2.2157145\ttotal: 8m\tremaining: 18.8s\n",
      "22136:\tlearn: 2.2156533\ttotal: 8m\tremaining: 18.7s\n",
      "22137:\tlearn: 2.2155736\ttotal: 8m\tremaining: 18.7s\n",
      "22138:\tlearn: 2.2155116\ttotal: 8m\tremaining: 18.7s\n",
      "22139:\tlearn: 2.2154420\ttotal: 8m\tremaining: 18.7s\n",
      "22140:\tlearn: 2.2153729\ttotal: 8m\tremaining: 18.7s\n",
      "22141:\tlearn: 2.2153107\ttotal: 8m\tremaining: 18.6s\n",
      "22142:\tlearn: 2.2152709\ttotal: 8m\tremaining: 18.6s\n",
      "22143:\tlearn: 2.2152028\ttotal: 8m\tremaining: 18.6s\n",
      "22144:\tlearn: 2.2151626\ttotal: 8m 1s\tremaining: 18.6s\n",
      "22145:\tlearn: 2.2151083\ttotal: 8m 1s\tremaining: 18.5s\n",
      "22146:\tlearn: 2.2149884\ttotal: 8m 1s\tremaining: 18.5s\n",
      "22147:\tlearn: 2.2148950\ttotal: 8m 1s\tremaining: 18.5s\n",
      "22148:\tlearn: 2.2148049\ttotal: 8m 1s\tremaining: 18.5s\n",
      "22149:\tlearn: 2.2146950\ttotal: 8m 1s\tremaining: 18.5s\n",
      "22150:\tlearn: 2.2146054\ttotal: 8m 1s\tremaining: 18.4s\n",
      "22151:\tlearn: 2.2145068\ttotal: 8m 1s\tremaining: 18.4s\n",
      "22152:\tlearn: 2.2144483\ttotal: 8m 1s\tremaining: 18.4s\n",
      "22153:\tlearn: 2.2143786\ttotal: 8m 1s\tremaining: 18.4s\n",
      "22154:\tlearn: 2.2143770\ttotal: 8m 1s\tremaining: 18.4s\n",
      "22155:\tlearn: 2.2143434\ttotal: 8m 1s\tremaining: 18.3s\n",
      "22156:\tlearn: 2.2142947\ttotal: 8m 1s\tremaining: 18.3s\n",
      "22157:\tlearn: 2.2142430\ttotal: 8m 1s\tremaining: 18.3s\n",
      "22158:\tlearn: 2.2141413\ttotal: 8m 1s\tremaining: 18.3s\n",
      "22159:\tlearn: 2.2140866\ttotal: 8m 1s\tremaining: 18.2s\n",
      "22160:\tlearn: 2.2140497\ttotal: 8m 1s\tremaining: 18.2s\n",
      "22161:\tlearn: 2.2139646\ttotal: 8m 1s\tremaining: 18.2s\n",
      "22162:\tlearn: 2.2138718\ttotal: 8m 1s\tremaining: 18.2s\n",
      "22163:\tlearn: 2.2138117\ttotal: 8m 1s\tremaining: 18.2s\n",
      "22164:\tlearn: 2.2137626\ttotal: 8m 1s\tremaining: 18.1s\n",
      "22165:\tlearn: 2.2137228\ttotal: 8m 1s\tremaining: 18.1s\n",
      "22166:\tlearn: 2.2136615\ttotal: 8m 1s\tremaining: 18.1s\n",
      "22167:\tlearn: 2.2136018\ttotal: 8m 1s\tremaining: 18.1s\n",
      "22168:\tlearn: 2.2134549\ttotal: 8m 1s\tremaining: 18s\n",
      "22169:\tlearn: 2.2133618\ttotal: 8m 1s\tremaining: 18s\n",
      "22170:\tlearn: 2.2132889\ttotal: 8m 1s\tremaining: 18s\n",
      "22171:\tlearn: 2.2132427\ttotal: 8m 1s\tremaining: 18s\n",
      "22172:\tlearn: 2.2131666\ttotal: 8m 1s\tremaining: 18s\n",
      "22173:\tlearn: 2.2130839\ttotal: 8m 1s\tremaining: 17.9s\n",
      "22174:\tlearn: 2.2130416\ttotal: 8m 1s\tremaining: 17.9s\n",
      "22175:\tlearn: 2.2129889\ttotal: 8m 1s\tremaining: 17.9s\n",
      "22176:\tlearn: 2.2128968\ttotal: 8m 1s\tremaining: 17.9s\n",
      "22177:\tlearn: 2.2128141\ttotal: 8m 1s\tremaining: 17.9s\n",
      "22178:\tlearn: 2.2127590\ttotal: 8m 1s\tremaining: 17.8s\n",
      "22179:\tlearn: 2.2127586\ttotal: 8m 1s\tremaining: 17.8s\n",
      "22180:\tlearn: 2.2126714\ttotal: 8m 1s\tremaining: 17.8s\n",
      "22181:\tlearn: 2.2125940\ttotal: 8m 1s\tremaining: 17.8s\n",
      "22182:\tlearn: 2.2125517\ttotal: 8m 1s\tremaining: 17.7s\n",
      "22183:\tlearn: 2.2124676\ttotal: 8m 1s\tremaining: 17.7s\n",
      "22184:\tlearn: 2.2124135\ttotal: 8m 1s\tremaining: 17.7s\n",
      "22185:\tlearn: 2.2123296\ttotal: 8m 1s\tremaining: 17.7s\n",
      "22186:\tlearn: 2.2123044\ttotal: 8m 1s\tremaining: 17.7s\n",
      "22187:\tlearn: 2.2122757\ttotal: 8m 1s\tremaining: 17.6s\n",
      "22188:\tlearn: 2.2121719\ttotal: 8m 1s\tremaining: 17.6s\n",
      "22189:\tlearn: 2.2121118\ttotal: 8m 1s\tremaining: 17.6s\n",
      "22190:\tlearn: 2.2120454\ttotal: 8m 1s\tremaining: 17.6s\n",
      "22191:\tlearn: 2.2119324\ttotal: 8m 2s\tremaining: 17.6s\n",
      "22192:\tlearn: 2.2118840\ttotal: 8m 2s\tremaining: 17.5s\n",
      "22193:\tlearn: 2.2118295\ttotal: 8m 2s\tremaining: 17.5s\n",
      "22194:\tlearn: 2.2117376\ttotal: 8m 2s\tremaining: 17.5s\n",
      "22195:\tlearn: 2.2116126\ttotal: 8m 2s\tremaining: 17.5s\n",
      "22196:\tlearn: 2.2115774\ttotal: 8m 2s\tremaining: 17.4s\n",
      "22197:\tlearn: 2.2115110\ttotal: 8m 2s\tremaining: 17.4s\n",
      "22198:\tlearn: 2.2114354\ttotal: 8m 2s\tremaining: 17.4s\n",
      "22199:\tlearn: 2.2113512\ttotal: 8m 2s\tremaining: 17.4s\n",
      "22200:\tlearn: 2.2113504\ttotal: 8m 2s\tremaining: 17.4s\n",
      "22201:\tlearn: 2.2112940\ttotal: 8m 2s\tremaining: 17.3s\n",
      "22202:\tlearn: 2.2112260\ttotal: 8m 2s\tremaining: 17.3s\n",
      "22203:\tlearn: 2.2111679\ttotal: 8m 2s\tremaining: 17.3s\n",
      "22204:\tlearn: 2.2111175\ttotal: 8m 2s\tremaining: 17.3s\n",
      "22205:\tlearn: 2.2110544\ttotal: 8m 2s\tremaining: 17.2s\n",
      "22206:\tlearn: 2.2110039\ttotal: 8m 2s\tremaining: 17.2s\n",
      "22207:\tlearn: 2.2108948\ttotal: 8m 2s\tremaining: 17.2s\n",
      "22208:\tlearn: 2.2108192\ttotal: 8m 2s\tremaining: 17.2s\n",
      "22209:\tlearn: 2.2107935\ttotal: 8m 2s\tremaining: 17.2s\n",
      "22210:\tlearn: 2.2107044\ttotal: 8m 2s\tremaining: 17.1s\n",
      "22211:\tlearn: 2.2107016\ttotal: 8m 2s\tremaining: 17.1s\n",
      "22212:\tlearn: 2.2106162\ttotal: 8m 2s\tremaining: 17.1s\n",
      "22213:\tlearn: 2.2105191\ttotal: 8m 2s\tremaining: 17.1s\n",
      "22214:\tlearn: 2.2103918\ttotal: 8m 2s\tremaining: 17s\n",
      "22215:\tlearn: 2.2102880\ttotal: 8m 2s\tremaining: 17s\n",
      "22216:\tlearn: 2.2102119\ttotal: 8m 2s\tremaining: 17s\n",
      "22217:\tlearn: 2.2101593\ttotal: 8m 2s\tremaining: 17s\n",
      "22218:\tlearn: 2.2100609\ttotal: 8m 2s\tremaining: 17s\n",
      "22219:\tlearn: 2.2100594\ttotal: 8m 2s\tremaining: 16.9s\n",
      "22220:\tlearn: 2.2099590\ttotal: 8m 2s\tremaining: 16.9s\n",
      "22221:\tlearn: 2.2098773\ttotal: 8m 2s\tremaining: 16.9s\n",
      "22222:\tlearn: 2.2098761\ttotal: 8m 2s\tremaining: 16.9s\n",
      "22223:\tlearn: 2.2097696\ttotal: 8m 2s\tremaining: 16.9s\n",
      "22224:\tlearn: 2.2096438\ttotal: 8m 2s\tremaining: 16.8s\n",
      "22225:\tlearn: 2.2095618\ttotal: 8m 2s\tremaining: 16.8s\n",
      "22226:\tlearn: 2.2094856\ttotal: 8m 2s\tremaining: 16.8s\n",
      "22227:\tlearn: 2.2094063\ttotal: 8m 2s\tremaining: 16.8s\n",
      "22228:\tlearn: 2.2092951\ttotal: 8m 2s\tremaining: 16.7s\n",
      "22229:\tlearn: 2.2092272\ttotal: 8m 2s\tremaining: 16.7s\n",
      "22230:\tlearn: 2.2091397\ttotal: 8m 2s\tremaining: 16.7s\n",
      "22231:\tlearn: 2.2090686\ttotal: 8m 2s\tremaining: 16.7s\n",
      "22232:\tlearn: 2.2089414\ttotal: 8m 2s\tremaining: 16.7s\n",
      "22233:\tlearn: 2.2088952\ttotal: 8m 2s\tremaining: 16.6s\n",
      "22234:\tlearn: 2.2088238\ttotal: 8m 2s\tremaining: 16.6s\n",
      "22235:\tlearn: 2.2087460\ttotal: 8m 2s\tremaining: 16.6s\n",
      "22236:\tlearn: 2.2087086\ttotal: 8m 2s\tremaining: 16.6s\n",
      "22237:\tlearn: 2.2086620\ttotal: 8m 3s\tremaining: 16.6s\n",
      "22238:\tlearn: 2.2086047\ttotal: 8m 3s\tremaining: 16.5s\n",
      "22239:\tlearn: 2.2085534\ttotal: 8m 3s\tremaining: 16.5s\n",
      "22240:\tlearn: 2.2084904\ttotal: 8m 3s\tremaining: 16.5s\n",
      "22241:\tlearn: 2.2083952\ttotal: 8m 3s\tremaining: 16.5s\n",
      "22242:\tlearn: 2.2082803\ttotal: 8m 3s\tremaining: 16.4s\n",
      "22243:\tlearn: 2.2082073\ttotal: 8m 3s\tremaining: 16.4s\n",
      "22244:\tlearn: 2.2081759\ttotal: 8m 3s\tremaining: 16.4s\n",
      "22245:\tlearn: 2.2080906\ttotal: 8m 3s\tremaining: 16.4s\n",
      "22246:\tlearn: 2.2080143\ttotal: 8m 3s\tremaining: 16.4s\n",
      "22247:\tlearn: 2.2079640\ttotal: 8m 3s\tremaining: 16.3s\n",
      "22248:\tlearn: 2.2078903\ttotal: 8m 3s\tremaining: 16.3s\n",
      "22249:\tlearn: 2.2078498\ttotal: 8m 3s\tremaining: 16.3s\n",
      "22250:\tlearn: 2.2077833\ttotal: 8m 3s\tremaining: 16.3s\n",
      "22251:\tlearn: 2.2076793\ttotal: 8m 3s\tremaining: 16.2s\n",
      "22252:\tlearn: 2.2074672\ttotal: 8m 3s\tremaining: 16.2s\n",
      "22253:\tlearn: 2.2073817\ttotal: 8m 3s\tremaining: 16.2s\n",
      "22254:\tlearn: 2.2072962\ttotal: 8m 3s\tremaining: 16.2s\n",
      "22255:\tlearn: 2.2072100\ttotal: 8m 3s\tremaining: 16.2s\n",
      "22256:\tlearn: 2.2072090\ttotal: 8m 3s\tremaining: 16.1s\n",
      "22257:\tlearn: 2.2070736\ttotal: 8m 3s\tremaining: 16.1s\n",
      "22258:\tlearn: 2.2070067\ttotal: 8m 3s\tremaining: 16.1s\n",
      "22259:\tlearn: 2.2069702\ttotal: 8m 3s\tremaining: 16.1s\n",
      "22260:\tlearn: 2.2068557\ttotal: 8m 3s\tremaining: 16.1s\n",
      "22261:\tlearn: 2.2068255\ttotal: 8m 3s\tremaining: 16s\n",
      "22262:\tlearn: 2.2067594\ttotal: 8m 3s\tremaining: 16s\n",
      "22263:\tlearn: 2.2067145\ttotal: 8m 3s\tremaining: 16s\n",
      "22264:\tlearn: 2.2066312\ttotal: 8m 3s\tremaining: 16s\n",
      "22265:\tlearn: 2.2065870\ttotal: 8m 3s\tremaining: 15.9s\n",
      "22266:\tlearn: 2.2065404\ttotal: 8m 3s\tremaining: 15.9s\n",
      "22267:\tlearn: 2.2064833\ttotal: 8m 3s\tremaining: 15.9s\n",
      "22268:\tlearn: 2.2063909\ttotal: 8m 3s\tremaining: 15.9s\n",
      "22269:\tlearn: 2.2063432\ttotal: 8m 3s\tremaining: 15.9s\n",
      "22270:\tlearn: 2.2062768\ttotal: 8m 3s\tremaining: 15.8s\n",
      "22271:\tlearn: 2.2062062\ttotal: 8m 3s\tremaining: 15.8s\n",
      "22272:\tlearn: 2.2061228\ttotal: 8m 3s\tremaining: 15.8s\n",
      "22273:\tlearn: 2.2060654\ttotal: 8m 3s\tremaining: 15.8s\n",
      "22274:\tlearn: 2.2059861\ttotal: 8m 3s\tremaining: 15.7s\n",
      "22275:\tlearn: 2.2059110\ttotal: 8m 3s\tremaining: 15.7s\n",
      "22276:\tlearn: 2.2058384\ttotal: 8m 3s\tremaining: 15.7s\n",
      "22277:\tlearn: 2.2057772\ttotal: 8m 3s\tremaining: 15.7s\n",
      "22278:\tlearn: 2.2056974\ttotal: 8m 3s\tremaining: 15.7s\n",
      "22279:\tlearn: 2.2056307\ttotal: 8m 3s\tremaining: 15.6s\n",
      "22280:\tlearn: 2.2055866\ttotal: 8m 3s\tremaining: 15.6s\n",
      "22281:\tlearn: 2.2055051\ttotal: 8m 3s\tremaining: 15.6s\n",
      "22282:\tlearn: 2.2054476\ttotal: 8m 3s\tremaining: 15.6s\n",
      "22283:\tlearn: 2.2054370\ttotal: 8m 3s\tremaining: 15.6s\n",
      "22284:\tlearn: 2.2053797\ttotal: 8m 3s\tremaining: 15.5s\n",
      "22285:\tlearn: 2.2053241\ttotal: 8m 4s\tremaining: 15.5s\n",
      "22286:\tlearn: 2.2052698\ttotal: 8m 4s\tremaining: 15.5s\n",
      "22287:\tlearn: 2.2051528\ttotal: 8m 4s\tremaining: 15.5s\n",
      "22288:\tlearn: 2.2050549\ttotal: 8m 4s\tremaining: 15.4s\n",
      "22289:\tlearn: 2.2049682\ttotal: 8m 4s\tremaining: 15.4s\n",
      "22290:\tlearn: 2.2049336\ttotal: 8m 4s\tremaining: 15.4s\n",
      "22291:\tlearn: 2.2048735\ttotal: 8m 4s\tremaining: 15.4s\n",
      "22292:\tlearn: 2.2047845\ttotal: 8m 4s\tremaining: 15.4s\n",
      "22293:\tlearn: 2.2047151\ttotal: 8m 4s\tremaining: 15.3s\n",
      "22294:\tlearn: 2.2046206\ttotal: 8m 4s\tremaining: 15.3s\n",
      "22295:\tlearn: 2.2045555\ttotal: 8m 4s\tremaining: 15.3s\n",
      "22296:\tlearn: 2.2044812\ttotal: 8m 4s\tremaining: 15.3s\n",
      "22297:\tlearn: 2.2043647\ttotal: 8m 4s\tremaining: 15.2s\n",
      "22298:\tlearn: 2.2042534\ttotal: 8m 4s\tremaining: 15.2s\n",
      "22299:\tlearn: 2.2041524\ttotal: 8m 4s\tremaining: 15.2s\n",
      "22300:\tlearn: 2.2040439\ttotal: 8m 4s\tremaining: 15.2s\n",
      "22301:\tlearn: 2.2039321\ttotal: 8m 4s\tremaining: 15.2s\n",
      "22302:\tlearn: 2.2038742\ttotal: 8m 4s\tremaining: 15.1s\n",
      "22303:\tlearn: 2.2037538\ttotal: 8m 4s\tremaining: 15.1s\n",
      "22304:\tlearn: 2.2037054\ttotal: 8m 4s\tremaining: 15.1s\n",
      "22305:\tlearn: 2.2036623\ttotal: 8m 4s\tremaining: 15.1s\n",
      "22306:\tlearn: 2.2035367\ttotal: 8m 4s\tremaining: 15.1s\n",
      "22307:\tlearn: 2.2034608\ttotal: 8m 4s\tremaining: 15s\n",
      "22308:\tlearn: 2.2034295\ttotal: 8m 4s\tremaining: 15s\n",
      "22309:\tlearn: 2.2034106\ttotal: 8m 4s\tremaining: 15s\n",
      "22310:\tlearn: 2.2032993\ttotal: 8m 4s\tremaining: 15s\n",
      "22311:\tlearn: 2.2032420\ttotal: 8m 4s\tremaining: 14.9s\n",
      "22312:\tlearn: 2.2031966\ttotal: 8m 4s\tremaining: 14.9s\n",
      "22313:\tlearn: 2.2030750\ttotal: 8m 4s\tremaining: 14.9s\n",
      "22314:\tlearn: 2.2030050\ttotal: 8m 4s\tremaining: 14.9s\n",
      "22315:\tlearn: 2.2029570\ttotal: 8m 4s\tremaining: 14.9s\n",
      "22316:\tlearn: 2.2028978\ttotal: 8m 4s\tremaining: 14.8s\n",
      "22317:\tlearn: 2.2028749\ttotal: 8m 4s\tremaining: 14.8s\n",
      "22318:\tlearn: 2.2028524\ttotal: 8m 4s\tremaining: 14.8s\n",
      "22319:\tlearn: 2.2027669\ttotal: 8m 4s\tremaining: 14.8s\n",
      "22320:\tlearn: 2.2026650\ttotal: 8m 4s\tremaining: 14.7s\n",
      "22321:\tlearn: 2.2025910\ttotal: 8m 4s\tremaining: 14.7s\n",
      "22322:\tlearn: 2.2025143\ttotal: 8m 4s\tremaining: 14.7s\n",
      "22323:\tlearn: 2.2024304\ttotal: 8m 4s\tremaining: 14.7s\n",
      "22324:\tlearn: 2.2023678\ttotal: 8m 4s\tremaining: 14.7s\n",
      "22325:\tlearn: 2.2023126\ttotal: 8m 4s\tremaining: 14.6s\n",
      "22326:\tlearn: 2.2022340\ttotal: 8m 4s\tremaining: 14.6s\n",
      "22327:\tlearn: 2.2021881\ttotal: 8m 4s\tremaining: 14.6s\n",
      "22328:\tlearn: 2.2020678\ttotal: 8m 4s\tremaining: 14.6s\n",
      "22329:\tlearn: 2.2020004\ttotal: 8m 4s\tremaining: 14.6s\n",
      "22330:\tlearn: 2.2019460\ttotal: 8m 4s\tremaining: 14.5s\n",
      "22331:\tlearn: 2.2018238\ttotal: 8m 5s\tremaining: 14.5s\n",
      "22332:\tlearn: 2.2017835\ttotal: 8m 5s\tremaining: 14.5s\n",
      "22333:\tlearn: 2.2017160\ttotal: 8m 5s\tremaining: 14.5s\n",
      "22334:\tlearn: 2.2017049\ttotal: 8m 5s\tremaining: 14.4s\n",
      "22335:\tlearn: 2.2016017\ttotal: 8m 5s\tremaining: 14.4s\n",
      "22336:\tlearn: 2.2015506\ttotal: 8m 5s\tremaining: 14.4s\n",
      "22337:\tlearn: 2.2014002\ttotal: 8m 5s\tremaining: 14.4s\n",
      "22338:\tlearn: 2.2013097\ttotal: 8m 5s\tremaining: 14.4s\n",
      "22339:\tlearn: 2.2012545\ttotal: 8m 5s\tremaining: 14.3s\n",
      "22340:\tlearn: 2.2011916\ttotal: 8m 5s\tremaining: 14.3s\n",
      "22341:\tlearn: 2.2011058\ttotal: 8m 5s\tremaining: 14.3s\n",
      "22342:\tlearn: 2.2010124\ttotal: 8m 5s\tremaining: 14.3s\n",
      "22343:\tlearn: 2.2009259\ttotal: 8m 5s\tremaining: 14.2s\n",
      "22344:\tlearn: 2.2008475\ttotal: 8m 5s\tremaining: 14.2s\n",
      "22345:\tlearn: 2.2007429\ttotal: 8m 5s\tremaining: 14.2s\n",
      "22346:\tlearn: 2.2006851\ttotal: 8m 5s\tremaining: 14.2s\n",
      "22347:\tlearn: 2.2005726\ttotal: 8m 5s\tremaining: 14.2s\n",
      "22348:\tlearn: 2.2004861\ttotal: 8m 5s\tremaining: 14.1s\n",
      "22349:\tlearn: 2.2004447\ttotal: 8m 5s\tremaining: 14.1s\n",
      "22350:\tlearn: 2.2003772\ttotal: 8m 5s\tremaining: 14.1s\n",
      "22351:\tlearn: 2.2003068\ttotal: 8m 5s\tremaining: 14.1s\n",
      "22352:\tlearn: 2.2002297\ttotal: 8m 5s\tremaining: 14.1s\n",
      "22353:\tlearn: 2.2001434\ttotal: 8m 5s\tremaining: 14s\n",
      "22354:\tlearn: 2.2000451\ttotal: 8m 5s\tremaining: 14s\n",
      "22355:\tlearn: 2.1999789\ttotal: 8m 5s\tremaining: 14s\n",
      "22356:\tlearn: 2.1999156\ttotal: 8m 5s\tremaining: 14s\n",
      "22357:\tlearn: 2.1998399\ttotal: 8m 5s\tremaining: 13.9s\n",
      "22358:\tlearn: 2.1997804\ttotal: 8m 5s\tremaining: 13.9s\n",
      "22359:\tlearn: 2.1997204\ttotal: 8m 5s\tremaining: 13.9s\n",
      "22360:\tlearn: 2.1996478\ttotal: 8m 5s\tremaining: 13.9s\n",
      "22361:\tlearn: 2.1995765\ttotal: 8m 5s\tremaining: 13.9s\n",
      "22362:\tlearn: 2.1995296\ttotal: 8m 5s\tremaining: 13.8s\n",
      "22363:\tlearn: 2.1994313\ttotal: 8m 5s\tremaining: 13.8s\n",
      "22364:\tlearn: 2.1993583\ttotal: 8m 5s\tremaining: 13.8s\n",
      "22365:\tlearn: 2.1993051\ttotal: 8m 5s\tremaining: 13.8s\n",
      "22366:\tlearn: 2.1992247\ttotal: 8m 5s\tremaining: 13.7s\n",
      "22367:\tlearn: 2.1991233\ttotal: 8m 5s\tremaining: 13.7s\n",
      "22368:\tlearn: 2.1990928\ttotal: 8m 5s\tremaining: 13.7s\n",
      "22369:\tlearn: 2.1990216\ttotal: 8m 5s\tremaining: 13.7s\n",
      "22370:\tlearn: 2.1989422\ttotal: 8m 5s\tremaining: 13.7s\n",
      "22371:\tlearn: 2.1988782\ttotal: 8m 5s\tremaining: 13.6s\n",
      "22372:\tlearn: 2.1988289\ttotal: 8m 5s\tremaining: 13.6s\n",
      "22373:\tlearn: 2.1987888\ttotal: 8m 6s\tremaining: 13.6s\n",
      "22374:\tlearn: 2.1987283\ttotal: 8m 6s\tremaining: 13.6s\n",
      "22375:\tlearn: 2.1986628\ttotal: 8m 6s\tremaining: 13.6s\n",
      "22376:\tlearn: 2.1985448\ttotal: 8m 6s\tremaining: 13.5s\n",
      "22377:\tlearn: 2.1984711\ttotal: 8m 6s\tremaining: 13.5s\n",
      "22378:\tlearn: 2.1984157\ttotal: 8m 6s\tremaining: 13.5s\n",
      "22379:\tlearn: 2.1983094\ttotal: 8m 6s\tremaining: 13.5s\n",
      "22380:\tlearn: 2.1982252\ttotal: 8m 6s\tremaining: 13.4s\n",
      "22381:\tlearn: 2.1981386\ttotal: 8m 6s\tremaining: 13.4s\n",
      "22382:\tlearn: 2.1980621\ttotal: 8m 6s\tremaining: 13.4s\n",
      "22383:\tlearn: 2.1979800\ttotal: 8m 6s\tremaining: 13.4s\n",
      "22384:\tlearn: 2.1979047\ttotal: 8m 6s\tremaining: 13.4s\n",
      "22385:\tlearn: 2.1978391\ttotal: 8m 6s\tremaining: 13.3s\n",
      "22386:\tlearn: 2.1977639\ttotal: 8m 6s\tremaining: 13.3s\n",
      "22387:\tlearn: 2.1976922\ttotal: 8m 6s\tremaining: 13.3s\n",
      "22388:\tlearn: 2.1976621\ttotal: 8m 6s\tremaining: 13.3s\n",
      "22389:\tlearn: 2.1975790\ttotal: 8m 6s\tremaining: 13.3s\n",
      "22390:\tlearn: 2.1975108\ttotal: 8m 6s\tremaining: 13.2s\n",
      "22391:\tlearn: 2.1974457\ttotal: 8m 6s\tremaining: 13.2s\n",
      "22392:\tlearn: 2.1973338\ttotal: 8m 6s\tremaining: 13.2s\n",
      "22393:\tlearn: 2.1972925\ttotal: 8m 6s\tremaining: 13.2s\n",
      "22394:\tlearn: 2.1972089\ttotal: 8m 6s\tremaining: 13.1s\n",
      "22395:\tlearn: 2.1971162\ttotal: 8m 6s\tremaining: 13.1s\n",
      "22396:\tlearn: 2.1970607\ttotal: 8m 6s\tremaining: 13.1s\n",
      "22397:\tlearn: 2.1969915\ttotal: 8m 6s\tremaining: 13.1s\n",
      "22398:\tlearn: 2.1969386\ttotal: 8m 6s\tremaining: 13.1s\n",
      "22399:\tlearn: 2.1968669\ttotal: 8m 6s\tremaining: 13s\n",
      "22400:\tlearn: 2.1967969\ttotal: 8m 6s\tremaining: 13s\n",
      "22401:\tlearn: 2.1967433\ttotal: 8m 6s\tremaining: 13s\n",
      "22402:\tlearn: 2.1966308\ttotal: 8m 6s\tremaining: 13s\n",
      "22403:\tlearn: 2.1965571\ttotal: 8m 6s\tremaining: 12.9s\n",
      "22404:\tlearn: 2.1965111\ttotal: 8m 6s\tremaining: 12.9s\n",
      "22405:\tlearn: 2.1964431\ttotal: 8m 6s\tremaining: 12.9s\n",
      "22406:\tlearn: 2.1963726\ttotal: 8m 6s\tremaining: 12.9s\n",
      "22407:\tlearn: 2.1962961\ttotal: 8m 6s\tremaining: 12.9s\n",
      "22408:\tlearn: 2.1962052\ttotal: 8m 6s\tremaining: 12.8s\n",
      "22409:\tlearn: 2.1961279\ttotal: 8m 6s\tremaining: 12.8s\n",
      "22410:\tlearn: 2.1960844\ttotal: 8m 6s\tremaining: 12.8s\n",
      "22411:\tlearn: 2.1960148\ttotal: 8m 6s\tremaining: 12.8s\n",
      "22412:\tlearn: 2.1959568\ttotal: 8m 7s\tremaining: 12.8s\n",
      "22413:\tlearn: 2.1958259\ttotal: 8m 7s\tremaining: 12.7s\n",
      "22414:\tlearn: 2.1957712\ttotal: 8m 7s\tremaining: 12.7s\n",
      "22415:\tlearn: 2.1956850\ttotal: 8m 7s\tremaining: 12.7s\n",
      "22416:\tlearn: 2.1956623\ttotal: 8m 7s\tremaining: 12.7s\n",
      "22417:\tlearn: 2.1955641\ttotal: 8m 7s\tremaining: 12.6s\n",
      "22418:\tlearn: 2.1954854\ttotal: 8m 7s\tremaining: 12.6s\n",
      "22419:\tlearn: 2.1954240\ttotal: 8m 7s\tremaining: 12.6s\n",
      "22420:\tlearn: 2.1953508\ttotal: 8m 7s\tremaining: 12.6s\n",
      "22421:\tlearn: 2.1953028\ttotal: 8m 7s\tremaining: 12.6s\n",
      "22422:\tlearn: 2.1952049\ttotal: 8m 7s\tremaining: 12.5s\n",
      "22423:\tlearn: 2.1951101\ttotal: 8m 7s\tremaining: 12.5s\n",
      "22424:\tlearn: 2.1950115\ttotal: 8m 7s\tremaining: 12.5s\n",
      "22425:\tlearn: 2.1949192\ttotal: 8m 7s\tremaining: 12.5s\n",
      "22426:\tlearn: 2.1948924\ttotal: 8m 7s\tremaining: 12.5s\n",
      "22427:\tlearn: 2.1948606\ttotal: 8m 7s\tremaining: 12.4s\n",
      "22428:\tlearn: 2.1947906\ttotal: 8m 7s\tremaining: 12.4s\n",
      "22429:\tlearn: 2.1947205\ttotal: 8m 7s\tremaining: 12.4s\n",
      "22430:\tlearn: 2.1947193\ttotal: 8m 7s\tremaining: 12.4s\n",
      "22431:\tlearn: 2.1946088\ttotal: 8m 7s\tremaining: 12.3s\n",
      "22432:\tlearn: 2.1945321\ttotal: 8m 7s\tremaining: 12.3s\n",
      "22433:\tlearn: 2.1944628\ttotal: 8m 7s\tremaining: 12.3s\n",
      "22434:\tlearn: 2.1943296\ttotal: 8m 7s\tremaining: 12.3s\n",
      "22435:\tlearn: 2.1942743\ttotal: 8m 7s\tremaining: 12.3s\n",
      "22436:\tlearn: 2.1942296\ttotal: 8m 7s\tremaining: 12.2s\n",
      "22437:\tlearn: 2.1941438\ttotal: 8m 7s\tremaining: 12.2s\n",
      "22438:\tlearn: 2.1940724\ttotal: 8m 7s\tremaining: 12.2s\n",
      "22439:\tlearn: 2.1939733\ttotal: 8m 7s\tremaining: 12.2s\n",
      "22440:\tlearn: 2.1938141\ttotal: 8m 7s\tremaining: 12.1s\n",
      "22441:\tlearn: 2.1937772\ttotal: 8m 7s\tremaining: 12.1s\n",
      "22442:\tlearn: 2.1937228\ttotal: 8m 7s\tremaining: 12.1s\n",
      "22443:\tlearn: 2.1936068\ttotal: 8m 7s\tremaining: 12.1s\n",
      "22444:\tlearn: 2.1935278\ttotal: 8m 7s\tremaining: 12.1s\n",
      "22445:\tlearn: 2.1934150\ttotal: 8m 7s\tremaining: 12s\n",
      "22446:\tlearn: 2.1933111\ttotal: 8m 7s\tremaining: 12s\n",
      "22447:\tlearn: 2.1932813\ttotal: 8m 7s\tremaining: 12s\n",
      "22448:\tlearn: 2.1932343\ttotal: 8m 7s\tremaining: 12s\n",
      "22449:\tlearn: 2.1932030\ttotal: 8m 7s\tremaining: 12s\n",
      "22450:\tlearn: 2.1930979\ttotal: 8m 7s\tremaining: 11.9s\n",
      "22451:\tlearn: 2.1930060\ttotal: 8m 7s\tremaining: 11.9s\n",
      "22452:\tlearn: 2.1929111\ttotal: 8m 7s\tremaining: 11.9s\n",
      "22453:\tlearn: 2.1928406\ttotal: 8m 8s\tremaining: 11.9s\n",
      "22454:\tlearn: 2.1927563\ttotal: 8m 8s\tremaining: 11.8s\n",
      "22455:\tlearn: 2.1926724\ttotal: 8m 8s\tremaining: 11.8s\n",
      "22456:\tlearn: 2.1926188\ttotal: 8m 8s\tremaining: 11.8s\n",
      "22457:\tlearn: 2.1925208\ttotal: 8m 8s\tremaining: 11.8s\n",
      "22458:\tlearn: 2.1924866\ttotal: 8m 8s\tremaining: 11.8s\n",
      "22459:\tlearn: 2.1923635\ttotal: 8m 8s\tremaining: 11.7s\n",
      "22460:\tlearn: 2.1923136\ttotal: 8m 8s\tremaining: 11.7s\n",
      "22461:\tlearn: 2.1922497\ttotal: 8m 8s\tremaining: 11.7s\n",
      "22462:\tlearn: 2.1922112\ttotal: 8m 8s\tremaining: 11.7s\n",
      "22463:\tlearn: 2.1921147\ttotal: 8m 8s\tremaining: 11.6s\n",
      "22464:\tlearn: 2.1920377\ttotal: 8m 8s\tremaining: 11.6s\n",
      "22465:\tlearn: 2.1919642\ttotal: 8m 8s\tremaining: 11.6s\n",
      "22466:\tlearn: 2.1918904\ttotal: 8m 8s\tremaining: 11.6s\n",
      "22467:\tlearn: 2.1918185\ttotal: 8m 8s\tremaining: 11.6s\n",
      "22468:\tlearn: 2.1917563\ttotal: 8m 8s\tremaining: 11.5s\n",
      "22469:\tlearn: 2.1917065\ttotal: 8m 8s\tremaining: 11.5s\n",
      "22470:\tlearn: 2.1915769\ttotal: 8m 8s\tremaining: 11.5s\n",
      "22471:\tlearn: 2.1915258\ttotal: 8m 8s\tremaining: 11.5s\n",
      "22472:\tlearn: 2.1914494\ttotal: 8m 8s\tremaining: 11.5s\n",
      "22473:\tlearn: 2.1913950\ttotal: 8m 8s\tremaining: 11.4s\n",
      "22474:\tlearn: 2.1913353\ttotal: 8m 8s\tremaining: 11.4s\n",
      "22475:\tlearn: 2.1912998\ttotal: 8m 8s\tremaining: 11.4s\n",
      "22476:\tlearn: 2.1912592\ttotal: 8m 8s\tremaining: 11.4s\n",
      "22477:\tlearn: 2.1911901\ttotal: 8m 8s\tremaining: 11.3s\n",
      "22478:\tlearn: 2.1911386\ttotal: 8m 8s\tremaining: 11.3s\n",
      "22479:\tlearn: 2.1910284\ttotal: 8m 8s\tremaining: 11.3s\n",
      "22480:\tlearn: 2.1909318\ttotal: 8m 8s\tremaining: 11.3s\n",
      "22481:\tlearn: 2.1908432\ttotal: 8m 8s\tremaining: 11.3s\n",
      "22482:\tlearn: 2.1907480\ttotal: 8m 8s\tremaining: 11.2s\n",
      "22483:\tlearn: 2.1906569\ttotal: 8m 8s\tremaining: 11.2s\n",
      "22484:\tlearn: 2.1905463\ttotal: 8m 8s\tremaining: 11.2s\n",
      "22485:\tlearn: 2.1904648\ttotal: 8m 8s\tremaining: 11.2s\n",
      "22486:\tlearn: 2.1903932\ttotal: 8m 8s\tremaining: 11.2s\n",
      "22487:\tlearn: 2.1902708\ttotal: 8m 8s\tremaining: 11.1s\n",
      "22488:\tlearn: 2.1902190\ttotal: 8m 8s\tremaining: 11.1s\n",
      "22489:\tlearn: 2.1901244\ttotal: 8m 8s\tremaining: 11.1s\n",
      "22490:\tlearn: 2.1900554\ttotal: 8m 8s\tremaining: 11.1s\n",
      "22491:\tlearn: 2.1899839\ttotal: 8m 8s\tremaining: 11s\n",
      "22492:\tlearn: 2.1899297\ttotal: 8m 9s\tremaining: 11s\n",
      "22493:\tlearn: 2.1898547\ttotal: 8m 9s\tremaining: 11s\n",
      "22494:\tlearn: 2.1897904\ttotal: 8m 9s\tremaining: 11s\n",
      "22495:\tlearn: 2.1897319\ttotal: 8m 9s\tremaining: 11s\n",
      "22496:\tlearn: 2.1896525\ttotal: 8m 9s\tremaining: 10.9s\n",
      "22497:\tlearn: 2.1895535\ttotal: 8m 9s\tremaining: 10.9s\n",
      "22498:\tlearn: 2.1895231\ttotal: 8m 9s\tremaining: 10.9s\n",
      "22499:\tlearn: 2.1894782\ttotal: 8m 9s\tremaining: 10.9s\n",
      "22500:\tlearn: 2.1893776\ttotal: 8m 9s\tremaining: 10.8s\n",
      "22501:\tlearn: 2.1893013\ttotal: 8m 9s\tremaining: 10.8s\n",
      "22502:\tlearn: 2.1892492\ttotal: 8m 9s\tremaining: 10.8s\n",
      "22503:\tlearn: 2.1892263\ttotal: 8m 9s\tremaining: 10.8s\n",
      "22504:\tlearn: 2.1891419\ttotal: 8m 9s\tremaining: 10.8s\n",
      "22505:\tlearn: 2.1890461\ttotal: 8m 9s\tremaining: 10.7s\n",
      "22506:\tlearn: 2.1889402\ttotal: 8m 9s\tremaining: 10.7s\n",
      "22507:\tlearn: 2.1888789\ttotal: 8m 9s\tremaining: 10.7s\n",
      "22508:\tlearn: 2.1887597\ttotal: 8m 9s\tremaining: 10.7s\n",
      "22509:\tlearn: 2.1886120\ttotal: 8m 9s\tremaining: 10.7s\n",
      "22510:\tlearn: 2.1885619\ttotal: 8m 9s\tremaining: 10.6s\n",
      "22511:\tlearn: 2.1884745\ttotal: 8m 9s\tremaining: 10.6s\n",
      "22512:\tlearn: 2.1883922\ttotal: 8m 9s\tremaining: 10.6s\n",
      "22513:\tlearn: 2.1883185\ttotal: 8m 9s\tremaining: 10.6s\n",
      "22514:\tlearn: 2.1882390\ttotal: 8m 9s\tremaining: 10.5s\n",
      "22515:\tlearn: 2.1881119\ttotal: 8m 9s\tremaining: 10.5s\n",
      "22516:\tlearn: 2.1880388\ttotal: 8m 9s\tremaining: 10.5s\n",
      "22517:\tlearn: 2.1879687\ttotal: 8m 9s\tremaining: 10.5s\n",
      "22518:\tlearn: 2.1879001\ttotal: 8m 9s\tremaining: 10.5s\n",
      "22519:\tlearn: 2.1877985\ttotal: 8m 9s\tremaining: 10.4s\n",
      "22520:\tlearn: 2.1877210\ttotal: 8m 9s\tremaining: 10.4s\n",
      "22521:\tlearn: 2.1876512\ttotal: 8m 9s\tremaining: 10.4s\n",
      "22522:\tlearn: 2.1875727\ttotal: 8m 9s\tremaining: 10.4s\n",
      "22523:\tlearn: 2.1874848\ttotal: 8m 9s\tremaining: 10.3s\n",
      "22524:\tlearn: 2.1874260\ttotal: 8m 9s\tremaining: 10.3s\n",
      "22525:\tlearn: 2.1873201\ttotal: 8m 9s\tremaining: 10.3s\n",
      "22526:\tlearn: 2.1872788\ttotal: 8m 9s\tremaining: 10.3s\n",
      "22527:\tlearn: 2.1872419\ttotal: 8m 9s\tremaining: 10.3s\n",
      "22528:\tlearn: 2.1871574\ttotal: 8m 9s\tremaining: 10.2s\n",
      "22529:\tlearn: 2.1871000\ttotal: 8m 9s\tremaining: 10.2s\n",
      "22530:\tlearn: 2.1870246\ttotal: 8m 9s\tremaining: 10.2s\n",
      "22531:\tlearn: 2.1869497\ttotal: 8m 9s\tremaining: 10.2s\n",
      "22532:\tlearn: 2.1869016\ttotal: 8m 9s\tremaining: 10.2s\n",
      "22533:\tlearn: 2.1868634\ttotal: 8m 9s\tremaining: 10.1s\n",
      "22534:\tlearn: 2.1867980\ttotal: 8m 10s\tremaining: 10.1s\n",
      "22535:\tlearn: 2.1867634\ttotal: 8m 10s\tremaining: 10.1s\n",
      "22536:\tlearn: 2.1866559\ttotal: 8m 10s\tremaining: 10.1s\n",
      "22537:\tlearn: 2.1865927\ttotal: 8m 10s\tremaining: 10s\n",
      "22538:\tlearn: 2.1865575\ttotal: 8m 10s\tremaining: 10s\n",
      "22539:\tlearn: 2.1864475\ttotal: 8m 10s\tremaining: 10s\n",
      "22540:\tlearn: 2.1863928\ttotal: 8m 10s\tremaining: 9.98s\n",
      "22541:\tlearn: 2.1863076\ttotal: 8m 10s\tremaining: 9.96s\n",
      "22542:\tlearn: 2.1862159\ttotal: 8m 10s\tremaining: 9.94s\n",
      "22543:\tlearn: 2.1861728\ttotal: 8m 10s\tremaining: 9.91s\n",
      "22544:\tlearn: 2.1860803\ttotal: 8m 10s\tremaining: 9.89s\n",
      "22545:\tlearn: 2.1860023\ttotal: 8m 10s\tremaining: 9.87s\n",
      "22546:\tlearn: 2.1859408\ttotal: 8m 10s\tremaining: 9.85s\n",
      "22547:\tlearn: 2.1858600\ttotal: 8m 10s\tremaining: 9.83s\n",
      "22548:\tlearn: 2.1858452\ttotal: 8m 10s\tremaining: 9.81s\n",
      "22549:\tlearn: 2.1857582\ttotal: 8m 10s\tremaining: 9.79s\n",
      "22550:\tlearn: 2.1857171\ttotal: 8m 10s\tremaining: 9.76s\n",
      "22551:\tlearn: 2.1856215\ttotal: 8m 10s\tremaining: 9.74s\n",
      "22552:\tlearn: 2.1855319\ttotal: 8m 10s\tremaining: 9.72s\n",
      "22553:\tlearn: 2.1854337\ttotal: 8m 10s\tremaining: 9.7s\n",
      "22554:\tlearn: 2.1853064\ttotal: 8m 10s\tremaining: 9.68s\n",
      "22555:\tlearn: 2.1852604\ttotal: 8m 10s\tremaining: 9.65s\n",
      "22556:\tlearn: 2.1851551\ttotal: 8m 10s\tremaining: 9.63s\n",
      "22557:\tlearn: 2.1850909\ttotal: 8m 10s\tremaining: 9.61s\n",
      "22558:\tlearn: 2.1850359\ttotal: 8m 10s\tremaining: 9.59s\n",
      "22559:\tlearn: 2.1850049\ttotal: 8m 10s\tremaining: 9.57s\n",
      "22560:\tlearn: 2.1849415\ttotal: 8m 10s\tremaining: 9.55s\n",
      "22561:\tlearn: 2.1849408\ttotal: 8m 10s\tremaining: 9.52s\n",
      "22562:\tlearn: 2.1849247\ttotal: 8m 10s\tremaining: 9.5s\n",
      "22563:\tlearn: 2.1848789\ttotal: 8m 10s\tremaining: 9.48s\n",
      "22564:\tlearn: 2.1848468\ttotal: 8m 10s\tremaining: 9.46s\n",
      "22565:\tlearn: 2.1847937\ttotal: 8m 10s\tremaining: 9.44s\n",
      "22566:\tlearn: 2.1847294\ttotal: 8m 10s\tremaining: 9.41s\n",
      "22567:\tlearn: 2.1846784\ttotal: 8m 10s\tremaining: 9.39s\n",
      "22568:\tlearn: 2.1846313\ttotal: 8m 10s\tremaining: 9.37s\n",
      "22569:\tlearn: 2.1845540\ttotal: 8m 10s\tremaining: 9.35s\n",
      "22570:\tlearn: 2.1845033\ttotal: 8m 10s\tremaining: 9.33s\n",
      "22571:\tlearn: 2.1843962\ttotal: 8m 10s\tremaining: 9.31s\n",
      "22572:\tlearn: 2.1843059\ttotal: 8m 10s\tremaining: 9.29s\n",
      "22573:\tlearn: 2.1842513\ttotal: 8m 10s\tremaining: 9.26s\n",
      "22574:\tlearn: 2.1841842\ttotal: 8m 10s\tremaining: 9.24s\n",
      "22575:\tlearn: 2.1841437\ttotal: 8m 10s\tremaining: 9.22s\n",
      "22576:\tlearn: 2.1840682\ttotal: 8m 10s\tremaining: 9.2s\n",
      "22577:\tlearn: 2.1840290\ttotal: 8m 10s\tremaining: 9.18s\n",
      "22578:\tlearn: 2.1839183\ttotal: 8m 10s\tremaining: 9.15s\n",
      "22579:\tlearn: 2.1838319\ttotal: 8m 11s\tremaining: 9.13s\n",
      "22580:\tlearn: 2.1837664\ttotal: 8m 11s\tremaining: 9.11s\n",
      "22581:\tlearn: 2.1837190\ttotal: 8m 11s\tremaining: 9.09s\n",
      "22582:\tlearn: 2.1836987\ttotal: 8m 11s\tremaining: 9.07s\n",
      "22583:\tlearn: 2.1836238\ttotal: 8m 11s\tremaining: 9.05s\n",
      "22584:\tlearn: 2.1835721\ttotal: 8m 11s\tremaining: 9.02s\n",
      "22585:\tlearn: 2.1834770\ttotal: 8m 11s\tremaining: 9s\n",
      "22586:\tlearn: 2.1834142\ttotal: 8m 11s\tremaining: 8.98s\n",
      "22587:\tlearn: 2.1833582\ttotal: 8m 11s\tremaining: 8.96s\n",
      "22588:\tlearn: 2.1832662\ttotal: 8m 11s\tremaining: 8.94s\n",
      "22589:\tlearn: 2.1831553\ttotal: 8m 11s\tremaining: 8.91s\n",
      "22590:\tlearn: 2.1831154\ttotal: 8m 11s\tremaining: 8.89s\n",
      "22591:\tlearn: 2.1830704\ttotal: 8m 11s\tremaining: 8.87s\n",
      "22592:\tlearn: 2.1829732\ttotal: 8m 11s\tremaining: 8.85s\n",
      "22593:\tlearn: 2.1828803\ttotal: 8m 11s\tremaining: 8.83s\n",
      "22594:\tlearn: 2.1828142\ttotal: 8m 11s\tremaining: 8.81s\n",
      "22595:\tlearn: 2.1827576\ttotal: 8m 11s\tremaining: 8.79s\n",
      "22596:\tlearn: 2.1826488\ttotal: 8m 11s\tremaining: 8.76s\n",
      "22597:\tlearn: 2.1824907\ttotal: 8m 11s\tremaining: 8.74s\n",
      "22598:\tlearn: 2.1823900\ttotal: 8m 11s\tremaining: 8.72s\n",
      "22599:\tlearn: 2.1822964\ttotal: 8m 11s\tremaining: 8.7s\n",
      "22600:\tlearn: 2.1821988\ttotal: 8m 11s\tremaining: 8.68s\n",
      "22601:\tlearn: 2.1821131\ttotal: 8m 11s\tremaining: 8.65s\n",
      "22602:\tlearn: 2.1820514\ttotal: 8m 11s\tremaining: 8.63s\n",
      "22603:\tlearn: 2.1819870\ttotal: 8m 11s\tremaining: 8.61s\n",
      "22604:\tlearn: 2.1818981\ttotal: 8m 11s\tremaining: 8.59s\n",
      "22605:\tlearn: 2.1818751\ttotal: 8m 11s\tremaining: 8.57s\n",
      "22606:\tlearn: 2.1818125\ttotal: 8m 11s\tremaining: 8.55s\n",
      "22607:\tlearn: 2.1817409\ttotal: 8m 11s\tremaining: 8.52s\n",
      "22608:\tlearn: 2.1816601\ttotal: 8m 11s\tremaining: 8.5s\n",
      "22609:\tlearn: 2.1815894\ttotal: 8m 11s\tremaining: 8.48s\n",
      "22610:\tlearn: 2.1815154\ttotal: 8m 11s\tremaining: 8.46s\n",
      "22611:\tlearn: 2.1814290\ttotal: 8m 11s\tremaining: 8.44s\n",
      "22612:\tlearn: 2.1813884\ttotal: 8m 11s\tremaining: 8.42s\n",
      "22613:\tlearn: 2.1812819\ttotal: 8m 11s\tremaining: 8.39s\n",
      "22614:\tlearn: 2.1812375\ttotal: 8m 11s\tremaining: 8.37s\n",
      "22615:\tlearn: 2.1811095\ttotal: 8m 11s\tremaining: 8.35s\n",
      "22616:\tlearn: 2.1810340\ttotal: 8m 11s\tremaining: 8.33s\n",
      "22617:\tlearn: 2.1809836\ttotal: 8m 11s\tremaining: 8.31s\n",
      "22618:\tlearn: 2.1809307\ttotal: 8m 11s\tremaining: 8.29s\n",
      "22619:\tlearn: 2.1808722\ttotal: 8m 11s\tremaining: 8.26s\n",
      "22620:\tlearn: 2.1807469\ttotal: 8m 11s\tremaining: 8.24s\n",
      "22621:\tlearn: 2.1806601\ttotal: 8m 11s\tremaining: 8.22s\n",
      "22622:\tlearn: 2.1806177\ttotal: 8m 12s\tremaining: 8.2s\n",
      "22623:\tlearn: 2.1805086\ttotal: 8m 12s\tremaining: 8.18s\n",
      "22624:\tlearn: 2.1804194\ttotal: 8m 12s\tremaining: 8.15s\n",
      "22625:\tlearn: 2.1803022\ttotal: 8m 12s\tremaining: 8.13s\n",
      "22626:\tlearn: 2.1802417\ttotal: 8m 12s\tremaining: 8.11s\n",
      "22627:\tlearn: 2.1801754\ttotal: 8m 12s\tremaining: 8.09s\n",
      "22628:\tlearn: 2.1801024\ttotal: 8m 12s\tremaining: 8.07s\n",
      "22629:\tlearn: 2.1800398\ttotal: 8m 12s\tremaining: 8.05s\n",
      "22630:\tlearn: 2.1799974\ttotal: 8m 12s\tremaining: 8.02s\n",
      "22631:\tlearn: 2.1799437\ttotal: 8m 12s\tremaining: 8s\n",
      "22632:\tlearn: 2.1798819\ttotal: 8m 12s\tremaining: 7.98s\n",
      "22633:\tlearn: 2.1798143\ttotal: 8m 12s\tremaining: 7.96s\n",
      "22634:\tlearn: 2.1797426\ttotal: 8m 12s\tremaining: 7.94s\n",
      "22635:\tlearn: 2.1797207\ttotal: 8m 12s\tremaining: 7.92s\n",
      "22636:\tlearn: 2.1796721\ttotal: 8m 12s\tremaining: 7.89s\n",
      "22637:\tlearn: 2.1795881\ttotal: 8m 12s\tremaining: 7.87s\n",
      "22638:\tlearn: 2.1795063\ttotal: 8m 12s\tremaining: 7.85s\n",
      "22639:\tlearn: 2.1794411\ttotal: 8m 12s\tremaining: 7.83s\n",
      "22640:\tlearn: 2.1793634\ttotal: 8m 12s\tremaining: 7.81s\n",
      "22641:\tlearn: 2.1793095\ttotal: 8m 12s\tremaining: 7.79s\n",
      "22642:\tlearn: 2.1792365\ttotal: 8m 12s\tremaining: 7.76s\n",
      "22643:\tlearn: 2.1791814\ttotal: 8m 12s\tremaining: 7.74s\n",
      "22644:\tlearn: 2.1790932\ttotal: 8m 12s\tremaining: 7.72s\n",
      "22645:\tlearn: 2.1789874\ttotal: 8m 12s\tremaining: 7.7s\n",
      "22646:\tlearn: 2.1788984\ttotal: 8m 12s\tremaining: 7.68s\n",
      "22647:\tlearn: 2.1788525\ttotal: 8m 12s\tremaining: 7.66s\n",
      "22648:\tlearn: 2.1788038\ttotal: 8m 12s\tremaining: 7.63s\n",
      "22649:\tlearn: 2.1787507\ttotal: 8m 12s\tremaining: 7.61s\n",
      "22650:\tlearn: 2.1786805\ttotal: 8m 12s\tremaining: 7.59s\n",
      "22651:\tlearn: 2.1786583\ttotal: 8m 12s\tremaining: 7.57s\n",
      "22652:\tlearn: 2.1785605\ttotal: 8m 12s\tremaining: 7.55s\n",
      "22653:\tlearn: 2.1785038\ttotal: 8m 12s\tremaining: 7.52s\n",
      "22654:\tlearn: 2.1784786\ttotal: 8m 12s\tremaining: 7.5s\n",
      "22655:\tlearn: 2.1784430\ttotal: 8m 12s\tremaining: 7.48s\n",
      "22656:\tlearn: 2.1784066\ttotal: 8m 12s\tremaining: 7.46s\n",
      "22657:\tlearn: 2.1783505\ttotal: 8m 12s\tremaining: 7.44s\n",
      "22658:\tlearn: 2.1782833\ttotal: 8m 12s\tremaining: 7.42s\n",
      "22659:\tlearn: 2.1781564\ttotal: 8m 12s\tremaining: 7.39s\n",
      "22660:\tlearn: 2.1780969\ttotal: 8m 12s\tremaining: 7.37s\n",
      "22661:\tlearn: 2.1779901\ttotal: 8m 12s\tremaining: 7.35s\n",
      "22662:\tlearn: 2.1779541\ttotal: 8m 12s\tremaining: 7.33s\n",
      "22663:\tlearn: 2.1779026\ttotal: 8m 12s\tremaining: 7.31s\n",
      "22664:\tlearn: 2.1778443\ttotal: 8m 12s\tremaining: 7.29s\n",
      "22665:\tlearn: 2.1778139\ttotal: 8m 12s\tremaining: 7.26s\n",
      "22666:\tlearn: 2.1777273\ttotal: 8m 12s\tremaining: 7.24s\n",
      "22667:\tlearn: 2.1776761\ttotal: 8m 12s\tremaining: 7.22s\n",
      "22668:\tlearn: 2.1775878\ttotal: 8m 12s\tremaining: 7.2s\n",
      "22669:\tlearn: 2.1774826\ttotal: 8m 13s\tremaining: 7.18s\n",
      "22670:\tlearn: 2.1773128\ttotal: 8m 13s\tremaining: 7.15s\n",
      "22671:\tlearn: 2.1772105\ttotal: 8m 13s\tremaining: 7.13s\n",
      "22672:\tlearn: 2.1771837\ttotal: 8m 13s\tremaining: 7.11s\n",
      "22673:\tlearn: 2.1771285\ttotal: 8m 13s\tremaining: 7.09s\n",
      "22674:\tlearn: 2.1770865\ttotal: 8m 13s\tremaining: 7.07s\n",
      "22675:\tlearn: 2.1769878\ttotal: 8m 13s\tremaining: 7.05s\n",
      "22676:\tlearn: 2.1769209\ttotal: 8m 13s\tremaining: 7.02s\n",
      "22677:\tlearn: 2.1768393\ttotal: 8m 13s\tremaining: 7s\n",
      "22678:\tlearn: 2.1767692\ttotal: 8m 13s\tremaining: 6.98s\n",
      "22679:\tlearn: 2.1767177\ttotal: 8m 13s\tremaining: 6.96s\n",
      "22680:\tlearn: 2.1766535\ttotal: 8m 13s\tremaining: 6.94s\n",
      "22681:\tlearn: 2.1765213\ttotal: 8m 13s\tremaining: 6.92s\n",
      "22682:\tlearn: 2.1764238\ttotal: 8m 13s\tremaining: 6.89s\n",
      "22683:\tlearn: 2.1763663\ttotal: 8m 13s\tremaining: 6.87s\n",
      "22684:\tlearn: 2.1762618\ttotal: 8m 13s\tremaining: 6.85s\n",
      "22685:\tlearn: 2.1761776\ttotal: 8m 13s\tremaining: 6.83s\n",
      "22686:\tlearn: 2.1761173\ttotal: 8m 13s\tremaining: 6.81s\n",
      "22687:\tlearn: 2.1759945\ttotal: 8m 13s\tremaining: 6.79s\n",
      "22688:\tlearn: 2.1759847\ttotal: 8m 13s\tremaining: 6.76s\n",
      "22689:\tlearn: 2.1759471\ttotal: 8m 13s\tremaining: 6.74s\n",
      "22690:\tlearn: 2.1758886\ttotal: 8m 13s\tremaining: 6.72s\n",
      "22691:\tlearn: 2.1758229\ttotal: 8m 13s\tremaining: 6.7s\n",
      "22692:\tlearn: 2.1757456\ttotal: 8m 13s\tremaining: 6.68s\n",
      "22693:\tlearn: 2.1756914\ttotal: 8m 13s\tremaining: 6.66s\n",
      "22694:\tlearn: 2.1756578\ttotal: 8m 13s\tremaining: 6.63s\n",
      "22695:\tlearn: 2.1755781\ttotal: 8m 13s\tremaining: 6.61s\n",
      "22696:\tlearn: 2.1755057\ttotal: 8m 13s\tremaining: 6.59s\n",
      "22697:\tlearn: 2.1754363\ttotal: 8m 13s\tremaining: 6.57s\n",
      "22698:\tlearn: 2.1753434\ttotal: 8m 13s\tremaining: 6.55s\n",
      "22699:\tlearn: 2.1752765\ttotal: 8m 13s\tremaining: 6.52s\n",
      "22700:\tlearn: 2.1751696\ttotal: 8m 13s\tremaining: 6.5s\n",
      "22701:\tlearn: 2.1750879\ttotal: 8m 13s\tremaining: 6.48s\n",
      "22702:\tlearn: 2.1750237\ttotal: 8m 13s\tremaining: 6.46s\n",
      "22703:\tlearn: 2.1749840\ttotal: 8m 13s\tremaining: 6.44s\n",
      "22704:\tlearn: 2.1748742\ttotal: 8m 13s\tremaining: 6.42s\n",
      "22705:\tlearn: 2.1747500\ttotal: 8m 13s\tremaining: 6.39s\n",
      "22706:\tlearn: 2.1746611\ttotal: 8m 13s\tremaining: 6.37s\n",
      "22707:\tlearn: 2.1745969\ttotal: 8m 13s\tremaining: 6.35s\n",
      "22708:\tlearn: 2.1745657\ttotal: 8m 13s\tremaining: 6.33s\n",
      "22709:\tlearn: 2.1744718\ttotal: 8m 13s\tremaining: 6.31s\n",
      "22710:\tlearn: 2.1744263\ttotal: 8m 13s\tremaining: 6.29s\n",
      "22711:\tlearn: 2.1743481\ttotal: 8m 13s\tremaining: 6.26s\n",
      "22712:\tlearn: 2.1742708\ttotal: 8m 14s\tremaining: 6.24s\n",
      "22713:\tlearn: 2.1741875\ttotal: 8m 14s\tremaining: 6.22s\n",
      "22714:\tlearn: 2.1741640\ttotal: 8m 14s\tremaining: 6.2s\n",
      "22715:\tlearn: 2.1741099\ttotal: 8m 14s\tremaining: 6.18s\n",
      "22716:\tlearn: 2.1740915\ttotal: 8m 14s\tremaining: 6.16s\n",
      "22717:\tlearn: 2.1740034\ttotal: 8m 14s\tremaining: 6.13s\n",
      "22718:\tlearn: 2.1739541\ttotal: 8m 14s\tremaining: 6.11s\n",
      "22719:\tlearn: 2.1739066\ttotal: 8m 14s\tremaining: 6.09s\n",
      "22720:\tlearn: 2.1738355\ttotal: 8m 14s\tremaining: 6.07s\n",
      "22721:\tlearn: 2.1737806\ttotal: 8m 14s\tremaining: 6.05s\n",
      "22722:\tlearn: 2.1737373\ttotal: 8m 14s\tremaining: 6.02s\n",
      "22723:\tlearn: 2.1736886\ttotal: 8m 14s\tremaining: 6s\n",
      "22724:\tlearn: 2.1736350\ttotal: 8m 14s\tremaining: 5.98s\n",
      "22725:\tlearn: 2.1735573\ttotal: 8m 14s\tremaining: 5.96s\n",
      "22726:\tlearn: 2.1734899\ttotal: 8m 14s\tremaining: 5.94s\n",
      "22727:\tlearn: 2.1734316\ttotal: 8m 14s\tremaining: 5.92s\n",
      "22728:\tlearn: 2.1733888\ttotal: 8m 14s\tremaining: 5.89s\n",
      "22729:\tlearn: 2.1733165\ttotal: 8m 14s\tremaining: 5.87s\n",
      "22730:\tlearn: 2.1732372\ttotal: 8m 14s\tremaining: 5.85s\n",
      "22731:\tlearn: 2.1731768\ttotal: 8m 14s\tremaining: 5.83s\n",
      "22732:\tlearn: 2.1730641\ttotal: 8m 14s\tremaining: 5.81s\n",
      "22733:\tlearn: 2.1729871\ttotal: 8m 14s\tremaining: 5.79s\n",
      "22734:\tlearn: 2.1728866\ttotal: 8m 14s\tremaining: 5.76s\n",
      "22735:\tlearn: 2.1727787\ttotal: 8m 14s\tremaining: 5.74s\n",
      "22736:\tlearn: 2.1727419\ttotal: 8m 14s\tremaining: 5.72s\n",
      "22737:\tlearn: 2.1726574\ttotal: 8m 14s\tremaining: 5.7s\n",
      "22738:\tlearn: 2.1725444\ttotal: 8m 14s\tremaining: 5.68s\n",
      "22739:\tlearn: 2.1724757\ttotal: 8m 14s\tremaining: 5.66s\n",
      "22740:\tlearn: 2.1724428\ttotal: 8m 14s\tremaining: 5.63s\n",
      "22741:\tlearn: 2.1723636\ttotal: 8m 14s\tremaining: 5.61s\n",
      "22742:\tlearn: 2.1722387\ttotal: 8m 14s\tremaining: 5.59s\n",
      "22743:\tlearn: 2.1722127\ttotal: 8m 14s\tremaining: 5.57s\n",
      "22744:\tlearn: 2.1721802\ttotal: 8m 14s\tremaining: 5.55s\n",
      "22745:\tlearn: 2.1721258\ttotal: 8m 14s\tremaining: 5.52s\n",
      "22746:\tlearn: 2.1720734\ttotal: 8m 14s\tremaining: 5.5s\n",
      "22747:\tlearn: 2.1720026\ttotal: 8m 14s\tremaining: 5.48s\n",
      "22748:\tlearn: 2.1719496\ttotal: 8m 14s\tremaining: 5.46s\n",
      "22749:\tlearn: 2.1718816\ttotal: 8m 14s\tremaining: 5.44s\n",
      "22750:\tlearn: 2.1718520\ttotal: 8m 14s\tremaining: 5.42s\n",
      "22751:\tlearn: 2.1717446\ttotal: 8m 14s\tremaining: 5.39s\n",
      "22752:\tlearn: 2.1716341\ttotal: 8m 14s\tremaining: 5.37s\n",
      "22753:\tlearn: 2.1715351\ttotal: 8m 14s\tremaining: 5.35s\n",
      "22754:\tlearn: 2.1714712\ttotal: 8m 14s\tremaining: 5.33s\n",
      "22755:\tlearn: 2.1714243\ttotal: 8m 14s\tremaining: 5.31s\n",
      "22756:\tlearn: 2.1713513\ttotal: 8m 14s\tremaining: 5.29s\n",
      "22757:\tlearn: 2.1712495\ttotal: 8m 15s\tremaining: 5.26s\n",
      "22758:\tlearn: 2.1711576\ttotal: 8m 15s\tremaining: 5.24s\n",
      "22759:\tlearn: 2.1711127\ttotal: 8m 15s\tremaining: 5.22s\n",
      "22760:\tlearn: 2.1710688\ttotal: 8m 15s\tremaining: 5.2s\n",
      "22761:\tlearn: 2.1710314\ttotal: 8m 15s\tremaining: 5.18s\n",
      "22762:\tlearn: 2.1709461\ttotal: 8m 15s\tremaining: 5.16s\n",
      "22763:\tlearn: 2.1708917\ttotal: 8m 15s\tremaining: 5.13s\n",
      "22764:\tlearn: 2.1708517\ttotal: 8m 15s\tremaining: 5.11s\n",
      "22765:\tlearn: 2.1708073\ttotal: 8m 15s\tremaining: 5.09s\n",
      "22766:\tlearn: 2.1706699\ttotal: 8m 15s\tremaining: 5.07s\n",
      "22767:\tlearn: 2.1706034\ttotal: 8m 15s\tremaining: 5.05s\n",
      "22768:\tlearn: 2.1705561\ttotal: 8m 15s\tremaining: 5.02s\n",
      "22769:\tlearn: 2.1704605\ttotal: 8m 15s\tremaining: 5s\n",
      "22770:\tlearn: 2.1703071\ttotal: 8m 15s\tremaining: 4.98s\n",
      "22771:\tlearn: 2.1701975\ttotal: 8m 15s\tremaining: 4.96s\n",
      "22772:\tlearn: 2.1701072\ttotal: 8m 15s\tremaining: 4.94s\n",
      "22773:\tlearn: 2.1700495\ttotal: 8m 15s\tremaining: 4.92s\n",
      "22774:\tlearn: 2.1699474\ttotal: 8m 15s\tremaining: 4.89s\n",
      "22775:\tlearn: 2.1698516\ttotal: 8m 15s\tremaining: 4.87s\n",
      "22776:\tlearn: 2.1697466\ttotal: 8m 15s\tremaining: 4.85s\n",
      "22777:\tlearn: 2.1697112\ttotal: 8m 15s\tremaining: 4.83s\n",
      "22778:\tlearn: 2.1696567\ttotal: 8m 15s\tremaining: 4.81s\n",
      "22779:\tlearn: 2.1695526\ttotal: 8m 15s\tremaining: 4.79s\n",
      "22780:\tlearn: 2.1694459\ttotal: 8m 15s\tremaining: 4.76s\n",
      "22781:\tlearn: 2.1693392\ttotal: 8m 15s\tremaining: 4.74s\n",
      "22782:\tlearn: 2.1693267\ttotal: 8m 15s\tremaining: 4.72s\n",
      "22783:\tlearn: 2.1691985\ttotal: 8m 15s\tremaining: 4.7s\n",
      "22784:\tlearn: 2.1690860\ttotal: 8m 15s\tremaining: 4.68s\n",
      "22785:\tlearn: 2.1690065\ttotal: 8m 15s\tremaining: 4.66s\n",
      "22786:\tlearn: 2.1689439\ttotal: 8m 15s\tremaining: 4.63s\n",
      "22787:\tlearn: 2.1688976\ttotal: 8m 15s\tremaining: 4.61s\n",
      "22788:\tlearn: 2.1688199\ttotal: 8m 15s\tremaining: 4.59s\n",
      "22789:\tlearn: 2.1687473\ttotal: 8m 15s\tremaining: 4.57s\n",
      "22790:\tlearn: 2.1687031\ttotal: 8m 15s\tremaining: 4.55s\n",
      "22791:\tlearn: 2.1686246\ttotal: 8m 15s\tremaining: 4.52s\n",
      "22792:\tlearn: 2.1685641\ttotal: 8m 15s\tremaining: 4.5s\n",
      "22793:\tlearn: 2.1685119\ttotal: 8m 15s\tremaining: 4.48s\n",
      "22794:\tlearn: 2.1684219\ttotal: 8m 15s\tremaining: 4.46s\n",
      "22795:\tlearn: 2.1683619\ttotal: 8m 15s\tremaining: 4.44s\n",
      "22796:\tlearn: 2.1683206\ttotal: 8m 15s\tremaining: 4.42s\n",
      "22797:\tlearn: 2.1682405\ttotal: 8m 15s\tremaining: 4.39s\n",
      "22798:\tlearn: 2.1681726\ttotal: 8m 15s\tremaining: 4.37s\n",
      "22799:\tlearn: 2.1681148\ttotal: 8m 15s\tremaining: 4.35s\n",
      "22800:\tlearn: 2.1680605\ttotal: 8m 16s\tremaining: 4.33s\n",
      "22801:\tlearn: 2.1679506\ttotal: 8m 16s\tremaining: 4.31s\n",
      "22802:\tlearn: 2.1678890\ttotal: 8m 16s\tremaining: 4.29s\n",
      "22803:\tlearn: 2.1678248\ttotal: 8m 16s\tremaining: 4.26s\n",
      "22804:\tlearn: 2.1678118\ttotal: 8m 16s\tremaining: 4.24s\n",
      "22805:\tlearn: 2.1677454\ttotal: 8m 16s\tremaining: 4.22s\n",
      "22806:\tlearn: 2.1676965\ttotal: 8m 16s\tremaining: 4.2s\n",
      "22807:\tlearn: 2.1675787\ttotal: 8m 16s\tremaining: 4.18s\n",
      "22808:\tlearn: 2.1674419\ttotal: 8m 16s\tremaining: 4.16s\n",
      "22809:\tlearn: 2.1673762\ttotal: 8m 16s\tremaining: 4.13s\n",
      "22810:\tlearn: 2.1673047\ttotal: 8m 16s\tremaining: 4.11s\n",
      "22811:\tlearn: 2.1672468\ttotal: 8m 16s\tremaining: 4.09s\n",
      "22812:\tlearn: 2.1671482\ttotal: 8m 16s\tremaining: 4.07s\n",
      "22813:\tlearn: 2.1671072\ttotal: 8m 16s\tremaining: 4.05s\n",
      "22814:\tlearn: 2.1670199\ttotal: 8m 16s\tremaining: 4.02s\n",
      "22815:\tlearn: 2.1669791\ttotal: 8m 16s\tremaining: 4s\n",
      "22816:\tlearn: 2.1668662\ttotal: 8m 16s\tremaining: 3.98s\n",
      "22817:\tlearn: 2.1668061\ttotal: 8m 16s\tremaining: 3.96s\n",
      "22818:\tlearn: 2.1667468\ttotal: 8m 16s\tremaining: 3.94s\n",
      "22819:\tlearn: 2.1666896\ttotal: 8m 16s\tremaining: 3.92s\n",
      "22820:\tlearn: 2.1666212\ttotal: 8m 16s\tremaining: 3.89s\n",
      "22821:\tlearn: 2.1666140\ttotal: 8m 16s\tremaining: 3.87s\n",
      "22822:\tlearn: 2.1665463\ttotal: 8m 16s\tremaining: 3.85s\n",
      "22823:\tlearn: 2.1664757\ttotal: 8m 16s\tremaining: 3.83s\n",
      "22824:\tlearn: 2.1664241\ttotal: 8m 16s\tremaining: 3.81s\n",
      "22825:\tlearn: 2.1663486\ttotal: 8m 16s\tremaining: 3.79s\n",
      "22826:\tlearn: 2.1662720\ttotal: 8m 16s\tremaining: 3.76s\n",
      "22827:\tlearn: 2.1661927\ttotal: 8m 16s\tremaining: 3.74s\n",
      "22828:\tlearn: 2.1661032\ttotal: 8m 16s\tremaining: 3.72s\n",
      "22829:\tlearn: 2.1660317\ttotal: 8m 16s\tremaining: 3.7s\n",
      "22830:\tlearn: 2.1659872\ttotal: 8m 16s\tremaining: 3.68s\n",
      "22831:\tlearn: 2.1658519\ttotal: 8m 16s\tremaining: 3.65s\n",
      "22832:\tlearn: 2.1657833\ttotal: 8m 16s\tremaining: 3.63s\n",
      "22833:\tlearn: 2.1657216\ttotal: 8m 16s\tremaining: 3.61s\n",
      "22834:\tlearn: 2.1656658\ttotal: 8m 16s\tremaining: 3.59s\n",
      "22835:\tlearn: 2.1655866\ttotal: 8m 16s\tremaining: 3.57s\n",
      "22836:\tlearn: 2.1655041\ttotal: 8m 16s\tremaining: 3.54s\n",
      "22837:\tlearn: 2.1654824\ttotal: 8m 16s\tremaining: 3.52s\n",
      "22838:\tlearn: 2.1654818\ttotal: 8m 16s\tremaining: 3.5s\n",
      "22839:\tlearn: 2.1654645\ttotal: 8m 16s\tremaining: 3.48s\n",
      "22840:\tlearn: 2.1654078\ttotal: 8m 16s\tremaining: 3.46s\n",
      "22841:\tlearn: 2.1653078\ttotal: 8m 16s\tremaining: 3.44s\n",
      "22842:\tlearn: 2.1652432\ttotal: 8m 16s\tremaining: 3.42s\n",
      "22843:\tlearn: 2.1651931\ttotal: 8m 16s\tremaining: 3.39s\n",
      "22844:\tlearn: 2.1651170\ttotal: 8m 16s\tremaining: 3.37s\n",
      "22845:\tlearn: 2.1650370\ttotal: 8m 17s\tremaining: 3.35s\n",
      "22846:\tlearn: 2.1649843\ttotal: 8m 17s\tremaining: 3.33s\n",
      "22847:\tlearn: 2.1649011\ttotal: 8m 17s\tremaining: 3.31s\n",
      "22848:\tlearn: 2.1648824\ttotal: 8m 17s\tremaining: 3.28s\n",
      "22849:\tlearn: 2.1647892\ttotal: 8m 17s\tremaining: 3.26s\n",
      "22850:\tlearn: 2.1647012\ttotal: 8m 17s\tremaining: 3.24s\n",
      "22851:\tlearn: 2.1646108\ttotal: 8m 17s\tremaining: 3.22s\n",
      "22852:\tlearn: 2.1645217\ttotal: 8m 17s\tremaining: 3.2s\n",
      "22853:\tlearn: 2.1644896\ttotal: 8m 17s\tremaining: 3.18s\n",
      "22854:\tlearn: 2.1644399\ttotal: 8m 17s\tremaining: 3.15s\n",
      "22855:\tlearn: 2.1643709\ttotal: 8m 17s\tremaining: 3.13s\n",
      "22856:\tlearn: 2.1643563\ttotal: 8m 17s\tremaining: 3.11s\n",
      "22857:\tlearn: 2.1642763\ttotal: 8m 17s\tremaining: 3.09s\n",
      "22858:\tlearn: 2.1641819\ttotal: 8m 17s\tremaining: 3.07s\n",
      "22859:\tlearn: 2.1641234\ttotal: 8m 17s\tremaining: 3.04s\n",
      "22860:\tlearn: 2.1640280\ttotal: 8m 17s\tremaining: 3.02s\n",
      "22861:\tlearn: 2.1640012\ttotal: 8m 17s\tremaining: 3s\n",
      "22862:\tlearn: 2.1639432\ttotal: 8m 17s\tremaining: 2.98s\n",
      "22863:\tlearn: 2.1638355\ttotal: 8m 17s\tremaining: 2.96s\n",
      "22864:\tlearn: 2.1637498\ttotal: 8m 17s\tremaining: 2.94s\n",
      "22865:\tlearn: 2.1636685\ttotal: 8m 17s\tremaining: 2.92s\n",
      "22866:\tlearn: 2.1635810\ttotal: 8m 17s\tremaining: 2.89s\n",
      "22867:\tlearn: 2.1634995\ttotal: 8m 17s\tremaining: 2.87s\n",
      "22868:\tlearn: 2.1634162\ttotal: 8m 17s\tremaining: 2.85s\n",
      "22869:\tlearn: 2.1633147\ttotal: 8m 17s\tremaining: 2.83s\n",
      "22870:\tlearn: 2.1632567\ttotal: 8m 17s\tremaining: 2.81s\n",
      "22871:\tlearn: 2.1631888\ttotal: 8m 17s\tremaining: 2.79s\n",
      "22872:\tlearn: 2.1631287\ttotal: 8m 17s\tremaining: 2.76s\n",
      "22873:\tlearn: 2.1630971\ttotal: 8m 17s\tremaining: 2.74s\n",
      "22874:\tlearn: 2.1630530\ttotal: 8m 17s\tremaining: 2.72s\n",
      "22875:\tlearn: 2.1629575\ttotal: 8m 17s\tremaining: 2.7s\n",
      "22876:\tlearn: 2.1628509\ttotal: 8m 17s\tremaining: 2.68s\n",
      "22877:\tlearn: 2.1627991\ttotal: 8m 17s\tremaining: 2.65s\n",
      "22878:\tlearn: 2.1627452\ttotal: 8m 17s\tremaining: 2.63s\n",
      "22879:\tlearn: 2.1626702\ttotal: 8m 17s\tremaining: 2.61s\n",
      "22880:\tlearn: 2.1626218\ttotal: 8m 17s\tremaining: 2.59s\n",
      "22881:\tlearn: 2.1625599\ttotal: 8m 17s\tremaining: 2.57s\n",
      "22882:\tlearn: 2.1624960\ttotal: 8m 17s\tremaining: 2.54s\n",
      "22883:\tlearn: 2.1623951\ttotal: 8m 17s\tremaining: 2.52s\n",
      "22884:\tlearn: 2.1623015\ttotal: 8m 17s\tremaining: 2.5s\n",
      "22885:\tlearn: 2.1622663\ttotal: 8m 17s\tremaining: 2.48s\n",
      "22886:\tlearn: 2.1622022\ttotal: 8m 18s\tremaining: 2.46s\n",
      "22887:\tlearn: 2.1621553\ttotal: 8m 18s\tremaining: 2.44s\n",
      "22888:\tlearn: 2.1620780\ttotal: 8m 18s\tremaining: 2.42s\n",
      "22889:\tlearn: 2.1619508\ttotal: 8m 18s\tremaining: 2.39s\n",
      "22890:\tlearn: 2.1618684\ttotal: 8m 18s\tremaining: 2.37s\n",
      "22891:\tlearn: 2.1617529\ttotal: 8m 18s\tremaining: 2.35s\n",
      "22892:\tlearn: 2.1616827\ttotal: 8m 18s\tremaining: 2.33s\n",
      "22893:\tlearn: 2.1616587\ttotal: 8m 18s\tremaining: 2.31s\n",
      "22894:\tlearn: 2.1616104\ttotal: 8m 18s\tremaining: 2.28s\n",
      "22895:\tlearn: 2.1615650\ttotal: 8m 18s\tremaining: 2.26s\n",
      "22896:\tlearn: 2.1615306\ttotal: 8m 18s\tremaining: 2.24s\n",
      "22897:\tlearn: 2.1614946\ttotal: 8m 18s\tremaining: 2.22s\n",
      "22898:\tlearn: 2.1614407\ttotal: 8m 18s\tremaining: 2.2s\n",
      "22899:\tlearn: 2.1613626\ttotal: 8m 18s\tremaining: 2.18s\n",
      "22900:\tlearn: 2.1612489\ttotal: 8m 18s\tremaining: 2.15s\n",
      "22901:\tlearn: 2.1611940\ttotal: 8m 18s\tremaining: 2.13s\n",
      "22902:\tlearn: 2.1610787\ttotal: 8m 18s\tremaining: 2.11s\n",
      "22903:\tlearn: 2.1610240\ttotal: 8m 18s\tremaining: 2.09s\n",
      "22904:\tlearn: 2.1609558\ttotal: 8m 18s\tremaining: 2.07s\n",
      "22905:\tlearn: 2.1608888\ttotal: 8m 18s\tremaining: 2.04s\n",
      "22906:\tlearn: 2.1608079\ttotal: 8m 18s\tremaining: 2.02s\n",
      "22907:\tlearn: 2.1607700\ttotal: 8m 18s\tremaining: 2s\n",
      "22908:\tlearn: 2.1607123\ttotal: 8m 18s\tremaining: 1.98s\n",
      "22909:\tlearn: 2.1606366\ttotal: 8m 18s\tremaining: 1.96s\n",
      "22910:\tlearn: 2.1605728\ttotal: 8m 18s\tremaining: 1.94s\n",
      "22911:\tlearn: 2.1605087\ttotal: 8m 18s\tremaining: 1.92s\n",
      "22912:\tlearn: 2.1604276\ttotal: 8m 18s\tremaining: 1.89s\n",
      "22913:\tlearn: 2.1603627\ttotal: 8m 18s\tremaining: 1.87s\n",
      "22914:\tlearn: 2.1602644\ttotal: 8m 18s\tremaining: 1.85s\n",
      "22915:\tlearn: 2.1601803\ttotal: 8m 18s\tremaining: 1.83s\n",
      "22916:\tlearn: 2.1601146\ttotal: 8m 18s\tremaining: 1.81s\n",
      "22917:\tlearn: 2.1600731\ttotal: 8m 18s\tremaining: 1.78s\n",
      "22918:\tlearn: 2.1599989\ttotal: 8m 18s\tremaining: 1.76s\n",
      "22919:\tlearn: 2.1599521\ttotal: 8m 18s\tremaining: 1.74s\n",
      "22920:\tlearn: 2.1599126\ttotal: 8m 18s\tremaining: 1.72s\n",
      "22921:\tlearn: 2.1598625\ttotal: 8m 18s\tremaining: 1.7s\n",
      "22922:\tlearn: 2.1597411\ttotal: 8m 18s\tremaining: 1.68s\n",
      "22923:\tlearn: 2.1596832\ttotal: 8m 18s\tremaining: 1.65s\n",
      "22924:\tlearn: 2.1595601\ttotal: 8m 18s\tremaining: 1.63s\n",
      "22925:\tlearn: 2.1595233\ttotal: 8m 18s\tremaining: 1.61s\n",
      "22926:\tlearn: 2.1594449\ttotal: 8m 18s\tremaining: 1.59s\n",
      "22927:\tlearn: 2.1593177\ttotal: 8m 18s\tremaining: 1.57s\n",
      "22928:\tlearn: 2.1592488\ttotal: 8m 18s\tremaining: 1.54s\n",
      "22929:\tlearn: 2.1591829\ttotal: 8m 19s\tremaining: 1.52s\n",
      "22930:\tlearn: 2.1591134\ttotal: 8m 19s\tremaining: 1.5s\n",
      "22931:\tlearn: 2.1590375\ttotal: 8m 19s\tremaining: 1.48s\n",
      "22932:\tlearn: 2.1589172\ttotal: 8m 19s\tremaining: 1.46s\n",
      "22933:\tlearn: 2.1588735\ttotal: 8m 19s\tremaining: 1.44s\n",
      "22934:\tlearn: 2.1587472\ttotal: 8m 19s\tremaining: 1.41s\n",
      "22935:\tlearn: 2.1586815\ttotal: 8m 19s\tremaining: 1.39s\n",
      "22936:\tlearn: 2.1585829\ttotal: 8m 19s\tremaining: 1.37s\n",
      "22937:\tlearn: 2.1585183\ttotal: 8m 19s\tremaining: 1.35s\n",
      "22938:\tlearn: 2.1584867\ttotal: 8m 19s\tremaining: 1.33s\n",
      "22939:\tlearn: 2.1584673\ttotal: 8m 19s\tremaining: 1.3s\n",
      "22940:\tlearn: 2.1583572\ttotal: 8m 19s\tremaining: 1.28s\n",
      "22941:\tlearn: 2.1582714\ttotal: 8m 19s\tremaining: 1.26s\n",
      "22942:\tlearn: 2.1581816\ttotal: 8m 19s\tremaining: 1.24s\n",
      "22943:\tlearn: 2.1581617\ttotal: 8m 19s\tremaining: 1.22s\n",
      "22944:\tlearn: 2.1580417\ttotal: 8m 19s\tremaining: 1.2s\n",
      "22945:\tlearn: 2.1580076\ttotal: 8m 19s\tremaining: 1.18s\n",
      "22946:\tlearn: 2.1579492\ttotal: 8m 19s\tremaining: 1.15s\n",
      "22947:\tlearn: 2.1578569\ttotal: 8m 19s\tremaining: 1.13s\n",
      "22948:\tlearn: 2.1578271\ttotal: 8m 19s\tremaining: 1.11s\n",
      "22949:\tlearn: 2.1577865\ttotal: 8m 19s\tremaining: 1.09s\n",
      "22950:\tlearn: 2.1577320\ttotal: 8m 19s\tremaining: 1.07s\n",
      "22951:\tlearn: 2.1577147\ttotal: 8m 19s\tremaining: 1.04s\n",
      "22952:\tlearn: 2.1576167\ttotal: 8m 19s\tremaining: 1.02s\n",
      "22953:\tlearn: 2.1575681\ttotal: 8m 19s\tremaining: 1s\n",
      "22954:\tlearn: 2.1575062\ttotal: 8m 19s\tremaining: 979ms\n",
      "22955:\tlearn: 2.1574038\ttotal: 8m 19s\tremaining: 958ms\n",
      "22956:\tlearn: 2.1573819\ttotal: 8m 19s\tremaining: 936ms\n",
      "22957:\tlearn: 2.1572555\ttotal: 8m 19s\tremaining: 914ms\n",
      "22958:\tlearn: 2.1571899\ttotal: 8m 19s\tremaining: 892ms\n",
      "22959:\tlearn: 2.1571042\ttotal: 8m 19s\tremaining: 870ms\n",
      "22960:\tlearn: 2.1570121\ttotal: 8m 19s\tremaining: 849ms\n",
      "22961:\tlearn: 2.1569398\ttotal: 8m 19s\tremaining: 827ms\n",
      "22962:\tlearn: 2.1568526\ttotal: 8m 19s\tremaining: 805ms\n",
      "22963:\tlearn: 2.1568009\ttotal: 8m 19s\tremaining: 783ms\n",
      "22964:\tlearn: 2.1567524\ttotal: 8m 19s\tremaining: 762ms\n",
      "22965:\tlearn: 2.1567275\ttotal: 8m 19s\tremaining: 740ms\n",
      "22966:\tlearn: 2.1566381\ttotal: 8m 19s\tremaining: 718ms\n",
      "22967:\tlearn: 2.1565612\ttotal: 8m 19s\tremaining: 696ms\n",
      "22968:\tlearn: 2.1565139\ttotal: 8m 19s\tremaining: 675ms\n",
      "22969:\tlearn: 2.1564353\ttotal: 8m 19s\tremaining: 653ms\n",
      "22970:\tlearn: 2.1563933\ttotal: 8m 19s\tremaining: 631ms\n",
      "22971:\tlearn: 2.1563257\ttotal: 8m 19s\tremaining: 609ms\n",
      "22972:\tlearn: 2.1562679\ttotal: 8m 19s\tremaining: 588ms\n",
      "22973:\tlearn: 2.1562344\ttotal: 8m 19s\tremaining: 566ms\n",
      "22974:\tlearn: 2.1561472\ttotal: 8m 19s\tremaining: 544ms\n",
      "22975:\tlearn: 2.1559994\ttotal: 8m 20s\tremaining: 522ms\n",
      "22976:\tlearn: 2.1559508\ttotal: 8m 20s\tremaining: 501ms\n",
      "22977:\tlearn: 2.1559113\ttotal: 8m 20s\tremaining: 479ms\n",
      "22978:\tlearn: 2.1558681\ttotal: 8m 20s\tremaining: 457ms\n",
      "22979:\tlearn: 2.1558265\ttotal: 8m 20s\tremaining: 435ms\n",
      "22980:\tlearn: 2.1557473\ttotal: 8m 20s\tremaining: 413ms\n",
      "22981:\tlearn: 2.1556721\ttotal: 8m 20s\tremaining: 392ms\n",
      "22982:\tlearn: 2.1556140\ttotal: 8m 20s\tremaining: 370ms\n",
      "22983:\tlearn: 2.1555579\ttotal: 8m 20s\tremaining: 348ms\n",
      "22984:\tlearn: 2.1554838\ttotal: 8m 20s\tremaining: 326ms\n",
      "22985:\tlearn: 2.1554256\ttotal: 8m 20s\tremaining: 305ms\n",
      "22986:\tlearn: 2.1553712\ttotal: 8m 20s\tremaining: 283ms\n",
      "22987:\tlearn: 2.1552814\ttotal: 8m 20s\tremaining: 261ms\n",
      "22988:\tlearn: 2.1552535\ttotal: 8m 20s\tremaining: 239ms\n",
      "22989:\tlearn: 2.1551952\ttotal: 8m 20s\tremaining: 218ms\n",
      "22990:\tlearn: 2.1551132\ttotal: 8m 20s\tremaining: 196ms\n",
      "22991:\tlearn: 2.1550680\ttotal: 8m 20s\tremaining: 174ms\n",
      "22992:\tlearn: 2.1550064\ttotal: 8m 20s\tremaining: 152ms\n",
      "22993:\tlearn: 2.1549272\ttotal: 8m 20s\tremaining: 131ms\n",
      "22994:\tlearn: 2.1548726\ttotal: 8m 20s\tremaining: 109ms\n",
      "22995:\tlearn: 2.1547846\ttotal: 8m 20s\tremaining: 87ms\n",
      "22996:\tlearn: 2.1547177\ttotal: 8m 20s\tremaining: 65.3ms\n",
      "22997:\tlearn: 2.1546653\ttotal: 8m 20s\tremaining: 43.5ms\n",
      "22998:\tlearn: 2.1545902\ttotal: 8m 20s\tremaining: 21.8ms\n",
      "22999:\tlearn: 2.1544571\ttotal: 8m 20s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nparams_catboost = {\\n    'iterations': [100, 200, 300, 500, 1000, 3000, 10000],\\n    'learning_rate': [0.001, 0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.1],\\n    'depth': range(1, 10, 1),\\n    'subsample': [x / 100.0 for x in range(5, 100, 10)],\\n    'colsample_bylevel': [x / 100.0 for x in range(5, 100, 10)],\\n    'min_data_in_leaf': range(1, 100, 10),\\n    'l2_leaf_reg': [1, 3, 5, 7, 9],\\n    #'min_child_samples': [1, 4, 8, 16, 32]\\n}\\n\\ngrid_search_catboost = RandomizedSearchCV(\\n    catboost_model,\\n    cv = TimeSeriesSplit(n_splits=4),\\n    param_distributions=params_catboost,\\n    n_jobs=-1,\\n    random_state=random_state,\\n    scoring='neg_mean_absolute_error'\\n)\\n\\ngrid_search_catboost.fit(features_train, target_train)\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_model = CatBoostRegressor(\n",
    "    iterations=23000,\n",
    "    learning_rate=0.015,\n",
    "    depth=6,\n",
    "    subsample=0.65,\n",
    "    colsample_bylevel=0.95,\n",
    "    min_data_in_leaf=51,\n",
    "    l2_leaf_reg=9\n",
    ")\n",
    "\n",
    "catboost_model.fit(feat_cat_train , target_all_train)\n",
    "\"\"\"\n",
    "params_catboost = {\n",
    "    'iterations': [100, 200, 300, 500, 1000, 3000, 10000],\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.1],\n",
    "    'depth': range(1, 10, 1),\n",
    "    'subsample': [x / 100.0 for x in range(5, 100, 10)],\n",
    "    'colsample_bylevel': [x / 100.0 for x in range(5, 100, 10)],\n",
    "    'min_data_in_leaf': range(1, 100, 10),\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    #'min_child_samples': [1, 4, 8, 16, 32]\n",
    "}\n",
    "\n",
    "grid_search_catboost = RandomizedSearchCV(\n",
    "    catboost_model,\n",
    "    cv = TimeSeriesSplit(n_splits=4),\n",
    "    param_distributions=params_catboost,\n",
    "    n_jobs=-1,\n",
    "    random_state=random_state,\n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "\n",
    "grid_search_catboost.fit(features_train, target_train)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_predict_test = catboost_model.predict(feat_cat_test)\n",
    "cat_predict_train = catboost_model.predict(feat_cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, cat_predict_train )\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, cat_predict_test )\n",
    "\n",
    "results = pd.concat([results,\n",
    "pd.DataFrame([[f'тренировочная CAT {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая CAT {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM</td>\n",
       "      <td>3.176235</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.996797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM</td>\n",
       "      <td>6.123915</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.985995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная XGB</td>\n",
       "      <td>3.847216</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.997486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая XGB</td>\n",
       "      <td>6.143893</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.984871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная CAT</td>\n",
       "      <td>1.653186</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.999549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая CAT</td>\n",
       "      <td>5.949680</td>\n",
       "      <td>0.014065</td>\n",
       "      <td>0.987062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Выборка       MAE      MAPE        R2\n",
       "0  тренировочная LGBM   3.176235  0.006670  0.996797\n",
       "1       тестовая LGBM   6.123915  0.014347  0.985995\n",
       "0   тренировочная XGB   3.847216  0.008094  0.997486\n",
       "1        тестовая XGB   6.143893  0.014411  0.984871\n",
       "0   тренировочная CAT   1.653186  0.003525  0.999549\n",
       "1        тестовая CAT   5.949680  0.014065  0.987062"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_cat = catboost_model.get_feature_importance()\n",
    "\n",
    "# Создаем DataFrame\n",
    "importances_df_cat = pd.DataFrame({\n",
    "    'feature': feat_cat_train.columns,\n",
    "    'importance': feature_importances_cat\n",
    "})\n",
    "\n",
    "# Сортируем DataFrame по важности признаков\n",
    "importances_df_cat = importances_df_cat.sort_values(by='importance', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>has_rain_probability_5</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>has_rain_probability</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>has_rain_probability_1</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>E_12</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>has_rain_probability_6</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>temp_9</td>\n",
       "      <td>1.354414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>target_lag_336</td>\n",
       "      <td>3.576399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>target_lag_24_1</td>\n",
       "      <td>4.562388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>target_lag_72</td>\n",
       "      <td>8.517591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>target_lag_24</td>\n",
       "      <td>53.600427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>673 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance\n",
       "169  has_rain_probability_5    0.000086\n",
       "17     has_rain_probability    0.000173\n",
       "49   has_rain_probability_1    0.000229\n",
       "368                    E_12    0.000343\n",
       "198  has_rain_probability_6    0.000418\n",
       "..                      ...         ...\n",
       "672                  temp_9    1.354414\n",
       "10           target_lag_336    3.576399\n",
       "40          target_lag_24_1    4.562388\n",
       "9             target_lag_72    8.517591\n",
       "8             target_lag_24   53.600427\n",
       "\n",
       "[673 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['has_rain_probability_5', 'has_rain_probability', 'has_rain_probability_1', 'E_12', 'has_rain_probability_6', 'year_11', 'has_rain_probability_13', 'clear_4', 'windy_15', 'N_5', 'clear_21', 'has_rain_probability_9', 'N_17', 'clear_12', 'WW_7', 'W_9', 'windy_5', 'cloudy_16', 'E_22', 'E_16', 'W_10', 'E', 'N_2', 'N_6', 'E_6', 'has_rain_probability_22', 'clear_17', 'clear_13', 'rainy_14', 'N_3', 'N_4', 'S_5', 'has_rain_probability_7', 'target_5', 'W_22', 'temp_5', 'windy_8', 'N_16', 'W_19', 'year_8', 'W', 'S_10', 'windy_22', 'clear_3', 'E_11', 'E_20', 'S_11', 'W_1', 'cloudy_22', 'clear_22', 'cloudy_21', 'E_23', 'has_rain_probability_16', 'Td_3', 'cloudy_18', 'windy_17', 'WW_10', 'Td_4', 'WW_11', 'windy_18', 'E_14', 'W_23', 'year_15', 'WW_19', 'W_16', 'rainy_8']\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "# Фильтруем DataFrame\n",
    "low_importance_features = importances_df_cat.loc[importances_df_cat['importance'] < 0.002, 'feature']\n",
    "\n",
    "# Выводим список признаков\n",
    "print(low_importance_features.tolist())\n",
    "print(len(low_importance_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "205f9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = xgb_model.feature_importances_\n",
    "# предположим, что 'X' - это ваши данные\n",
    "feature_name = feat_xgb_test.columns\n",
    "# создание DataFrame\n",
    "importance_df_xgb = pd.DataFrame({'feature': feature_name, 'importance': importance})\n",
    "# сортировка по важности\n",
    "importance_df_xgb = importance_df_xgb.sort_values(by='importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['windy_18', 'U_15', 'N_6', 'W_21', 'W_23', 'rainy_8', 'N_16', 'WW_4', 'E_7', 'S_10', 'clear_21', 'U_21', 'W_15', 'U_14', 'year_13', 'E_13', 'E_5', 'windy_14', 'U_16', 'clear_15', 'W_7', 'S_22', 'W_14', 'WW_10', 'windy_21', 'U_10', 'S_9', 'clear_8', 'S_11', 'U_18', 'W_20', 'windy_15', 'Td_5', 'S_21', 'U_12', 'N_22', 'U_8', 'cloudy_16', 'U_13', 'W_18', 'S_8', 'U_11', 'N_1', 'WW_7', 'E_8', 'W_12', 'WW_5', 'W_16', 'has_rain_probability_6', 'U_9', 'U_6', 'WW_14', 'E_2', 'has_rain_probability', 'W_4', 'E_11', 'W_11', 'E', 'windy_20', 'WW_13', 'WW_22', 'WW_20', 'N', 'WW_21', 'N_2', 'E_12', 'E_21', 'year_4', 'WW_6', 'E_14', 'E_1', 'W_2', 'W_9', 'S_12', 'WW_19', 'WW_17', 'E_16', 'S_13', 'WW_15', 'year_18', 'E_23', 'E_22', 'rainy_15', 'N_10', 'WW_11', 'E_20', 'S_4', 'W_1', 'E_4', 'E_9', 'has_rain_probability_15', 'WW_16', 'has_rain_probability_19', 'E_3', 'WW_12', 'WW_18', 'E_15', 'has_rain_probability_16', 'year_15', 'year_9']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Фильтруем DataFrame\n",
    "low_importance_xgb = importance_df_xgb.loc[importance_df_xgb['importance'] < 0.0001, 'feature']\n",
    "\n",
    "# Выводим список признаков\n",
    "print(low_importance_xgb.tolist())\n",
    "print(len(low_importance_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0fd63ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>U_6</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>WW_14</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>E_2</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>has_rain_probability</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>W_4</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>E_11</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>W_11</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>E</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>windy_20</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>WW_13</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>WW_22</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>WW_20</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>N</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>WW_21</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>N_2</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>E_12</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>E_21</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>year_4</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>WW_6</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>E_14</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>E_1</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>W_2</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>W_9</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>S_12</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>WW_19</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>WW_17</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>E_16</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>S_13</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>WW_15</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>year_18</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>E_23</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>E_22</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>rainy_15</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>N_10</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>WW_11</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>E_20</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>S_4</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>W_1</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>E_4</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>E_9</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>has_rain_probability_15</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>WW_16</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>has_rain_probability_19</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>E_3</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>WW_12</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>WW_18</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>E_15</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>has_rain_probability_16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>year_15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>year_9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  importance\n",
       "208                      U_6    0.000075\n",
       "458                    WW_14    0.000075\n",
       "88                       E_2    0.000075\n",
       "17      has_rain_probability    0.000074\n",
       "150                      W_4    0.000073\n",
       "370                     E_11    0.000072\n",
       "369                     W_11    0.000071\n",
       "25                         E    0.000071\n",
       "640                 windy_20    0.000069\n",
       "426                    WW_13    0.000069\n",
       "710                    WW_22    0.000069\n",
       "646                    WW_20    0.000068\n",
       "22                         N    0.000065\n",
       "678                    WW_21    0.000064\n",
       "85                       N_2    0.000064\n",
       "400                     E_12    0.000062\n",
       "683                     E_21    0.000057\n",
       "128                   year_4    0.000057\n",
       "209                     WW_6    0.000056\n",
       "463                     E_14    0.000055\n",
       "57                       E_1    0.000054\n",
       "87                       W_2    0.000054\n",
       "306                      W_9    0.000053\n",
       "398                     S_12    0.000053\n",
       "614                    WW_19    0.000053\n",
       "551                    WW_17    0.000051\n",
       "526                     E_16    0.000050\n",
       "429                     S_13    0.000050\n",
       "490                    WW_15    0.000049\n",
       "565                  year_18    0.000049\n",
       "747                     E_23    0.000049\n",
       "715                     E_22    0.000048\n",
       "483                 rainy_15    0.000048\n",
       "336                     N_10    0.000048\n",
       "365                    WW_11    0.000047\n",
       "651                     E_20    0.000045\n",
       "149                      S_4    0.000045\n",
       "56                       W_1    0.000044\n",
       "151                      E_4    0.000043\n",
       "307                      E_9    0.000041\n",
       "487  has_rain_probability_15    0.000041\n",
       "521                    WW_16    0.000041\n",
       "611  has_rain_probability_19    0.000037\n",
       "119                      E_3    0.000036\n",
       "395                    WW_12    0.000034\n",
       "583                    WW_18    0.000022\n",
       "495                     E_15    0.000021\n",
       "518  has_rain_probability_16    0.000000\n",
       "472                  year_15    0.000000\n",
       "284                   year_9    0.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df_xgb.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3365ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(importance_df_lgbm, importance_df_xgb, on='feature', how='outer', suffixes=('_lgbm', '_xgb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09e15c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_lgbm</th>\n",
       "      <th>importance_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target_lag_24</td>\n",
       "      <td>3341</td>\n",
       "      <td>0.503236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target_lag_336</td>\n",
       "      <td>1548</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target_lag_72</td>\n",
       "      <td>1283</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target_lag_24_1</td>\n",
       "      <td>950</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>target_lag_72_23</td>\n",
       "      <td>860</td>\n",
       "      <td>0.002217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>year_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>year_19</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>year_16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>year_6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>preholidays_12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance_lgbm  importance_xgb\n",
       "0       target_lag_24             3341        0.503236\n",
       "1      target_lag_336             1548        0.006494\n",
       "2       target_lag_72             1283        0.002909\n",
       "3     target_lag_24_1              950        0.000855\n",
       "4    target_lag_72_23              860        0.002217\n",
       "..                ...              ...             ...\n",
       "793            year_3                1        0.001493\n",
       "794           year_19                1             NaN\n",
       "795           year_16                0             NaN\n",
       "796            year_6                0             NaN\n",
       "797    preholidays_12                0             NaN\n",
       "\n",
       "[798 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe31a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена NaN на 0 в столбце 'importance_xgb'\n",
    "merged_df['importance_xgb'].fillna(0, inplace=True)\n",
    "\n",
    "# Нормализация важности признаков\n",
    "merged_df['importance_lgbm'] = merged_df['importance_lgbm'] / merged_df['importance_lgbm'].max()\n",
    "merged_df['importance_xgb'] = merged_df['importance_xgb'] / merged_df['importance_xgb'].max()\n",
    "\n",
    "# Создание столбца 'importance_ensemble', который является средним значением 'importance_lgbm' и 'importance_xgb'\n",
    "merged_df['importance_ensemble'] = (merged_df['importance_lgbm'] + merged_df['importance_xgb']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecf1b32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_lgbm</th>\n",
       "      <th>importance_xgb</th>\n",
       "      <th>importance_ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target_lag_24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target_lag_336</td>\n",
       "      <td>0.463334</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>0.238120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target_lag_72</td>\n",
       "      <td>0.384017</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.194899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target_lag_24_1</td>\n",
       "      <td>0.284346</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.143022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>target_lag_72_23</td>\n",
       "      <td>0.257408</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.130906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>year_3</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.001633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>year_19</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>year_16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>year_6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>preholidays_12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance_lgbm  importance_xgb  importance_ensemble\n",
       "0       target_lag_24         1.000000        1.000000             1.000000\n",
       "1      target_lag_336         0.463334        0.012905             0.238120\n",
       "2       target_lag_72         0.384017        0.005781             0.194899\n",
       "3     target_lag_24_1         0.284346        0.001698             0.143022\n",
       "4    target_lag_72_23         0.257408        0.004405             0.130906\n",
       "..                ...              ...             ...                  ...\n",
       "793            year_3         0.000299        0.002966             0.001633\n",
       "794           year_19         0.000299        0.000000             0.000150\n",
       "795           year_16         0.000000        0.000000             0.000000\n",
       "796            year_6         0.000000        0.000000             0.000000\n",
       "797    preholidays_12         0.000000        0.000000             0.000000\n",
       "\n",
       "[798 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c55ddba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/anaconda3/envs/p311/lib/python3.11/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/anaconda3/envs/p311/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ab34de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_excel('feature_importance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('feature_importance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1cf4d4",
   "metadata": {},
   "source": [
    "### 4 Объединяем результаты ансамбля моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_simple_ensemble_train = (xgb_predict_train + l_predict_train)/2\n",
    "predict_simple_ensemble_test = (xgb_predict_test + l_predict_test)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, predict_simple_ensemble_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, predict_simple_ensemble_test)\n",
    "\n",
    "results_ensemble = results\n",
    "results_ensemble = pd.concat([results_ensemble,\n",
    "pd.DataFrame([[f'тренировочная ансамбля LGBM и XGB  {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая ансамбля LGBM и XGB {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM</td>\n",
       "      <td>3.176235</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.996797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM</td>\n",
       "      <td>6.123915</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.985995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная XGB</td>\n",
       "      <td>3.847216</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.997486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая XGB</td>\n",
       "      <td>6.143893</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.984871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная CAT</td>\n",
       "      <td>1.653186</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.999549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая CAT</td>\n",
       "      <td>5.949680</td>\n",
       "      <td>0.014065</td>\n",
       "      <td>0.987062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная ансамбля LGBM и XGB</td>\n",
       "      <td>3.398171</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.997498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая ансамбля LGBM и XGB</td>\n",
       "      <td>5.962481</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.986196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Выборка       MAE      MAPE        R2\n",
       "0                  тренировочная LGBM   3.176235  0.006670  0.996797\n",
       "1                       тестовая LGBM   6.123915  0.014347  0.985995\n",
       "0                   тренировочная XGB   3.847216  0.008094  0.997486\n",
       "1                        тестовая XGB   6.143893  0.014411  0.984871\n",
       "0                   тренировочная CAT   1.653186  0.003525  0.999549\n",
       "1                        тестовая CAT   5.949680  0.014065  0.987062\n",
       "0  тренировочная ансамбля LGBM и XGB    3.398171  0.007138  0.997498\n",
       "1        тестовая ансамбля LGBM и XGB   5.962481  0.013958  0.986196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_simple_ensemble_train = (cat_predict_train + l_predict_train)/2\n",
    "predict_simple_ensemble_test = (cat_predict_test + l_predict_test)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, predict_simple_ensemble_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, predict_simple_ensemble_test)\n",
    "\n",
    "\n",
    "results_ensemble = pd.concat([results_ensemble,\n",
    "pd.DataFrame([[f'тренировочная ансамбля CatBoost и LGBM  {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая ансамбля CatBoost и LGBM {FEATURES} ', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM</td>\n",
       "      <td>3.176235</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.996797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM</td>\n",
       "      <td>6.123915</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.985995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная XGB</td>\n",
       "      <td>3.847216</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.997486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая XGB</td>\n",
       "      <td>6.143893</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.984871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная CAT</td>\n",
       "      <td>1.653186</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.999549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая CAT</td>\n",
       "      <td>5.949680</td>\n",
       "      <td>0.014065</td>\n",
       "      <td>0.987062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная ансамбля LGBM и XGB</td>\n",
       "      <td>3.398171</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.997498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая ансамбля LGBM и XGB</td>\n",
       "      <td>5.962481</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.986196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная ансамбля CatBoost и LGBM</td>\n",
       "      <td>2.308165</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.998719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая ансамбля CatBoost и LGBM</td>\n",
       "      <td>5.873769</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.987240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Выборка       MAE      MAPE        R2\n",
       "0                       тренировочная LGBM   3.176235  0.006670  0.996797\n",
       "1                            тестовая LGBM   6.123915  0.014347  0.985995\n",
       "0                        тренировочная XGB   3.847216  0.008094  0.997486\n",
       "1                             тестовая XGB   6.143893  0.014411  0.984871\n",
       "0                        тренировочная CAT   1.653186  0.003525  0.999549\n",
       "1                             тестовая CAT   5.949680  0.014065  0.987062\n",
       "0       тренировочная ансамбля LGBM и XGB    3.398171  0.007138  0.997498\n",
       "1             тестовая ансамбля LGBM и XGB   5.962481  0.013958  0.986196\n",
       "0  тренировочная ансамбля CatBoost и LGBM    2.308165  0.004868  0.998719\n",
       "1       тестовая ансамбля CatBoost и LGBM    5.873769  0.013813  0.987240"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_simple_ensemble_train = xgb_predict_train*0.3 + l_predict_train*0.23 + cat_predict_train*0.47\n",
    "predict_simple_ensemble_test = xgb_predict_test*0.3 + l_predict_test*0.23 + cat_predict_test*0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, predict_simple_ensemble_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, predict_simple_ensemble_test)\n",
    "\n",
    "\n",
    "results_ensemble = pd.concat([results_ensemble,\n",
    "pd.DataFrame([[f'тренировочная ансамбля CatBoost, LGBM и XGBoost {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая ансамбля CatBoost, LGBM и XGBoost {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM</td>\n",
       "      <td>3.176235</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.996797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM</td>\n",
       "      <td>6.123915</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.985995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная XGB</td>\n",
       "      <td>3.847216</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.997486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая XGB</td>\n",
       "      <td>6.143893</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.984871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная CAT</td>\n",
       "      <td>1.653186</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.999549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая CAT</td>\n",
       "      <td>5.949680</td>\n",
       "      <td>0.014065</td>\n",
       "      <td>0.987062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная ансамбля LGBM и XGB</td>\n",
       "      <td>3.398171</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.997498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая ансамбля LGBM и XGB</td>\n",
       "      <td>5.962481</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.986196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная ансамбля CatBoost и LGBM</td>\n",
       "      <td>2.308165</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.998719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая ансамбля CatBoost и LGBM</td>\n",
       "      <td>5.873769</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.987240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная ансамбля CatBoost, LGBM и XGBoost</td>\n",
       "      <td>2.445402</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.998848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая ансамбля CatBoost, LGBM и XGBoost</td>\n",
       "      <td>5.804957</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>0.987182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Выборка       MAE      MAPE  \\\n",
       "0                               тренировочная LGBM   3.176235  0.006670   \n",
       "1                                    тестовая LGBM   6.123915  0.014347   \n",
       "0                                тренировочная XGB   3.847216  0.008094   \n",
       "1                                     тестовая XGB   6.143893  0.014411   \n",
       "0                                тренировочная CAT   1.653186  0.003525   \n",
       "1                                     тестовая CAT   5.949680  0.014065   \n",
       "0               тренировочная ансамбля LGBM и XGB    3.398171  0.007138   \n",
       "1                     тестовая ансамбля LGBM и XGB   5.962481  0.013958   \n",
       "0          тренировочная ансамбля CatBoost и LGBM    2.308165  0.004868   \n",
       "1               тестовая ансамбля CatBoost и LGBM    5.873769  0.013813   \n",
       "0  тренировочная ансамбля CatBoost, LGBM и XGBoost   2.445402  0.005156   \n",
       "1       тестовая ансамбля CatBoost, LGBM и XGBoost   5.804957  0.013638   \n",
       "\n",
       "         R2  \n",
       "0  0.996797  \n",
       "1  0.985995  \n",
       "0  0.997486  \n",
       "1  0.984871  \n",
       "0  0.999549  \n",
       "1  0.987062  \n",
       "0  0.997498  \n",
       "1  0.986196  \n",
       "0  0.998719  \n",
       "1  0.987240  \n",
       "0  0.998848  \n",
       "1  0.987182  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
