{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5606014",
   "metadata": {},
   "source": [
    "## Энергетический оракул\n",
    "Ноутбук команды #12\n",
    "\n",
    "Работа выполнена на основе модели LightGBM\n",
    "\n",
    "\n",
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4351135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True )\n",
    "\n",
    "from xgboost.callback import TrainingCallback\n",
    "import time\n",
    "\n",
    "\n",
    "random_state = 12345\n",
    "NUM_ITERATIONS = 5000\n",
    "\n",
    "FEATURES = 'base feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26bfa344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45891200",
   "metadata": {},
   "source": [
    "#### 1.1 Функции для расшифровки прогноза погоды в колонке 'weather_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece12617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "\n",
    "# функция формирует колонки 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability', 'has_rain_probability'\n",
    "# в колонках число, которое 0 при отсутсвии упоминания явления в weather_pred или степень упоминания\n",
    "# функция дает в колонках номер первого списка, элемент которого есть в строке плюс 1\n",
    "# списки cloudy_list, rainy_list, windy_list, clear_list можно модифицировать\n",
    "# соответственно, можно экспериментировать с расположением значений в списках\n",
    "# например, сейчас 'дождь', 'снег', 'д+сн' - первая степень  дождя, а 'гроз', 'ливень' - вторая\n",
    "# а можно сделать снег второй, а грозу с ливнем убрать в третью\n",
    "# также сделал отдельный список для \"ясности\", чтобы выделить 'ясно' и 'солнечно'\n",
    "\n",
    "def in_what_list(weather, big_list):\n",
    "    for list_number, small_list in enumerate(big_list):\n",
    "        if any(word in weather for word in small_list):\n",
    "            return list_number+1\n",
    "    return 0\n",
    "\n",
    "def weather_split2(row):\n",
    "    weather = row['weather_pred']\n",
    "    cloudy_list = [['проясн', 'пер.об.', 'п/об'], ['пасм', 'обл']]\n",
    "    rainy_list = [['дождь', 'снег', 'д+сн'], ['гроз', 'ливень']]\n",
    "    windy_list = [['вет'],['штор']]\n",
    "    clear_list = [['проясн'], ['ясно'], ['солнеч']]\n",
    "    numbers = re.findall(r'\\d+', weather)\n",
    "    cloudy = in_what_list(weather, cloudy_list)\n",
    "    rainy = in_what_list(weather, rainy_list)\n",
    "    windy = in_what_list(weather, windy_list)\n",
    "    clear = in_what_list(weather, clear_list)\n",
    "    rain_probability = 0 if len(numbers)==0 else int(numbers[0])\n",
    "    has_rain_probability = int(len(numbers)==0)\n",
    "    return cloudy, rainy, windy, clear, rain_probability, has_rain_probability\n",
    "\n",
    "def fill_weather_columns(df):\n",
    "    df['weather_pred'] = df['weather_pred'].fillna('')\n",
    "    df['cloudy'], df['rainy'], df['windy'], df['clear'], df['rain_probability'], df['has_rain_probability'] = \\\n",
    "                zip(*df.apply(weather_split2, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39d660",
   "metadata": {},
   "source": [
    "#### 1.2 Функции для загрузки данных о ВВП \n",
    "данные загружаются из файла 'data/VVP.csv'\n",
    "\n",
    "Некоторые научные работы указывают на прямую связь величины потребления электричества и показателя ВВП, который отражает ситуацию в экономике. Данные по экономике публикуются различными министерствами с разной периодичностью. Для использования в работе были взяты фактические данные по ВВП с сайта investing, который агрегирует публикации Минэкономразвития. Данные за месяц побликуются с месячной задержкой, поэтому модель использует для прогнозирования данные за прошлые месяцы, которые известны.   \n",
    "  \n",
    "Ссылка на данные: https://ru.investing.com/economic-calendar/russian-monthly-gdp-407\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3dd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция добавляет данные о ВВП из файла 'data/VVP.csv' в датасет\n",
    "\n",
    "def add_vvp2(data, file_source = 'data/VVP.csv'):\n",
    "    \"\"\"\n",
    "    сырой датафрем подаем на вход\n",
    "    \"\"\"\n",
    "    # обработаем файл с динамикой ВВП\n",
    "    vvp = pd.read_csv(file_source)\n",
    "    # преобразуем дату файла-источника в формат datetime64 и дропнем один столбик\n",
    "    vvp['date'] = pd.to_datetime(vvp['date'], format ='%Y-%m-%d %H:%M:%S')\n",
    "    vvp.drop('for_month',axis=1,inplace=True) \n",
    "    \n",
    "    # обработаем основной фрейм - создадим столбец для соединения, который потом удалим\n",
    "    data['date_temp'] = pd.to_datetime(data['date'], format = '%Y-%m-%d' )\n",
    "    data['date_temp'] = data['date_temp'] + pd.to_timedelta(data['time'] , 'H')\n",
    "    \n",
    "    # соединяем основной фрейм и ВВП по дате объявления показтеля ВВП\n",
    "    for idx in reversed(vvp.index):\n",
    "        data.loc[data['date_temp']>=vvp.date[idx],'VVP'] = vvp.VVP_perc[idx]\n",
    "        \n",
    "    data.drop('date_temp',axis=1,inplace=True)   \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe769599",
   "metadata": {},
   "source": [
    "#### 1.3 Функции для загрузки архива данных о фактической погоде\n",
    "данные загружаются из файла 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "Изначально данные для формирования таблицы \"preprocessing_loaded_table\" были взяты из с сайта [https://rp5.ru](https://rp5.ru/Архив_погоды_в_Храброво,_им._императрицы_Елизаветы_Петровны_(аэропорт),_METAR), где хранятся архивы погоды в аэрапорту Калининграда, за период с 31.12.2018 по 30.09.2023\n",
    "\n",
    "Описание данных в таблице:\n",
    "- Местное время в Храброво / им. императрицы Елизаветы Петровны (аэропорт) - Дата / Местное время\n",
    "- T -  Темпиратура воздуха\n",
    "- Po - Давление на уровне станции\n",
    "- P - Давление приведённое к уровню моря\n",
    "- U - Относительная влажность\n",
    "- DD - Направление ветра\n",
    "- Ff - Скорость ветра\n",
    "- ff10 - Максимальное значение порыва ветра\n",
    "- WW - Особое явление текущей погоды (осадки)\n",
    "- W'W' - Явление недавней погоды, имеющее оперативное значение\n",
    "- с - Общая облачность\n",
    "- VV - Горизонтальная дальность видимости\n",
    "- Td - Темпиратура точки росы\n",
    "\n",
    "Данные, которые были взяты из данной таблицы и загружаются из 'data/preprocessing_loaded_table.csv':\n",
    "- P - не подверглось изменению\n",
    "- U - не подверглось изменению\n",
    "- Td - не подверглась изменению\n",
    "\n",
    " WW - разделили на 4 категории:\n",
    "- Нет осадков (где были пропуски)\n",
    "- слабый дождь\n",
    "- сильный дождь\n",
    "- снег\n",
    "\n",
    "DD - создали 4 столбца, соответствующих сторонам горизонта, которые принимали значения 0; 0.5 и 1 в зависимости от силы ветра в конкретном направлении\n",
    "- N - north\n",
    "- S - south\n",
    "- W - west\n",
    "- E - east\n",
    "\n",
    "В дальнейшем эти данные использовались с лагом в сутки: в поля на завтрашний день записывались данные сегодняшнего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb3456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для работы с данными о фактической погоде из 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "# Кодировка информации об осадках из колонки WW\n",
    "def true_weather_WW_replace(ww):\n",
    "    if ww=='нет осадков':\n",
    "        return 0\n",
    "    elif ww=='слабый дождь':\n",
    "        return 1\n",
    "    elif (ww=='сильный дождь') or (ww=='снег'):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Вычисление Timestamp из даты и времени\n",
    "def row_plus_hours_to_index(row):\n",
    "    return row['date'] + pd.to_timedelta(row['time'] , 'H')\n",
    "\n",
    "# Функция для сдвига на сутки (в скачанном датасете разбивка по 30 мин, поэтому timeshift=48)\n",
    "def shift_features_fact(df, timeshift=48):\n",
    "    list_fact_columns=list(df.columns)\n",
    "    list_fact_columns.remove('date_tw')\n",
    "    new_df = df.copy()\n",
    "    for column in list_fact_columns:\n",
    "        new_df[column] = new_df[column].shift(timeshift)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5eb669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления метрики mae по дням из почасовых массивов данных\n",
    "\n",
    "def mae_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    return mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "# Функция для вычисления метрик по дням из почасовых массивов данных\n",
    "\n",
    "def metrics_hour(y_true, y_pred):\n",
    "\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808c109",
   "metadata": {},
   "source": [
    "#### 1.5 Чтение файлов с данными\n",
    "Данные объединяются в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a4ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начало открытого теста: 2023-04-01 00:00:00     конец открытого теста: 2023-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# читаем исходные датасеты и складываем в один\n",
    "train_ds = pd.read_csv('data/train_dataset.csv')\n",
    "test_ds = pd.read_csv('data/test_dataset.csv')\n",
    "train_ds = pd.concat([train_ds, test_ds])\n",
    "\n",
    "# запоминаем дату начала тестовых данных, потом также поступим и с закрытым датасетом\n",
    "open_test_begin = pd.to_datetime(test_ds['date']).min()\n",
    "open_test_end = pd.to_datetime(test_ds['date']).max() + pd.to_timedelta(1,'d')\n",
    "print('начало открытого теста:', open_test_begin, '    конец открытого теста:', open_test_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237ce32",
   "metadata": {},
   "source": [
    "#### 1.6 Формирование колонок с производными от даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16090ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем дату и делаем из нее колонки\n",
    "train_ds['date'] = pd.to_datetime(train_ds['date'])\n",
    "train_ds['year'] = train_ds['date'].dt.year\n",
    "train_ds['month'] = train_ds['date'].dt.month\n",
    "train_ds['day_of_week'] = train_ds['date'].dt.dayofweek\n",
    "train_ds['day'] = train_ds['date'].dt.day\n",
    "train_ds['day_of_year'] = train_ds['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e3cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>target</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_pred</th>\n",
       "      <th>weather_pred</th>\n",
       "      <th>weather_fact</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27565</th>\n",
       "      <td>2022-02-22</td>\n",
       "      <td>13</td>\n",
       "      <td>656.314</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, 35% дождь</td>\n",
       "      <td>пасмурно</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>23</td>\n",
       "      <td>457.142</td>\n",
       "      <td>13.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>пасм, 41% дождь</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8819</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>11</td>\n",
       "      <td>538.697</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>малообл</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>6</td>\n",
       "      <td>293.517</td>\n",
       "      <td>17.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>пасм, 58% дождь</td>\n",
       "      <td>ясно</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>12</td>\n",
       "      <td>573.399</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>обл, 38%</td>\n",
       "      <td>пасмурно</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  time   target  temp  temp_pred     weather_pred  \\\n",
       "27565 2022-02-22    13  656.314   0.8        2.0  пасм, 35% дождь   \n",
       "6551  2019-09-30    23  457.142  13.3       12.0  пасм, 41% дождь   \n",
       "8819  2020-01-03    11  538.697   1.5        2.0          малообл   \n",
       "2430  2023-07-11     6  293.517  17.1       17.0  пасм, 58% дождь   \n",
       "10356 2020-03-07    12  573.399   6.1        8.0         обл, 38%   \n",
       "\n",
       "      weather_fact  year  month  day_of_week  day  day_of_year  \n",
       "27565     пасмурно  2022      2            1   22           53  \n",
       "6551   пасм, ветер  2019      9            0   30          273  \n",
       "8819   пасм, ветер  2020      1            4    3            3  \n",
       "2430          ясно  2023      7            1   11          192  \n",
       "10356     пасмурно  2020      3            5    7           67  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98567815",
   "metadata": {},
   "source": [
    "#### 1.7 Подгрузка Auggumentaci в праздниках"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9963b",
   "metadata": {},
   "source": [
    "\n",
    "df_holidays = pd.read_csv('data/holidays_aug.csv')\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "# Добавление данных о праздниках из файла 'data/holidays.csv'\n",
    "\n",
    "\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())\n",
    "# Assuming df_holidays and train_ds are your dataframes\n",
    "train_ds = pd.merge(train_ds, df_holidays, on='date', how='left')\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())\n",
    "# Fill NaN values with 0\n",
    "train_ds['holidays'].fillna(0, inplace=True)\n",
    "train_ds['preholidays'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "train_ds['holidays'] = train_ds['holidays'].astype(int)\n",
    "train_ds['preholidays'] = train_ds['preholidays'].astype(int)\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5a0f9",
   "metadata": {},
   "source": [
    "#### 1.7.1 Подгрузка данных о праздниках на весь DS праздниках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ddfd107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер DS (40152, 12) дубликатов -  0\n",
      "размер DS (40152, 14) дубликатов -  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_holidays_true = pd.read_csv('data/holidays_true.csv')\n",
    "df_holidays_true['date'] = pd.to_datetime(df_holidays_true['date'])\n",
    "# Добавление данных о праздниках из файла 'data/holidays.csv'\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())\n",
    "# Assuming df_holidays and train_ds are your dataframes\n",
    "train_ds = pd.merge(train_ds, df_holidays_true, on='date', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "train_ds['holidays_true'].fillna(0, inplace=True)\n",
    "train_ds['preholidays_true'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "train_ds['holidays_true'] = train_ds['holidays_true'].astype(int)\n",
    "train_ds['preholidays_true'] = train_ds['preholidays_true'].astype(int)\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b32c4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40152 entries, 0 to 40151\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   date              40152 non-null  datetime64[ns]\n",
      " 1   time              40152 non-null  int64         \n",
      " 2   target            40152 non-null  float64       \n",
      " 3   temp              40152 non-null  float64       \n",
      " 4   temp_pred         40040 non-null  float64       \n",
      " 5   weather_pred      40040 non-null  object        \n",
      " 6   weather_fact      40151 non-null  object        \n",
      " 7   year              40152 non-null  int32         \n",
      " 8   month             40152 non-null  int32         \n",
      " 9   day_of_week       40152 non-null  int32         \n",
      " 10  day               40152 non-null  int32         \n",
      " 11  day_of_year       40152 non-null  int32         \n",
      " 12  holidays_true     40152 non-null  int64         \n",
      " 13  preholidays_true  40152 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int32(5), int64(3), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdfa6e",
   "metadata": {},
   "source": [
    "#### 1.8 Формирование колонок со значением целевого признака в предыдущие дни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91cfdcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер DS (40152, 15) дубликатов -  0\n",
      "размер DS (40152, 20) дубликатов -  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/2320664940.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_ds['temp_last_day'].fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Добавление колонок с временными лагами\n",
    "\n",
    "# создаем столбец 'temp_last_day'\n",
    "train_ds['temp_last_day'] = train_ds['temp'].shift(24)\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())\n",
    "# заполняем пропущенные значения в 'temp_last_day'\n",
    "train_ds['temp_last_day'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# создаем столбцы с временными лагами для 'target'\n",
    "lags = [24, 48, 72, 7*24, 14*24]\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'] = train_ds['target'].shift(lag)\n",
    "\n",
    "# заполняем пропущенные значения в столбцах с лагами\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'].fillna(0, inplace=True)\n",
    "\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c4022",
   "metadata": {},
   "source": [
    "#### 1.9 Формирование колонок с ВВП и данными о погоде посредством ранее описанных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79aa7c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>P</th>\n",
       "      <th>U</th>\n",
       "      <th>WW</th>\n",
       "      <th>Td</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>W</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 00:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 00:30:00</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 01:00:00</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 01:30:00</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31 02:00:00</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82146</th>\n",
       "      <td>2023-09-30 21:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82147</th>\n",
       "      <td>2023-09-30 22:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82148</th>\n",
       "      <td>2023-09-30 22:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>сильный дождь</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82149</th>\n",
       "      <td>2023-09-30 23:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>сильный дождь</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82150</th>\n",
       "      <td>2023-09-30 23:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82151 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date      P      U             WW    Td    N    S    W  \\\n",
       "0      2018-12-31 00:00:00  763.5  100.0   слабый дождь   2.0  1.0  0.0  0.0   \n",
       "1      2018-12-31 00:30:00  764.3   93.0   слабый дождь   1.0  1.0  0.0  0.0   \n",
       "2      2018-12-31 01:00:00  764.3   93.0   слабый дождь   1.0  1.0  0.0  0.0   \n",
       "3      2018-12-31 01:30:00  765.0   93.0   слабый дождь   2.0  1.0  0.0  0.0   \n",
       "4      2018-12-31 02:00:00  765.0   93.0    нет осадков   2.0  1.0  0.0  0.0   \n",
       "...                    ...    ...    ...            ...   ...  ...  ...  ...   \n",
       "82146  2023-09-30 21:30:00  763.5   82.0    нет осадков  12.0  0.0  0.0  1.0   \n",
       "82147  2023-09-30 22:00:00  763.5   82.0    нет осадков  12.0  0.5  0.0  1.0   \n",
       "82148  2023-09-30 22:30:00  763.5   77.0  сильный дождь  11.0  0.0  0.0  1.0   \n",
       "82149  2023-09-30 23:00:00  763.5   94.0  сильный дождь  13.0  0.5  0.0  1.0   \n",
       "82150  2023-09-30 23:30:00  763.5   94.0    нет осадков  13.0  0.0  0.5  1.0   \n",
       "\n",
       "         E  \n",
       "0      0.0  \n",
       "1      0.5  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "82146  0.0  \n",
       "82147  0.0  \n",
       "82148  0.0  \n",
       "82149  0.0  \n",
       "82150  0.0  \n",
       "\n",
       "[82151 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# применяем функцию добавления ВВП\n",
    "train_ds = add_vvp2(train_ds)\n",
    "\n",
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "train_ds = fill_weather_columns(train_ds)\n",
    "\n",
    "\n",
    "# Читаем файл с архивом фактической погоды\n",
    "df_true_weather = pd.read_csv('data/preprocessing_loaded_table.csv')\n",
    "display(df_true_weather)\n",
    "\n",
    "# Форматируем колонки\n",
    "df_true_weather['WW'] = df_true_weather['WW'].apply(true_weather_WW_replace)\n",
    "df_true_weather['date'] = pd.to_datetime(df_true_weather['date'])\n",
    "df_true_weather = df_true_weather.rename(columns={'date':'date_tw'})\n",
    "# Применяем сдвиг на сутки, чтобы не заглядывать в будущее\n",
    "df_true_weather = shift_features_fact(df_true_weather)\n",
    "# Добавляем в датасет\n",
    "train_ds['date_hours'] = train_ds.apply(row_plus_hours_to_index, axis=1)\n",
    "train_ds = train_ds.merge(df_true_weather, left_on='date_hours', right_on='date_tw')\n",
    "train_ds = train_ds.drop(['date_hours', 'date_tw'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc76ee",
   "metadata": {},
   "source": [
    "#### 1.10 Демонстрация сформированного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a939b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'target', 'temp', 'temp_pred', 'weather_pred',\n",
       "       'weather_fact', 'year', 'month', 'day_of_week', 'day', 'day_of_year',\n",
       "       'holidays_true', 'preholidays_true', 'temp_last_day', 'target_lag_24',\n",
       "       'target_lag_48', 'target_lag_72', 'target_lag_168', 'target_lag_336',\n",
       "       'VVP', 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability',\n",
       "       'has_rain_probability', 'P', 'U', 'WW', 'Td', 'N', 'S', 'W', 'E'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Итоговый набор колонок\n",
    "train_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51e77ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>target</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_pred</th>\n",
       "      <th>weather_pred</th>\n",
       "      <th>weather_fact</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>rain_probability</th>\n",
       "      <th>has_rain_probability</th>\n",
       "      <th>P</th>\n",
       "      <th>U</th>\n",
       "      <th>WW</th>\n",
       "      <th>Td</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>W</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>481.510</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>763.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>462.872</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>449.718</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>430.908</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>765.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>415.163</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>766.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  time   target  temp  temp_pred weather_pred weather_fact  year  \\\n",
       "0 2019-01-01     0  481.510   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "1 2019-01-01     1  462.872   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "2 2019-01-01     2  449.718   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "3 2019-01-01     3  430.908   4.3        2.0  пасм, ветер  ветер, пасм  2019   \n",
       "4 2019-01-01     4  415.163   4.3        2.0  пасм, ветер  ветер, пасм  2019   \n",
       "\n",
       "   month  day_of_week  ...  rain_probability  has_rain_probability      P  \\\n",
       "0      1            1  ...                 0                     1  763.5   \n",
       "1      1            1  ...                 0                     1  764.3   \n",
       "2      1            1  ...                 0                     1  765.0   \n",
       "3      1            1  ...                 0                     1  765.8   \n",
       "4      1            1  ...                 0                     1  766.6   \n",
       "\n",
       "       U   WW   Td    N    S    W    E  \n",
       "0  100.0  1.0  2.0  1.0  0.0  0.0  0.0  \n",
       "1   93.0  1.0  1.0  1.0  0.0  0.0  0.0  \n",
       "2   93.0  0.0  2.0  1.0  0.0  0.0  0.0  \n",
       "3   87.0  0.0  1.0  1.0  0.0  0.0  0.0  \n",
       "4   87.0  0.0  1.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17ec6c",
   "metadata": {},
   "source": [
    "#### 1.11.1 Добавление среднего за час предыдущего дня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28eebfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_evening(values, evening=19):\n",
    "    return values[evening:].mean()\n",
    "\n",
    "evening_slices = [0, 19, 22]\n",
    "    \n",
    "for evening_slice in evening_slices:\n",
    "    train_ds[['last_evening_avg_target_'+str(evening_slice), 'last_evening_avg_temp_'+str(evening_slice)]] = \\\n",
    "        train_ds[['date', 'target', 'temp']].groupby(by='date').transform(mean_evening, evening=evening_slice).shift(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76699a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'target', 'temp', 'temp_pred', 'weather_pred',\n",
       "       'weather_fact', 'year', 'month', 'day_of_week', 'day', 'day_of_year',\n",
       "       'holidays_true', 'preholidays_true', 'temp_last_day', 'target_lag_24',\n",
       "       'target_lag_48', 'target_lag_72', 'target_lag_168', 'target_lag_336',\n",
       "       'VVP', 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability',\n",
       "       'has_rain_probability', 'P', 'U', 'WW', 'Td', 'N', 'S', 'W', 'E',\n",
       "       'last_evening_avg_target_0', 'last_evening_avg_temp_0',\n",
       "       'last_evening_avg_target_19', 'last_evening_avg_temp_19',\n",
       "       'last_evening_avg_target_22', 'last_evening_avg_temp_22'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69383cb",
   "metadata": {},
   "source": [
    "#### 1.11 Исключение лишних колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65d6619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'time',\n",
       " 'temp_pred',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'day',\n",
       " 'holidays_true',\n",
       " 'preholidays_true',\n",
       " 'temp_last_day',\n",
       " 'target_lag_24',\n",
       " 'target_lag_72',\n",
       " 'target_lag_336',\n",
       " 'VVP',\n",
       " 'cloudy',\n",
       " 'rainy',\n",
       " 'windy',\n",
       " 'clear',\n",
       " 'rain_probability',\n",
       " 'has_rain_probability',\n",
       " 'P',\n",
       " 'U',\n",
       " 'WW',\n",
       " 'Td',\n",
       " 'N',\n",
       " 'S',\n",
       " 'W',\n",
       " 'E',\n",
       " 'last_evening_avg_target_0',\n",
       " 'last_evening_avg_temp_0',\n",
       " 'last_evening_avg_target_19',\n",
       " 'last_evening_avg_temp_19',\n",
       " 'last_evening_avg_target_22',\n",
       " 'last_evening_avg_temp_22']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отбираем признаки. Все лишние колонки здесь отбрасываем, кроме 'date', которую уберем позже \n",
    "\n",
    "feature_cols = list(train_ds.columns)\n",
    "\n",
    "# выбрасываем взгляд в прошлое и расшифрованную погоду\n",
    "drop_list = ['target', 'day_of_year', 'weather_pred', 'weather_fact', 'temp']\n",
    "\n",
    "# выбрасываем признаки, найденные процедурно в процессе оптимизации\n",
    "# КОМАНДЕ: здесь можно добавлять признаки на выброс с целью оптимизации\n",
    "drop_list = drop_list + ['target_lag_48', 'target_lag_168'] #, 'temp_pred'] #, 'target_lag_336'] \n",
    "\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)\n",
    "\n",
    "# Итоговый список признаков\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38de5b2",
   "metadata": {},
   "source": [
    "#### 1.11.2 Добавление среднего за час предыдущего дня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b859804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "FEATURE_WINDOW_SIZE = 24\n",
    "feature_cols_no_date = feature_cols.copy()\n",
    "feature_cols_no_date.remove('date')\n",
    "\n",
    "\n",
    "for lag in range(1,FEATURE_WINDOW_SIZE):\n",
    "    for column in feature_cols_no_date:\n",
    "        train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cc026",
   "metadata": {},
   "source": [
    "#### 1.11.2 Добавление лагов за час "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9fc38dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/64960772.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds['target'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/64960772.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/64960772.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds['target'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/64960772.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/64960772.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds['target'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/64960772.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n"
     ]
    }
   ],
   "source": [
    "target_lags=[1, 5, 9]\n",
    "\n",
    "for lag in target_lags:\n",
    "    train_ds['target_'+str(lag)] = train_ds['target'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
    "    train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d23393e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'time',\n",
       " 'temp_pred',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'day',\n",
       " 'holidays_true',\n",
       " 'preholidays_true',\n",
       " 'temp_last_day',\n",
       " 'target_lag_24',\n",
       " 'target_lag_72',\n",
       " 'target_lag_336',\n",
       " 'VVP',\n",
       " 'cloudy',\n",
       " 'rainy',\n",
       " 'windy',\n",
       " 'clear',\n",
       " 'rain_probability',\n",
       " 'has_rain_probability',\n",
       " 'P',\n",
       " 'U',\n",
       " 'WW',\n",
       " 'Td',\n",
       " 'N',\n",
       " 'S',\n",
       " 'W',\n",
       " 'E',\n",
       " 'last_evening_avg_target_0',\n",
       " 'last_evening_avg_temp_0',\n",
       " 'last_evening_avg_target_19',\n",
       " 'last_evening_avg_temp_19',\n",
       " 'last_evening_avg_target_22',\n",
       " 'last_evening_avg_temp_22',\n",
       " 'time_1',\n",
       " 'temp_pred_1',\n",
       " 'year_1',\n",
       " 'month_1',\n",
       " 'day_of_week_1',\n",
       " 'day_1',\n",
       " 'holidays_true_1',\n",
       " 'preholidays_true_1',\n",
       " 'temp_last_day_1',\n",
       " 'target_lag_24_1',\n",
       " 'target_lag_72_1',\n",
       " 'target_lag_336_1',\n",
       " 'VVP_1',\n",
       " 'cloudy_1',\n",
       " 'rainy_1',\n",
       " 'windy_1',\n",
       " 'clear_1',\n",
       " 'rain_probability_1',\n",
       " 'has_rain_probability_1',\n",
       " 'P_1',\n",
       " 'U_1',\n",
       " 'WW_1',\n",
       " 'Td_1',\n",
       " 'N_1',\n",
       " 'S_1',\n",
       " 'W_1',\n",
       " 'E_1',\n",
       " 'last_evening_avg_target_0_1',\n",
       " 'last_evening_avg_temp_0_1',\n",
       " 'last_evening_avg_target_19_1',\n",
       " 'last_evening_avg_temp_19_1',\n",
       " 'last_evening_avg_target_22_1',\n",
       " 'last_evening_avg_temp_22_1',\n",
       " 'time_2',\n",
       " 'temp_pred_2',\n",
       " 'year_2',\n",
       " 'month_2',\n",
       " 'day_of_week_2',\n",
       " 'day_2',\n",
       " 'holidays_true_2',\n",
       " 'preholidays_true_2',\n",
       " 'temp_last_day_2',\n",
       " 'target_lag_24_2',\n",
       " 'target_lag_72_2',\n",
       " 'target_lag_336_2',\n",
       " 'VVP_2',\n",
       " 'cloudy_2',\n",
       " 'rainy_2',\n",
       " 'windy_2',\n",
       " 'clear_2',\n",
       " 'rain_probability_2',\n",
       " 'has_rain_probability_2',\n",
       " 'P_2',\n",
       " 'U_2',\n",
       " 'WW_2',\n",
       " 'Td_2',\n",
       " 'N_2',\n",
       " 'S_2',\n",
       " 'W_2',\n",
       " 'E_2',\n",
       " 'last_evening_avg_target_0_2',\n",
       " 'last_evening_avg_temp_0_2',\n",
       " 'last_evening_avg_target_19_2',\n",
       " 'last_evening_avg_temp_19_2',\n",
       " 'last_evening_avg_target_22_2',\n",
       " 'last_evening_avg_temp_22_2',\n",
       " 'time_3',\n",
       " 'temp_pred_3',\n",
       " 'year_3',\n",
       " 'month_3',\n",
       " 'day_of_week_3',\n",
       " 'day_3',\n",
       " 'holidays_true_3',\n",
       " 'preholidays_true_3',\n",
       " 'temp_last_day_3',\n",
       " 'target_lag_24_3',\n",
       " 'target_lag_72_3',\n",
       " 'target_lag_336_3',\n",
       " 'VVP_3',\n",
       " 'cloudy_3',\n",
       " 'rainy_3',\n",
       " 'windy_3',\n",
       " 'clear_3',\n",
       " 'rain_probability_3',\n",
       " 'has_rain_probability_3',\n",
       " 'P_3',\n",
       " 'U_3',\n",
       " 'WW_3',\n",
       " 'Td_3',\n",
       " 'N_3',\n",
       " 'S_3',\n",
       " 'W_3',\n",
       " 'E_3',\n",
       " 'last_evening_avg_target_0_3',\n",
       " 'last_evening_avg_temp_0_3',\n",
       " 'last_evening_avg_target_19_3',\n",
       " 'last_evening_avg_temp_19_3',\n",
       " 'last_evening_avg_target_22_3',\n",
       " 'last_evening_avg_temp_22_3',\n",
       " 'time_4',\n",
       " 'temp_pred_4',\n",
       " 'year_4',\n",
       " 'month_4',\n",
       " 'day_of_week_4',\n",
       " 'day_4',\n",
       " 'holidays_true_4',\n",
       " 'preholidays_true_4',\n",
       " 'temp_last_day_4',\n",
       " 'target_lag_24_4',\n",
       " 'target_lag_72_4',\n",
       " 'target_lag_336_4',\n",
       " 'VVP_4',\n",
       " 'cloudy_4',\n",
       " 'rainy_4',\n",
       " 'windy_4',\n",
       " 'clear_4',\n",
       " 'rain_probability_4',\n",
       " 'has_rain_probability_4',\n",
       " 'P_4',\n",
       " 'U_4',\n",
       " 'WW_4',\n",
       " 'Td_4',\n",
       " 'N_4',\n",
       " 'S_4',\n",
       " 'W_4',\n",
       " 'E_4',\n",
       " 'last_evening_avg_target_0_4',\n",
       " 'last_evening_avg_temp_0_4',\n",
       " 'last_evening_avg_target_19_4',\n",
       " 'last_evening_avg_temp_19_4',\n",
       " 'last_evening_avg_target_22_4',\n",
       " 'last_evening_avg_temp_22_4',\n",
       " 'time_5',\n",
       " 'temp_pred_5',\n",
       " 'year_5',\n",
       " 'month_5',\n",
       " 'day_of_week_5',\n",
       " 'day_5',\n",
       " 'holidays_true_5',\n",
       " 'preholidays_true_5',\n",
       " 'temp_last_day_5',\n",
       " 'target_lag_24_5',\n",
       " 'target_lag_72_5',\n",
       " 'target_lag_336_5',\n",
       " 'VVP_5',\n",
       " 'cloudy_5',\n",
       " 'rainy_5',\n",
       " 'windy_5',\n",
       " 'clear_5',\n",
       " 'rain_probability_5',\n",
       " 'has_rain_probability_5',\n",
       " 'P_5',\n",
       " 'U_5',\n",
       " 'WW_5',\n",
       " 'Td_5',\n",
       " 'N_5',\n",
       " 'S_5',\n",
       " 'W_5',\n",
       " 'E_5',\n",
       " 'last_evening_avg_target_0_5',\n",
       " 'last_evening_avg_temp_0_5',\n",
       " 'last_evening_avg_target_19_5',\n",
       " 'last_evening_avg_temp_19_5',\n",
       " 'last_evening_avg_target_22_5',\n",
       " 'last_evening_avg_temp_22_5',\n",
       " 'time_6',\n",
       " 'temp_pred_6',\n",
       " 'year_6',\n",
       " 'month_6',\n",
       " 'day_of_week_6',\n",
       " 'day_6',\n",
       " 'holidays_true_6',\n",
       " 'preholidays_true_6',\n",
       " 'temp_last_day_6',\n",
       " 'target_lag_24_6',\n",
       " 'target_lag_72_6',\n",
       " 'target_lag_336_6',\n",
       " 'VVP_6',\n",
       " 'cloudy_6',\n",
       " 'rainy_6',\n",
       " 'windy_6',\n",
       " 'clear_6',\n",
       " 'rain_probability_6',\n",
       " 'has_rain_probability_6',\n",
       " 'P_6',\n",
       " 'U_6',\n",
       " 'WW_6',\n",
       " 'Td_6',\n",
       " 'N_6',\n",
       " 'S_6',\n",
       " 'W_6',\n",
       " 'E_6',\n",
       " 'last_evening_avg_target_0_6',\n",
       " 'last_evening_avg_temp_0_6',\n",
       " 'last_evening_avg_target_19_6',\n",
       " 'last_evening_avg_temp_19_6',\n",
       " 'last_evening_avg_target_22_6',\n",
       " 'last_evening_avg_temp_22_6',\n",
       " 'time_7',\n",
       " 'temp_pred_7',\n",
       " 'year_7',\n",
       " 'month_7',\n",
       " 'day_of_week_7',\n",
       " 'day_7',\n",
       " 'holidays_true_7',\n",
       " 'preholidays_true_7',\n",
       " 'temp_last_day_7',\n",
       " 'target_lag_24_7',\n",
       " 'target_lag_72_7',\n",
       " 'target_lag_336_7',\n",
       " 'VVP_7',\n",
       " 'cloudy_7',\n",
       " 'rainy_7',\n",
       " 'windy_7',\n",
       " 'clear_7',\n",
       " 'rain_probability_7',\n",
       " 'has_rain_probability_7',\n",
       " 'P_7',\n",
       " 'U_7',\n",
       " 'WW_7',\n",
       " 'Td_7',\n",
       " 'N_7',\n",
       " 'S_7',\n",
       " 'W_7',\n",
       " 'E_7',\n",
       " 'last_evening_avg_target_0_7',\n",
       " 'last_evening_avg_temp_0_7',\n",
       " 'last_evening_avg_target_19_7',\n",
       " 'last_evening_avg_temp_19_7',\n",
       " 'last_evening_avg_target_22_7',\n",
       " 'last_evening_avg_temp_22_7',\n",
       " 'time_8',\n",
       " 'temp_pred_8',\n",
       " 'year_8',\n",
       " 'month_8',\n",
       " 'day_of_week_8',\n",
       " 'day_8',\n",
       " 'holidays_true_8',\n",
       " 'preholidays_true_8',\n",
       " 'temp_last_day_8',\n",
       " 'target_lag_24_8',\n",
       " 'target_lag_72_8',\n",
       " 'target_lag_336_8',\n",
       " 'VVP_8',\n",
       " 'cloudy_8',\n",
       " 'rainy_8',\n",
       " 'windy_8',\n",
       " 'clear_8',\n",
       " 'rain_probability_8',\n",
       " 'has_rain_probability_8',\n",
       " 'P_8',\n",
       " 'U_8',\n",
       " 'WW_8',\n",
       " 'Td_8',\n",
       " 'N_8',\n",
       " 'S_8',\n",
       " 'W_8',\n",
       " 'E_8',\n",
       " 'last_evening_avg_target_0_8',\n",
       " 'last_evening_avg_temp_0_8',\n",
       " 'last_evening_avg_target_19_8',\n",
       " 'last_evening_avg_temp_19_8',\n",
       " 'last_evening_avg_target_22_8',\n",
       " 'last_evening_avg_temp_22_8',\n",
       " 'time_9',\n",
       " 'temp_pred_9',\n",
       " 'year_9',\n",
       " 'month_9',\n",
       " 'day_of_week_9',\n",
       " 'day_9',\n",
       " 'holidays_true_9',\n",
       " 'preholidays_true_9',\n",
       " 'temp_last_day_9',\n",
       " 'target_lag_24_9',\n",
       " 'target_lag_72_9',\n",
       " 'target_lag_336_9',\n",
       " 'VVP_9',\n",
       " 'cloudy_9',\n",
       " 'rainy_9',\n",
       " 'windy_9',\n",
       " 'clear_9',\n",
       " 'rain_probability_9',\n",
       " 'has_rain_probability_9',\n",
       " 'P_9',\n",
       " 'U_9',\n",
       " 'WW_9',\n",
       " 'Td_9',\n",
       " 'N_9',\n",
       " 'S_9',\n",
       " 'W_9',\n",
       " 'E_9',\n",
       " 'last_evening_avg_target_0_9',\n",
       " 'last_evening_avg_temp_0_9',\n",
       " 'last_evening_avg_target_19_9',\n",
       " 'last_evening_avg_temp_19_9',\n",
       " 'last_evening_avg_target_22_9',\n",
       " 'last_evening_avg_temp_22_9',\n",
       " 'time_10',\n",
       " 'temp_pred_10',\n",
       " 'year_10',\n",
       " 'month_10',\n",
       " 'day_of_week_10',\n",
       " 'day_10',\n",
       " 'holidays_true_10',\n",
       " 'preholidays_true_10',\n",
       " 'temp_last_day_10',\n",
       " 'target_lag_24_10',\n",
       " 'target_lag_72_10',\n",
       " 'target_lag_336_10',\n",
       " 'VVP_10',\n",
       " 'cloudy_10',\n",
       " 'rainy_10',\n",
       " 'windy_10',\n",
       " 'clear_10',\n",
       " 'rain_probability_10',\n",
       " 'has_rain_probability_10',\n",
       " 'P_10',\n",
       " 'U_10',\n",
       " 'WW_10',\n",
       " 'Td_10',\n",
       " 'N_10',\n",
       " 'S_10',\n",
       " 'W_10',\n",
       " 'E_10',\n",
       " 'last_evening_avg_target_0_10',\n",
       " 'last_evening_avg_temp_0_10',\n",
       " 'last_evening_avg_target_19_10',\n",
       " 'last_evening_avg_temp_19_10',\n",
       " 'last_evening_avg_target_22_10',\n",
       " 'last_evening_avg_temp_22_10',\n",
       " 'time_11',\n",
       " 'temp_pred_11',\n",
       " 'year_11',\n",
       " 'month_11',\n",
       " 'day_of_week_11',\n",
       " 'day_11',\n",
       " 'holidays_true_11',\n",
       " 'preholidays_true_11',\n",
       " 'temp_last_day_11',\n",
       " 'target_lag_24_11',\n",
       " 'target_lag_72_11',\n",
       " 'target_lag_336_11',\n",
       " 'VVP_11',\n",
       " 'cloudy_11',\n",
       " 'rainy_11',\n",
       " 'windy_11',\n",
       " 'clear_11',\n",
       " 'rain_probability_11',\n",
       " 'has_rain_probability_11',\n",
       " 'P_11',\n",
       " 'U_11',\n",
       " 'WW_11',\n",
       " 'Td_11',\n",
       " 'N_11',\n",
       " 'S_11',\n",
       " 'W_11',\n",
       " 'E_11',\n",
       " 'last_evening_avg_target_0_11',\n",
       " 'last_evening_avg_temp_0_11',\n",
       " 'last_evening_avg_target_19_11',\n",
       " 'last_evening_avg_temp_19_11',\n",
       " 'last_evening_avg_target_22_11',\n",
       " 'last_evening_avg_temp_22_11',\n",
       " 'time_12',\n",
       " 'temp_pred_12',\n",
       " 'year_12',\n",
       " 'month_12',\n",
       " 'day_of_week_12',\n",
       " 'day_12',\n",
       " 'holidays_true_12',\n",
       " 'preholidays_true_12',\n",
       " 'temp_last_day_12',\n",
       " 'target_lag_24_12',\n",
       " 'target_lag_72_12',\n",
       " 'target_lag_336_12',\n",
       " 'VVP_12',\n",
       " 'cloudy_12',\n",
       " 'rainy_12',\n",
       " 'windy_12',\n",
       " 'clear_12',\n",
       " 'rain_probability_12',\n",
       " 'has_rain_probability_12',\n",
       " 'P_12',\n",
       " 'U_12',\n",
       " 'WW_12',\n",
       " 'Td_12',\n",
       " 'N_12',\n",
       " 'S_12',\n",
       " 'W_12',\n",
       " 'E_12',\n",
       " 'last_evening_avg_target_0_12',\n",
       " 'last_evening_avg_temp_0_12',\n",
       " 'last_evening_avg_target_19_12',\n",
       " 'last_evening_avg_temp_19_12',\n",
       " 'last_evening_avg_target_22_12',\n",
       " 'last_evening_avg_temp_22_12',\n",
       " 'time_13',\n",
       " 'temp_pred_13',\n",
       " 'year_13',\n",
       " 'month_13',\n",
       " 'day_of_week_13',\n",
       " 'day_13',\n",
       " 'holidays_true_13',\n",
       " 'preholidays_true_13',\n",
       " 'temp_last_day_13',\n",
       " 'target_lag_24_13',\n",
       " 'target_lag_72_13',\n",
       " 'target_lag_336_13',\n",
       " 'VVP_13',\n",
       " 'cloudy_13',\n",
       " 'rainy_13',\n",
       " 'windy_13',\n",
       " 'clear_13',\n",
       " 'rain_probability_13',\n",
       " 'has_rain_probability_13',\n",
       " 'P_13',\n",
       " 'U_13',\n",
       " 'WW_13',\n",
       " 'Td_13',\n",
       " 'N_13',\n",
       " 'S_13',\n",
       " 'W_13',\n",
       " 'E_13',\n",
       " 'last_evening_avg_target_0_13',\n",
       " 'last_evening_avg_temp_0_13',\n",
       " 'last_evening_avg_target_19_13',\n",
       " 'last_evening_avg_temp_19_13',\n",
       " 'last_evening_avg_target_22_13',\n",
       " 'last_evening_avg_temp_22_13',\n",
       " 'time_14',\n",
       " 'temp_pred_14',\n",
       " 'year_14',\n",
       " 'month_14',\n",
       " 'day_of_week_14',\n",
       " 'day_14',\n",
       " 'holidays_true_14',\n",
       " 'preholidays_true_14',\n",
       " 'temp_last_day_14',\n",
       " 'target_lag_24_14',\n",
       " 'target_lag_72_14',\n",
       " 'target_lag_336_14',\n",
       " 'VVP_14',\n",
       " 'cloudy_14',\n",
       " 'rainy_14',\n",
       " 'windy_14',\n",
       " 'clear_14',\n",
       " 'rain_probability_14',\n",
       " 'has_rain_probability_14',\n",
       " 'P_14',\n",
       " 'U_14',\n",
       " 'WW_14',\n",
       " 'Td_14',\n",
       " 'N_14',\n",
       " 'S_14',\n",
       " 'W_14',\n",
       " 'E_14',\n",
       " 'last_evening_avg_target_0_14',\n",
       " 'last_evening_avg_temp_0_14',\n",
       " 'last_evening_avg_target_19_14',\n",
       " 'last_evening_avg_temp_19_14',\n",
       " 'last_evening_avg_target_22_14',\n",
       " 'last_evening_avg_temp_22_14',\n",
       " 'time_15',\n",
       " 'temp_pred_15',\n",
       " 'year_15',\n",
       " 'month_15',\n",
       " 'day_of_week_15',\n",
       " 'day_15',\n",
       " 'holidays_true_15',\n",
       " 'preholidays_true_15',\n",
       " 'temp_last_day_15',\n",
       " 'target_lag_24_15',\n",
       " 'target_lag_72_15',\n",
       " 'target_lag_336_15',\n",
       " 'VVP_15',\n",
       " 'cloudy_15',\n",
       " 'rainy_15',\n",
       " 'windy_15',\n",
       " 'clear_15',\n",
       " 'rain_probability_15',\n",
       " 'has_rain_probability_15',\n",
       " 'P_15',\n",
       " 'U_15',\n",
       " 'WW_15',\n",
       " 'Td_15',\n",
       " 'N_15',\n",
       " 'S_15',\n",
       " 'W_15',\n",
       " 'E_15',\n",
       " 'last_evening_avg_target_0_15',\n",
       " 'last_evening_avg_temp_0_15',\n",
       " 'last_evening_avg_target_19_15',\n",
       " 'last_evening_avg_temp_19_15',\n",
       " 'last_evening_avg_target_22_15',\n",
       " 'last_evening_avg_temp_22_15',\n",
       " 'time_16',\n",
       " 'temp_pred_16',\n",
       " 'year_16',\n",
       " 'month_16',\n",
       " 'day_of_week_16',\n",
       " 'day_16',\n",
       " 'holidays_true_16',\n",
       " 'preholidays_true_16',\n",
       " 'temp_last_day_16',\n",
       " 'target_lag_24_16',\n",
       " 'target_lag_72_16',\n",
       " 'target_lag_336_16',\n",
       " 'VVP_16',\n",
       " 'cloudy_16',\n",
       " 'rainy_16',\n",
       " 'windy_16',\n",
       " 'clear_16',\n",
       " 'rain_probability_16',\n",
       " 'has_rain_probability_16',\n",
       " 'P_16',\n",
       " 'U_16',\n",
       " 'WW_16',\n",
       " 'Td_16',\n",
       " 'N_16',\n",
       " 'S_16',\n",
       " 'W_16',\n",
       " 'E_16',\n",
       " 'last_evening_avg_target_0_16',\n",
       " 'last_evening_avg_temp_0_16',\n",
       " 'last_evening_avg_target_19_16',\n",
       " 'last_evening_avg_temp_19_16',\n",
       " 'last_evening_avg_target_22_16',\n",
       " 'last_evening_avg_temp_22_16',\n",
       " 'time_17',\n",
       " 'temp_pred_17',\n",
       " 'year_17',\n",
       " 'month_17',\n",
       " 'day_of_week_17',\n",
       " 'day_17',\n",
       " 'holidays_true_17',\n",
       " 'preholidays_true_17',\n",
       " 'temp_last_day_17',\n",
       " 'target_lag_24_17',\n",
       " 'target_lag_72_17',\n",
       " 'target_lag_336_17',\n",
       " 'VVP_17',\n",
       " 'cloudy_17',\n",
       " 'rainy_17',\n",
       " 'windy_17',\n",
       " 'clear_17',\n",
       " 'rain_probability_17',\n",
       " 'has_rain_probability_17',\n",
       " 'P_17',\n",
       " 'U_17',\n",
       " 'WW_17',\n",
       " 'Td_17',\n",
       " 'N_17',\n",
       " 'S_17',\n",
       " 'W_17',\n",
       " 'E_17',\n",
       " 'last_evening_avg_target_0_17',\n",
       " 'last_evening_avg_temp_0_17',\n",
       " 'last_evening_avg_target_19_17',\n",
       " 'last_evening_avg_temp_19_17',\n",
       " 'last_evening_avg_target_22_17',\n",
       " 'last_evening_avg_temp_22_17',\n",
       " 'time_18',\n",
       " 'temp_pred_18',\n",
       " 'year_18',\n",
       " 'month_18',\n",
       " 'day_of_week_18',\n",
       " 'day_18',\n",
       " 'holidays_true_18',\n",
       " 'preholidays_true_18',\n",
       " 'temp_last_day_18',\n",
       " 'target_lag_24_18',\n",
       " 'target_lag_72_18',\n",
       " 'target_lag_336_18',\n",
       " 'VVP_18',\n",
       " 'cloudy_18',\n",
       " 'rainy_18',\n",
       " 'windy_18',\n",
       " 'clear_18',\n",
       " 'rain_probability_18',\n",
       " 'has_rain_probability_18',\n",
       " 'P_18',\n",
       " 'U_18',\n",
       " 'WW_18',\n",
       " 'Td_18',\n",
       " 'N_18',\n",
       " 'S_18',\n",
       " 'W_18',\n",
       " 'E_18',\n",
       " 'last_evening_avg_target_0_18',\n",
       " 'last_evening_avg_temp_0_18',\n",
       " 'last_evening_avg_target_19_18',\n",
       " 'last_evening_avg_temp_19_18',\n",
       " 'last_evening_avg_target_22_18',\n",
       " 'last_evening_avg_temp_22_18',\n",
       " 'time_19',\n",
       " 'temp_pred_19',\n",
       " 'year_19',\n",
       " 'month_19',\n",
       " 'day_of_week_19',\n",
       " 'day_19',\n",
       " 'holidays_true_19',\n",
       " 'preholidays_true_19',\n",
       " 'temp_last_day_19',\n",
       " 'target_lag_24_19',\n",
       " 'target_lag_72_19',\n",
       " 'target_lag_336_19',\n",
       " 'VVP_19',\n",
       " 'cloudy_19',\n",
       " 'rainy_19',\n",
       " 'windy_19',\n",
       " 'clear_19',\n",
       " 'rain_probability_19',\n",
       " 'has_rain_probability_19',\n",
       " 'P_19',\n",
       " 'U_19',\n",
       " 'WW_19',\n",
       " 'Td_19',\n",
       " 'N_19',\n",
       " 'S_19',\n",
       " 'W_19',\n",
       " 'E_19',\n",
       " 'last_evening_avg_target_0_19',\n",
       " 'last_evening_avg_temp_0_19',\n",
       " 'last_evening_avg_target_19_19',\n",
       " 'last_evening_avg_temp_19_19',\n",
       " 'last_evening_avg_target_22_19',\n",
       " 'last_evening_avg_temp_22_19',\n",
       " 'time_20',\n",
       " 'temp_pred_20',\n",
       " 'year_20',\n",
       " 'month_20',\n",
       " 'day_of_week_20',\n",
       " 'day_20',\n",
       " 'holidays_true_20',\n",
       " 'preholidays_true_20',\n",
       " 'temp_last_day_20',\n",
       " 'target_lag_24_20',\n",
       " 'target_lag_72_20',\n",
       " 'target_lag_336_20',\n",
       " 'VVP_20',\n",
       " 'cloudy_20',\n",
       " 'rainy_20',\n",
       " 'windy_20',\n",
       " 'clear_20',\n",
       " 'rain_probability_20',\n",
       " 'has_rain_probability_20',\n",
       " 'P_20',\n",
       " 'U_20',\n",
       " 'WW_20',\n",
       " 'Td_20',\n",
       " 'N_20',\n",
       " 'S_20',\n",
       " 'W_20',\n",
       " 'E_20',\n",
       " 'last_evening_avg_target_0_20',\n",
       " 'last_evening_avg_temp_0_20',\n",
       " 'last_evening_avg_target_19_20',\n",
       " 'last_evening_avg_temp_19_20',\n",
       " 'last_evening_avg_target_22_20',\n",
       " 'last_evening_avg_temp_22_20',\n",
       " 'time_21',\n",
       " 'temp_pred_21',\n",
       " 'year_21',\n",
       " 'month_21',\n",
       " 'day_of_week_21',\n",
       " 'day_21',\n",
       " 'holidays_true_21',\n",
       " 'preholidays_true_21',\n",
       " 'temp_last_day_21',\n",
       " 'target_lag_24_21',\n",
       " 'target_lag_72_21',\n",
       " 'target_lag_336_21',\n",
       " 'VVP_21',\n",
       " 'cloudy_21',\n",
       " 'rainy_21',\n",
       " 'windy_21',\n",
       " 'clear_21',\n",
       " 'rain_probability_21',\n",
       " 'has_rain_probability_21',\n",
       " 'P_21',\n",
       " 'U_21',\n",
       " 'WW_21',\n",
       " 'Td_21',\n",
       " 'N_21',\n",
       " 'S_21',\n",
       " 'W_21',\n",
       " 'E_21',\n",
       " 'last_evening_avg_target_0_21',\n",
       " 'last_evening_avg_temp_0_21',\n",
       " 'last_evening_avg_target_19_21',\n",
       " 'last_evening_avg_temp_19_21',\n",
       " 'last_evening_avg_target_22_21',\n",
       " 'last_evening_avg_temp_22_21',\n",
       " 'time_22',\n",
       " 'temp_pred_22',\n",
       " 'year_22',\n",
       " 'month_22',\n",
       " 'day_of_week_22',\n",
       " 'day_22',\n",
       " 'holidays_true_22',\n",
       " 'preholidays_true_22',\n",
       " 'temp_last_day_22',\n",
       " 'target_lag_24_22',\n",
       " 'target_lag_72_22',\n",
       " 'target_lag_336_22',\n",
       " 'VVP_22',\n",
       " 'cloudy_22',\n",
       " 'rainy_22',\n",
       " 'windy_22',\n",
       " 'clear_22',\n",
       " 'rain_probability_22',\n",
       " 'has_rain_probability_22',\n",
       " 'P_22',\n",
       " 'U_22',\n",
       " 'WW_22',\n",
       " 'Td_22',\n",
       " 'N_22',\n",
       " 'S_22',\n",
       " 'W_22',\n",
       " 'E_22',\n",
       " 'last_evening_avg_target_0_22',\n",
       " 'last_evening_avg_temp_0_22',\n",
       " 'last_evening_avg_target_19_22',\n",
       " 'last_evening_avg_temp_19_22',\n",
       " 'last_evening_avg_target_22_22',\n",
       " 'last_evening_avg_temp_22_22',\n",
       " 'time_23',\n",
       " 'temp_pred_23',\n",
       " 'year_23',\n",
       " 'month_23',\n",
       " 'day_of_week_23',\n",
       " 'day_23',\n",
       " 'holidays_true_23',\n",
       " 'preholidays_true_23',\n",
       " 'temp_last_day_23',\n",
       " 'target_lag_24_23',\n",
       " 'target_lag_72_23',\n",
       " 'target_lag_336_23',\n",
       " 'VVP_23',\n",
       " 'cloudy_23',\n",
       " 'rainy_23',\n",
       " 'windy_23',\n",
       " 'clear_23',\n",
       " 'rain_probability_23',\n",
       " 'has_rain_probability_23',\n",
       " 'P_23',\n",
       " 'U_23',\n",
       " 'WW_23',\n",
       " 'Td_23',\n",
       " 'N_23',\n",
       " 'S_23',\n",
       " 'W_23',\n",
       " 'E_23',\n",
       " 'last_evening_avg_target_0_23',\n",
       " 'last_evening_avg_temp_0_23',\n",
       " 'last_evening_avg_target_19_23',\n",
       " 'last_evening_avg_temp_19_23',\n",
       " 'last_evening_avg_target_22_23',\n",
       " 'last_evening_avg_temp_22_23',\n",
       " 'target_1',\n",
       " 'temp_1',\n",
       " 'target_5',\n",
       " 'temp_5',\n",
       " 'target_9',\n",
       " 'temp_9']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = list(train_ds.columns)\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)\n",
    "\n",
    "# Итоговый список признаков\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b4fad",
   "metadata": {},
   "source": [
    "#### 1.11.13 Аугументации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a044a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_aug = [\n",
    "'temp_pred',\n",
    "'temp_last_day',\n",
    "'target_lag_24',\n",
    "'target_lag_72',\n",
    "'target_lag_336',\n",
    "'VVP',\n",
    "'P',\n",
    "'U',\n",
    "'Td',\n",
    "'last_evening_avg_target_0',\n",
    "'last_evening_avg_temp_0',\n",
    "'last_evening_avg_target_19',\n",
    "'last_evening_avg_temp_19',\n",
    "'last_evening_avg_target_22',\n",
    "'last_evening_avg_temp_22',\n",
    "'temp_pred_1',\n",
    "'temp_last_day_1',\n",
    "'target_lag_24_1',\n",
    "'target_lag_72_1',\n",
    "'target_lag_336_1',\n",
    "'VVP_1',\n",
    "'P_1',\n",
    "'U_1',\n",
    "'Td_1',\n",
    "'last_evening_avg_target_0_1',\n",
    "'last_evening_avg_temp_0_1',\n",
    "'last_evening_avg_target_19_1',\n",
    "'last_evening_avg_temp_19_1',\n",
    "'last_evening_avg_target_22_1',\n",
    "'last_evening_avg_temp_22_1',\n",
    "'temp_pred_2',\n",
    "'temp_last_day_2',\n",
    "'target_lag_24_2',\n",
    "'target_lag_72_2',\n",
    "'target_lag_336_2',\n",
    "'VVP_2',\n",
    "'P_2',\n",
    "'U_2',\n",
    "'Td_2',\n",
    "'last_evening_avg_target_0_2',\n",
    "'last_evening_avg_temp_0_2',\n",
    "'last_evening_avg_target_19_2',\n",
    "'last_evening_avg_temp_19_2',\n",
    "'last_evening_avg_target_22_2',\n",
    "'last_evening_avg_temp_22_2',\n",
    "'temp_pred_3',\n",
    "'temp_last_day_3',\n",
    "'target_lag_24_3',\n",
    "'target_lag_72_3',\n",
    "'target_lag_336_3',\n",
    "'VVP_3',\n",
    "'P_3',\n",
    "'U_3',\n",
    "'Td_3',\n",
    "'last_evening_avg_target_0_3',\n",
    "'last_evening_avg_temp_0_3',\n",
    "'last_evening_avg_target_19_3',\n",
    "'last_evening_avg_temp_19_3',\n",
    "'last_evening_avg_target_22_3',\n",
    "'last_evening_avg_temp_22_3',\n",
    "'temp_pred_4',\n",
    "'temp_last_day_4',\n",
    "'target_lag_24_4',\n",
    "'target_lag_72_4',\n",
    "'target_lag_336_4',\n",
    "'VVP_4',\n",
    "'P_4',\n",
    "'U_4',\n",
    "'Td_4',\n",
    "'last_evening_avg_target_0_4',\n",
    "'last_evening_avg_temp_0_4',\n",
    "'last_evening_avg_target_19_4',\n",
    "'last_evening_avg_temp_19_4',\n",
    "'last_evening_avg_target_22_4',\n",
    "'last_evening_avg_temp_22_4',\n",
    "'temp_pred_5',\n",
    "'temp_last_day_5',\n",
    "'target_lag_24_5',\n",
    "'target_lag_72_5',\n",
    "'target_lag_336_5',\n",
    "'VVP_5',\n",
    "'P_5',\n",
    "'U_5',\n",
    "'Td_5',\n",
    "'last_evening_avg_target_0_5',\n",
    "'last_evening_avg_temp_0_5',\n",
    "'last_evening_avg_target_19_5',\n",
    "'last_evening_avg_temp_19_5',\n",
    "'last_evening_avg_target_22_5',\n",
    "'last_evening_avg_temp_22_5',\n",
    "'temp_pred_6',\n",
    "'temp_last_day_6',\n",
    "'target_lag_24_6',\n",
    "'target_lag_72_6',\n",
    "'target_lag_336_6',\n",
    "'VVP_6',\n",
    "'P_6',\n",
    "'U_6',\n",
    "'Td_6',\n",
    "'last_evening_avg_target_0_6',\n",
    "'last_evening_avg_temp_0_6',\n",
    "'last_evening_avg_target_19_6',\n",
    "'last_evening_avg_temp_19_6',\n",
    "'last_evening_avg_target_22_6',\n",
    "'last_evening_avg_temp_22_6',\n",
    "'temp_pred_7',\n",
    "'temp_last_day_7',\n",
    "'target_lag_24_7',\n",
    "'target_lag_72_7',\n",
    "'target_lag_336_7',\n",
    "'VVP_7',\n",
    "'P_7',\n",
    "'U_7',\n",
    "'Td_7',\n",
    "'last_evening_avg_target_0_7',\n",
    "'last_evening_avg_temp_0_7',\n",
    "'last_evening_avg_target_19_7',\n",
    "'last_evening_avg_temp_19_7',\n",
    "'last_evening_avg_target_22_7',\n",
    "'last_evening_avg_temp_22_7',\n",
    "'temp_pred_8',\n",
    "'temp_last_day_8',\n",
    "'target_lag_24_8',\n",
    "'target_lag_72_8',\n",
    "'target_lag_336_8',\n",
    "'VVP_8',\n",
    "'P_8',\n",
    "'U_8',\n",
    "'Td_8',\n",
    "'last_evening_avg_target_0_8',\n",
    "'last_evening_avg_temp_0_8',\n",
    "'last_evening_avg_target_19_8',\n",
    "'last_evening_avg_temp_19_8',\n",
    "'last_evening_avg_target_22_8',\n",
    "'last_evening_avg_temp_22_8',\n",
    "'temp_pred_9',\n",
    "'temp_last_day_9',\n",
    "'target_lag_24_9',\n",
    "'target_lag_72_9',\n",
    "'target_lag_336_9',\n",
    "'VVP_9',\n",
    "'P_9',\n",
    "'U_9',\n",
    "'Td_9',\n",
    "'last_evening_avg_target_0_9',\n",
    "'last_evening_avg_temp_0_9',\n",
    "'last_evening_avg_target_19_9',\n",
    "'last_evening_avg_temp_19_9',\n",
    "'last_evening_avg_target_22_9',\n",
    "'last_evening_avg_temp_22_9',\n",
    "'temp_pred_10',\n",
    "'temp_last_day_10',\n",
    "'target_lag_24_10',\n",
    "'target_lag_72_10',\n",
    "'target_lag_336_10',\n",
    "'VVP_10',\n",
    "'P_10',\n",
    "'U_10',\n",
    "'Td_10',\n",
    "'last_evening_avg_target_0_10',\n",
    "'last_evening_avg_temp_0_10',\n",
    "'last_evening_avg_target_19_10',\n",
    "'last_evening_avg_temp_19_10',\n",
    "'last_evening_avg_target_22_10',\n",
    "'last_evening_avg_temp_22_10',\n",
    "'temp_pred_11',\n",
    "'temp_last_day_11',\n",
    "'target_lag_24_11',\n",
    "'target_lag_72_11',\n",
    "'target_lag_336_11',\n",
    "'VVP_11',\n",
    "'P_11',\n",
    "'U_11',\n",
    "'Td_11',\n",
    "'last_evening_avg_target_0_11',\n",
    "'last_evening_avg_temp_0_11',\n",
    "'last_evening_avg_target_19_11',\n",
    "'last_evening_avg_temp_19_11',\n",
    "'last_evening_avg_target_22_11',\n",
    "'last_evening_avg_temp_22_11',\n",
    "'temp_pred_12',\n",
    "'temp_last_day_12',\n",
    "'target_lag_24_12',\n",
    "'target_lag_72_12',\n",
    "'target_lag_336_12',\n",
    "'VVP_12',\n",
    "'P_12',\n",
    "'U_12',\n",
    "'Td_12',\n",
    "'last_evening_avg_target_0_12',\n",
    "'last_evening_avg_temp_0_12',\n",
    "'last_evening_avg_target_19_12',\n",
    "'last_evening_avg_temp_19_12',\n",
    "'last_evening_avg_target_22_12',\n",
    "'last_evening_avg_temp_22_12',\n",
    "'temp_pred_13',\n",
    "'temp_last_day_13',\n",
    "'target_lag_24_13',\n",
    "'target_lag_72_13',\n",
    "'target_lag_336_13',\n",
    "'VVP_13',\n",
    "'P_13',\n",
    "'U_13',\n",
    "'Td_13',\n",
    "'last_evening_avg_target_0_13',\n",
    "'last_evening_avg_temp_0_13',\n",
    "'last_evening_avg_target_19_13',\n",
    "'last_evening_avg_temp_19_13',\n",
    "'last_evening_avg_target_22_13',\n",
    "'last_evening_avg_temp_22_13',\n",
    "'temp_pred_14',\n",
    "'temp_last_day_14',\n",
    "'target_lag_24_14',\n",
    "'target_lag_72_14',\n",
    "'target_lag_336_14',\n",
    "'VVP_14',\n",
    "'P_14',\n",
    "'U_14',\n",
    "'Td_14',\n",
    "'last_evening_avg_target_0_14',\n",
    "'last_evening_avg_temp_0_14',\n",
    "'last_evening_avg_target_19_14',\n",
    "'last_evening_avg_temp_19_14',\n",
    "'last_evening_avg_target_22_14',\n",
    "'last_evening_avg_temp_22_14',\n",
    "'temp_pred_15',\n",
    "'temp_last_day_15',\n",
    "'target_lag_24_15',\n",
    "'target_lag_72_15',\n",
    "'target_lag_336_15',\n",
    "'VVP_15',\n",
    "'P_15',\n",
    "'U_15',\n",
    "'Td_15',\n",
    "'last_evening_avg_target_0_15',\n",
    "'last_evening_avg_temp_0_15',\n",
    "'last_evening_avg_target_19_15',\n",
    "'last_evening_avg_temp_19_15',\n",
    "'last_evening_avg_target_22_15',\n",
    "'last_evening_avg_temp_22_15',\n",
    "'temp_pred_16',\n",
    "'temp_last_day_16',\n",
    "'target_lag_24_16',\n",
    "'target_lag_72_16',\n",
    "'target_lag_336_16',\n",
    "'VVP_16',\n",
    "'P_16',\n",
    "'U_16',\n",
    "'Td_16',\n",
    "'last_evening_avg_target_0_16',\n",
    "'last_evening_avg_temp_0_16',\n",
    "'last_evening_avg_target_19_16',\n",
    "'last_evening_avg_temp_19_16',\n",
    "'last_evening_avg_target_22_16',\n",
    "'last_evening_avg_temp_22_16',\n",
    "'temp_pred_17',\n",
    "'temp_last_day_17',\n",
    "'target_lag_24_17',\n",
    "'target_lag_72_17',\n",
    "'target_lag_336_17',\n",
    "'VVP_17',\n",
    "'P_17',\n",
    "'U_17',\n",
    "'Td_17',\n",
    "'last_evening_avg_target_0_17',\n",
    "'last_evening_avg_temp_0_17',\n",
    "'last_evening_avg_target_19_17',\n",
    "'last_evening_avg_temp_19_17',\n",
    "'last_evening_avg_target_22_17',\n",
    "'last_evening_avg_temp_22_17',\n",
    "'temp_pred_18',\n",
    "'temp_last_day_18',\n",
    "'target_lag_24_18',\n",
    "'target_lag_72_18',\n",
    "'target_lag_336_18',\n",
    "'VVP_18',\n",
    "'P_18',\n",
    "'U_18',\n",
    "'Td_18',\n",
    "'last_evening_avg_target_0_18',\n",
    "'last_evening_avg_temp_0_18',\n",
    "'last_evening_avg_target_19_18',\n",
    "'last_evening_avg_temp_19_18',\n",
    "'last_evening_avg_target_22_18',\n",
    "'last_evening_avg_temp_22_18',\n",
    "'temp_pred_19',\n",
    "'temp_last_day_19',\n",
    "'target_lag_24_19',\n",
    "'target_lag_72_19',\n",
    "'target_lag_336_19',\n",
    "'VVP_19',\n",
    "'P_19',\n",
    "'U_19',\n",
    "'Td_19',\n",
    "'last_evening_avg_target_0_19',\n",
    "'last_evening_avg_temp_0_19',\n",
    "'last_evening_avg_target_19_19',\n",
    "'last_evening_avg_temp_19_19',\n",
    "'last_evening_avg_target_22_19',\n",
    "'last_evening_avg_temp_22_19',\n",
    "'temp_pred_20',\n",
    "'temp_last_day_20',\n",
    "'target_lag_24_20',\n",
    "'target_lag_72_20',\n",
    "'target_lag_336_20',\n",
    "'VVP_20',\n",
    "'P_20',\n",
    "'U_20',\n",
    "'Td_20',\n",
    "'last_evening_avg_target_0_20',\n",
    "'last_evening_avg_temp_0_20',\n",
    "'last_evening_avg_target_19_20',\n",
    "'last_evening_avg_temp_19_20',\n",
    "'last_evening_avg_target_22_20',\n",
    "'last_evening_avg_temp_22_20',\n",
    "'temp_pred_21',\n",
    "'temp_last_day_21',\n",
    "'target_lag_24_21',\n",
    "'target_lag_72_21',\n",
    "'target_lag_336_21',\n",
    "'VVP_21',\n",
    "'P_21',\n",
    "'U_21',\n",
    "'Td_21',\n",
    "'last_evening_avg_target_0_21',\n",
    "'last_evening_avg_temp_0_21',\n",
    "'last_evening_avg_target_19_21',\n",
    "'last_evening_avg_temp_19_21',\n",
    "'last_evening_avg_target_22_21',\n",
    "'last_evening_avg_temp_22_21',\n",
    "'temp_pred_22',\n",
    "'temp_last_day_22',\n",
    "'target_lag_24_22',\n",
    "'target_lag_72_22',\n",
    "'target_lag_336_22',\n",
    "'VVP_22',\n",
    "'P_22',\n",
    "'U_22',\n",
    "'Td_22',\n",
    "'last_evening_avg_target_0_22',\n",
    "'last_evening_avg_temp_0_22',\n",
    "'last_evening_avg_target_19_22',\n",
    "'last_evening_avg_temp_19_22',\n",
    "'last_evening_avg_target_22_22',\n",
    "'last_evening_avg_temp_22_22',\n",
    "'temp_pred_23',\n",
    "'temp_last_day_23',\n",
    "'target_lag_24_23',\n",
    "'target_lag_72_23',\n",
    "'target_lag_336_23',\n",
    "'VVP_23',\n",
    "'P_23',\n",
    "'U_23',\n",
    "'Td_23',\n",
    "'last_evening_avg_target_0_23',\n",
    "'last_evening_avg_temp_0_23',\n",
    "'last_evening_avg_target_19_23',\n",
    "'last_evening_avg_temp_19_23',\n",
    "'last_evening_avg_target_22_23',\n",
    "'last_evening_avg_temp_22_23',\n",
    "'target_1',\n",
    "'temp_1',\n",
    "'target_5',\n",
    "'temp_5',\n",
    "'target_9',\n",
    "'temp_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0765394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'time', 'temp_pred', 'year', 'month', 'day_of_week', 'day', 'holidays_true', 'preholidays_true', 'temp_last_day', 'target_lag_24', 'target_lag_72', 'target_lag_336', 'VVP', 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability', 'has_rain_probability', 'P', 'U', 'WW', 'Td', 'N', 'S', 'W', 'E', 'last_evening_avg_target_0', 'last_evening_avg_temp_0', 'last_evening_avg_target_19', 'last_evening_avg_temp_19', 'last_evening_avg_target_22', 'last_evening_avg_temp_22', 'time_1', 'temp_pred_1', 'year_1', 'month_1', 'day_of_week_1', 'day_1', 'holidays_true_1', 'preholidays_true_1', 'temp_last_day_1', 'target_lag_24_1', 'target_lag_72_1', 'target_lag_336_1', 'VVP_1', 'cloudy_1', 'rainy_1', 'windy_1', 'clear_1', 'rain_probability_1', 'has_rain_probability_1', 'P_1', 'U_1', 'WW_1', 'Td_1', 'N_1', 'S_1', 'W_1', 'E_1', 'last_evening_avg_target_0_1', 'last_evening_avg_temp_0_1', 'last_evening_avg_target_19_1', 'last_evening_avg_temp_19_1', 'last_evening_avg_target_22_1', 'last_evening_avg_temp_22_1', 'time_2', 'temp_pred_2', 'year_2', 'month_2', 'day_of_week_2', 'day_2', 'holidays_true_2', 'preholidays_true_2', 'temp_last_day_2', 'target_lag_24_2', 'target_lag_72_2', 'target_lag_336_2', 'VVP_2', 'cloudy_2', 'rainy_2', 'windy_2', 'clear_2', 'rain_probability_2', 'has_rain_probability_2', 'P_2', 'U_2', 'WW_2', 'Td_2', 'N_2', 'S_2', 'W_2', 'E_2', 'last_evening_avg_target_0_2', 'last_evening_avg_temp_0_2', 'last_evening_avg_target_19_2', 'last_evening_avg_temp_19_2', 'last_evening_avg_target_22_2', 'last_evening_avg_temp_22_2', 'time_3', 'temp_pred_3', 'year_3', 'month_3', 'day_of_week_3', 'day_3', 'holidays_true_3', 'preholidays_true_3', 'temp_last_day_3', 'target_lag_24_3', 'target_lag_72_3', 'target_lag_336_3', 'VVP_3', 'cloudy_3', 'rainy_3', 'windy_3', 'clear_3', 'rain_probability_3', 'has_rain_probability_3', 'P_3', 'U_3', 'WW_3', 'Td_3', 'N_3', 'S_3', 'W_3', 'E_3', 'last_evening_avg_target_0_3', 'last_evening_avg_temp_0_3', 'last_evening_avg_target_19_3', 'last_evening_avg_temp_19_3', 'last_evening_avg_target_22_3', 'last_evening_avg_temp_22_3', 'time_4', 'temp_pred_4', 'year_4', 'month_4', 'day_of_week_4', 'day_4', 'holidays_true_4', 'preholidays_true_4', 'temp_last_day_4', 'target_lag_24_4', 'target_lag_72_4', 'target_lag_336_4', 'VVP_4', 'cloudy_4', 'rainy_4', 'windy_4', 'clear_4', 'rain_probability_4', 'has_rain_probability_4', 'P_4', 'U_4', 'WW_4', 'Td_4', 'N_4', 'S_4', 'W_4', 'E_4', 'last_evening_avg_target_0_4', 'last_evening_avg_temp_0_4', 'last_evening_avg_target_19_4', 'last_evening_avg_temp_19_4', 'last_evening_avg_target_22_4', 'last_evening_avg_temp_22_4', 'time_5', 'temp_pred_5', 'year_5', 'month_5', 'day_of_week_5', 'day_5', 'holidays_true_5', 'preholidays_true_5', 'temp_last_day_5', 'target_lag_24_5', 'target_lag_72_5', 'target_lag_336_5', 'VVP_5', 'cloudy_5', 'rainy_5', 'windy_5', 'clear_5', 'rain_probability_5', 'has_rain_probability_5', 'P_5', 'U_5', 'WW_5', 'Td_5', 'N_5', 'S_5', 'W_5', 'E_5', 'last_evening_avg_target_0_5', 'last_evening_avg_temp_0_5', 'last_evening_avg_target_19_5', 'last_evening_avg_temp_19_5', 'last_evening_avg_target_22_5', 'last_evening_avg_temp_22_5', 'time_6', 'temp_pred_6', 'year_6', 'month_6', 'day_of_week_6', 'day_6', 'holidays_true_6', 'preholidays_true_6', 'temp_last_day_6', 'target_lag_24_6', 'target_lag_72_6', 'target_lag_336_6', 'VVP_6', 'cloudy_6', 'rainy_6', 'windy_6', 'clear_6', 'rain_probability_6', 'has_rain_probability_6', 'P_6', 'U_6', 'WW_6', 'Td_6', 'N_6', 'S_6', 'W_6', 'E_6', 'last_evening_avg_target_0_6', 'last_evening_avg_temp_0_6', 'last_evening_avg_target_19_6', 'last_evening_avg_temp_19_6', 'last_evening_avg_target_22_6', 'last_evening_avg_temp_22_6', 'time_7', 'temp_pred_7', 'year_7', 'month_7', 'day_of_week_7', 'day_7', 'holidays_true_7', 'preholidays_true_7', 'temp_last_day_7', 'target_lag_24_7', 'target_lag_72_7', 'target_lag_336_7', 'VVP_7', 'cloudy_7', 'rainy_7', 'windy_7', 'clear_7', 'rain_probability_7', 'has_rain_probability_7', 'P_7', 'U_7', 'WW_7', 'Td_7', 'N_7', 'S_7', 'W_7', 'E_7', 'last_evening_avg_target_0_7', 'last_evening_avg_temp_0_7', 'last_evening_avg_target_19_7', 'last_evening_avg_temp_19_7', 'last_evening_avg_target_22_7', 'last_evening_avg_temp_22_7', 'time_8', 'temp_pred_8', 'year_8', 'month_8', 'day_of_week_8', 'day_8', 'holidays_true_8', 'preholidays_true_8', 'temp_last_day_8', 'target_lag_24_8', 'target_lag_72_8', 'target_lag_336_8', 'VVP_8', 'cloudy_8', 'rainy_8', 'windy_8', 'clear_8', 'rain_probability_8', 'has_rain_probability_8', 'P_8', 'U_8', 'WW_8', 'Td_8', 'N_8', 'S_8', 'W_8', 'E_8', 'last_evening_avg_target_0_8', 'last_evening_avg_temp_0_8', 'last_evening_avg_target_19_8', 'last_evening_avg_temp_19_8', 'last_evening_avg_target_22_8', 'last_evening_avg_temp_22_8', 'time_9', 'temp_pred_9', 'year_9', 'month_9', 'day_of_week_9', 'day_9', 'holidays_true_9', 'preholidays_true_9', 'temp_last_day_9', 'target_lag_24_9', 'target_lag_72_9', 'target_lag_336_9', 'VVP_9', 'cloudy_9', 'rainy_9', 'windy_9', 'clear_9', 'rain_probability_9', 'has_rain_probability_9', 'P_9', 'U_9', 'WW_9', 'Td_9', 'N_9', 'S_9', 'W_9', 'E_9', 'last_evening_avg_target_0_9', 'last_evening_avg_temp_0_9', 'last_evening_avg_target_19_9', 'last_evening_avg_temp_19_9', 'last_evening_avg_target_22_9', 'last_evening_avg_temp_22_9', 'time_10', 'temp_pred_10', 'year_10', 'month_10', 'day_of_week_10', 'day_10', 'holidays_true_10', 'preholidays_true_10', 'temp_last_day_10', 'target_lag_24_10', 'target_lag_72_10', 'target_lag_336_10', 'VVP_10', 'cloudy_10', 'rainy_10', 'windy_10', 'clear_10', 'rain_probability_10', 'has_rain_probability_10', 'P_10', 'U_10', 'WW_10', 'Td_10', 'N_10', 'S_10', 'W_10', 'E_10', 'last_evening_avg_target_0_10', 'last_evening_avg_temp_0_10', 'last_evening_avg_target_19_10', 'last_evening_avg_temp_19_10', 'last_evening_avg_target_22_10', 'last_evening_avg_temp_22_10', 'time_11', 'temp_pred_11', 'year_11', 'month_11', 'day_of_week_11', 'day_11', 'holidays_true_11', 'preholidays_true_11', 'temp_last_day_11', 'target_lag_24_11', 'target_lag_72_11', 'target_lag_336_11', 'VVP_11', 'cloudy_11', 'rainy_11', 'windy_11', 'clear_11', 'rain_probability_11', 'has_rain_probability_11', 'P_11', 'U_11', 'WW_11', 'Td_11', 'N_11', 'S_11', 'W_11', 'E_11', 'last_evening_avg_target_0_11', 'last_evening_avg_temp_0_11', 'last_evening_avg_target_19_11', 'last_evening_avg_temp_19_11', 'last_evening_avg_target_22_11', 'last_evening_avg_temp_22_11', 'time_12', 'temp_pred_12', 'year_12', 'month_12', 'day_of_week_12', 'day_12', 'holidays_true_12', 'preholidays_true_12', 'temp_last_day_12', 'target_lag_24_12', 'target_lag_72_12', 'target_lag_336_12', 'VVP_12', 'cloudy_12', 'rainy_12', 'windy_12', 'clear_12', 'rain_probability_12', 'has_rain_probability_12', 'P_12', 'U_12', 'WW_12', 'Td_12', 'N_12', 'S_12', 'W_12', 'E_12', 'last_evening_avg_target_0_12', 'last_evening_avg_temp_0_12', 'last_evening_avg_target_19_12', 'last_evening_avg_temp_19_12', 'last_evening_avg_target_22_12', 'last_evening_avg_temp_22_12', 'time_13', 'temp_pred_13', 'year_13', 'month_13', 'day_of_week_13', 'day_13', 'holidays_true_13', 'preholidays_true_13', 'temp_last_day_13', 'target_lag_24_13', 'target_lag_72_13', 'target_lag_336_13', 'VVP_13', 'cloudy_13', 'rainy_13', 'windy_13', 'clear_13', 'rain_probability_13', 'has_rain_probability_13', 'P_13', 'U_13', 'WW_13', 'Td_13', 'N_13', 'S_13', 'W_13', 'E_13', 'last_evening_avg_target_0_13', 'last_evening_avg_temp_0_13', 'last_evening_avg_target_19_13', 'last_evening_avg_temp_19_13', 'last_evening_avg_target_22_13', 'last_evening_avg_temp_22_13', 'time_14', 'temp_pred_14', 'year_14', 'month_14', 'day_of_week_14', 'day_14', 'holidays_true_14', 'preholidays_true_14', 'temp_last_day_14', 'target_lag_24_14', 'target_lag_72_14', 'target_lag_336_14', 'VVP_14', 'cloudy_14', 'rainy_14', 'windy_14', 'clear_14', 'rain_probability_14', 'has_rain_probability_14', 'P_14', 'U_14', 'WW_14', 'Td_14', 'N_14', 'S_14', 'W_14', 'E_14', 'last_evening_avg_target_0_14', 'last_evening_avg_temp_0_14', 'last_evening_avg_target_19_14', 'last_evening_avg_temp_19_14', 'last_evening_avg_target_22_14', 'last_evening_avg_temp_22_14', 'time_15', 'temp_pred_15', 'year_15', 'month_15', 'day_of_week_15', 'day_15', 'holidays_true_15', 'preholidays_true_15', 'temp_last_day_15', 'target_lag_24_15', 'target_lag_72_15', 'target_lag_336_15', 'VVP_15', 'cloudy_15', 'rainy_15', 'windy_15', 'clear_15', 'rain_probability_15', 'has_rain_probability_15', 'P_15', 'U_15', 'WW_15', 'Td_15', 'N_15', 'S_15', 'W_15', 'E_15', 'last_evening_avg_target_0_15', 'last_evening_avg_temp_0_15', 'last_evening_avg_target_19_15', 'last_evening_avg_temp_19_15', 'last_evening_avg_target_22_15', 'last_evening_avg_temp_22_15', 'time_16', 'temp_pred_16', 'year_16', 'month_16', 'day_of_week_16', 'day_16', 'holidays_true_16', 'preholidays_true_16', 'temp_last_day_16', 'target_lag_24_16', 'target_lag_72_16', 'target_lag_336_16', 'VVP_16', 'cloudy_16', 'rainy_16', 'windy_16', 'clear_16', 'rain_probability_16', 'has_rain_probability_16', 'P_16', 'U_16', 'WW_16', 'Td_16', 'N_16', 'S_16', 'W_16', 'E_16', 'last_evening_avg_target_0_16', 'last_evening_avg_temp_0_16', 'last_evening_avg_target_19_16', 'last_evening_avg_temp_19_16', 'last_evening_avg_target_22_16', 'last_evening_avg_temp_22_16', 'time_17', 'temp_pred_17', 'year_17', 'month_17', 'day_of_week_17', 'day_17', 'holidays_true_17', 'preholidays_true_17', 'temp_last_day_17', 'target_lag_24_17', 'target_lag_72_17', 'target_lag_336_17', 'VVP_17', 'cloudy_17', 'rainy_17', 'windy_17', 'clear_17', 'rain_probability_17', 'has_rain_probability_17', 'P_17', 'U_17', 'WW_17', 'Td_17', 'N_17', 'S_17', 'W_17', 'E_17', 'last_evening_avg_target_0_17', 'last_evening_avg_temp_0_17', 'last_evening_avg_target_19_17', 'last_evening_avg_temp_19_17', 'last_evening_avg_target_22_17', 'last_evening_avg_temp_22_17', 'time_18', 'temp_pred_18', 'year_18', 'month_18', 'day_of_week_18', 'day_18', 'holidays_true_18', 'preholidays_true_18', 'temp_last_day_18', 'target_lag_24_18', 'target_lag_72_18', 'target_lag_336_18', 'VVP_18', 'cloudy_18', 'rainy_18', 'windy_18', 'clear_18', 'rain_probability_18', 'has_rain_probability_18', 'P_18', 'U_18', 'WW_18', 'Td_18', 'N_18', 'S_18', 'W_18', 'E_18', 'last_evening_avg_target_0_18', 'last_evening_avg_temp_0_18', 'last_evening_avg_target_19_18', 'last_evening_avg_temp_19_18', 'last_evening_avg_target_22_18', 'last_evening_avg_temp_22_18', 'time_19', 'temp_pred_19', 'year_19', 'month_19', 'day_of_week_19', 'day_19', 'holidays_true_19', 'preholidays_true_19', 'temp_last_day_19', 'target_lag_24_19', 'target_lag_72_19', 'target_lag_336_19', 'VVP_19', 'cloudy_19', 'rainy_19', 'windy_19', 'clear_19', 'rain_probability_19', 'has_rain_probability_19', 'P_19', 'U_19', 'WW_19', 'Td_19', 'N_19', 'S_19', 'W_19', 'E_19', 'last_evening_avg_target_0_19', 'last_evening_avg_temp_0_19', 'last_evening_avg_target_19_19', 'last_evening_avg_temp_19_19', 'last_evening_avg_target_22_19', 'last_evening_avg_temp_22_19', 'time_20', 'temp_pred_20', 'year_20', 'month_20', 'day_of_week_20', 'day_20', 'holidays_true_20', 'preholidays_true_20', 'temp_last_day_20', 'target_lag_24_20', 'target_lag_72_20', 'target_lag_336_20', 'VVP_20', 'cloudy_20', 'rainy_20', 'windy_20', 'clear_20', 'rain_probability_20', 'has_rain_probability_20', 'P_20', 'U_20', 'WW_20', 'Td_20', 'N_20', 'S_20', 'W_20', 'E_20', 'last_evening_avg_target_0_20', 'last_evening_avg_temp_0_20', 'last_evening_avg_target_19_20', 'last_evening_avg_temp_19_20', 'last_evening_avg_target_22_20', 'last_evening_avg_temp_22_20', 'time_21', 'temp_pred_21', 'year_21', 'month_21', 'day_of_week_21', 'day_21', 'holidays_true_21', 'preholidays_true_21', 'temp_last_day_21', 'target_lag_24_21', 'target_lag_72_21', 'target_lag_336_21', 'VVP_21', 'cloudy_21', 'rainy_21', 'windy_21', 'clear_21', 'rain_probability_21', 'has_rain_probability_21', 'P_21', 'U_21', 'WW_21', 'Td_21', 'N_21', 'S_21', 'W_21', 'E_21', 'last_evening_avg_target_0_21', 'last_evening_avg_temp_0_21', 'last_evening_avg_target_19_21', 'last_evening_avg_temp_19_21', 'last_evening_avg_target_22_21', 'last_evening_avg_temp_22_21', 'time_22', 'temp_pred_22', 'year_22', 'month_22', 'day_of_week_22', 'day_22', 'holidays_true_22', 'preholidays_true_22', 'temp_last_day_22', 'target_lag_24_22', 'target_lag_72_22', 'target_lag_336_22', 'VVP_22', 'cloudy_22', 'rainy_22', 'windy_22', 'clear_22', 'rain_probability_22', 'has_rain_probability_22', 'P_22', 'U_22', 'WW_22', 'Td_22', 'N_22', 'S_22', 'W_22', 'E_22', 'last_evening_avg_target_0_22', 'last_evening_avg_temp_0_22', 'last_evening_avg_target_19_22', 'last_evening_avg_temp_19_22', 'last_evening_avg_target_22_22', 'last_evening_avg_temp_22_22', 'time_23', 'temp_pred_23', 'year_23', 'month_23', 'day_of_week_23', 'day_23', 'holidays_true_23', 'preholidays_true_23', 'temp_last_day_23', 'target_lag_24_23', 'target_lag_72_23', 'target_lag_336_23', 'VVP_23', 'cloudy_23', 'rainy_23', 'windy_23', 'clear_23', 'rain_probability_23', 'has_rain_probability_23', 'P_23', 'U_23', 'WW_23', 'Td_23', 'N_23', 'S_23', 'W_23', 'E_23', 'last_evening_avg_target_0_23', 'last_evening_avg_temp_0_23', 'last_evening_avg_target_19_23', 'last_evening_avg_temp_19_23', 'last_evening_avg_target_22_23', 'last_evening_avg_temp_22_23', 'target_1', 'temp_1', 'target_5', 'temp_5', 'target_9', 'temp_9', 'target']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "temp_pred         float64\n",
       "temp_last_day     float64\n",
       "target_lag_24     float64\n",
       "target_lag_72     float64\n",
       "target_lag_336    float64\n",
       "                   ...   \n",
       "temp_1            float64\n",
       "target_5          float64\n",
       "temp_5            float64\n",
       "target_9          float64\n",
       "temp_9            float64\n",
       "Length: 366, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_target = feature_cols +['target']\n",
    "#feature_target.remove('date')\n",
    "print(feature_target)\n",
    "\n",
    "train_ds[feature_aug].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06b4774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8576a14879ff456da58b17ec79bfd5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=560672), Label(value='0 / 560672')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def augment_row(df_to_augment, features_to_augment, alpha, i, random_1):\n",
    "\n",
    "\n",
    "    random.seed(random_1*i)\n",
    "\n",
    "    random_sample1 = random.randint(0000, 50000)\n",
    "    random_sample2 = random.randint(50001, 100000)\n",
    "\n",
    "    df_sample1 = df_to_augment.sample(frac=1,\n",
    "                                     random_state=random_sample1\n",
    "                                     )\n",
    "    df_sample2 = df_to_augment.sample(frac=1,\n",
    "                                     random_state = random_sample2\n",
    "                                     )\n",
    "\n",
    "    lmbda = np.random.beta(alpha, alpha)\n",
    "\n",
    "    df_mixup_sample = df_sample1.copy()\n",
    "    df_mixup_sample[features_to_augment] = df_sample1[features_to_augment] * lmbda + df_sample2[features_to_augment] * (1 - lmbda)\n",
    "        \n",
    "    other_features = list(set(df_to_augment.columns) - set(features_to_augment))\n",
    "    df_mixup_sample[other_features] = df_sample1[other_features]\n",
    "\n",
    "    return df_mixup_sample\n",
    "\n",
    "def mixup(df, alpha, features_to_augment, n_augmentations):\n",
    "    random.seed(random_state) #random.seed(42)\n",
    "    random_1 = random.randint(500, 9500)\n",
    "\n",
    "    \n",
    "    df_to_augment = df[(df['date'] < open_test_begin) & (df['month'].isin(list(range(4,10))))]\n",
    "    df_to_keep = df[(df['date'] >= open_test_begin) | (df['month'].isin([1,2,3,10,11,12]))]\n",
    "\n",
    "    df_mixup = pd.concat([augment_row(df_to_augment, features_to_augment, alpha, i, random_1) for i in range(n_augmentations)]).parallel_apply(lambda x: x)\n",
    "\n",
    "    df_final = pd.concat([ df_mixup,\n",
    "                           df_to_augment,  #нужно раскомитить если обучение с нуля\n",
    "                           df_to_keep])\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n",
    "n_augmentations = 32\n",
    "alpha=0.3 #15\n",
    "n_frac = 1\n",
    "train_ds_mixup = mixup(train_ds[feature_target], alpha, feature_aug, n_augmentations)\n",
    "FEATURES = '_Aug_32_alpha_3_summer'\n",
    "num = 'FULL ds' #номер модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "680b75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40027, 800) (600699, 800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_82143/132879785.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds_mixup.reset_index(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[feature_target].shape, train_ds_mixup.shape)\n",
    "train_ds_mixup.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f34c90",
   "metadata": {},
   "source": [
    "#### 1.12 Выделение наборов данных для обучения, валидации и тестирования\n",
    "\n",
    "Выделялось два набора данных для обучения и валидации:\n",
    "1. Обучение на данных с 2019 по 2021 с валидацией на 2022\n",
    "2. Обучение на данных с 2019 по 2022 с валидацией на первом квартале 2023\n",
    "\n",
    "Первый набор позволяет оценить влияние сезонности на обучение и предсказания, второй позволяет обучить модель на большем объеме данных и на более актуальных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a2b8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем набор датасетов для обучения и проверки\n",
    "features = train_ds_mixup[feature_cols]\n",
    "target = train_ds_mixup['target']\n",
    "\n",
    "# Функция для выделения временных интервалов из таблиц признаков и целей\n",
    "# на этом этапе отбрасываем колонку 'date'\n",
    "def features_interval(features, target, date1, date2):\n",
    "    features_interval = features[ (features['date']>=date1) & (features['date']<date2) ]\n",
    "    target_interval = target[features_interval.index]\n",
    "    features_interval = features_interval.drop('date', axis=1)\n",
    "    return features_interval, target_interval\n",
    "\n",
    "\n",
    "\n",
    "# для первичного подбора гиперпараметров будем обучать на 19-22 годах, валидировать август-сентябрь 2022\n",
    "features_all_train, target_all_train = features_interval(features, target, '2019-01-01', '2022-08-01')\n",
    "features_open_test, target_open_test = features_interval(features, target, '2022-08-01', '2022-09-30')\n",
    "\n",
    "# для проверки на тестовой выборке будем учиться на всем тренировочном датасете\n",
    "features_all_train, target_all_train = features_interval(features, target, '2019-01-01', open_test_end)\n",
    "features_open_test, target_open_test = features_interval(features, target, open_test_begin, open_test_end)\n",
    "\n",
    "features_open_test_sum, target_open_test_sum = features_interval(features, target, '2023-06-01', open_test_end)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "946f7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=('Выборка', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f69ef2",
   "metadata": {},
   "source": [
    "### 4. Проверка метрик на тестовом датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca38f19",
   "metadata": {},
   "source": [
    "#### 4.1 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b9a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [#'preholidays',\n",
    "            #'has_rain_probability', 'W', 'E',\n",
    "            #'holidays' \n",
    "            ]\n",
    "feat_lgbm_train = features_all_train.drop(columns=drop_list)\n",
    "feat_lgbm_test = features_open_test.drop(columns=drop_list)\n",
    "print(feat_lgbm_train.shape, target_all_train.shape, feat_lgbm_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88929019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "# Здесь обучаем на всем тренировочном датасете\n",
    "\n",
    "params= {'num_leaves': 34, 'min_child_samples': 16, \n",
    "          'max_depth': 8, 'learning_rate': 0.012, \n",
    "          'min_sum_hessian_in_leaf': 1e-4,\n",
    "          'objective': 'regression_l1', 'feature_fraction': 0.9574152630927155,\n",
    "          'n_jobs':-1, 'num_iterations':10000\n",
    "          }\n",
    "\n",
    "params = {'num_leaves':15, \n",
    "          'learning_rate':0.02, \n",
    "          'feature_fraction':1, \n",
    "          'num_iterations':10000, \n",
    "          'random_state':random_state, \n",
    "          'objective':'regression_l1',\n",
    "          'n_jobs':-1}\n",
    "\n",
    "\n",
    "\n",
    "def print_iteration_info(env):\n",
    "    # выводим номер итерации и время, затраченное на предыдущую итерацию\n",
    "    print('Iteration:', env.iteration)\n",
    "\n",
    "\n",
    "lgbm_model_all_train = lgb.LGBMRegressor(**params)\n",
    "lgbm_model_all_train.fit(feat_lgbm_train, target_all_train, callbacks=[print_iteration_info])\n",
    "\n",
    "l_predict_train = lgbm_model_all_train.predict(feat_lgbm_train)\n",
    "l_predict_test = lgbm_model_all_train.predict(feat_lgbm_test)\n",
    "\n",
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, l_predict_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, l_predict_test)\n",
    "\n",
    "results = pd.DataFrame([[f'тренировочная LGBM {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая LGBM {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129bac4",
   "metadata": {},
   "source": [
    "# До обучение модели \n",
    "\n",
    "\n",
    "params= {'num_leaves': 34, 'min_child_samples': 16, \n",
    "          'max_depth': 8, 'learning_rate': 0.012, \n",
    "          'min_sum_hessian_in_leaf': 1e-4,\n",
    "          'objective': 'regression_l1', 'feature_fraction': 0.9574152630927155,\n",
    "          'n_jobs':-1, 'num_iterations':10000\n",
    "          }\n",
    "\n",
    "def print_iteration_info(env):\n",
    "    # выводим номер итерации и время, затраченное на предыдущую итерацию\n",
    "    print('Iteration:', env.iteration)\n",
    "\n",
    "\n",
    "\n",
    "lgbm_model_all_train.fit(feat_lgbm_train, target_all_train, callbacks=[print_iteration_info],  init_model=lgbm_model_all_train)\n",
    "\n",
    "l_predict_train = lgbm_model_all_train.predict(feat_lgbm_train)\n",
    "l_predict_test = lgbm_model_all_train.predict(feat_lgbm_test)\n",
    "\n",
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, l_predict_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, l_predict_test)\n",
    "\n",
    "results = pd.DataFrame([[f'тренировочная LGBM add train {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая LGBM add train {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47121cb",
   "metadata": {},
   "source": [
    "#### 4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43f228a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'temp_pred', 'year', 'month', 'day_of_week', 'day',\n",
       "       'holidays_true', 'preholidays_true', 'temp_last_day', 'target_lag_24',\n",
       "       ...\n",
       "       'last_evening_avg_target_19_23', 'last_evening_avg_temp_19_23',\n",
       "       'last_evening_avg_target_22_23', 'last_evening_avg_temp_22_23',\n",
       "       'target_1', 'temp_1', 'target_5', 'temp_5', 'target_9', 'temp_9'],\n",
       "      dtype='object', length=798)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f8dba00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['time', 'temp_pred', 'year', 'month', 'day_of_week', 'day',\n",
       "        'holidays_true', 'temp_last_day', 'target_lag_24', 'target_lag_72',\n",
       "        ...\n",
       "        'last_evening_avg_target_19_23', 'last_evening_avg_temp_19_23',\n",
       "        'last_evening_avg_target_22_23', 'last_evening_avg_temp_22_23',\n",
       "        'target_1', 'temp_1', 'target_5', 'temp_5', 'target_9', 'temp_9'],\n",
       "       dtype='object', length=774),\n",
       " Index(['time', 'temp_pred', 'year', 'month', 'day_of_week', 'day',\n",
       "        'holidays_true', 'temp_last_day', 'target_lag_24', 'target_lag_72',\n",
       "        ...\n",
       "        'last_evening_avg_target_19_23', 'last_evening_avg_temp_19_23',\n",
       "        'last_evening_avg_target_22_23', 'last_evening_avg_temp_22_23',\n",
       "        'target_1', 'temp_1', 'target_5', 'temp_5', 'target_9', 'temp_9'],\n",
       "       dtype='object', length=774))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_list = ['preholidays_true',\n",
    "            #'has_rain_probability', \n",
    "            # 'W', 'E'\n",
    "            ]\n",
    "n_values = range(1, 24)\n",
    "preholidays = ['preholidays_true_{}'.format(n) for n in n_values]\n",
    "#has_rain = ['has_rain_probability_{}'.format(n) for n in n_values]\n",
    "#W_wind = ['W_{}'.format(n) for n in n_values]\n",
    "#E_wind = ['E_{}'.format(n) for n in n_values]\n",
    "\n",
    "drop_list = drop_list + preholidays #+ has_rain + W_wind + E_wind\n",
    "\n",
    "feat_xgb_train = features_all_train.drop(columns=drop_list)\n",
    "feat_xgb_test = features_open_test.drop(columns=drop_list)\n",
    "feat_xgb_train.columns, feat_xgb_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    max_depth=7,\n",
    "    n_estimators=1190, #n_estimators=195, #\n",
    "    learning_rate=0.009, #learning_rate=0.1, #\n",
    "    tree_method='exact',\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    gamma=2,\n",
    "    colsample_bytree=1,\n",
    "    random_state=random_state\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c485a569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/xgboost/sklearn.py:885: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Time for last iteration: -7.954346179962158\n",
      "Iteration: 1 Time for last iteration: -3.851109027862549\n",
      "Iteration: 2 Time for last iteration: -3.820694923400879\n",
      "Iteration: 3 Time for last iteration: -3.7689507007598877\n",
      "Iteration: 4 Time for last iteration: -3.9395508766174316\n",
      "Iteration: 5 Time for last iteration: -3.976970672607422\n",
      "Iteration: 6 Time for last iteration: -3.9511427879333496\n",
      "Iteration: 7 Time for last iteration: -4.357666969299316\n",
      "Iteration: 8 Time for last iteration: -5.009012937545776\n",
      "Iteration: 9 Time for last iteration: -4.314996004104614\n",
      "Iteration: 10 Time for last iteration: -4.339528799057007\n",
      "Iteration: 11 Time for last iteration: -4.276592969894409\n",
      "Iteration: 12 Time for last iteration: -4.564397811889648\n",
      "Iteration: 13 Time for last iteration: -4.236433029174805\n",
      "Iteration: 14 Time for last iteration: -4.251938104629517\n",
      "Iteration: 15 Time for last iteration: -4.353200912475586\n",
      "Iteration: 16 Time for last iteration: -4.175693035125732\n",
      "Iteration: 17 Time for last iteration: -4.144140958786011\n",
      "Iteration: 18 Time for last iteration: -4.077541828155518\n",
      "Iteration: 19 Time for last iteration: -4.364701747894287\n",
      "Iteration: 20 Time for last iteration: -4.130523920059204\n",
      "Iteration: 21 Time for last iteration: -4.045159101486206\n",
      "Iteration: 22 Time for last iteration: -4.089580059051514\n",
      "Iteration: 23 Time for last iteration: -4.188736915588379\n",
      "Iteration: 24 Time for last iteration: -4.091204881668091\n",
      "Iteration: 25 Time for last iteration: -4.1199469566345215\n",
      "Iteration: 26 Time for last iteration: -4.234934091567993\n",
      "Iteration: 27 Time for last iteration: -4.277517080307007\n",
      "Iteration: 28 Time for last iteration: -4.151387929916382\n",
      "Iteration: 29 Time for last iteration: -4.8113720417022705\n",
      "Iteration: 30 Time for last iteration: -4.810459136962891\n",
      "Iteration: 31 Time for last iteration: -4.683189868927002\n",
      "Iteration: 32 Time for last iteration: -4.550647020339966\n",
      "Iteration: 33 Time for last iteration: -4.702538967132568\n",
      "Iteration: 34 Time for last iteration: -4.547429084777832\n",
      "Iteration: 35 Time for last iteration: -4.5835840702056885\n",
      "Iteration: 36 Time for last iteration: -4.665450096130371\n",
      "Iteration: 37 Time for last iteration: -4.599506139755249\n",
      "Iteration: 38 Time for last iteration: -4.674633026123047\n",
      "Iteration: 39 Time for last iteration: -4.663909912109375\n",
      "Iteration: 40 Time for last iteration: -4.720873117446899\n",
      "Iteration: 41 Time for last iteration: -4.816114187240601\n",
      "Iteration: 42 Time for last iteration: -4.800947189331055\n",
      "Iteration: 43 Time for last iteration: -5.161530017852783\n",
      "Iteration: 44 Time for last iteration: -5.1524858474731445\n",
      "Iteration: 45 Time for last iteration: -5.022156000137329\n",
      "Iteration: 46 Time for last iteration: -4.947957992553711\n",
      "Iteration: 47 Time for last iteration: -4.85769510269165\n",
      "Iteration: 48 Time for last iteration: -5.11197304725647\n",
      "Iteration: 49 Time for last iteration: -4.694792985916138\n",
      "Iteration: 50 Time for last iteration: -4.618656873703003\n",
      "Iteration: 51 Time for last iteration: -4.554123163223267\n",
      "Iteration: 52 Time for last iteration: -4.626152992248535\n",
      "Iteration: 53 Time for last iteration: -4.7585227489471436\n",
      "Iteration: 54 Time for last iteration: -4.8632493019104\n",
      "Iteration: 55 Time for last iteration: -4.706692934036255\n",
      "Iteration: 56 Time for last iteration: -4.6920530796051025\n",
      "Iteration: 57 Time for last iteration: -4.8388872146606445\n",
      "Iteration: 58 Time for last iteration: -4.988811016082764\n",
      "Iteration: 59 Time for last iteration: -4.640501022338867\n",
      "Iteration: 60 Time for last iteration: -4.721771001815796\n",
      "Iteration: 61 Time for last iteration: -4.471433162689209\n",
      "Iteration: 62 Time for last iteration: -4.351866960525513\n",
      "Iteration: 63 Time for last iteration: -4.294049978256226\n",
      "Iteration: 64 Time for last iteration: -4.238624095916748\n",
      "Iteration: 65 Time for last iteration: -4.2645628452301025\n",
      "Iteration: 66 Time for last iteration: -4.225245237350464\n",
      "Iteration: 67 Time for last iteration: -4.2877418994903564\n",
      "Iteration: 68 Time for last iteration: -4.3239829540252686\n",
      "Iteration: 69 Time for last iteration: -4.241498947143555\n",
      "Iteration: 70 Time for last iteration: -4.241727113723755\n",
      "Iteration: 71 Time for last iteration: -4.155644178390503\n",
      "Iteration: 72 Time for last iteration: -4.4920878410339355\n",
      "Iteration: 73 Time for last iteration: -4.55635666847229\n",
      "Iteration: 74 Time for last iteration: -4.450862884521484\n",
      "Iteration: 75 Time for last iteration: -5.103631258010864\n",
      "Iteration: 76 Time for last iteration: -4.992284059524536\n",
      "Iteration: 77 Time for last iteration: -5.109851121902466\n",
      "Iteration: 78 Time for last iteration: -5.053272247314453\n",
      "Iteration: 79 Time for last iteration: -4.653134822845459\n",
      "Iteration: 80 Time for last iteration: -4.7114198207855225\n",
      "Iteration: 81 Time for last iteration: -4.6577441692352295\n",
      "Iteration: 82 Time for last iteration: -4.895749807357788\n",
      "Iteration: 83 Time for last iteration: -4.903384685516357\n",
      "Iteration: 84 Time for last iteration: -4.6369640827178955\n",
      "Iteration: 85 Time for last iteration: -4.872097015380859\n",
      "Iteration: 86 Time for last iteration: -4.739338159561157\n",
      "Iteration: 87 Time for last iteration: -4.7300779819488525\n",
      "Iteration: 88 Time for last iteration: -4.691432237625122\n",
      "Iteration: 89 Time for last iteration: -4.763777732849121\n",
      "Iteration: 90 Time for last iteration: -4.723409175872803\n",
      "Iteration: 91 Time for last iteration: -4.720641136169434\n",
      "Iteration: 92 Time for last iteration: -4.735931158065796\n",
      "Iteration: 93 Time for last iteration: -4.819322109222412\n",
      "Iteration: 94 Time for last iteration: -4.582803964614868\n",
      "Iteration: 95 Time for last iteration: -4.762561082839966\n",
      "Iteration: 96 Time for last iteration: -4.510548114776611\n",
      "Iteration: 97 Time for last iteration: -4.727827310562134\n",
      "Iteration: 98 Time for last iteration: -4.89379620552063\n",
      "Iteration: 99 Time for last iteration: -4.520194053649902\n",
      "Iteration: 100 Time for last iteration: -4.731054782867432\n",
      "Iteration: 101 Time for last iteration: -4.718137741088867\n",
      "Iteration: 102 Time for last iteration: -4.728257656097412\n",
      "Iteration: 103 Time for last iteration: -4.5302300453186035\n",
      "Iteration: 104 Time for last iteration: -4.675106048583984\n",
      "Iteration: 105 Time for last iteration: -5.049559116363525\n",
      "Iteration: 106 Time for last iteration: -5.00672721862793\n",
      "Iteration: 107 Time for last iteration: -4.903281927108765\n",
      "Iteration: 108 Time for last iteration: -4.572115898132324\n",
      "Iteration: 109 Time for last iteration: -4.749758958816528\n",
      "Iteration: 110 Time for last iteration: -4.906162977218628\n",
      "Iteration: 111 Time for last iteration: -4.867657899856567\n",
      "Iteration: 112 Time for last iteration: -4.718371868133545\n",
      "Iteration: 113 Time for last iteration: -4.609199047088623\n",
      "Iteration: 114 Time for last iteration: -4.775206089019775\n",
      "Iteration: 115 Time for last iteration: -4.718335866928101\n",
      "Iteration: 116 Time for last iteration: -4.827889919281006\n",
      "Iteration: 117 Time for last iteration: -4.6372880935668945\n",
      "Iteration: 118 Time for last iteration: -4.8570239543914795\n",
      "Iteration: 119 Time for last iteration: -4.544461011886597\n",
      "Iteration: 120 Time for last iteration: -4.569706916809082\n",
      "Iteration: 121 Time for last iteration: -4.7082579135894775\n",
      "Iteration: 122 Time for last iteration: -4.738706827163696\n",
      "Iteration: 123 Time for last iteration: -5.00911283493042\n",
      "Iteration: 124 Time for last iteration: -4.548717737197876\n",
      "Iteration: 125 Time for last iteration: -4.773385047912598\n",
      "Iteration: 126 Time for last iteration: -4.578091859817505\n",
      "Iteration: 127 Time for last iteration: -4.760642051696777\n",
      "Iteration: 128 Time for last iteration: -4.578230142593384\n",
      "Iteration: 129 Time for last iteration: -4.526462078094482\n",
      "Iteration: 130 Time for last iteration: -4.512944936752319\n",
      "Iteration: 131 Time for last iteration: -4.715801954269409\n",
      "Iteration: 132 Time for last iteration: -4.563736915588379\n",
      "Iteration: 133 Time for last iteration: -4.809449195861816\n",
      "Iteration: 134 Time for last iteration: -4.622365236282349\n",
      "Iteration: 135 Time for last iteration: -4.584795951843262\n",
      "Iteration: 136 Time for last iteration: -4.511338233947754\n",
      "Iteration: 137 Time for last iteration: -4.6078221797943115\n",
      "Iteration: 138 Time for last iteration: -4.798403263092041\n",
      "Iteration: 139 Time for last iteration: -4.56346321105957\n",
      "Iteration: 140 Time for last iteration: -4.756514072418213\n",
      "Iteration: 141 Time for last iteration: -4.642225027084351\n",
      "Iteration: 142 Time for last iteration: -4.77629017829895\n",
      "Iteration: 143 Time for last iteration: -4.834002256393433\n",
      "Iteration: 144 Time for last iteration: -4.760793924331665\n",
      "Iteration: 145 Time for last iteration: -4.587145090103149\n",
      "Iteration: 146 Time for last iteration: -4.8088178634643555\n",
      "Iteration: 147 Time for last iteration: -4.6209821701049805\n",
      "Iteration: 148 Time for last iteration: -4.635960102081299\n",
      "Iteration: 149 Time for last iteration: -4.811732053756714\n",
      "Iteration: 150 Time for last iteration: -4.66031289100647\n",
      "Iteration: 151 Time for last iteration: -4.584931135177612\n",
      "Iteration: 152 Time for last iteration: -4.396823883056641\n",
      "Iteration: 153 Time for last iteration: -4.397246837615967\n",
      "Iteration: 154 Time for last iteration: -4.509900093078613\n",
      "Iteration: 155 Time for last iteration: -4.469858169555664\n",
      "Iteration: 156 Time for last iteration: -4.735170125961304\n",
      "Iteration: 157 Time for last iteration: -4.6344990730285645\n",
      "Iteration: 158 Time for last iteration: -4.577824115753174\n",
      "Iteration: 159 Time for last iteration: -4.575547933578491\n",
      "Iteration: 160 Time for last iteration: -4.732958078384399\n",
      "Iteration: 161 Time for last iteration: -4.618714809417725\n",
      "Iteration: 162 Time for last iteration: -4.787324905395508\n",
      "Iteration: 163 Time for last iteration: -4.745928049087524\n",
      "Iteration: 164 Time for last iteration: -4.6312291622161865\n",
      "Iteration: 165 Time for last iteration: -4.541469097137451\n",
      "Iteration: 166 Time for last iteration: -4.447199106216431\n",
      "Iteration: 167 Time for last iteration: -4.547536134719849\n",
      "Iteration: 168 Time for last iteration: -4.879794120788574\n",
      "Iteration: 169 Time for last iteration: -4.507405042648315\n",
      "Iteration: 170 Time for last iteration: -4.641258001327515\n",
      "Iteration: 171 Time for last iteration: -4.525886297225952\n",
      "Iteration: 172 Time for last iteration: -4.5343451499938965\n",
      "Iteration: 173 Time for last iteration: -4.3594748973846436\n",
      "Iteration: 174 Time for last iteration: -4.464529991149902\n",
      "Iteration: 175 Time for last iteration: -4.631933927536011\n",
      "Iteration: 176 Time for last iteration: -4.343334913253784\n",
      "Iteration: 177 Time for last iteration: -4.379106760025024\n",
      "Iteration: 178 Time for last iteration: -4.6135687828063965\n",
      "Iteration: 179 Time for last iteration: -4.9452900886535645\n",
      "Iteration: 180 Time for last iteration: -4.887060165405273\n",
      "Iteration: 181 Time for last iteration: -4.641790866851807\n",
      "Iteration: 182 Time for last iteration: -4.604913949966431\n",
      "Iteration: 183 Time for last iteration: -4.6645917892456055\n",
      "Iteration: 184 Time for last iteration: -4.467200994491577\n",
      "Iteration: 185 Time for last iteration: -4.670956134796143\n",
      "Iteration: 186 Time for last iteration: -4.455126047134399\n",
      "Iteration: 187 Time for last iteration: -4.663379192352295\n",
      "Iteration: 188 Time for last iteration: -4.629243850708008\n",
      "Iteration: 189 Time for last iteration: -4.592947244644165\n",
      "Iteration: 190 Time for last iteration: -4.828571081161499\n",
      "Iteration: 191 Time for last iteration: -4.7422239780426025\n",
      "Iteration: 192 Time for last iteration: -4.437243223190308\n",
      "Iteration: 193 Time for last iteration: -4.5450758934021\n",
      "Iteration: 194 Time for last iteration: -4.704207897186279\n",
      "Iteration: 195 Time for last iteration: -4.532270193099976\n",
      "Iteration: 196 Time for last iteration: -4.518923759460449\n",
      "Iteration: 197 Time for last iteration: -4.682545900344849\n",
      "Iteration: 198 Time for last iteration: -4.729722023010254\n",
      "Iteration: 199 Time for last iteration: -4.5375847816467285\n",
      "Iteration: 200 Time for last iteration: -4.3867409229278564\n",
      "Iteration: 201 Time for last iteration: -4.629760026931763\n",
      "Iteration: 202 Time for last iteration: -4.635207891464233\n",
      "Iteration: 203 Time for last iteration: -4.55546498298645\n",
      "Iteration: 204 Time for last iteration: -4.628164052963257\n",
      "Iteration: 205 Time for last iteration: -4.431711912155151\n",
      "Iteration: 206 Time for last iteration: -4.437255144119263\n",
      "Iteration: 207 Time for last iteration: -4.405670881271362\n",
      "Iteration: 208 Time for last iteration: -4.400835990905762\n",
      "Iteration: 209 Time for last iteration: -4.475727081298828\n",
      "Iteration: 210 Time for last iteration: -5.393908977508545\n",
      "Iteration: 211 Time for last iteration: -4.6743268966674805\n",
      "Iteration: 212 Time for last iteration: -4.495438814163208\n",
      "Iteration: 213 Time for last iteration: -4.653299808502197\n",
      "Iteration: 214 Time for last iteration: -4.675958633422852\n"
     ]
    }
   ],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "\n",
    "\n",
    "class IterationInfoCallback(TrainingCallback):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        print('Iteration:', epoch, 'Time for last iteration:', self.start_time - time.time())\n",
    "        self.start_time = time.time()\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "xgb_model_all_train = xgb_model.fit(feat_xgb_train, target_all_train, callbacks=[IterationInfoCallback()])\n",
    "\n",
    "xgb_predict_test = xgb_model_all_train.predict(feat_xgb_test)\n",
    "xgb_predict_train = xgb_model_all_train.predict(feat_xgb_train)\n",
    "\n",
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, xgb_predict_train )\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, xgb_predict_test )\n",
    "\n",
    "results = pd.concat([results,\n",
    "pd.DataFrame([[f'тренировочная XGB {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая XGB {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['preholidays_true',\n",
    "            ]\n",
    "n_values = range(1, 24)\n",
    "preholidays = ['preholidays_true_{}'.format(n) for n in n_values]\n",
    "\n",
    "\n",
    "drop_list = drop_list + preholidays #+ has_rain + W_wind + E_wind\n",
    "\n",
    "feat_xgb_test_summ = features_open_test_sum.drop(columns=drop_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_predict_test_sum = xgb_model_all_train.predict(feat_xgb_test_summ)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test_sum, xgb_predict_test_sum )\n",
    "results = pd.concat([results,\n",
    "pd.DataFrame([ [f'тестовая XGB summer{FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e9496",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19eaded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#num = 3\n",
    "# определите путь к папке, которую вы хотите создать\n",
    "folder_path = \"models\"\n",
    "\n",
    "# проверьте, существует ли уже папка\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "xgb_model.save_model(f'models/xgb_model{FEATURES}_{num}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e232b25",
   "metadata": {},
   "source": [
    "### 5. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ensemble = pd.DataFrame(columns=('Выборка', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c8a35",
   "metadata": {},
   "source": [
    "### Simple Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15100001",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_simple_ensemble_train = (xgb_predict_train + l_predict_train)/2\n",
    "predict_simple_ensemble_test = (xgb_predict_test + l_predict_test)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, predict_simple_ensemble_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, predict_simple_ensemble_test)\n",
    "\n",
    "results_ensemble = pd.concat([results_ensemble,\n",
    "pd.DataFrame([[f'тренировочная simple_ensemble  {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая simple_ensemble {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_ensemble)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864aa633",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_day(target_open_test, predict_simple_ensemble_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#num = 3\n",
    "# определите путь к папке, которую вы хотите создать\n",
    "folder_path = \"models\"\n",
    "\n",
    "# проверьте, существует ли уже папка\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "lgbm_model_all_train.booster_.save_model(f'models/lgb_model{FEATURES}_{num}.txt')\n",
    "xgb_model.save_model(f'models/xgb_model{FEATURES}_{num}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURES = 'BASE'\n",
    "results.to_csv(f'models/results_LGBM_XGBoost_simple_ensemble_{FEATURES}_{num}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
