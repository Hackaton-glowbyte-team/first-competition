{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5606014",
   "metadata": {},
   "source": [
    "## Энергетический оракул\n",
    "Ноутбук команды #12\n",
    "\n",
    "Работа выполнена на основе модели LightGBM\n",
    "\n",
    "\n",
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4351135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True )\n",
    "\n",
    "from xgboost.callback import TrainingCallback\n",
    "import time\n",
    "\n",
    "\n",
    "random_state = 12345\n",
    "NUM_ITERATIONS = 5000\n",
    "\n",
    "FEATURES = 'base feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26bfa344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45891200",
   "metadata": {},
   "source": [
    "#### 1.1 Функции для расшифровки прогноза погоды в колонке 'weather_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece12617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "\n",
    "# функция формирует колонки 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability', 'has_rain_probability'\n",
    "# в колонках число, которое 0 при отсутсвии упоминания явления в weather_pred или степень упоминания\n",
    "# функция дает в колонках номер первого списка, элемент которого есть в строке плюс 1\n",
    "# списки cloudy_list, rainy_list, windy_list, clear_list можно модифицировать\n",
    "# соответственно, можно экспериментировать с расположением значений в списках\n",
    "# например, сейчас 'дождь', 'снег', 'д+сн' - первая степень  дождя, а 'гроз', 'ливень' - вторая\n",
    "# а можно сделать снег второй, а грозу с ливнем убрать в третью\n",
    "# также сделал отдельный список для \"ясности\", чтобы выделить 'ясно' и 'солнечно'\n",
    "\n",
    "def in_what_list(weather, big_list):\n",
    "    for list_number, small_list in enumerate(big_list):\n",
    "        if any(word in weather for word in small_list):\n",
    "            return list_number+1\n",
    "    return 0\n",
    "\n",
    "def weather_split2(row):\n",
    "    weather = row['weather_pred']\n",
    "    cloudy_list = [['проясн', 'пер.об.', 'п/об'], ['пасм', 'обл']]\n",
    "    rainy_list = [['дождь', 'снег', 'д+сн'], ['гроз', 'ливень']]\n",
    "    windy_list = [['вет'],['штор']]\n",
    "    clear_list = [['проясн'], ['ясно'], ['солнеч']]\n",
    "    numbers = re.findall(r'\\d+', weather)\n",
    "    cloudy = in_what_list(weather, cloudy_list)\n",
    "    rainy = in_what_list(weather, rainy_list)\n",
    "    windy = in_what_list(weather, windy_list)\n",
    "    clear = in_what_list(weather, clear_list)\n",
    "    rain_probability = 0 if len(numbers)==0 else int(numbers[0])\n",
    "    has_rain_probability = int(len(numbers)==0)\n",
    "    return cloudy, rainy, windy, clear, rain_probability, has_rain_probability\n",
    "\n",
    "def fill_weather_columns(df):\n",
    "    df['weather_pred'] = df['weather_pred'].fillna('')\n",
    "    df['cloudy'], df['rainy'], df['windy'], df['clear'], df['rain_probability'], df['has_rain_probability'] = \\\n",
    "                zip(*df.apply(weather_split2, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39d660",
   "metadata": {},
   "source": [
    "#### 1.2 Функции для загрузки данных о ВВП \n",
    "данные загружаются из файла 'data/VVP.csv'\n",
    "\n",
    "Некоторые научные работы указывают на прямую связь величины потребления электричества и показателя ВВП, который отражает ситуацию в экономике. Данные по экономике публикуются различными министерствами с разной периодичностью. Для использования в работе были взяты фактические данные по ВВП с сайта investing, который агрегирует публикации Минэкономразвития. Данные за месяц побликуются с месячной задержкой, поэтому модель использует для прогнозирования данные за прошлые месяцы, которые известны.   \n",
    "  \n",
    "Ссылка на данные: https://ru.investing.com/economic-calendar/russian-monthly-gdp-407\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3dd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция добавляет данные о ВВП из файла 'data/VVP.csv' в датасет\n",
    "\n",
    "def add_vvp2(data, file_source = 'data/VVP.csv'):\n",
    "    \"\"\"\n",
    "    сырой датафрем подаем на вход\n",
    "    \"\"\"\n",
    "    # обработаем файл с динамикой ВВП\n",
    "    vvp = pd.read_csv(file_source)\n",
    "    # преобразуем дату файла-источника в формат datetime64 и дропнем один столбик\n",
    "    vvp['date'] = pd.to_datetime(vvp['date'], format ='%Y-%m-%d %H:%M:%S')\n",
    "    vvp.drop('for_month',axis=1,inplace=True) \n",
    "    \n",
    "    # обработаем основной фрейм - создадим столбец для соединения, который потом удалим\n",
    "    data['date_temp'] = pd.to_datetime(data['date'], format = '%Y-%m-%d' )\n",
    "    data['date_temp'] = data['date_temp'] + pd.to_timedelta(data['time'] , 'H')\n",
    "    \n",
    "    # соединяем основной фрейм и ВВП по дате объявления показтеля ВВП\n",
    "    for idx in reversed(vvp.index):\n",
    "        data.loc[data['date_temp']>=vvp.date[idx],'VVP'] = vvp.VVP_perc[idx]\n",
    "        \n",
    "    data.drop('date_temp',axis=1,inplace=True)   \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe769599",
   "metadata": {},
   "source": [
    "#### 1.3 Функции для загрузки архива данных о фактической погоде\n",
    "данные загружаются из файла 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "Изначально данные для формирования таблицы \"preprocessing_loaded_table\" были взяты из с сайта [https://rp5.ru](https://rp5.ru/Архив_погоды_в_Храброво,_им._императрицы_Елизаветы_Петровны_(аэропорт),_METAR), где хранятся архивы погоды в аэрапорту Калининграда, за период с 31.12.2018 по 30.09.2023\n",
    "\n",
    "Описание данных в таблице:\n",
    "- Местное время в Храброво / им. императрицы Елизаветы Петровны (аэропорт) - Дата / Местное время\n",
    "- T -  Темпиратура воздуха\n",
    "- Po - Давление на уровне станции\n",
    "- P - Давление приведённое к уровню моря\n",
    "- U - Относительная влажность\n",
    "- DD - Направление ветра\n",
    "- Ff - Скорость ветра\n",
    "- ff10 - Максимальное значение порыва ветра\n",
    "- WW - Особое явление текущей погоды (осадки)\n",
    "- W'W' - Явление недавней погоды, имеющее оперативное значение\n",
    "- с - Общая облачность\n",
    "- VV - Горизонтальная дальность видимости\n",
    "- Td - Темпиратура точки росы\n",
    "\n",
    "Данные, которые были взяты из данной таблицы и загружаются из 'data/preprocessing_loaded_table.csv':\n",
    "- P - не подверглось изменению\n",
    "- U - не подверглось изменению\n",
    "- Td - не подверглась изменению\n",
    "\n",
    " WW - разделили на 4 категории:\n",
    "- Нет осадков (где были пропуски)\n",
    "- слабый дождь\n",
    "- сильный дождь\n",
    "- снег\n",
    "\n",
    "DD - создали 4 столбца, соответствующих сторонам горизонта, которые принимали значения 0; 0.5 и 1 в зависимости от силы ветра в конкретном направлении\n",
    "- N - north\n",
    "- S - south\n",
    "- W - west\n",
    "- E - east\n",
    "\n",
    "В дальнейшем эти данные использовались с лагом в сутки: в поля на завтрашний день записывались данные сегодняшнего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb3456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для работы с данными о фактической погоде из 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "# Кодировка информации об осадках из колонки WW\n",
    "def true_weather_WW_replace(ww):\n",
    "    if ww=='нет осадков':\n",
    "        return 0\n",
    "    elif ww=='слабый дождь':\n",
    "        return 1\n",
    "    elif (ww=='сильный дождь') or (ww=='снег'):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Вычисление Timestamp из даты и времени\n",
    "def row_plus_hours_to_index(row):\n",
    "    return row['date'] + pd.to_timedelta(row['time'] , 'H')\n",
    "\n",
    "# Функция для сдвига на сутки (в скачанном датасете разбивка по 30 мин, поэтому timeshift=48)\n",
    "def shift_features_fact(df, timeshift=48):\n",
    "    list_fact_columns=list(df.columns)\n",
    "    list_fact_columns.remove('date_tw')\n",
    "    new_df = df.copy()\n",
    "    for column in list_fact_columns:\n",
    "        new_df[column] = new_df[column].shift(timeshift)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5eb669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления метрики mae по дням из почасовых массивов данных\n",
    "\n",
    "def mae_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    return mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "# Функция для вычисления метрик по дням из почасовых массивов данных\n",
    "\n",
    "def metrics_hour(y_true, y_pred):\n",
    "\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808c109",
   "metadata": {},
   "source": [
    "#### 1.5 Чтение файлов с данными\n",
    "Данные объединяются в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a4ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начало открытого теста: 2023-04-01 00:00:00     конец открытого теста: 2023-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# читаем исходные датасеты и складываем в один\n",
    "train_ds = pd.read_csv('data/train_dataset.csv')\n",
    "test_ds = pd.read_csv('data/test_dataset.csv')\n",
    "train_ds = pd.concat([train_ds, test_ds])\n",
    "\n",
    "# запоминаем дату начала тестовых данных, потом также поступим и с закрытым датасетом\n",
    "open_test_begin = pd.to_datetime(test_ds['date']).min()\n",
    "open_test_end = pd.to_datetime(test_ds['date']).max() + pd.to_timedelta(1,'d')\n",
    "print('начало открытого теста:', open_test_begin, '    конец открытого теста:', open_test_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237ce32",
   "metadata": {},
   "source": [
    "#### 1.6 Формирование колонок с производными от даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16090ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем дату и делаем из нее колонки\n",
    "train_ds['date'] = pd.to_datetime(train_ds['date'])\n",
    "train_ds['year'] = train_ds['date'].dt.year\n",
    "train_ds['month'] = train_ds['date'].dt.month\n",
    "train_ds['day_of_week'] = train_ds['date'].dt.dayofweek\n",
    "train_ds['day'] = train_ds['date'].dt.day\n",
    "train_ds['day_of_year'] = train_ds['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e3cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>target</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_pred</th>\n",
       "      <th>weather_pred</th>\n",
       "      <th>weather_fact</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>21</td>\n",
       "      <td>524.178</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ясно</td>\n",
       "      <td>пасм, слаб.дождь</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34818</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>18</td>\n",
       "      <td>694.846</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>пасм, ветер, 74%  дождь</td>\n",
       "      <td>дымка</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33157</th>\n",
       "      <td>2022-10-13</td>\n",
       "      <td>13</td>\n",
       "      <td>519.836</td>\n",
       "      <td>14.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>облачно</td>\n",
       "      <td>облачно</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34541</th>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>5</td>\n",
       "      <td>503.541</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>пасмурно</td>\n",
       "      <td>пасм, дымка</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25896</th>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>0</td>\n",
       "      <td>567.499</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>пасм, 16%</td>\n",
       "      <td>пасм, морось</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  time   target  temp  temp_pred             weather_pred  \\\n",
       "381   2023-04-16    21  524.178   5.7        6.0                     ясно   \n",
       "34818 2022-12-21    18  694.846   2.0        3.0  пасм, ветер, 74%  дождь   \n",
       "33157 2022-10-13    13  519.836  14.6       14.0                  облачно   \n",
       "34541 2022-12-10     5  503.541  -4.9       -4.0                 пасмурно   \n",
       "25896 2021-12-15     0  567.499   3.0        3.0                пасм, 16%   \n",
       "\n",
       "           weather_fact  year  month  day_of_week  day  day_of_year  \n",
       "381    пасм, слаб.дождь  2023      4            6   16          106  \n",
       "34818             дымка  2022     12            2   21          355  \n",
       "33157           облачно  2022     10            3   13          286  \n",
       "34541       пасм, дымка  2022     12            5   10          344  \n",
       "25896      пасм, морось  2021     12            2   15          349  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98567815",
   "metadata": {},
   "source": [
    "#### 1.7 Подгрузка Auggumentaci в праздниках"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9963b",
   "metadata": {},
   "source": [
    "\n",
    "df_holidays = pd.read_csv('data/holidays_aug.csv')\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "# Добавление данных о праздниках из файла 'data/holidays.csv'\n",
    "\n",
    "\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())\n",
    "# Assuming df_holidays and train_ds are your dataframes\n",
    "train_ds = pd.merge(train_ds, df_holidays, on='date', how='left')\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())\n",
    "# Fill NaN values with 0\n",
    "train_ds['holidays'].fillna(0, inplace=True)\n",
    "train_ds['preholidays'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "train_ds['holidays'] = train_ds['holidays'].astype(int)\n",
    "train_ds['preholidays'] = train_ds['preholidays'].astype(int)\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5a0f9",
   "metadata": {},
   "source": [
    "#### 1.7.1 Подгрузка данных о праздниках на весь DS праздниках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ddfd107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер DS (40152, 12) дубликатов -  0\n",
      "размер DS (40152, 14) дубликатов -  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_holidays_true = pd.read_csv('data/holidays_true.csv')\n",
    "df_holidays_true['date'] = pd.to_datetime(df_holidays_true['date'])\n",
    "# Добавление данных о праздниках из файла 'data/holidays.csv'\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())\n",
    "# Assuming df_holidays and train_ds are your dataframes\n",
    "train_ds = pd.merge(train_ds, df_holidays_true, on='date', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "train_ds['holidays_true'].fillna(0, inplace=True)\n",
    "train_ds['preholidays_true'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "train_ds['holidays_true'] = train_ds['holidays_true'].astype(int)\n",
    "train_ds['preholidays_true'] = train_ds['preholidays_true'].astype(int)\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b32c4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40152 entries, 0 to 40151\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   date              40152 non-null  datetime64[ns]\n",
      " 1   time              40152 non-null  int64         \n",
      " 2   target            40152 non-null  float64       \n",
      " 3   temp              40152 non-null  float64       \n",
      " 4   temp_pred         40040 non-null  float64       \n",
      " 5   weather_pred      40040 non-null  object        \n",
      " 6   weather_fact      40151 non-null  object        \n",
      " 7   year              40152 non-null  int32         \n",
      " 8   month             40152 non-null  int32         \n",
      " 9   day_of_week       40152 non-null  int32         \n",
      " 10  day               40152 non-null  int32         \n",
      " 11  day_of_year       40152 non-null  int32         \n",
      " 12  holidays_true     40152 non-null  int64         \n",
      " 13  preholidays_true  40152 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int32(5), int64(3), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdfa6e",
   "metadata": {},
   "source": [
    "#### 1.8 Формирование колонок со значением целевого признака в предыдущие дни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91cfdcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер DS (40152, 15) дубликатов -  0\n",
      "размер DS (40152, 20) дубликатов -  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/2320664940.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_ds['temp_last_day'].fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Добавление колонок с временными лагами\n",
    "\n",
    "# создаем столбец 'temp_last_day'\n",
    "train_ds['temp_last_day'] = train_ds['temp'].shift(24)\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())\n",
    "# заполняем пропущенные значения в 'temp_last_day'\n",
    "train_ds['temp_last_day'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# создаем столбцы с временными лагами для 'target'\n",
    "lags = [24, 48, 72, 7*24, 14*24]\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'] = train_ds['target'].shift(lag)\n",
    "\n",
    "# заполняем пропущенные значения в столбцах с лагами\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'].fillna(0, inplace=True)\n",
    "\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c4022",
   "metadata": {},
   "source": [
    "#### 1.9 Формирование колонок с ВВП и данными о погоде посредством ранее описанных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79aa7c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>P</th>\n",
       "      <th>U</th>\n",
       "      <th>WW</th>\n",
       "      <th>Td</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>W</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 00:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 00:30:00</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 01:00:00</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 01:30:00</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>слабый дождь</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31 02:00:00</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82146</th>\n",
       "      <td>2023-09-30 21:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82147</th>\n",
       "      <td>2023-09-30 22:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82148</th>\n",
       "      <td>2023-09-30 22:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>сильный дождь</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82149</th>\n",
       "      <td>2023-09-30 23:00:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>сильный дождь</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82150</th>\n",
       "      <td>2023-09-30 23:30:00</td>\n",
       "      <td>763.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>нет осадков</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82151 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date      P      U             WW    Td    N    S    W  \\\n",
       "0      2018-12-31 00:00:00  763.5  100.0   слабый дождь   2.0  1.0  0.0  0.0   \n",
       "1      2018-12-31 00:30:00  764.3   93.0   слабый дождь   1.0  1.0  0.0  0.0   \n",
       "2      2018-12-31 01:00:00  764.3   93.0   слабый дождь   1.0  1.0  0.0  0.0   \n",
       "3      2018-12-31 01:30:00  765.0   93.0   слабый дождь   2.0  1.0  0.0  0.0   \n",
       "4      2018-12-31 02:00:00  765.0   93.0    нет осадков   2.0  1.0  0.0  0.0   \n",
       "...                    ...    ...    ...            ...   ...  ...  ...  ...   \n",
       "82146  2023-09-30 21:30:00  763.5   82.0    нет осадков  12.0  0.0  0.0  1.0   \n",
       "82147  2023-09-30 22:00:00  763.5   82.0    нет осадков  12.0  0.5  0.0  1.0   \n",
       "82148  2023-09-30 22:30:00  763.5   77.0  сильный дождь  11.0  0.0  0.0  1.0   \n",
       "82149  2023-09-30 23:00:00  763.5   94.0  сильный дождь  13.0  0.5  0.0  1.0   \n",
       "82150  2023-09-30 23:30:00  763.5   94.0    нет осадков  13.0  0.0  0.5  1.0   \n",
       "\n",
       "         E  \n",
       "0      0.0  \n",
       "1      0.5  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "82146  0.0  \n",
       "82147  0.0  \n",
       "82148  0.0  \n",
       "82149  0.0  \n",
       "82150  0.0  \n",
       "\n",
       "[82151 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# применяем функцию добавления ВВП\n",
    "train_ds = add_vvp2(train_ds)\n",
    "\n",
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "train_ds = fill_weather_columns(train_ds)\n",
    "\n",
    "\n",
    "# Читаем файл с архивом фактической погоды\n",
    "df_true_weather = pd.read_csv('data/preprocessing_loaded_table.csv')\n",
    "display(df_true_weather)\n",
    "\n",
    "# Форматируем колонки\n",
    "df_true_weather['WW'] = df_true_weather['WW'].apply(true_weather_WW_replace)\n",
    "df_true_weather['date'] = pd.to_datetime(df_true_weather['date'])\n",
    "df_true_weather = df_true_weather.rename(columns={'date':'date_tw'})\n",
    "# Применяем сдвиг на сутки, чтобы не заглядывать в будущее\n",
    "df_true_weather = shift_features_fact(df_true_weather)\n",
    "# Добавляем в датасет\n",
    "train_ds['date_hours'] = train_ds.apply(row_plus_hours_to_index, axis=1)\n",
    "train_ds = train_ds.merge(df_true_weather, left_on='date_hours', right_on='date_tw')\n",
    "train_ds = train_ds.drop(['date_hours', 'date_tw'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc76ee",
   "metadata": {},
   "source": [
    "#### 1.10 Демонстрация сформированного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a939b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'target', 'temp', 'temp_pred', 'weather_pred',\n",
       "       'weather_fact', 'year', 'month', 'day_of_week', 'day', 'day_of_year',\n",
       "       'holidays_true', 'preholidays_true', 'temp_last_day', 'target_lag_24',\n",
       "       'target_lag_48', 'target_lag_72', 'target_lag_168', 'target_lag_336',\n",
       "       'VVP', 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability',\n",
       "       'has_rain_probability', 'P', 'U', 'WW', 'Td', 'N', 'S', 'W', 'E'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Итоговый набор колонок\n",
    "train_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51e77ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>target</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_pred</th>\n",
       "      <th>weather_pred</th>\n",
       "      <th>weather_fact</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>rain_probability</th>\n",
       "      <th>has_rain_probability</th>\n",
       "      <th>P</th>\n",
       "      <th>U</th>\n",
       "      <th>WW</th>\n",
       "      <th>Td</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>W</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>481.510</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>763.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>462.872</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>449.718</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>430.908</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>765.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>415.163</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>766.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  time   target  temp  temp_pred weather_pred weather_fact  year  \\\n",
       "0 2019-01-01     0  481.510   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "1 2019-01-01     1  462.872   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "2 2019-01-01     2  449.718   2.9        2.0  пасм, ветер        ветер  2019   \n",
       "3 2019-01-01     3  430.908   4.3        2.0  пасм, ветер  ветер, пасм  2019   \n",
       "4 2019-01-01     4  415.163   4.3        2.0  пасм, ветер  ветер, пасм  2019   \n",
       "\n",
       "   month  day_of_week  ...  rain_probability  has_rain_probability      P  \\\n",
       "0      1            1  ...                 0                     1  763.5   \n",
       "1      1            1  ...                 0                     1  764.3   \n",
       "2      1            1  ...                 0                     1  765.0   \n",
       "3      1            1  ...                 0                     1  765.8   \n",
       "4      1            1  ...                 0                     1  766.6   \n",
       "\n",
       "       U   WW   Td    N    S    W    E  \n",
       "0  100.0  1.0  2.0  1.0  0.0  0.0  0.0  \n",
       "1   93.0  1.0  1.0  1.0  0.0  0.0  0.0  \n",
       "2   93.0  0.0  2.0  1.0  0.0  0.0  0.0  \n",
       "3   87.0  0.0  1.0  1.0  0.0  0.0  0.0  \n",
       "4   87.0  0.0  1.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17ec6c",
   "metadata": {},
   "source": [
    "#### 1.11.1 Добавление среднего за час предыдущего дня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28eebfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_evening(values, evening=19):\n",
    "    return values[evening:].mean()\n",
    "\n",
    "evening_slices = [0, 19, 22]\n",
    "    \n",
    "for evening_slice in evening_slices:\n",
    "    train_ds[['last_evening_avg_target_'+str(evening_slice), 'last_evening_avg_temp_'+str(evening_slice)]] = \\\n",
    "        train_ds[['date', 'target', 'temp']].groupby(by='date').transform(mean_evening, evening=evening_slice).shift(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76699a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'target', 'temp', 'temp_pred', 'weather_pred',\n",
       "       'weather_fact', 'year', 'month', 'day_of_week', 'day', 'day_of_year',\n",
       "       'holidays_true', 'preholidays_true', 'temp_last_day', 'target_lag_24',\n",
       "       'target_lag_48', 'target_lag_72', 'target_lag_168', 'target_lag_336',\n",
       "       'VVP', 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability',\n",
       "       'has_rain_probability', 'P', 'U', 'WW', 'Td', 'N', 'S', 'W', 'E',\n",
       "       'last_evening_avg_target_0', 'last_evening_avg_temp_0',\n",
       "       'last_evening_avg_target_19', 'last_evening_avg_temp_19',\n",
       "       'last_evening_avg_target_22', 'last_evening_avg_temp_22'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69383cb",
   "metadata": {},
   "source": [
    "#### 1.11 Исключение лишних колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65d6619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'time',\n",
       " 'temp_pred',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'day',\n",
       " 'holidays_true',\n",
       " 'preholidays_true',\n",
       " 'temp_last_day',\n",
       " 'target_lag_24',\n",
       " 'target_lag_72',\n",
       " 'target_lag_336',\n",
       " 'VVP',\n",
       " 'cloudy',\n",
       " 'rainy',\n",
       " 'windy',\n",
       " 'clear',\n",
       " 'rain_probability',\n",
       " 'has_rain_probability',\n",
       " 'P',\n",
       " 'U',\n",
       " 'WW',\n",
       " 'Td',\n",
       " 'N',\n",
       " 'S',\n",
       " 'W',\n",
       " 'E',\n",
       " 'last_evening_avg_target_0',\n",
       " 'last_evening_avg_temp_0',\n",
       " 'last_evening_avg_target_19',\n",
       " 'last_evening_avg_temp_19',\n",
       " 'last_evening_avg_target_22',\n",
       " 'last_evening_avg_temp_22']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отбираем признаки. Все лишние колонки здесь отбрасываем, кроме 'date', которую уберем позже \n",
    "\n",
    "feature_cols = list(train_ds.columns)\n",
    "\n",
    "# выбрасываем взгляд в прошлое и расшифрованную погоду\n",
    "drop_list = ['target', 'day_of_year', 'weather_pred', 'weather_fact', 'temp']\n",
    "\n",
    "# выбрасываем признаки, найденные процедурно в процессе оптимизации\n",
    "# КОМАНДЕ: здесь можно добавлять признаки на выброс с целью оптимизации\n",
    "drop_list = drop_list + ['target_lag_48', 'target_lag_168'] #, 'temp_pred'] #, 'target_lag_336'] \n",
    "\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)\n",
    "\n",
    "# Итоговый список признаков\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38de5b2",
   "metadata": {},
   "source": [
    "#### 1.11.2 Добавление среднего за час предыдущего дня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b859804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/4047160460.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "FEATURE_WINDOW_SIZE = 24\n",
    "feature_cols_no_date = feature_cols.copy()\n",
    "feature_cols_no_date.remove('date')\n",
    "\n",
    "\n",
    "for lag in range(1,FEATURE_WINDOW_SIZE):\n",
    "    for column in feature_cols_no_date:\n",
    "        train_ds[column+'_'+str(lag)] = train_ds[column].shift(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cc026",
   "metadata": {},
   "source": [
    "#### 1.11.2 Добавление лагов за час "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9fc38dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/64960772.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds['target'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/64960772.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/64960772.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds['target'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/64960772.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/64960772.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['target_'+str(lag)] = train_ds['target'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/64960772.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)\n"
     ]
    }
   ],
   "source": [
    "target_lags=[1, 5, 9]\n",
    "\n",
    "for lag in target_lags:\n",
    "    train_ds['target_'+str(lag)] = train_ds['target'].shift(lag).where(train_ds['time']<lag, np.NaN)\n",
    "    train_ds['temp_'+str(lag)] = train_ds['temp'].shift(lag).where(train_ds['time']<lag, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d23393e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'time',\n",
       " 'temp_pred',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'day',\n",
       " 'holidays_true',\n",
       " 'preholidays_true',\n",
       " 'temp_last_day',\n",
       " 'target_lag_24',\n",
       " 'target_lag_72',\n",
       " 'target_lag_336',\n",
       " 'VVP',\n",
       " 'cloudy',\n",
       " 'rainy',\n",
       " 'windy',\n",
       " 'clear',\n",
       " 'rain_probability',\n",
       " 'has_rain_probability',\n",
       " 'P',\n",
       " 'U',\n",
       " 'WW',\n",
       " 'Td',\n",
       " 'N',\n",
       " 'S',\n",
       " 'W',\n",
       " 'E',\n",
       " 'last_evening_avg_target_0',\n",
       " 'last_evening_avg_temp_0',\n",
       " 'last_evening_avg_target_19',\n",
       " 'last_evening_avg_temp_19',\n",
       " 'last_evening_avg_target_22',\n",
       " 'last_evening_avg_temp_22',\n",
       " 'time_1',\n",
       " 'temp_pred_1',\n",
       " 'year_1',\n",
       " 'month_1',\n",
       " 'day_of_week_1',\n",
       " 'day_1',\n",
       " 'holidays_true_1',\n",
       " 'preholidays_true_1',\n",
       " 'temp_last_day_1',\n",
       " 'target_lag_24_1',\n",
       " 'target_lag_72_1',\n",
       " 'target_lag_336_1',\n",
       " 'VVP_1',\n",
       " 'cloudy_1',\n",
       " 'rainy_1',\n",
       " 'windy_1',\n",
       " 'clear_1',\n",
       " 'rain_probability_1',\n",
       " 'has_rain_probability_1',\n",
       " 'P_1',\n",
       " 'U_1',\n",
       " 'WW_1',\n",
       " 'Td_1',\n",
       " 'N_1',\n",
       " 'S_1',\n",
       " 'W_1',\n",
       " 'E_1',\n",
       " 'last_evening_avg_target_0_1',\n",
       " 'last_evening_avg_temp_0_1',\n",
       " 'last_evening_avg_target_19_1',\n",
       " 'last_evening_avg_temp_19_1',\n",
       " 'last_evening_avg_target_22_1',\n",
       " 'last_evening_avg_temp_22_1',\n",
       " 'time_2',\n",
       " 'temp_pred_2',\n",
       " 'year_2',\n",
       " 'month_2',\n",
       " 'day_of_week_2',\n",
       " 'day_2',\n",
       " 'holidays_true_2',\n",
       " 'preholidays_true_2',\n",
       " 'temp_last_day_2',\n",
       " 'target_lag_24_2',\n",
       " 'target_lag_72_2',\n",
       " 'target_lag_336_2',\n",
       " 'VVP_2',\n",
       " 'cloudy_2',\n",
       " 'rainy_2',\n",
       " 'windy_2',\n",
       " 'clear_2',\n",
       " 'rain_probability_2',\n",
       " 'has_rain_probability_2',\n",
       " 'P_2',\n",
       " 'U_2',\n",
       " 'WW_2',\n",
       " 'Td_2',\n",
       " 'N_2',\n",
       " 'S_2',\n",
       " 'W_2',\n",
       " 'E_2',\n",
       " 'last_evening_avg_target_0_2',\n",
       " 'last_evening_avg_temp_0_2',\n",
       " 'last_evening_avg_target_19_2',\n",
       " 'last_evening_avg_temp_19_2',\n",
       " 'last_evening_avg_target_22_2',\n",
       " 'last_evening_avg_temp_22_2',\n",
       " 'time_3',\n",
       " 'temp_pred_3',\n",
       " 'year_3',\n",
       " 'month_3',\n",
       " 'day_of_week_3',\n",
       " 'day_3',\n",
       " 'holidays_true_3',\n",
       " 'preholidays_true_3',\n",
       " 'temp_last_day_3',\n",
       " 'target_lag_24_3',\n",
       " 'target_lag_72_3',\n",
       " 'target_lag_336_3',\n",
       " 'VVP_3',\n",
       " 'cloudy_3',\n",
       " 'rainy_3',\n",
       " 'windy_3',\n",
       " 'clear_3',\n",
       " 'rain_probability_3',\n",
       " 'has_rain_probability_3',\n",
       " 'P_3',\n",
       " 'U_3',\n",
       " 'WW_3',\n",
       " 'Td_3',\n",
       " 'N_3',\n",
       " 'S_3',\n",
       " 'W_3',\n",
       " 'E_3',\n",
       " 'last_evening_avg_target_0_3',\n",
       " 'last_evening_avg_temp_0_3',\n",
       " 'last_evening_avg_target_19_3',\n",
       " 'last_evening_avg_temp_19_3',\n",
       " 'last_evening_avg_target_22_3',\n",
       " 'last_evening_avg_temp_22_3',\n",
       " 'time_4',\n",
       " 'temp_pred_4',\n",
       " 'year_4',\n",
       " 'month_4',\n",
       " 'day_of_week_4',\n",
       " 'day_4',\n",
       " 'holidays_true_4',\n",
       " 'preholidays_true_4',\n",
       " 'temp_last_day_4',\n",
       " 'target_lag_24_4',\n",
       " 'target_lag_72_4',\n",
       " 'target_lag_336_4',\n",
       " 'VVP_4',\n",
       " 'cloudy_4',\n",
       " 'rainy_4',\n",
       " 'windy_4',\n",
       " 'clear_4',\n",
       " 'rain_probability_4',\n",
       " 'has_rain_probability_4',\n",
       " 'P_4',\n",
       " 'U_4',\n",
       " 'WW_4',\n",
       " 'Td_4',\n",
       " 'N_4',\n",
       " 'S_4',\n",
       " 'W_4',\n",
       " 'E_4',\n",
       " 'last_evening_avg_target_0_4',\n",
       " 'last_evening_avg_temp_0_4',\n",
       " 'last_evening_avg_target_19_4',\n",
       " 'last_evening_avg_temp_19_4',\n",
       " 'last_evening_avg_target_22_4',\n",
       " 'last_evening_avg_temp_22_4',\n",
       " 'time_5',\n",
       " 'temp_pred_5',\n",
       " 'year_5',\n",
       " 'month_5',\n",
       " 'day_of_week_5',\n",
       " 'day_5',\n",
       " 'holidays_true_5',\n",
       " 'preholidays_true_5',\n",
       " 'temp_last_day_5',\n",
       " 'target_lag_24_5',\n",
       " 'target_lag_72_5',\n",
       " 'target_lag_336_5',\n",
       " 'VVP_5',\n",
       " 'cloudy_5',\n",
       " 'rainy_5',\n",
       " 'windy_5',\n",
       " 'clear_5',\n",
       " 'rain_probability_5',\n",
       " 'has_rain_probability_5',\n",
       " 'P_5',\n",
       " 'U_5',\n",
       " 'WW_5',\n",
       " 'Td_5',\n",
       " 'N_5',\n",
       " 'S_5',\n",
       " 'W_5',\n",
       " 'E_5',\n",
       " 'last_evening_avg_target_0_5',\n",
       " 'last_evening_avg_temp_0_5',\n",
       " 'last_evening_avg_target_19_5',\n",
       " 'last_evening_avg_temp_19_5',\n",
       " 'last_evening_avg_target_22_5',\n",
       " 'last_evening_avg_temp_22_5',\n",
       " 'time_6',\n",
       " 'temp_pred_6',\n",
       " 'year_6',\n",
       " 'month_6',\n",
       " 'day_of_week_6',\n",
       " 'day_6',\n",
       " 'holidays_true_6',\n",
       " 'preholidays_true_6',\n",
       " 'temp_last_day_6',\n",
       " 'target_lag_24_6',\n",
       " 'target_lag_72_6',\n",
       " 'target_lag_336_6',\n",
       " 'VVP_6',\n",
       " 'cloudy_6',\n",
       " 'rainy_6',\n",
       " 'windy_6',\n",
       " 'clear_6',\n",
       " 'rain_probability_6',\n",
       " 'has_rain_probability_6',\n",
       " 'P_6',\n",
       " 'U_6',\n",
       " 'WW_6',\n",
       " 'Td_6',\n",
       " 'N_6',\n",
       " 'S_6',\n",
       " 'W_6',\n",
       " 'E_6',\n",
       " 'last_evening_avg_target_0_6',\n",
       " 'last_evening_avg_temp_0_6',\n",
       " 'last_evening_avg_target_19_6',\n",
       " 'last_evening_avg_temp_19_6',\n",
       " 'last_evening_avg_target_22_6',\n",
       " 'last_evening_avg_temp_22_6',\n",
       " 'time_7',\n",
       " 'temp_pred_7',\n",
       " 'year_7',\n",
       " 'month_7',\n",
       " 'day_of_week_7',\n",
       " 'day_7',\n",
       " 'holidays_true_7',\n",
       " 'preholidays_true_7',\n",
       " 'temp_last_day_7',\n",
       " 'target_lag_24_7',\n",
       " 'target_lag_72_7',\n",
       " 'target_lag_336_7',\n",
       " 'VVP_7',\n",
       " 'cloudy_7',\n",
       " 'rainy_7',\n",
       " 'windy_7',\n",
       " 'clear_7',\n",
       " 'rain_probability_7',\n",
       " 'has_rain_probability_7',\n",
       " 'P_7',\n",
       " 'U_7',\n",
       " 'WW_7',\n",
       " 'Td_7',\n",
       " 'N_7',\n",
       " 'S_7',\n",
       " 'W_7',\n",
       " 'E_7',\n",
       " 'last_evening_avg_target_0_7',\n",
       " 'last_evening_avg_temp_0_7',\n",
       " 'last_evening_avg_target_19_7',\n",
       " 'last_evening_avg_temp_19_7',\n",
       " 'last_evening_avg_target_22_7',\n",
       " 'last_evening_avg_temp_22_7',\n",
       " 'time_8',\n",
       " 'temp_pred_8',\n",
       " 'year_8',\n",
       " 'month_8',\n",
       " 'day_of_week_8',\n",
       " 'day_8',\n",
       " 'holidays_true_8',\n",
       " 'preholidays_true_8',\n",
       " 'temp_last_day_8',\n",
       " 'target_lag_24_8',\n",
       " 'target_lag_72_8',\n",
       " 'target_lag_336_8',\n",
       " 'VVP_8',\n",
       " 'cloudy_8',\n",
       " 'rainy_8',\n",
       " 'windy_8',\n",
       " 'clear_8',\n",
       " 'rain_probability_8',\n",
       " 'has_rain_probability_8',\n",
       " 'P_8',\n",
       " 'U_8',\n",
       " 'WW_8',\n",
       " 'Td_8',\n",
       " 'N_8',\n",
       " 'S_8',\n",
       " 'W_8',\n",
       " 'E_8',\n",
       " 'last_evening_avg_target_0_8',\n",
       " 'last_evening_avg_temp_0_8',\n",
       " 'last_evening_avg_target_19_8',\n",
       " 'last_evening_avg_temp_19_8',\n",
       " 'last_evening_avg_target_22_8',\n",
       " 'last_evening_avg_temp_22_8',\n",
       " 'time_9',\n",
       " 'temp_pred_9',\n",
       " 'year_9',\n",
       " 'month_9',\n",
       " 'day_of_week_9',\n",
       " 'day_9',\n",
       " 'holidays_true_9',\n",
       " 'preholidays_true_9',\n",
       " 'temp_last_day_9',\n",
       " 'target_lag_24_9',\n",
       " 'target_lag_72_9',\n",
       " 'target_lag_336_9',\n",
       " 'VVP_9',\n",
       " 'cloudy_9',\n",
       " 'rainy_9',\n",
       " 'windy_9',\n",
       " 'clear_9',\n",
       " 'rain_probability_9',\n",
       " 'has_rain_probability_9',\n",
       " 'P_9',\n",
       " 'U_9',\n",
       " 'WW_9',\n",
       " 'Td_9',\n",
       " 'N_9',\n",
       " 'S_9',\n",
       " 'W_9',\n",
       " 'E_9',\n",
       " 'last_evening_avg_target_0_9',\n",
       " 'last_evening_avg_temp_0_9',\n",
       " 'last_evening_avg_target_19_9',\n",
       " 'last_evening_avg_temp_19_9',\n",
       " 'last_evening_avg_target_22_9',\n",
       " 'last_evening_avg_temp_22_9',\n",
       " 'time_10',\n",
       " 'temp_pred_10',\n",
       " 'year_10',\n",
       " 'month_10',\n",
       " 'day_of_week_10',\n",
       " 'day_10',\n",
       " 'holidays_true_10',\n",
       " 'preholidays_true_10',\n",
       " 'temp_last_day_10',\n",
       " 'target_lag_24_10',\n",
       " 'target_lag_72_10',\n",
       " 'target_lag_336_10',\n",
       " 'VVP_10',\n",
       " 'cloudy_10',\n",
       " 'rainy_10',\n",
       " 'windy_10',\n",
       " 'clear_10',\n",
       " 'rain_probability_10',\n",
       " 'has_rain_probability_10',\n",
       " 'P_10',\n",
       " 'U_10',\n",
       " 'WW_10',\n",
       " 'Td_10',\n",
       " 'N_10',\n",
       " 'S_10',\n",
       " 'W_10',\n",
       " 'E_10',\n",
       " 'last_evening_avg_target_0_10',\n",
       " 'last_evening_avg_temp_0_10',\n",
       " 'last_evening_avg_target_19_10',\n",
       " 'last_evening_avg_temp_19_10',\n",
       " 'last_evening_avg_target_22_10',\n",
       " 'last_evening_avg_temp_22_10',\n",
       " 'time_11',\n",
       " 'temp_pred_11',\n",
       " 'year_11',\n",
       " 'month_11',\n",
       " 'day_of_week_11',\n",
       " 'day_11',\n",
       " 'holidays_true_11',\n",
       " 'preholidays_true_11',\n",
       " 'temp_last_day_11',\n",
       " 'target_lag_24_11',\n",
       " 'target_lag_72_11',\n",
       " 'target_lag_336_11',\n",
       " 'VVP_11',\n",
       " 'cloudy_11',\n",
       " 'rainy_11',\n",
       " 'windy_11',\n",
       " 'clear_11',\n",
       " 'rain_probability_11',\n",
       " 'has_rain_probability_11',\n",
       " 'P_11',\n",
       " 'U_11',\n",
       " 'WW_11',\n",
       " 'Td_11',\n",
       " 'N_11',\n",
       " 'S_11',\n",
       " 'W_11',\n",
       " 'E_11',\n",
       " 'last_evening_avg_target_0_11',\n",
       " 'last_evening_avg_temp_0_11',\n",
       " 'last_evening_avg_target_19_11',\n",
       " 'last_evening_avg_temp_19_11',\n",
       " 'last_evening_avg_target_22_11',\n",
       " 'last_evening_avg_temp_22_11',\n",
       " 'time_12',\n",
       " 'temp_pred_12',\n",
       " 'year_12',\n",
       " 'month_12',\n",
       " 'day_of_week_12',\n",
       " 'day_12',\n",
       " 'holidays_true_12',\n",
       " 'preholidays_true_12',\n",
       " 'temp_last_day_12',\n",
       " 'target_lag_24_12',\n",
       " 'target_lag_72_12',\n",
       " 'target_lag_336_12',\n",
       " 'VVP_12',\n",
       " 'cloudy_12',\n",
       " 'rainy_12',\n",
       " 'windy_12',\n",
       " 'clear_12',\n",
       " 'rain_probability_12',\n",
       " 'has_rain_probability_12',\n",
       " 'P_12',\n",
       " 'U_12',\n",
       " 'WW_12',\n",
       " 'Td_12',\n",
       " 'N_12',\n",
       " 'S_12',\n",
       " 'W_12',\n",
       " 'E_12',\n",
       " 'last_evening_avg_target_0_12',\n",
       " 'last_evening_avg_temp_0_12',\n",
       " 'last_evening_avg_target_19_12',\n",
       " 'last_evening_avg_temp_19_12',\n",
       " 'last_evening_avg_target_22_12',\n",
       " 'last_evening_avg_temp_22_12',\n",
       " 'time_13',\n",
       " 'temp_pred_13',\n",
       " 'year_13',\n",
       " 'month_13',\n",
       " 'day_of_week_13',\n",
       " 'day_13',\n",
       " 'holidays_true_13',\n",
       " 'preholidays_true_13',\n",
       " 'temp_last_day_13',\n",
       " 'target_lag_24_13',\n",
       " 'target_lag_72_13',\n",
       " 'target_lag_336_13',\n",
       " 'VVP_13',\n",
       " 'cloudy_13',\n",
       " 'rainy_13',\n",
       " 'windy_13',\n",
       " 'clear_13',\n",
       " 'rain_probability_13',\n",
       " 'has_rain_probability_13',\n",
       " 'P_13',\n",
       " 'U_13',\n",
       " 'WW_13',\n",
       " 'Td_13',\n",
       " 'N_13',\n",
       " 'S_13',\n",
       " 'W_13',\n",
       " 'E_13',\n",
       " 'last_evening_avg_target_0_13',\n",
       " 'last_evening_avg_temp_0_13',\n",
       " 'last_evening_avg_target_19_13',\n",
       " 'last_evening_avg_temp_19_13',\n",
       " 'last_evening_avg_target_22_13',\n",
       " 'last_evening_avg_temp_22_13',\n",
       " 'time_14',\n",
       " 'temp_pred_14',\n",
       " 'year_14',\n",
       " 'month_14',\n",
       " 'day_of_week_14',\n",
       " 'day_14',\n",
       " 'holidays_true_14',\n",
       " 'preholidays_true_14',\n",
       " 'temp_last_day_14',\n",
       " 'target_lag_24_14',\n",
       " 'target_lag_72_14',\n",
       " 'target_lag_336_14',\n",
       " 'VVP_14',\n",
       " 'cloudy_14',\n",
       " 'rainy_14',\n",
       " 'windy_14',\n",
       " 'clear_14',\n",
       " 'rain_probability_14',\n",
       " 'has_rain_probability_14',\n",
       " 'P_14',\n",
       " 'U_14',\n",
       " 'WW_14',\n",
       " 'Td_14',\n",
       " 'N_14',\n",
       " 'S_14',\n",
       " 'W_14',\n",
       " 'E_14',\n",
       " 'last_evening_avg_target_0_14',\n",
       " 'last_evening_avg_temp_0_14',\n",
       " 'last_evening_avg_target_19_14',\n",
       " 'last_evening_avg_temp_19_14',\n",
       " 'last_evening_avg_target_22_14',\n",
       " 'last_evening_avg_temp_22_14',\n",
       " 'time_15',\n",
       " 'temp_pred_15',\n",
       " 'year_15',\n",
       " 'month_15',\n",
       " 'day_of_week_15',\n",
       " 'day_15',\n",
       " 'holidays_true_15',\n",
       " 'preholidays_true_15',\n",
       " 'temp_last_day_15',\n",
       " 'target_lag_24_15',\n",
       " 'target_lag_72_15',\n",
       " 'target_lag_336_15',\n",
       " 'VVP_15',\n",
       " 'cloudy_15',\n",
       " 'rainy_15',\n",
       " 'windy_15',\n",
       " 'clear_15',\n",
       " 'rain_probability_15',\n",
       " 'has_rain_probability_15',\n",
       " 'P_15',\n",
       " 'U_15',\n",
       " 'WW_15',\n",
       " 'Td_15',\n",
       " 'N_15',\n",
       " 'S_15',\n",
       " 'W_15',\n",
       " 'E_15',\n",
       " 'last_evening_avg_target_0_15',\n",
       " 'last_evening_avg_temp_0_15',\n",
       " 'last_evening_avg_target_19_15',\n",
       " 'last_evening_avg_temp_19_15',\n",
       " 'last_evening_avg_target_22_15',\n",
       " 'last_evening_avg_temp_22_15',\n",
       " 'time_16',\n",
       " 'temp_pred_16',\n",
       " 'year_16',\n",
       " 'month_16',\n",
       " 'day_of_week_16',\n",
       " 'day_16',\n",
       " 'holidays_true_16',\n",
       " 'preholidays_true_16',\n",
       " 'temp_last_day_16',\n",
       " 'target_lag_24_16',\n",
       " 'target_lag_72_16',\n",
       " 'target_lag_336_16',\n",
       " 'VVP_16',\n",
       " 'cloudy_16',\n",
       " 'rainy_16',\n",
       " 'windy_16',\n",
       " 'clear_16',\n",
       " 'rain_probability_16',\n",
       " 'has_rain_probability_16',\n",
       " 'P_16',\n",
       " 'U_16',\n",
       " 'WW_16',\n",
       " 'Td_16',\n",
       " 'N_16',\n",
       " 'S_16',\n",
       " 'W_16',\n",
       " 'E_16',\n",
       " 'last_evening_avg_target_0_16',\n",
       " 'last_evening_avg_temp_0_16',\n",
       " 'last_evening_avg_target_19_16',\n",
       " 'last_evening_avg_temp_19_16',\n",
       " 'last_evening_avg_target_22_16',\n",
       " 'last_evening_avg_temp_22_16',\n",
       " 'time_17',\n",
       " 'temp_pred_17',\n",
       " 'year_17',\n",
       " 'month_17',\n",
       " 'day_of_week_17',\n",
       " 'day_17',\n",
       " 'holidays_true_17',\n",
       " 'preholidays_true_17',\n",
       " 'temp_last_day_17',\n",
       " 'target_lag_24_17',\n",
       " 'target_lag_72_17',\n",
       " 'target_lag_336_17',\n",
       " 'VVP_17',\n",
       " 'cloudy_17',\n",
       " 'rainy_17',\n",
       " 'windy_17',\n",
       " 'clear_17',\n",
       " 'rain_probability_17',\n",
       " 'has_rain_probability_17',\n",
       " 'P_17',\n",
       " 'U_17',\n",
       " 'WW_17',\n",
       " 'Td_17',\n",
       " 'N_17',\n",
       " 'S_17',\n",
       " 'W_17',\n",
       " 'E_17',\n",
       " 'last_evening_avg_target_0_17',\n",
       " 'last_evening_avg_temp_0_17',\n",
       " 'last_evening_avg_target_19_17',\n",
       " 'last_evening_avg_temp_19_17',\n",
       " 'last_evening_avg_target_22_17',\n",
       " 'last_evening_avg_temp_22_17',\n",
       " 'time_18',\n",
       " 'temp_pred_18',\n",
       " 'year_18',\n",
       " 'month_18',\n",
       " 'day_of_week_18',\n",
       " 'day_18',\n",
       " 'holidays_true_18',\n",
       " 'preholidays_true_18',\n",
       " 'temp_last_day_18',\n",
       " 'target_lag_24_18',\n",
       " 'target_lag_72_18',\n",
       " 'target_lag_336_18',\n",
       " 'VVP_18',\n",
       " 'cloudy_18',\n",
       " 'rainy_18',\n",
       " 'windy_18',\n",
       " 'clear_18',\n",
       " 'rain_probability_18',\n",
       " 'has_rain_probability_18',\n",
       " 'P_18',\n",
       " 'U_18',\n",
       " 'WW_18',\n",
       " 'Td_18',\n",
       " 'N_18',\n",
       " 'S_18',\n",
       " 'W_18',\n",
       " 'E_18',\n",
       " 'last_evening_avg_target_0_18',\n",
       " 'last_evening_avg_temp_0_18',\n",
       " 'last_evening_avg_target_19_18',\n",
       " 'last_evening_avg_temp_19_18',\n",
       " 'last_evening_avg_target_22_18',\n",
       " 'last_evening_avg_temp_22_18',\n",
       " 'time_19',\n",
       " 'temp_pred_19',\n",
       " 'year_19',\n",
       " 'month_19',\n",
       " 'day_of_week_19',\n",
       " 'day_19',\n",
       " 'holidays_true_19',\n",
       " 'preholidays_true_19',\n",
       " 'temp_last_day_19',\n",
       " 'target_lag_24_19',\n",
       " 'target_lag_72_19',\n",
       " 'target_lag_336_19',\n",
       " 'VVP_19',\n",
       " 'cloudy_19',\n",
       " 'rainy_19',\n",
       " 'windy_19',\n",
       " 'clear_19',\n",
       " 'rain_probability_19',\n",
       " 'has_rain_probability_19',\n",
       " 'P_19',\n",
       " 'U_19',\n",
       " 'WW_19',\n",
       " 'Td_19',\n",
       " 'N_19',\n",
       " 'S_19',\n",
       " 'W_19',\n",
       " 'E_19',\n",
       " 'last_evening_avg_target_0_19',\n",
       " 'last_evening_avg_temp_0_19',\n",
       " 'last_evening_avg_target_19_19',\n",
       " 'last_evening_avg_temp_19_19',\n",
       " 'last_evening_avg_target_22_19',\n",
       " 'last_evening_avg_temp_22_19',\n",
       " 'time_20',\n",
       " 'temp_pred_20',\n",
       " 'year_20',\n",
       " 'month_20',\n",
       " 'day_of_week_20',\n",
       " 'day_20',\n",
       " 'holidays_true_20',\n",
       " 'preholidays_true_20',\n",
       " 'temp_last_day_20',\n",
       " 'target_lag_24_20',\n",
       " 'target_lag_72_20',\n",
       " 'target_lag_336_20',\n",
       " 'VVP_20',\n",
       " 'cloudy_20',\n",
       " 'rainy_20',\n",
       " 'windy_20',\n",
       " 'clear_20',\n",
       " 'rain_probability_20',\n",
       " 'has_rain_probability_20',\n",
       " 'P_20',\n",
       " 'U_20',\n",
       " 'WW_20',\n",
       " 'Td_20',\n",
       " 'N_20',\n",
       " 'S_20',\n",
       " 'W_20',\n",
       " 'E_20',\n",
       " 'last_evening_avg_target_0_20',\n",
       " 'last_evening_avg_temp_0_20',\n",
       " 'last_evening_avg_target_19_20',\n",
       " 'last_evening_avg_temp_19_20',\n",
       " 'last_evening_avg_target_22_20',\n",
       " 'last_evening_avg_temp_22_20',\n",
       " 'time_21',\n",
       " 'temp_pred_21',\n",
       " 'year_21',\n",
       " 'month_21',\n",
       " 'day_of_week_21',\n",
       " 'day_21',\n",
       " 'holidays_true_21',\n",
       " 'preholidays_true_21',\n",
       " 'temp_last_day_21',\n",
       " 'target_lag_24_21',\n",
       " 'target_lag_72_21',\n",
       " 'target_lag_336_21',\n",
       " 'VVP_21',\n",
       " 'cloudy_21',\n",
       " 'rainy_21',\n",
       " 'windy_21',\n",
       " 'clear_21',\n",
       " 'rain_probability_21',\n",
       " 'has_rain_probability_21',\n",
       " 'P_21',\n",
       " 'U_21',\n",
       " 'WW_21',\n",
       " 'Td_21',\n",
       " 'N_21',\n",
       " 'S_21',\n",
       " 'W_21',\n",
       " 'E_21',\n",
       " 'last_evening_avg_target_0_21',\n",
       " 'last_evening_avg_temp_0_21',\n",
       " 'last_evening_avg_target_19_21',\n",
       " 'last_evening_avg_temp_19_21',\n",
       " 'last_evening_avg_target_22_21',\n",
       " 'last_evening_avg_temp_22_21',\n",
       " 'time_22',\n",
       " 'temp_pred_22',\n",
       " 'year_22',\n",
       " 'month_22',\n",
       " 'day_of_week_22',\n",
       " 'day_22',\n",
       " 'holidays_true_22',\n",
       " 'preholidays_true_22',\n",
       " 'temp_last_day_22',\n",
       " 'target_lag_24_22',\n",
       " 'target_lag_72_22',\n",
       " 'target_lag_336_22',\n",
       " 'VVP_22',\n",
       " 'cloudy_22',\n",
       " 'rainy_22',\n",
       " 'windy_22',\n",
       " 'clear_22',\n",
       " 'rain_probability_22',\n",
       " 'has_rain_probability_22',\n",
       " 'P_22',\n",
       " 'U_22',\n",
       " 'WW_22',\n",
       " 'Td_22',\n",
       " 'N_22',\n",
       " 'S_22',\n",
       " 'W_22',\n",
       " 'E_22',\n",
       " 'last_evening_avg_target_0_22',\n",
       " 'last_evening_avg_temp_0_22',\n",
       " 'last_evening_avg_target_19_22',\n",
       " 'last_evening_avg_temp_19_22',\n",
       " 'last_evening_avg_target_22_22',\n",
       " 'last_evening_avg_temp_22_22',\n",
       " 'time_23',\n",
       " 'temp_pred_23',\n",
       " 'year_23',\n",
       " 'month_23',\n",
       " 'day_of_week_23',\n",
       " 'day_23',\n",
       " 'holidays_true_23',\n",
       " 'preholidays_true_23',\n",
       " 'temp_last_day_23',\n",
       " 'target_lag_24_23',\n",
       " 'target_lag_72_23',\n",
       " 'target_lag_336_23',\n",
       " 'VVP_23',\n",
       " 'cloudy_23',\n",
       " 'rainy_23',\n",
       " 'windy_23',\n",
       " 'clear_23',\n",
       " 'rain_probability_23',\n",
       " 'has_rain_probability_23',\n",
       " 'P_23',\n",
       " 'U_23',\n",
       " 'WW_23',\n",
       " 'Td_23',\n",
       " 'N_23',\n",
       " 'S_23',\n",
       " 'W_23',\n",
       " 'E_23',\n",
       " 'last_evening_avg_target_0_23',\n",
       " 'last_evening_avg_temp_0_23',\n",
       " 'last_evening_avg_target_19_23',\n",
       " 'last_evening_avg_temp_19_23',\n",
       " 'last_evening_avg_target_22_23',\n",
       " 'last_evening_avg_temp_22_23',\n",
       " 'target_1',\n",
       " 'temp_1',\n",
       " 'target_5',\n",
       " 'temp_5',\n",
       " 'target_9',\n",
       " 'temp_9']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = list(train_ds.columns)\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)\n",
    "\n",
    "# Итоговый список признаков\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итоговый набор колонок\n",
    "train_ds.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b4fad",
   "metadata": {},
   "source": [
    "#### 1.11.13 Аугументации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a044a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_aug = [\n",
    "'temp_pred',\n",
    "'temp_last_day',\n",
    "'target_lag_24',\n",
    "'target_lag_72',\n",
    "'target_lag_336',\n",
    "'VVP',\n",
    "'P',\n",
    "'U',\n",
    "'Td',\n",
    "'last_evening_avg_target_0',\n",
    "'last_evening_avg_temp_0',\n",
    "'last_evening_avg_target_19',\n",
    "'last_evening_avg_temp_19',\n",
    "'last_evening_avg_target_22',\n",
    "'last_evening_avg_temp_22',\n",
    "'temp_pred_1',\n",
    "'temp_last_day_1',\n",
    "'target_lag_24_1',\n",
    "'target_lag_72_1',\n",
    "'target_lag_336_1',\n",
    "'VVP_1',\n",
    "'P_1',\n",
    "'U_1',\n",
    "'Td_1',\n",
    "'last_evening_avg_target_0_1',\n",
    "'last_evening_avg_temp_0_1',\n",
    "'last_evening_avg_target_19_1',\n",
    "'last_evening_avg_temp_19_1',\n",
    "'last_evening_avg_target_22_1',\n",
    "'last_evening_avg_temp_22_1',\n",
    "'temp_pred_2',\n",
    "'temp_last_day_2',\n",
    "'target_lag_24_2',\n",
    "'target_lag_72_2',\n",
    "'target_lag_336_2',\n",
    "'VVP_2',\n",
    "'P_2',\n",
    "'U_2',\n",
    "'Td_2',\n",
    "'last_evening_avg_target_0_2',\n",
    "'last_evening_avg_temp_0_2',\n",
    "'last_evening_avg_target_19_2',\n",
    "'last_evening_avg_temp_19_2',\n",
    "'last_evening_avg_target_22_2',\n",
    "'last_evening_avg_temp_22_2',\n",
    "'temp_pred_3',\n",
    "'temp_last_day_3',\n",
    "'target_lag_24_3',\n",
    "'target_lag_72_3',\n",
    "'target_lag_336_3',\n",
    "'VVP_3',\n",
    "'P_3',\n",
    "'U_3',\n",
    "'Td_3',\n",
    "'last_evening_avg_target_0_3',\n",
    "'last_evening_avg_temp_0_3',\n",
    "'last_evening_avg_target_19_3',\n",
    "'last_evening_avg_temp_19_3',\n",
    "'last_evening_avg_target_22_3',\n",
    "'last_evening_avg_temp_22_3',\n",
    "'temp_pred_4',\n",
    "'temp_last_day_4',\n",
    "'target_lag_24_4',\n",
    "'target_lag_72_4',\n",
    "'target_lag_336_4',\n",
    "'VVP_4',\n",
    "'P_4',\n",
    "'U_4',\n",
    "'Td_4',\n",
    "'last_evening_avg_target_0_4',\n",
    "'last_evening_avg_temp_0_4',\n",
    "'last_evening_avg_target_19_4',\n",
    "'last_evening_avg_temp_19_4',\n",
    "'last_evening_avg_target_22_4',\n",
    "'last_evening_avg_temp_22_4',\n",
    "'temp_pred_5',\n",
    "'temp_last_day_5',\n",
    "'target_lag_24_5',\n",
    "'target_lag_72_5',\n",
    "'target_lag_336_5',\n",
    "'VVP_5',\n",
    "'P_5',\n",
    "'U_5',\n",
    "'Td_5',\n",
    "'last_evening_avg_target_0_5',\n",
    "'last_evening_avg_temp_0_5',\n",
    "'last_evening_avg_target_19_5',\n",
    "'last_evening_avg_temp_19_5',\n",
    "'last_evening_avg_target_22_5',\n",
    "'last_evening_avg_temp_22_5',\n",
    "'temp_pred_6',\n",
    "'temp_last_day_6',\n",
    "'target_lag_24_6',\n",
    "'target_lag_72_6',\n",
    "'target_lag_336_6',\n",
    "'VVP_6',\n",
    "'P_6',\n",
    "'U_6',\n",
    "'Td_6',\n",
    "'last_evening_avg_target_0_6',\n",
    "'last_evening_avg_temp_0_6',\n",
    "'last_evening_avg_target_19_6',\n",
    "'last_evening_avg_temp_19_6',\n",
    "'last_evening_avg_target_22_6',\n",
    "'last_evening_avg_temp_22_6',\n",
    "'temp_pred_7',\n",
    "'temp_last_day_7',\n",
    "'target_lag_24_7',\n",
    "'target_lag_72_7',\n",
    "'target_lag_336_7',\n",
    "'VVP_7',\n",
    "'P_7',\n",
    "'U_7',\n",
    "'Td_7',\n",
    "'last_evening_avg_target_0_7',\n",
    "'last_evening_avg_temp_0_7',\n",
    "'last_evening_avg_target_19_7',\n",
    "'last_evening_avg_temp_19_7',\n",
    "'last_evening_avg_target_22_7',\n",
    "'last_evening_avg_temp_22_7',\n",
    "'temp_pred_8',\n",
    "'temp_last_day_8',\n",
    "'target_lag_24_8',\n",
    "'target_lag_72_8',\n",
    "'target_lag_336_8',\n",
    "'VVP_8',\n",
    "'P_8',\n",
    "'U_8',\n",
    "'Td_8',\n",
    "'last_evening_avg_target_0_8',\n",
    "'last_evening_avg_temp_0_8',\n",
    "'last_evening_avg_target_19_8',\n",
    "'last_evening_avg_temp_19_8',\n",
    "'last_evening_avg_target_22_8',\n",
    "'last_evening_avg_temp_22_8',\n",
    "'temp_pred_9',\n",
    "'temp_last_day_9',\n",
    "'target_lag_24_9',\n",
    "'target_lag_72_9',\n",
    "'target_lag_336_9',\n",
    "'VVP_9',\n",
    "'P_9',\n",
    "'U_9',\n",
    "'Td_9',\n",
    "'last_evening_avg_target_0_9',\n",
    "'last_evening_avg_temp_0_9',\n",
    "'last_evening_avg_target_19_9',\n",
    "'last_evening_avg_temp_19_9',\n",
    "'last_evening_avg_target_22_9',\n",
    "'last_evening_avg_temp_22_9',\n",
    "'temp_pred_10',\n",
    "'temp_last_day_10',\n",
    "'target_lag_24_10',\n",
    "'target_lag_72_10',\n",
    "'target_lag_336_10',\n",
    "'VVP_10',\n",
    "'P_10',\n",
    "'U_10',\n",
    "'Td_10',\n",
    "'last_evening_avg_target_0_10',\n",
    "'last_evening_avg_temp_0_10',\n",
    "'last_evening_avg_target_19_10',\n",
    "'last_evening_avg_temp_19_10',\n",
    "'last_evening_avg_target_22_10',\n",
    "'last_evening_avg_temp_22_10',\n",
    "'temp_pred_11',\n",
    "'temp_last_day_11',\n",
    "'target_lag_24_11',\n",
    "'target_lag_72_11',\n",
    "'target_lag_336_11',\n",
    "'VVP_11',\n",
    "'P_11',\n",
    "'U_11',\n",
    "'Td_11',\n",
    "'last_evening_avg_target_0_11',\n",
    "'last_evening_avg_temp_0_11',\n",
    "'last_evening_avg_target_19_11',\n",
    "'last_evening_avg_temp_19_11',\n",
    "'last_evening_avg_target_22_11',\n",
    "'last_evening_avg_temp_22_11',\n",
    "'temp_pred_12',\n",
    "'temp_last_day_12',\n",
    "'target_lag_24_12',\n",
    "'target_lag_72_12',\n",
    "'target_lag_336_12',\n",
    "'VVP_12',\n",
    "'P_12',\n",
    "'U_12',\n",
    "'Td_12',\n",
    "'last_evening_avg_target_0_12',\n",
    "'last_evening_avg_temp_0_12',\n",
    "'last_evening_avg_target_19_12',\n",
    "'last_evening_avg_temp_19_12',\n",
    "'last_evening_avg_target_22_12',\n",
    "'last_evening_avg_temp_22_12',\n",
    "'temp_pred_13',\n",
    "'temp_last_day_13',\n",
    "'target_lag_24_13',\n",
    "'target_lag_72_13',\n",
    "'target_lag_336_13',\n",
    "'VVP_13',\n",
    "'P_13',\n",
    "'U_13',\n",
    "'Td_13',\n",
    "'last_evening_avg_target_0_13',\n",
    "'last_evening_avg_temp_0_13',\n",
    "'last_evening_avg_target_19_13',\n",
    "'last_evening_avg_temp_19_13',\n",
    "'last_evening_avg_target_22_13',\n",
    "'last_evening_avg_temp_22_13',\n",
    "'temp_pred_14',\n",
    "'temp_last_day_14',\n",
    "'target_lag_24_14',\n",
    "'target_lag_72_14',\n",
    "'target_lag_336_14',\n",
    "'VVP_14',\n",
    "'P_14',\n",
    "'U_14',\n",
    "'Td_14',\n",
    "'last_evening_avg_target_0_14',\n",
    "'last_evening_avg_temp_0_14',\n",
    "'last_evening_avg_target_19_14',\n",
    "'last_evening_avg_temp_19_14',\n",
    "'last_evening_avg_target_22_14',\n",
    "'last_evening_avg_temp_22_14',\n",
    "'temp_pred_15',\n",
    "'temp_last_day_15',\n",
    "'target_lag_24_15',\n",
    "'target_lag_72_15',\n",
    "'target_lag_336_15',\n",
    "'VVP_15',\n",
    "'P_15',\n",
    "'U_15',\n",
    "'Td_15',\n",
    "'last_evening_avg_target_0_15',\n",
    "'last_evening_avg_temp_0_15',\n",
    "'last_evening_avg_target_19_15',\n",
    "'last_evening_avg_temp_19_15',\n",
    "'last_evening_avg_target_22_15',\n",
    "'last_evening_avg_temp_22_15',\n",
    "'temp_pred_16',\n",
    "'temp_last_day_16',\n",
    "'target_lag_24_16',\n",
    "'target_lag_72_16',\n",
    "'target_lag_336_16',\n",
    "'VVP_16',\n",
    "'P_16',\n",
    "'U_16',\n",
    "'Td_16',\n",
    "'last_evening_avg_target_0_16',\n",
    "'last_evening_avg_temp_0_16',\n",
    "'last_evening_avg_target_19_16',\n",
    "'last_evening_avg_temp_19_16',\n",
    "'last_evening_avg_target_22_16',\n",
    "'last_evening_avg_temp_22_16',\n",
    "'temp_pred_17',\n",
    "'temp_last_day_17',\n",
    "'target_lag_24_17',\n",
    "'target_lag_72_17',\n",
    "'target_lag_336_17',\n",
    "'VVP_17',\n",
    "'P_17',\n",
    "'U_17',\n",
    "'Td_17',\n",
    "'last_evening_avg_target_0_17',\n",
    "'last_evening_avg_temp_0_17',\n",
    "'last_evening_avg_target_19_17',\n",
    "'last_evening_avg_temp_19_17',\n",
    "'last_evening_avg_target_22_17',\n",
    "'last_evening_avg_temp_22_17',\n",
    "'temp_pred_18',\n",
    "'temp_last_day_18',\n",
    "'target_lag_24_18',\n",
    "'target_lag_72_18',\n",
    "'target_lag_336_18',\n",
    "'VVP_18',\n",
    "'P_18',\n",
    "'U_18',\n",
    "'Td_18',\n",
    "'last_evening_avg_target_0_18',\n",
    "'last_evening_avg_temp_0_18',\n",
    "'last_evening_avg_target_19_18',\n",
    "'last_evening_avg_temp_19_18',\n",
    "'last_evening_avg_target_22_18',\n",
    "'last_evening_avg_temp_22_18',\n",
    "'temp_pred_19',\n",
    "'temp_last_day_19',\n",
    "'target_lag_24_19',\n",
    "'target_lag_72_19',\n",
    "'target_lag_336_19',\n",
    "'VVP_19',\n",
    "'P_19',\n",
    "'U_19',\n",
    "'Td_19',\n",
    "'last_evening_avg_target_0_19',\n",
    "'last_evening_avg_temp_0_19',\n",
    "'last_evening_avg_target_19_19',\n",
    "'last_evening_avg_temp_19_19',\n",
    "'last_evening_avg_target_22_19',\n",
    "'last_evening_avg_temp_22_19',\n",
    "'temp_pred_20',\n",
    "'temp_last_day_20',\n",
    "'target_lag_24_20',\n",
    "'target_lag_72_20',\n",
    "'target_lag_336_20',\n",
    "'VVP_20',\n",
    "'P_20',\n",
    "'U_20',\n",
    "'Td_20',\n",
    "'last_evening_avg_target_0_20',\n",
    "'last_evening_avg_temp_0_20',\n",
    "'last_evening_avg_target_19_20',\n",
    "'last_evening_avg_temp_19_20',\n",
    "'last_evening_avg_target_22_20',\n",
    "'last_evening_avg_temp_22_20',\n",
    "'temp_pred_21',\n",
    "'temp_last_day_21',\n",
    "'target_lag_24_21',\n",
    "'target_lag_72_21',\n",
    "'target_lag_336_21',\n",
    "'VVP_21',\n",
    "'P_21',\n",
    "'U_21',\n",
    "'Td_21',\n",
    "'last_evening_avg_target_0_21',\n",
    "'last_evening_avg_temp_0_21',\n",
    "'last_evening_avg_target_19_21',\n",
    "'last_evening_avg_temp_19_21',\n",
    "'last_evening_avg_target_22_21',\n",
    "'last_evening_avg_temp_22_21',\n",
    "'temp_pred_22',\n",
    "'temp_last_day_22',\n",
    "'target_lag_24_22',\n",
    "'target_lag_72_22',\n",
    "'target_lag_336_22',\n",
    "'VVP_22',\n",
    "'P_22',\n",
    "'U_22',\n",
    "'Td_22',\n",
    "'last_evening_avg_target_0_22',\n",
    "'last_evening_avg_temp_0_22',\n",
    "'last_evening_avg_target_19_22',\n",
    "'last_evening_avg_temp_19_22',\n",
    "'last_evening_avg_target_22_22',\n",
    "'last_evening_avg_temp_22_22',\n",
    "'temp_pred_23',\n",
    "'temp_last_day_23',\n",
    "'target_lag_24_23',\n",
    "'target_lag_72_23',\n",
    "'target_lag_336_23',\n",
    "'VVP_23',\n",
    "'P_23',\n",
    "'U_23',\n",
    "'Td_23',\n",
    "'last_evening_avg_target_0_23',\n",
    "'last_evening_avg_temp_0_23',\n",
    "'last_evening_avg_target_19_23',\n",
    "'last_evening_avg_temp_19_23',\n",
    "'last_evening_avg_target_22_23',\n",
    "'last_evening_avg_temp_22_23',\n",
    "'target_1',\n",
    "'temp_1',\n",
    "'target_5',\n",
    "'temp_5',\n",
    "'target_9',\n",
    "'temp_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0765394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'time', 'temp_pred', 'year', 'month', 'day_of_week', 'day', 'holidays_true', 'preholidays_true', 'temp_last_day', 'target_lag_24', 'target_lag_72', 'target_lag_336', 'VVP', 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability', 'has_rain_probability', 'P', 'U', 'WW', 'Td', 'N', 'S', 'W', 'E', 'last_evening_avg_target_0', 'last_evening_avg_temp_0', 'last_evening_avg_target_19', 'last_evening_avg_temp_19', 'last_evening_avg_target_22', 'last_evening_avg_temp_22', 'time_1', 'temp_pred_1', 'year_1', 'month_1', 'day_of_week_1', 'day_1', 'holidays_true_1', 'preholidays_true_1', 'temp_last_day_1', 'target_lag_24_1', 'target_lag_72_1', 'target_lag_336_1', 'VVP_1', 'cloudy_1', 'rainy_1', 'windy_1', 'clear_1', 'rain_probability_1', 'has_rain_probability_1', 'P_1', 'U_1', 'WW_1', 'Td_1', 'N_1', 'S_1', 'W_1', 'E_1', 'last_evening_avg_target_0_1', 'last_evening_avg_temp_0_1', 'last_evening_avg_target_19_1', 'last_evening_avg_temp_19_1', 'last_evening_avg_target_22_1', 'last_evening_avg_temp_22_1', 'time_2', 'temp_pred_2', 'year_2', 'month_2', 'day_of_week_2', 'day_2', 'holidays_true_2', 'preholidays_true_2', 'temp_last_day_2', 'target_lag_24_2', 'target_lag_72_2', 'target_lag_336_2', 'VVP_2', 'cloudy_2', 'rainy_2', 'windy_2', 'clear_2', 'rain_probability_2', 'has_rain_probability_2', 'P_2', 'U_2', 'WW_2', 'Td_2', 'N_2', 'S_2', 'W_2', 'E_2', 'last_evening_avg_target_0_2', 'last_evening_avg_temp_0_2', 'last_evening_avg_target_19_2', 'last_evening_avg_temp_19_2', 'last_evening_avg_target_22_2', 'last_evening_avg_temp_22_2', 'time_3', 'temp_pred_3', 'year_3', 'month_3', 'day_of_week_3', 'day_3', 'holidays_true_3', 'preholidays_true_3', 'temp_last_day_3', 'target_lag_24_3', 'target_lag_72_3', 'target_lag_336_3', 'VVP_3', 'cloudy_3', 'rainy_3', 'windy_3', 'clear_3', 'rain_probability_3', 'has_rain_probability_3', 'P_3', 'U_3', 'WW_3', 'Td_3', 'N_3', 'S_3', 'W_3', 'E_3', 'last_evening_avg_target_0_3', 'last_evening_avg_temp_0_3', 'last_evening_avg_target_19_3', 'last_evening_avg_temp_19_3', 'last_evening_avg_target_22_3', 'last_evening_avg_temp_22_3', 'time_4', 'temp_pred_4', 'year_4', 'month_4', 'day_of_week_4', 'day_4', 'holidays_true_4', 'preholidays_true_4', 'temp_last_day_4', 'target_lag_24_4', 'target_lag_72_4', 'target_lag_336_4', 'VVP_4', 'cloudy_4', 'rainy_4', 'windy_4', 'clear_4', 'rain_probability_4', 'has_rain_probability_4', 'P_4', 'U_4', 'WW_4', 'Td_4', 'N_4', 'S_4', 'W_4', 'E_4', 'last_evening_avg_target_0_4', 'last_evening_avg_temp_0_4', 'last_evening_avg_target_19_4', 'last_evening_avg_temp_19_4', 'last_evening_avg_target_22_4', 'last_evening_avg_temp_22_4', 'time_5', 'temp_pred_5', 'year_5', 'month_5', 'day_of_week_5', 'day_5', 'holidays_true_5', 'preholidays_true_5', 'temp_last_day_5', 'target_lag_24_5', 'target_lag_72_5', 'target_lag_336_5', 'VVP_5', 'cloudy_5', 'rainy_5', 'windy_5', 'clear_5', 'rain_probability_5', 'has_rain_probability_5', 'P_5', 'U_5', 'WW_5', 'Td_5', 'N_5', 'S_5', 'W_5', 'E_5', 'last_evening_avg_target_0_5', 'last_evening_avg_temp_0_5', 'last_evening_avg_target_19_5', 'last_evening_avg_temp_19_5', 'last_evening_avg_target_22_5', 'last_evening_avg_temp_22_5', 'time_6', 'temp_pred_6', 'year_6', 'month_6', 'day_of_week_6', 'day_6', 'holidays_true_6', 'preholidays_true_6', 'temp_last_day_6', 'target_lag_24_6', 'target_lag_72_6', 'target_lag_336_6', 'VVP_6', 'cloudy_6', 'rainy_6', 'windy_6', 'clear_6', 'rain_probability_6', 'has_rain_probability_6', 'P_6', 'U_6', 'WW_6', 'Td_6', 'N_6', 'S_6', 'W_6', 'E_6', 'last_evening_avg_target_0_6', 'last_evening_avg_temp_0_6', 'last_evening_avg_target_19_6', 'last_evening_avg_temp_19_6', 'last_evening_avg_target_22_6', 'last_evening_avg_temp_22_6', 'time_7', 'temp_pred_7', 'year_7', 'month_7', 'day_of_week_7', 'day_7', 'holidays_true_7', 'preholidays_true_7', 'temp_last_day_7', 'target_lag_24_7', 'target_lag_72_7', 'target_lag_336_7', 'VVP_7', 'cloudy_7', 'rainy_7', 'windy_7', 'clear_7', 'rain_probability_7', 'has_rain_probability_7', 'P_7', 'U_7', 'WW_7', 'Td_7', 'N_7', 'S_7', 'W_7', 'E_7', 'last_evening_avg_target_0_7', 'last_evening_avg_temp_0_7', 'last_evening_avg_target_19_7', 'last_evening_avg_temp_19_7', 'last_evening_avg_target_22_7', 'last_evening_avg_temp_22_7', 'time_8', 'temp_pred_8', 'year_8', 'month_8', 'day_of_week_8', 'day_8', 'holidays_true_8', 'preholidays_true_8', 'temp_last_day_8', 'target_lag_24_8', 'target_lag_72_8', 'target_lag_336_8', 'VVP_8', 'cloudy_8', 'rainy_8', 'windy_8', 'clear_8', 'rain_probability_8', 'has_rain_probability_8', 'P_8', 'U_8', 'WW_8', 'Td_8', 'N_8', 'S_8', 'W_8', 'E_8', 'last_evening_avg_target_0_8', 'last_evening_avg_temp_0_8', 'last_evening_avg_target_19_8', 'last_evening_avg_temp_19_8', 'last_evening_avg_target_22_8', 'last_evening_avg_temp_22_8', 'time_9', 'temp_pred_9', 'year_9', 'month_9', 'day_of_week_9', 'day_9', 'holidays_true_9', 'preholidays_true_9', 'temp_last_day_9', 'target_lag_24_9', 'target_lag_72_9', 'target_lag_336_9', 'VVP_9', 'cloudy_9', 'rainy_9', 'windy_9', 'clear_9', 'rain_probability_9', 'has_rain_probability_9', 'P_9', 'U_9', 'WW_9', 'Td_9', 'N_9', 'S_9', 'W_9', 'E_9', 'last_evening_avg_target_0_9', 'last_evening_avg_temp_0_9', 'last_evening_avg_target_19_9', 'last_evening_avg_temp_19_9', 'last_evening_avg_target_22_9', 'last_evening_avg_temp_22_9', 'time_10', 'temp_pred_10', 'year_10', 'month_10', 'day_of_week_10', 'day_10', 'holidays_true_10', 'preholidays_true_10', 'temp_last_day_10', 'target_lag_24_10', 'target_lag_72_10', 'target_lag_336_10', 'VVP_10', 'cloudy_10', 'rainy_10', 'windy_10', 'clear_10', 'rain_probability_10', 'has_rain_probability_10', 'P_10', 'U_10', 'WW_10', 'Td_10', 'N_10', 'S_10', 'W_10', 'E_10', 'last_evening_avg_target_0_10', 'last_evening_avg_temp_0_10', 'last_evening_avg_target_19_10', 'last_evening_avg_temp_19_10', 'last_evening_avg_target_22_10', 'last_evening_avg_temp_22_10', 'time_11', 'temp_pred_11', 'year_11', 'month_11', 'day_of_week_11', 'day_11', 'holidays_true_11', 'preholidays_true_11', 'temp_last_day_11', 'target_lag_24_11', 'target_lag_72_11', 'target_lag_336_11', 'VVP_11', 'cloudy_11', 'rainy_11', 'windy_11', 'clear_11', 'rain_probability_11', 'has_rain_probability_11', 'P_11', 'U_11', 'WW_11', 'Td_11', 'N_11', 'S_11', 'W_11', 'E_11', 'last_evening_avg_target_0_11', 'last_evening_avg_temp_0_11', 'last_evening_avg_target_19_11', 'last_evening_avg_temp_19_11', 'last_evening_avg_target_22_11', 'last_evening_avg_temp_22_11', 'time_12', 'temp_pred_12', 'year_12', 'month_12', 'day_of_week_12', 'day_12', 'holidays_true_12', 'preholidays_true_12', 'temp_last_day_12', 'target_lag_24_12', 'target_lag_72_12', 'target_lag_336_12', 'VVP_12', 'cloudy_12', 'rainy_12', 'windy_12', 'clear_12', 'rain_probability_12', 'has_rain_probability_12', 'P_12', 'U_12', 'WW_12', 'Td_12', 'N_12', 'S_12', 'W_12', 'E_12', 'last_evening_avg_target_0_12', 'last_evening_avg_temp_0_12', 'last_evening_avg_target_19_12', 'last_evening_avg_temp_19_12', 'last_evening_avg_target_22_12', 'last_evening_avg_temp_22_12', 'time_13', 'temp_pred_13', 'year_13', 'month_13', 'day_of_week_13', 'day_13', 'holidays_true_13', 'preholidays_true_13', 'temp_last_day_13', 'target_lag_24_13', 'target_lag_72_13', 'target_lag_336_13', 'VVP_13', 'cloudy_13', 'rainy_13', 'windy_13', 'clear_13', 'rain_probability_13', 'has_rain_probability_13', 'P_13', 'U_13', 'WW_13', 'Td_13', 'N_13', 'S_13', 'W_13', 'E_13', 'last_evening_avg_target_0_13', 'last_evening_avg_temp_0_13', 'last_evening_avg_target_19_13', 'last_evening_avg_temp_19_13', 'last_evening_avg_target_22_13', 'last_evening_avg_temp_22_13', 'time_14', 'temp_pred_14', 'year_14', 'month_14', 'day_of_week_14', 'day_14', 'holidays_true_14', 'preholidays_true_14', 'temp_last_day_14', 'target_lag_24_14', 'target_lag_72_14', 'target_lag_336_14', 'VVP_14', 'cloudy_14', 'rainy_14', 'windy_14', 'clear_14', 'rain_probability_14', 'has_rain_probability_14', 'P_14', 'U_14', 'WW_14', 'Td_14', 'N_14', 'S_14', 'W_14', 'E_14', 'last_evening_avg_target_0_14', 'last_evening_avg_temp_0_14', 'last_evening_avg_target_19_14', 'last_evening_avg_temp_19_14', 'last_evening_avg_target_22_14', 'last_evening_avg_temp_22_14', 'time_15', 'temp_pred_15', 'year_15', 'month_15', 'day_of_week_15', 'day_15', 'holidays_true_15', 'preholidays_true_15', 'temp_last_day_15', 'target_lag_24_15', 'target_lag_72_15', 'target_lag_336_15', 'VVP_15', 'cloudy_15', 'rainy_15', 'windy_15', 'clear_15', 'rain_probability_15', 'has_rain_probability_15', 'P_15', 'U_15', 'WW_15', 'Td_15', 'N_15', 'S_15', 'W_15', 'E_15', 'last_evening_avg_target_0_15', 'last_evening_avg_temp_0_15', 'last_evening_avg_target_19_15', 'last_evening_avg_temp_19_15', 'last_evening_avg_target_22_15', 'last_evening_avg_temp_22_15', 'time_16', 'temp_pred_16', 'year_16', 'month_16', 'day_of_week_16', 'day_16', 'holidays_true_16', 'preholidays_true_16', 'temp_last_day_16', 'target_lag_24_16', 'target_lag_72_16', 'target_lag_336_16', 'VVP_16', 'cloudy_16', 'rainy_16', 'windy_16', 'clear_16', 'rain_probability_16', 'has_rain_probability_16', 'P_16', 'U_16', 'WW_16', 'Td_16', 'N_16', 'S_16', 'W_16', 'E_16', 'last_evening_avg_target_0_16', 'last_evening_avg_temp_0_16', 'last_evening_avg_target_19_16', 'last_evening_avg_temp_19_16', 'last_evening_avg_target_22_16', 'last_evening_avg_temp_22_16', 'time_17', 'temp_pred_17', 'year_17', 'month_17', 'day_of_week_17', 'day_17', 'holidays_true_17', 'preholidays_true_17', 'temp_last_day_17', 'target_lag_24_17', 'target_lag_72_17', 'target_lag_336_17', 'VVP_17', 'cloudy_17', 'rainy_17', 'windy_17', 'clear_17', 'rain_probability_17', 'has_rain_probability_17', 'P_17', 'U_17', 'WW_17', 'Td_17', 'N_17', 'S_17', 'W_17', 'E_17', 'last_evening_avg_target_0_17', 'last_evening_avg_temp_0_17', 'last_evening_avg_target_19_17', 'last_evening_avg_temp_19_17', 'last_evening_avg_target_22_17', 'last_evening_avg_temp_22_17', 'time_18', 'temp_pred_18', 'year_18', 'month_18', 'day_of_week_18', 'day_18', 'holidays_true_18', 'preholidays_true_18', 'temp_last_day_18', 'target_lag_24_18', 'target_lag_72_18', 'target_lag_336_18', 'VVP_18', 'cloudy_18', 'rainy_18', 'windy_18', 'clear_18', 'rain_probability_18', 'has_rain_probability_18', 'P_18', 'U_18', 'WW_18', 'Td_18', 'N_18', 'S_18', 'W_18', 'E_18', 'last_evening_avg_target_0_18', 'last_evening_avg_temp_0_18', 'last_evening_avg_target_19_18', 'last_evening_avg_temp_19_18', 'last_evening_avg_target_22_18', 'last_evening_avg_temp_22_18', 'time_19', 'temp_pred_19', 'year_19', 'month_19', 'day_of_week_19', 'day_19', 'holidays_true_19', 'preholidays_true_19', 'temp_last_day_19', 'target_lag_24_19', 'target_lag_72_19', 'target_lag_336_19', 'VVP_19', 'cloudy_19', 'rainy_19', 'windy_19', 'clear_19', 'rain_probability_19', 'has_rain_probability_19', 'P_19', 'U_19', 'WW_19', 'Td_19', 'N_19', 'S_19', 'W_19', 'E_19', 'last_evening_avg_target_0_19', 'last_evening_avg_temp_0_19', 'last_evening_avg_target_19_19', 'last_evening_avg_temp_19_19', 'last_evening_avg_target_22_19', 'last_evening_avg_temp_22_19', 'time_20', 'temp_pred_20', 'year_20', 'month_20', 'day_of_week_20', 'day_20', 'holidays_true_20', 'preholidays_true_20', 'temp_last_day_20', 'target_lag_24_20', 'target_lag_72_20', 'target_lag_336_20', 'VVP_20', 'cloudy_20', 'rainy_20', 'windy_20', 'clear_20', 'rain_probability_20', 'has_rain_probability_20', 'P_20', 'U_20', 'WW_20', 'Td_20', 'N_20', 'S_20', 'W_20', 'E_20', 'last_evening_avg_target_0_20', 'last_evening_avg_temp_0_20', 'last_evening_avg_target_19_20', 'last_evening_avg_temp_19_20', 'last_evening_avg_target_22_20', 'last_evening_avg_temp_22_20', 'time_21', 'temp_pred_21', 'year_21', 'month_21', 'day_of_week_21', 'day_21', 'holidays_true_21', 'preholidays_true_21', 'temp_last_day_21', 'target_lag_24_21', 'target_lag_72_21', 'target_lag_336_21', 'VVP_21', 'cloudy_21', 'rainy_21', 'windy_21', 'clear_21', 'rain_probability_21', 'has_rain_probability_21', 'P_21', 'U_21', 'WW_21', 'Td_21', 'N_21', 'S_21', 'W_21', 'E_21', 'last_evening_avg_target_0_21', 'last_evening_avg_temp_0_21', 'last_evening_avg_target_19_21', 'last_evening_avg_temp_19_21', 'last_evening_avg_target_22_21', 'last_evening_avg_temp_22_21', 'time_22', 'temp_pred_22', 'year_22', 'month_22', 'day_of_week_22', 'day_22', 'holidays_true_22', 'preholidays_true_22', 'temp_last_day_22', 'target_lag_24_22', 'target_lag_72_22', 'target_lag_336_22', 'VVP_22', 'cloudy_22', 'rainy_22', 'windy_22', 'clear_22', 'rain_probability_22', 'has_rain_probability_22', 'P_22', 'U_22', 'WW_22', 'Td_22', 'N_22', 'S_22', 'W_22', 'E_22', 'last_evening_avg_target_0_22', 'last_evening_avg_temp_0_22', 'last_evening_avg_target_19_22', 'last_evening_avg_temp_19_22', 'last_evening_avg_target_22_22', 'last_evening_avg_temp_22_22', 'time_23', 'temp_pred_23', 'year_23', 'month_23', 'day_of_week_23', 'day_23', 'holidays_true_23', 'preholidays_true_23', 'temp_last_day_23', 'target_lag_24_23', 'target_lag_72_23', 'target_lag_336_23', 'VVP_23', 'cloudy_23', 'rainy_23', 'windy_23', 'clear_23', 'rain_probability_23', 'has_rain_probability_23', 'P_23', 'U_23', 'WW_23', 'Td_23', 'N_23', 'S_23', 'W_23', 'E_23', 'last_evening_avg_target_0_23', 'last_evening_avg_temp_0_23', 'last_evening_avg_target_19_23', 'last_evening_avg_temp_19_23', 'last_evening_avg_target_22_23', 'last_evening_avg_temp_22_23', 'target_1', 'temp_1', 'target_5', 'temp_5', 'target_9', 'temp_9', 'target']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "temp_pred         float64\n",
       "temp_last_day     float64\n",
       "target_lag_24     float64\n",
       "target_lag_72     float64\n",
       "target_lag_336    float64\n",
       "                   ...   \n",
       "temp_1            float64\n",
       "target_5          float64\n",
       "temp_5            float64\n",
       "target_9          float64\n",
       "temp_9            float64\n",
       "Length: 366, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_target = feature_cols +['target']\n",
    "#feature_target.remove('date')\n",
    "print(feature_target)\n",
    "\n",
    "train_ds[feature_aug].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06b4774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afa6ff15d40473696f68fdbcece619f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1001916), Label(value='0 / 1001916…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def augment_row(df_to_augment, features_to_augment, alpha, i, random_1):\n",
    "\n",
    "\n",
    "    random.seed(random_1*i)\n",
    "\n",
    "    random_sample1 = random.randint(0000, 50000)\n",
    "    random_sample2 = random.randint(50001, 100000)\n",
    "\n",
    "    df_sample1 = df_to_augment.sample(frac=1,\n",
    "                                     random_state=random_sample1\n",
    "                                     )\n",
    "    df_sample2 = df_to_augment.sample(frac=1,\n",
    "                                     random_state = random_sample2\n",
    "                                     )\n",
    "\n",
    "    lmbda = np.random.beta(alpha, alpha)\n",
    "\n",
    "    df_mixup_sample = df_sample1.copy()\n",
    "    df_mixup_sample[features_to_augment] = df_sample1[features_to_augment] * lmbda + df_sample2[features_to_augment] * (1 - lmbda)\n",
    "        \n",
    "    other_features = list(set(df_to_augment.columns) - set(features_to_augment))\n",
    "    df_mixup_sample[other_features] = df_sample1[other_features]\n",
    "\n",
    "    return df_mixup_sample\n",
    "\n",
    "def mixup(df, alpha, features_to_augment, n_augmentations):\n",
    "    random.seed(random_state) #random.seed(42)\n",
    "    random_1 = random.randint(500, 9500)\n",
    "\n",
    "    \n",
    "    df_to_augment = df[(df['date'] < open_test_begin)]\n",
    "    df_to_keep = df[(df['date'] >= open_test_begin)]\n",
    "\n",
    "    df_mixup = pd.concat([augment_row(df_to_augment, features_to_augment, alpha, i, random_1) for i in range(n_augmentations)]).parallel_apply(lambda x: x)\n",
    "\n",
    "    df_final = pd.concat([ df_mixup,\n",
    "                           df_to_augment,  #нужно раскомитить если обучение с нуля\n",
    "                           df_to_keep])\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n",
    "n_augmentations = 27\n",
    "alpha=0.3 #15\n",
    "n_frac = 1\n",
    "train_ds_mixup = mixup(train_ds[feature_target], alpha, feature_aug, n_augmentations)\n",
    "FEATURES = '_Aug_27_alpha_3'\n",
    "num = 6 #номер модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "680b75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40027, 800) (1041943, 801)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_37729/132879785.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_ds_mixup.reset_index(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[feature_target].shape, train_ds_mixup.shape)\n",
    "train_ds_mixup.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f34c90",
   "metadata": {},
   "source": [
    "#### 1.12 Выделение наборов данных для обучения, валидации и тестирования\n",
    "\n",
    "Выделялось два набора данных для обучения и валидации:\n",
    "1. Обучение на данных с 2019 по 2021 с валидацией на 2022\n",
    "2. Обучение на данных с 2019 по 2022 с валидацией на первом квартале 2023\n",
    "\n",
    "Первый набор позволяет оценить влияние сезонности на обучение и предсказания, второй позволяет обучить модель на большем объеме данных и на более актуальных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a2b8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем набор датасетов для обучения и проверки\n",
    "features = train_ds_mixup[feature_cols]\n",
    "target = train_ds_mixup['target']\n",
    "\n",
    "# Функция для выделения временных интервалов из таблиц признаков и целей\n",
    "# на этом этапе отбрасываем колонку 'date'\n",
    "def features_interval(features, target, date1, date2):\n",
    "    features_interval = features[ (features['date']>=date1) & (features['date']<date2) ]\n",
    "    target_interval = target[features_interval.index]\n",
    "    features_interval = features_interval.drop('date', axis=1)\n",
    "    return features_interval, target_interval\n",
    "\n",
    "\n",
    "\n",
    "# для первичного подбора гиперпараметров будем обучать на 19-22 годах, валидировать август-сентябрь 2022\n",
    "features_all_train, target_all_train = features_interval(features, target, '2019-01-01', '2022-08-01')\n",
    "features_open_test, target_open_test = features_interval(features, target, '2022-08-01', '2022-09-30')\n",
    "\n",
    "# для проверки на тестовой выборке будем учиться на всем тренировочном датасете\n",
    "features_all_train, target_all_train = features_interval(features, target, '2019-01-01', open_test_begin)\n",
    "features_open_test, target_open_test = features_interval(features, target, open_test_begin, open_test_end)\n",
    "\n",
    "features_open_test_sum, target_open_test_sum = features_interval(features, target, '2023-06-01', open_test_end)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f69ef2",
   "metadata": {},
   "source": [
    "### 4. Проверка метрик на тестовом датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca38f19",
   "metadata": {},
   "source": [
    "#### 4.1 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21b9a7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'temp_pred', 'year', 'month', 'day_of_week', 'day',\n",
       "       'holidays_true', 'preholidays_true', 'temp_last_day', 'target_lag_24',\n",
       "       ...\n",
       "       'last_evening_avg_target_19_23', 'last_evening_avg_temp_19_23',\n",
       "       'last_evening_avg_target_22_23', 'last_evening_avg_temp_22_23',\n",
       "       'target_1', 'temp_1', 'target_5', 'temp_5', 'target_9', 'temp_9'],\n",
       "      dtype='object', length=798)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "031f6476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1041943, 798) (1041943,) (2919, 798)\n"
     ]
    }
   ],
   "source": [
    "drop_list = [#'preholidays',\n",
    "            #'has_rain_probability', 'W', 'E',\n",
    "            #'holidays' \n",
    "            ]\n",
    "feat_lgbm_train = features_all_train.drop(columns=drop_list)\n",
    "feat_lgbm_test = features_open_test.drop(columns=drop_list)\n",
    "print(feat_lgbm_train.shape, target_all_train.shape, feat_lgbm_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88929019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/maxsemakov/Documents/glowbyte/first-competition-1/main_notebook_XGBOOST_short_dop_model.ipynb Ячейка 49\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxsemakov/Documents/glowbyte/first-competition-1/main_notebook_XGBOOST_short_dop_model.ipynb#X66sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mIteration:\u001b[39m\u001b[39m'\u001b[39m, env\u001b[39m.\u001b[39miteration)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxsemakov/Documents/glowbyte/first-competition-1/main_notebook_XGBOOST_short_dop_model.ipynb#X66sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m lgbm_model_all_train \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mLGBMRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maxsemakov/Documents/glowbyte/first-competition-1/main_notebook_XGBOOST_short_dop_model.ipynb#X66sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m lgbm_model_all_train\u001b[39m.\u001b[39;49mfit(feat_lgbm_train, target_all_train, callbacks\u001b[39m=\u001b[39;49m[print_iteration_info])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxsemakov/Documents/glowbyte/first-competition-1/main_notebook_XGBOOST_short_dop_model.ipynb#X66sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m l_predict_train \u001b[39m=\u001b[39m lgbm_model_all_train\u001b[39m.\u001b[39mpredict(feat_lgbm_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxsemakov/Documents/glowbyte/first-competition-1/main_notebook_XGBOOST_short_dop_model.ipynb#X66sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m l_predict_test \u001b[39m=\u001b[39m lgbm_model_all_train\u001b[39m.\u001b[39mpredict(feat_lgbm_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1034\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     init_model: Optional[Union[\u001b[39mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLGBMRegressor\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1048\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1049\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1050\u001b[0m         X,\n\u001b[1;32m   1051\u001b[0m         y,\n\u001b[1;32m   1052\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1053\u001b[0m         init_score\u001b[39m=\u001b[39;49minit_score,\n\u001b[1;32m   1054\u001b[0m         eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1055\u001b[0m         eval_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[1;32m   1056\u001b[0m         eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[1;32m   1057\u001b[0m         eval_init_score\u001b[39m=\u001b[39;49meval_init_score,\n\u001b[1;32m   1058\u001b[0m         eval_metric\u001b[39m=\u001b[39;49meval_metric,\n\u001b[1;32m   1059\u001b[0m         feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m   1060\u001b[0m         categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[1;32m   1061\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1062\u001b[0m         init_model\u001b[39m=\u001b[39;49minit_model\n\u001b[1;32m   1063\u001b[0m     )\n\u001b[1;32m   1064\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/sklearn.py:842\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    839\u001b[0m evals_result: _EvalResultDict \u001b[39m=\u001b[39m {}\n\u001b[1;32m    840\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 842\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m    843\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    844\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[1;32m    845\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[1;32m    846\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[1;32m    847\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[1;32m    848\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    849\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[1;32m    850\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m    851\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[1;32m    852\u001b[0m )\n\u001b[1;32m    854\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n\u001b[1;32m    855\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_best_iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster\u001b[39m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/engine.py:245\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[1;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    247\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/basic.py:3096\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3089\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[1;32m   3090\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[1;32m   3091\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   3092\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[1;32m   3093\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   3094\u001b[0m     )\n\u001b[1;32m   3095\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 3096\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[1;32m   3097\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   3098\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/basic.py:2210\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2203\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\n\u001b[1;32m   2204\u001b[0m                 predictor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor,\n\u001b[1;32m   2205\u001b[0m                 data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[1;32m   2206\u001b[0m                 used_indices\u001b[39m=\u001b[39mused_indices\n\u001b[1;32m   2207\u001b[0m             )\n\u001b[1;32m   2208\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2209\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[0;32m-> 2210\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel, reference\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2211\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[1;32m   2212\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[1;32m   2213\u001b[0m                     feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name, categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m   2214\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[1;32m   2215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/basic.py:1801\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m   1799\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas_categorical \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39mpandas_categorical\n\u001b[1;32m   1800\u001b[0m     categorical_feature \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39mcategorical_feature\n\u001b[0;32m-> 1801\u001b[0m data, feature_name, categorical_feature, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas_categorical \u001b[39m=\u001b[39m _data_from_pandas(data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m   1802\u001b[0m                                                                                      feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m   1803\u001b[0m                                                                                      categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[1;32m   1804\u001b[0m                                                                                      pandas_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpandas_categorical)\n\u001b[1;32m   1806\u001b[0m \u001b[39m# process for args\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m params \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m params\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/lightgbm/basic.py:704\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    701\u001b[0m target_dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfind_common_type(df_dtypes, [])\n\u001b[1;32m    702\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49mtarget_dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    705\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[39m# 1.0 <= pd version < 1.1 and nullable dtypes, least common case\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[39m# raises error because array is casted to type(pd.NA) and there's no na_value argument\u001b[39;00m\n\u001b[1;32m    708\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mastype(target_dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/pandas/core/frame.py:1892\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1891\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1892\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1893\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[1;32m   1894\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/pandas/core/internals/managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1656\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1657\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/p311/lib/python3.11/site-packages/pandas/core/internals/managers.py:1716\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1714\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[1;32m   1715\u001b[0m     result[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m arr\n\u001b[0;32m-> 1716\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1718\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n\u001b[1;32m   1719\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSome items were not contained in blocks\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "# Здесь обучаем на всем тренировочном датасете\n",
    "\n",
    "\n",
    "\n",
    "params = {'num_leaves':15, \n",
    "          'learning_rate':0.02, \n",
    "          'feature_fraction':1, \n",
    "          'num_iterations':10000, \n",
    "          'random_state':random_state, \n",
    "          'objective':'regression_l1',\n",
    "          'n_jobs':-1}\n",
    "params= {'num_leaves': 34, 'min_child_samples': 16, \n",
    "          'max_depth': 8, 'learning_rate': 0.012, \n",
    "          'min_sum_hessian_in_leaf': 1e-4,\n",
    "          'objective': 'regression_l1', 'feature_fraction': 0.9574152630927155,\n",
    "          'n_jobs':-1, 'num_iterations':10000\n",
    "          }\n",
    "\n",
    "\n",
    "def print_iteration_info(env):\n",
    "    # выводим номер итерации и время, затраченное на предыдущую итерацию\n",
    "    print('Iteration:', env.iteration)\n",
    "\n",
    "\n",
    "lgbm_model_all_train = lgb.LGBMRegressor(**params)\n",
    "lgbm_model_all_train.fit(feat_lgbm_train, target_all_train, callbacks=[print_iteration_info])\n",
    "\n",
    "l_predict_train = lgbm_model_all_train.predict(feat_lgbm_train)\n",
    "l_predict_test = lgbm_model_all_train.predict(feat_lgbm_test)\n",
    "\n",
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, l_predict_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, l_predict_test)\n",
    "\n",
    "results = pd.DataFrame([[f'тренировочная LGBM {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая LGBM {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129bac4",
   "metadata": {},
   "source": [
    "# До обучение модели \n",
    "\n",
    "\n",
    "params= {'num_leaves': 34, 'min_child_samples': 16, \n",
    "          'max_depth': 8, 'learning_rate': 0.012, \n",
    "          'min_sum_hessian_in_leaf': 1e-4,\n",
    "          'objective': 'regression_l1', 'feature_fraction': 0.9574152630927155,\n",
    "          'n_jobs':-1, 'num_iterations':10000\n",
    "          }\n",
    "\n",
    "def print_iteration_info(env):\n",
    "    # выводим номер итерации и время, затраченное на предыдущую итерацию\n",
    "    print('Iteration:', env.iteration)\n",
    "\n",
    "\n",
    "\n",
    "lgbm_model_all_train.fit(feat_lgbm_train, target_all_train, callbacks=[print_iteration_info],  init_model=lgbm_model_all_train)\n",
    "\n",
    "l_predict_train = lgbm_model_all_train.predict(feat_lgbm_train)\n",
    "l_predict_test = lgbm_model_all_train.predict(feat_lgbm_test)\n",
    "\n",
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, l_predict_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, l_predict_test)\n",
    "\n",
    "results = pd.DataFrame([[f'тренировочная LGBM add train {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая LGBM add train {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f64e5aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Выборка</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>тренировочная LGBM _Aug_27_alpha_3</td>\n",
       "      <td>3.335556</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.996601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>тестовая LGBM _Aug_27_alpha_3</td>\n",
       "      <td>5.652768</td>\n",
       "      <td>0.013195</td>\n",
       "      <td>0.987176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Выборка       MAE      MAPE        R2\n",
       "0  тренировочная LGBM _Aug_27_alpha_3  3.335556  0.006983  0.996601\n",
       "1       тестовая LGBM _Aug_27_alpha_3  5.652768  0.013195  0.987176"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47121cb",
   "metadata": {},
   "source": [
    "#### 4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f228a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8dba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['preholidays_true',\n",
    "            #'has_rain_probability', \n",
    "            # 'W', 'E'\n",
    "            ]\n",
    "n_values = range(1, 24)\n",
    "preholidays = ['preholidays_true_{}'.format(n) for n in n_values]\n",
    "#has_rain = ['has_rain_probability_{}'.format(n) for n in n_values]\n",
    "#W_wind = ['W_{}'.format(n) for n in n_values]\n",
    "#E_wind = ['E_{}'.format(n) for n in n_values]\n",
    "\n",
    "drop_list = drop_list + preholidays #+ has_rain + W_wind + E_wind\n",
    "\n",
    "feat_xgb_train = features_all_train.drop(columns=drop_list)\n",
    "feat_xgb_test = features_open_test.drop(columns=drop_list)\n",
    "feat_xgb_train.columns, feat_xgb_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    max_depth=7,\n",
    "    n_estimators=1190, #n_estimators=195, #\n",
    "    learning_rate=0.009, #learning_rate=0.1, #\n",
    "    tree_method='exact',\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    gamma=2,\n",
    "    colsample_bytree=1,\n",
    "    random_state=random_state\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "\n",
    "\n",
    "class IterationInfoCallback(TrainingCallback):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        print('Iteration:', epoch, 'Time for last iteration:', self.start_time - time.time())\n",
    "        self.start_time = time.time()\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "xgb_model_all_train = xgb_model.fit(feat_xgb_train, target_all_train, callbacks=[IterationInfoCallback()])\n",
    "\n",
    "xgb_predict_test = xgb_model_all_train.predict(feat_xgb_test)\n",
    "xgb_predict_train = xgb_model_all_train.predict(feat_xgb_train)\n",
    "\n",
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, xgb_predict_train )\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, xgb_predict_test )\n",
    "\n",
    "results = pd.concat([results,\n",
    "pd.DataFrame([[f'тренировочная XGB {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая XGB {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['preholidays_true',\n",
    "            ]\n",
    "n_values = range(1, 24)\n",
    "preholidays = ['preholidays_true_{}'.format(n) for n in n_values]\n",
    "\n",
    "\n",
    "drop_list = drop_list + preholidays #+ has_rain + W_wind + E_wind\n",
    "\n",
    "feat_xgb_test_summ = features_open_test_sum.drop(columns=drop_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_predict_test_sum = xgb_model_all_train.predict(feat_xgb_test_summ)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test_sum, xgb_predict_test_sum )\n",
    "results = pd.concat([results,\n",
    "pd.DataFrame([ [f'тестовая XGB summer{FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e9496",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e232b25",
   "metadata": {},
   "source": [
    "### 5. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ensemble = pd.DataFrame(columns=('Выборка', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c8a35",
   "metadata": {},
   "source": [
    "### Simple Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15100001",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_simple_ensemble_train = (xgb_predict_train + l_predict_train)/2\n",
    "predict_simple_ensemble_test = (xgb_predict_test + l_predict_test)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train, predict_simple_ensemble_train)\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test, predict_simple_ensemble_test)\n",
    "\n",
    "results_ensemble = pd.concat([results_ensemble,\n",
    "pd.DataFrame([[f'тренировочная simple_ensemble  {FEATURES}', mae_train, mape_train, r2_train], [f'тестовая simple_ensemble {FEATURES}', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка', 'MAE', 'MAPE', 'R2'))\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_ensemble)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864aa633",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_day(target_open_test, predict_simple_ensemble_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#num = 3\n",
    "# определите путь к папке, которую вы хотите создать\n",
    "folder_path = \"models\"\n",
    "\n",
    "# проверьте, существует ли уже папка\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "lgbm_model_all_train.booster_.save_model(f'models/lgb_model{FEATURES}_{num}.txt')\n",
    "xgb_model.save_model(f'models/xgb_model{FEATURES}_{num}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURES = 'BASE'\n",
    "results.to_csv(f'models/results_LGBM_XGBoost_simple_ensemble_{FEATURES}_{num}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
