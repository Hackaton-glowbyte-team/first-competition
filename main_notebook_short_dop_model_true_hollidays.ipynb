{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5606014",
   "metadata": {},
   "source": [
    "## Энергетический оракул\n",
    "Ноутбук команды #12\n",
    "\n",
    "Работа выполнена на основе модели LightGBM\n",
    "\n",
    "\n",
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4351135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_state = 12345\n",
    "NUM_ITERATIONS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750543e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    return mean_absolute_error(y_true_grouped, y_pred_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45891200",
   "metadata": {},
   "source": [
    "#### 1.1 Функции для расшифровки прогноза погоды в колонке 'weather_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece12617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "\n",
    "# функция формирует колонки 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability', 'has_rain_probability'\n",
    "# в колонках число, которое 0 при отсутсвии упоминания явления в weather_pred или степень упоминания\n",
    "# функция дает в колонках номер первого списка, элемент которого есть в строке плюс 1\n",
    "# списки cloudy_list, rainy_list, windy_list, clear_list можно модифицировать\n",
    "# соответственно, можно экспериментировать с расположением значений в списках\n",
    "# например, сейчас 'дождь', 'снег', 'д+сн' - первая степень  дождя, а 'гроз', 'ливень' - вторая\n",
    "# а можно сделать снег второй, а грозу с ливнем убрать в третью\n",
    "# также сделал отдельный список для \"ясности\", чтобы выделить 'ясно' и 'солнечно'\n",
    "\n",
    "def in_what_list(weather, big_list):\n",
    "    for list_number, small_list in enumerate(big_list):\n",
    "        if any(word in weather for word in small_list):\n",
    "            return list_number+1\n",
    "    return 0\n",
    "\n",
    "def weather_split2(row):\n",
    "    weather = row['weather_pred']\n",
    "    cloudy_list = [['проясн', 'пер.об.', 'п/об'], ['пасм', 'обл']]\n",
    "    rainy_list = [['дождь', 'снег', 'д+сн'], ['гроз', 'ливень']]\n",
    "    windy_list = [['вет'],['штор']]\n",
    "    clear_list = [['проясн'], ['ясно'], ['солнеч']]\n",
    "    numbers = re.findall(r'\\d+', weather)\n",
    "    cloudy = in_what_list(weather, cloudy_list)\n",
    "    rainy = in_what_list(weather, rainy_list)\n",
    "    windy = in_what_list(weather, windy_list)\n",
    "    clear = in_what_list(weather, clear_list)\n",
    "    rain_probability = 0 if len(numbers)==0 else int(numbers[0])\n",
    "    has_rain_probability = int(len(numbers)==0)\n",
    "    return cloudy, rainy, windy, clear, rain_probability, has_rain_probability\n",
    "\n",
    "def fill_weather_columns(df):\n",
    "    df['weather_pred'] = df['weather_pred'].fillna('')\n",
    "    df['cloudy'], df['rainy'], df['windy'], df['clear'], df['rain_probability'], df['has_rain_probability'] = \\\n",
    "                zip(*df.apply(weather_split2, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39d660",
   "metadata": {},
   "source": [
    "#### 1.2 Функции для загрузки данных о ВВП \n",
    "данные загружаются из файла 'data/VVP.csv'\n",
    "\n",
    "Некоторые научные работы указывают на прямую связь величины потребления электричества и показателя ВВП, который отражает ситуацию в экономике. Данные по экономике публикуются различными министерствами с разной периодичностью. Для использования в работе были взяты фактические данные по ВВП с сайта investing, который агрегирует публикации Минэкономразвития. Данные за месяц побликуются с месячной задержкой, поэтому модель использует для прогнозирования данные за прошлые месяцы, которые известны.   \n",
    "  \n",
    "Ссылка на данные: https://ru.investing.com/economic-calendar/russian-monthly-gdp-407\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3dd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция добавляет данные о ВВП из файла 'data/VVP.csv' в датасет\n",
    "\n",
    "def add_vvp2(data, file_source = 'data/VVP.csv'):\n",
    "    \"\"\"\n",
    "    сырой датафрем подаем на вход\n",
    "    \"\"\"\n",
    "    # обработаем файл с динамикой ВВП\n",
    "    vvp = pd.read_csv(file_source)\n",
    "    # преобразуем дату файла-источника в формат datetime64 и дропнем один столбик\n",
    "    vvp['date'] = pd.to_datetime(vvp['date'], format ='%Y-%m-%d %H:%M:%S')\n",
    "    vvp.drop('for_month',axis=1,inplace=True) \n",
    "    \n",
    "    # обработаем основной фрейм - создадим столбец для соединения, который потом удалим\n",
    "    data['date_temp'] = pd.to_datetime(data['date'], format = '%Y-%m-%d' )\n",
    "    data['date_temp'] = data['date_temp'] + pd.to_timedelta(data['time'] , 'H')\n",
    "    \n",
    "    # соединяем основной фрейм и ВВП по дате объявления показтеля ВВП\n",
    "    for idx in reversed(vvp.index):\n",
    "        data.loc[data['date_temp']>=vvp.date[idx],'VVP'] = vvp.VVP_perc[idx]\n",
    "        \n",
    "    data.drop('date_temp',axis=1,inplace=True)   \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe769599",
   "metadata": {},
   "source": [
    "#### 1.3 Функции для загрузки архива данных о фактической погоде\n",
    "данные загружаются из файла 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "Изначально данные для формирования таблицы \"preprocessing_loaded_table\" были взяты из с сайта [https://rp5.ru](https://rp5.ru/Архив_погоды_в_Храброво,_им._императрицы_Елизаветы_Петровны_(аэропорт),_METAR), где хранятся архивы погоды в аэрапорту Калининграда, за период с 31.12.2018 по 30.09.2023\n",
    "\n",
    "Описание данных в таблице:\n",
    "- Местное время в Храброво / им. императрицы Елизаветы Петровны (аэропорт) - Дата / Местное время\n",
    "- T -  Темпиратура воздуха\n",
    "- Po - Давление на уровне станции\n",
    "- P - Давление приведённое к уровню моря\n",
    "- U - Относительная влажность\n",
    "- DD - Направление ветра\n",
    "- Ff - Скорость ветра\n",
    "- ff10 - Максимальное значение порыва ветра\n",
    "- WW - Особое явление текущей погоды (осадки)\n",
    "- W'W' - Явление недавней погоды, имеющее оперативное значение\n",
    "- с - Общая облачность\n",
    "- VV - Горизонтальная дальность видимости\n",
    "- Td - Темпиратура точки росы\n",
    "\n",
    "Данные, которые были взяты из данной таблицы и загружаются из 'data/preprocessing_loaded_table.csv':\n",
    "- P - не подверглось изменению\n",
    "- U - не подверглось изменению\n",
    "- Td - не подверглась изменению\n",
    "\n",
    " WW - разделили на 4 категории:\n",
    "- Нет осадков (где были пропуски)\n",
    "- слабый дождь\n",
    "- сильный дождь\n",
    "- снег\n",
    "\n",
    "DD - создали 4 столбца, соответствующих сторонам горизонта, которые принимали значения 0; 0.5 и 1 в зависимости от силы ветра в конкретном направлении\n",
    "- N - north\n",
    "- S - south\n",
    "- W - west\n",
    "- E - east\n",
    "\n",
    "В дальнейшем эти данные использовались с лагом в сутки: в поля на завтрашний день записывались данные сегодняшнего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для работы с данными о фактической погоде из 'data/preprocessing_loaded_table.csv'\n",
    "\n",
    "# Кодировка информации об осадках из колонки WW\n",
    "def true_weather_WW_replace(ww):\n",
    "    if ww=='нет осадков':\n",
    "        return 0\n",
    "    elif ww=='слабый дождь':\n",
    "        return 1\n",
    "    elif (ww=='сильный дождь') or (ww=='снег'):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Вычисление Timestamp из даты и времени\n",
    "def row_plus_hours_to_index(row):\n",
    "    return row['date'] + pd.to_timedelta(row['time'] , 'H')\n",
    "\n",
    "# Функция для сдвига на сутки (в скачанном датасете разбивка по 30 мин, поэтому timeshift=48)\n",
    "def shift_features_fact(df, timeshift=48):\n",
    "    list_fact_columns=list(df.columns)\n",
    "    list_fact_columns.remove('date_tw')\n",
    "    new_df = df.copy()\n",
    "    for column in list_fact_columns:\n",
    "        new_df[column] = new_df[column].shift(timeshift)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления метрики mae по дням из почасовых массивов данных\n",
    "\n",
    "def mae_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    return mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "# Функция для вычисления метрик по дням из почасовых массивов данных\n",
    "\n",
    "def metrics_hour(y_true, y_pred):\n",
    "\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808c109",
   "metadata": {},
   "source": [
    "#### 1.5 Чтение файлов с данными\n",
    "Данные объединяются в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем исходные датасеты и складываем в один\n",
    "train_ds = pd.read_csv('data/train_dataset.csv')\n",
    "test_ds = pd.read_csv('data/test_dataset.csv')\n",
    "train_ds = pd.concat([train_ds, test_ds])\n",
    "\n",
    "# запоминаем дату начала тестовых данных, потом также поступим и с закрытым датасетом\n",
    "open_test_begin = pd.to_datetime(test_ds['date']).min()\n",
    "open_test_end = pd.to_datetime(test_ds['date']).max() + pd.to_timedelta(1,'d')\n",
    "print('начало открытого теста:', open_test_begin, '    конец открытого теста:', open_test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = train_ds.duplicated()\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237ce32",
   "metadata": {},
   "source": [
    "#### 1.6 Формирование колонок с производными от даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16090ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем дату и делаем из нее колонки\n",
    "train_ds['date'] = pd.to_datetime(train_ds['date'])\n",
    "train_ds['year'] = train_ds['date'].dt.year\n",
    "train_ds['month'] = train_ds['date'].dt.month\n",
    "train_ds['day_of_week'] = train_ds['date'].dt.dayofweek\n",
    "train_ds['day'] = train_ds['date'].dt.day\n",
    "train_ds['day_of_year'] = train_ds['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98567815",
   "metadata": {},
   "source": [
    "#### 1.7 Подгрузка данных о праздниках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03029389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление данных о праздниках из файла 'data/holidays.csv'\n",
    "\n",
    "df_holidays = pd.read_csv('data/holidays.csv')\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "\n",
    "# Assuming df_holidays and train_ds are your dataframes\n",
    "train_ds = pd.merge(train_ds, df_holidays, on='date', how='left')\n",
    "print('размер DS', train_ds.shape, 'дубликатов - ', train_ds.duplicated().sum())\n",
    "# Fill NaN values with 0\n",
    "train_ds['holidays'].fillna(0, inplace=True)\n",
    "train_ds['preholidays'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "train_ds['holidays'] = train_ds['holidays'].astype(int)\n",
    "train_ds['preholidays'] = train_ds['preholidays'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdfa6e",
   "metadata": {},
   "source": [
    "#### 1.8 Формирование колонок со значением целевого признака в предыдущие дни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faece945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление колонок с временными лагами\n",
    "\n",
    "# создаем столбец 'temp_last_day'\n",
    "train_ds['temp_last_day'] = train_ds['temp'].shift(24)\n",
    "\n",
    "# заполняем пропущенные значения в 'temp_last_day'\n",
    "train_ds['temp_last_day'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# создаем столбцы с временными лагами для 'target'\n",
    "lags = [1, 12,  24, 35, 40, 48, 72, 7*24, 14*24]\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'] = train_ds['target'].shift(lag)\n",
    "\n",
    "\"\"\"count_rollins = [24,\n",
    "                    #7*24, \n",
    "                    #28*24,\n",
    "                    #56*24\n",
    "                    ] \n",
    "for count_rollin in count_rollins:  \n",
    "    train_ds[f'mean_{count_rollin}'] = train_ds['target_lag_24'].rolling(count_rollin).mean()\n",
    "\n",
    "count_rollins = [24, 7*24, 28*24] \n",
    "for count_rollin in count_rollins:  \n",
    "    train_ds[f'temp_mean_{count_rollin}'] = train_ds['temp'].rolling(count_rollin).mean().shift(24)\"\"\"\n",
    "# заполняем пропущенные значения в столбцах с лагами\n",
    "for lag in lags:\n",
    "    train_ds[f'target_lag_{lag}'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddbecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = train_ds.duplicated()\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c4022",
   "metadata": {},
   "source": [
    "#### 1.9 Формирование колонок с ВВП и данными о погоде посредством ранее описанных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применяем функцию добавления ВВП\n",
    "train_ds = add_vvp2(train_ds)\n",
    "\n",
    "# Расшифровка прогноза в колонке 'weather_pred'\n",
    "train_ds = fill_weather_columns(train_ds)\n",
    "\n",
    "\n",
    "# Читаем файл с архивом фактической погоды\n",
    "df_true_weather = pd.read_csv('data/preprocessing_loaded_table.csv')\n",
    "display(df_true_weather)\n",
    "\n",
    "# Форматируем колонки\n",
    "df_true_weather['WW'] = df_true_weather['WW'].apply(true_weather_WW_replace)\n",
    "df_true_weather['date'] = pd.to_datetime(df_true_weather['date'])\n",
    "df_true_weather = df_true_weather.rename(columns={'date':'date_tw'})\n",
    "# Применяем сдвиг на сутки, чтобы не заглядывать в будущее\n",
    "df_true_weather = shift_features_fact(df_true_weather)\n",
    "# Добавляем в датасет\n",
    "train_ds['date_hours'] = train_ds.apply(row_plus_hours_to_index, axis=1)\n",
    "train_ds = train_ds.merge(df_true_weather, left_on='date_hours', right_on='date_tw')\n",
    "train_ds = train_ds.drop(['date_hours', 'date_tw'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0de996",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = train_ds.duplicated()\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc76ee",
   "metadata": {},
   "source": [
    "#### 1.10 Демонстрация сформированного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итоговый набор колонок\n",
    "train_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = train_ds.duplicated()\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69383cb",
   "metadata": {},
   "source": [
    "#### 1.11 Исключение лишних колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем признаки. Все лишние колонки здесь отбрасываем, кроме 'date', которую уберем позже \n",
    "\n",
    "feature_cols = list(train_ds.columns)\n",
    "\n",
    "# выбрасываем взгляд в прошлое и расшифрованную погоду\n",
    "drop_list = ['target', 'day_of_year', 'weather_pred', 'weather_fact', 'temp']\n",
    "\n",
    "# выбрасываем признаки, найденные процедурно в процессе оптимизации\n",
    "# КОМАНДЕ: здесь можно добавлять признаки на выброс с целью оптимизации\n",
    "drop_list = drop_list + ['target_lag_48', 'target_lag_168', \n",
    "                         'has_rain_probability', 'preholidays',\n",
    "                          'W', 'E'] \n",
    "\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)\n",
    "\n",
    "# Итоговый список признаков\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f34c90",
   "metadata": {},
   "source": [
    "#### 1.12 Выделение наборов данных для обучения, валидации и тестирования\n",
    "\n",
    "Выделялось два набора данных для обучения и валидации:\n",
    "1. Обучение на данных с 2019 по 2021 с валидацией на 2022\n",
    "2. Обучение на данных с 2019 по 2022 с валидацией на первом квартале 2023\n",
    "\n",
    "Первый набор позволяет оценить влияние сезонности на обучение и предсказания, второй позволяет обучить модель на большем объеме данных и на более актуальных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем набор датасетов для обучения и проверки\n",
    "\n",
    "features = train_ds[feature_cols]\n",
    "target = train_ds['target']\n",
    "\n",
    "# Функция для выделения временных интервалов из таблиц признаков и целей\n",
    "# на этом этапе отбрасываем колонку 'date'\n",
    "def features_interval(features, target, date1, date2):\n",
    "    features_interval = features[ (features['date']>=date1) & (features['date']<date2) ]\n",
    "    target_interval = target[features_interval.index]\n",
    "    features_interval = features_interval.drop('date', axis=1)\n",
    "    return features_interval, target_interval\n",
    "\n",
    "\n",
    "\n",
    "# отбор признаков будем производить, обучая на 19-22 и проверяя по первому кварталу 2023\n",
    "# с дополнительным контролем на вариантах из первичного обучения\n",
    "features_2022, target_2022 = features_interval(features, target, '2019-01-01', '2023-01-01')\n",
    "features_2023, target_2023 = features_interval(features, target, '2023-01-01', open_test_begin)\n",
    "\n",
    "# для проверки на тестовой выборке будем учиться на всем тренировочном датасете\n",
    "features_all_train, target_all_train = features_interval(features, target, '2019-01-01', open_test_begin)\n",
    "features_open_test, target_open_test = features_interval(features, target, open_test_begin, open_test_end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77183b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = features.duplicated()\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a967384f",
   "metadata": {},
   "source": [
    "### 2. Обучение моделей\n",
    "\n",
    "В настоящей работе обучается модель LightGBM\n",
    "\n",
    "#### 2.1 Гиперпараметры\n",
    "Были подобраны следующие значения гиперпараметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves':15, 'learning_rate':0.02, 'feature_fraction':1, 'num_iterations':NUM_ITERATIONS, 'random_state':random_state, 'objective':'regression_l1', 'n_jobs':-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10f0f4",
   "metadata": {},
   "source": [
    "#### 2.3 Процедурный отбор признаков\n",
    "Для каждого признака проверим метрику без него и сравним с базовой метрикой, полученной со всеми признаками. Данная процедура позволит улучшить результаты за счет исключения признаков. Здесь обучение проходит на данных за 2019-2022 годы с валидацией на первом квартале 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f69ef2",
   "metadata": {},
   "source": [
    "### 4 Проверка метрик на тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_lgbm =  features_all_train.drop(columns=['target_lag_1','target_lag_12'])\n",
    "feature_lgbm_test = features_open_test.drop(columns=['target_lag_1','target_lag_12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88929019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "# Здесь обучаем на всем тренировочном датасете\n",
    "params = {'num_leaves':15, 'learning_rate':0.02, 'feature_fraction':0.98, 'num_iterations':10000, 'random_state':random_state, 'objective':'regression_l1', 'n_jobs':-1}\n",
    "\n",
    "lgbm_model_all_train = lgb.LGBMRegressor(**params)\n",
    "lgbm_model_all_train.fit(feature_lgbm, target_all_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2af5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = lgbm_model_all_train.predict(feature_lgbm)\n",
    "predict_test = lgbm_model_all_train.predict(feature_lgbm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train,predict_train )\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test,predict_test )\n",
    "\n",
    "pd.DataFrame([['тренировочная на часе', mae_train, mape_train, r2_train], ['тестовая', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка на часе', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e22c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка метрики лучшей модели на тестовом датасете\n",
    "# Здесь обучаем на всем тренировочном датасете\n",
    "params = {'num_leaves':15, 'learning_rate':0.02, 'feature_fraction':0.98, 'num_iterations':10000, 'random_state':random_state, 'objective':'regression_l1', 'n_jobs':-1}\n",
    "\n",
    "lgbm_model_lag = lgb.LGBMRegressor(**params)\n",
    "lgbm_model_lag.fit(features_all_train, target_all_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7298a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_df = []\n",
    "predictions = [0]*24  # инициализируем список для хранения последних 24 предсказаний\n",
    "\n",
    "for i in range(len(features_open_test)):\n",
    "    row = features_open_test.iloc[i]\n",
    "    row_time = int(row['time'])\n",
    "\n",
    "    if row['time'] > 0:\n",
    "        row['target_lag_1'] = predictions[row_time - 1]\n",
    "    if row['time'] > 11:\n",
    "        row['target_lag_12'] = predictions[row_time - 12]\n",
    "    #if row['time'] > 22:\n",
    "    #    row['target_lag_23'] = predictions[row_time - 23]\n",
    "\n",
    "    prediction = lgbm_model_lag.predict(row.values.reshape(1, -1))[0]\n",
    "    predict_test_df.append(prediction)\n",
    "    \n",
    "    # обновляем список предсказаний\n",
    "    predictions[row_time] = prediction\n",
    "\n",
    "predict_train_df = []\n",
    "predictions = [0]*24  # инициализируем список для хранения последних 24 предсказаний\n",
    "\n",
    "for i in range(len(features_all_train)):\n",
    "    row = features_all_train.iloc[i]\n",
    "    row_time = int(row['time'])\n",
    "    \n",
    "    if row['time'] > 0:\n",
    "        row['target_lag_1'] = predictions[row_time - 1]\n",
    "    if row['time'] > 11:\n",
    "        row['target_lag_12'] = predictions[row_time - 12]\n",
    "    #if row['time'] > 22:\n",
    "    #    row['target_lag_23'] = predictions[row_time - 23]\n",
    "\n",
    "    prediction = lgbm_model_lag.predict(row.values.reshape(1, -1))[0]\n",
    "    predict_train_df.append(prediction)\n",
    "    \n",
    "    # обновляем список предсказаний\n",
    "    predictions[row_time] = prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train,predict_train_df )\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test,predict_test_df )\n",
    "\n",
    "pd.DataFrame([['тренировочная на часе', mae_train, mape_train, r2_train], ['тестовая', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка на часе', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcd93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mae day = {mae_day(target_open_test,predict_test_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf71f5",
   "metadata": {},
   "source": [
    "#### 2.4 График важности признаков\n",
    "Визуализируем значение feature_importances_ модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ad33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График важности признаков\n",
    "\n",
    "tmp_feature_cols = feature_cols.copy()\n",
    "tmp_feature_cols.remove('date')\n",
    "tmp_feature_cols.remove('target_lag_1')\n",
    "feature_importances = pd.DataFrame([tmp_feature_cols, lgbm_model_all_train.feature_importances_]).T.sort_values(by = 1)\n",
    "feature_importances.plot(kind='barh', x=0, y=1, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "lgbm_model_all_train.booster_.save_model('lgbm_model_pred.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_open_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a5de4",
   "metadata": {},
   "source": [
    "### Optuna search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793da1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a0c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves':15, 'learning_rate':0.02, 'feature_fraction':0.98, \n",
    "'num_iterations':10000, 'random_state':random_state, 'objective':'regression_l1', 'n_jobs':-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfacea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = feature_lgbm, target_all_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816aca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 3, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01,  0.1),\n",
    "        'objective': trial.suggest_categorical('objective', ['regression_l1', 'regression_l2']),\n",
    "        'random_state':random_state,\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'n_jobs': 10,\n",
    "        'num_iterations':10000      \n",
    "                }\n",
    "    \n",
    "    model = LGBMRegressor( **params)\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    scores = []\n",
    "    for train_index, valid_index in tqdm(tscv.split(X_train), total=3):\n",
    "        X_train_fold, X_valid_fold = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "        y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        \n",
    "        score = mean_absolute_error(y_valid_fold, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34702e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5dd009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {'num_leaves': 34, 'min_child_samples': 16, \n",
    "          'max_depth': 8, 'learning_rate': 0.01206843641003463, \n",
    "          'objective': 'regression_l1', 'feature_fraction': 0.9574152630927155,\n",
    "          'n_jobs':-1, 'num_iterations':10000\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63313fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "study= [FrozenTrial(number=73, state=1, values=[9.761631678943006],\n",
    " datetime_start=datetime.datetime(2023, 11, 2, 21, 58, 0, 233317), \n",
    " datetime_complete=datetime.datetime(2023, 11, 2, 22, 5, 15, 146635), \n",
    " params={'num_leaves': 34, 'min_child_samples': 16, 'max_depth': 8, \n",
    " 'learning_rate': 0.01206843641003463, 'objective': 'regression_l1', \n",
    " 'feature_fraction': 0.9574152630927155}, user_attrs={}, system_attrs={},\n",
    "  intermediate_values={}, distributions={'num_leaves': IntDistribution(high=256, log=False, low=2, step=1), \n",
    "  'min_child_samples': IntDistribution(high=200, log=False, low=3, step=1),\n",
    "   'max_depth': IntDistribution(high=8, log=False, low=3, step=1), \n",
    "   'learning_rate': FloatDistribution(high=0.1, log=True, low=0.01, step=None),\n",
    "    'objective': CategoricalDistribution(choices=('regression_l1', 'regression_l2')),\n",
    "     'feature_fraction': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=73, value=None)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor( **params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = model.predict(feature_lgbm)\n",
    "predict_test = model.predict(feature_lgbm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_train, mape_train, r2_train = metrics_hour(target_all_train,predict_train )\n",
    "mae_open_test, mape_open_test, r2_open_test = metrics_hour(target_open_test,predict_test )\n",
    "\n",
    "pd.DataFrame([['тренировочная на часе', mae_train, mape_train, r2_train], ['тестовая', mae_open_test, mape_open_test, r2_open_test]], \n",
    "             columns=('Выборка на часе', 'MAE', 'MAPE', 'R2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13491670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
