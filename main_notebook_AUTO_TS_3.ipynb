{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5606014",
   "metadata": {},
   "source": [
    "## Энергетический оракул\n",
    "Ноутбук команды #12\n",
    "\n",
    "Работа выполнена на основе модели LightGBM\n",
    "\n",
    "\n",
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4351135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_preprocess import DataTransformer\n",
    "random_state = 12345\n",
    "NUM_ITERATIONS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5eb669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления метрики mae по дням из почасовых массивов данных\n",
    "\n",
    "def mae_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    return mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "# Функция для вычисления метрик по дням из почасовых массивов данных\n",
    "\n",
    "def metrics_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    mae = mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "    mape = mean_absolute_percentage_error(y_true_grouped, y_pred_grouped)\n",
    "    r2 = r2_score(y_true_grouped, y_pred_grouped)\n",
    "    return mae, mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808c109",
   "metadata": {},
   "source": [
    "#### 1.5 Чтение файлов с данными\n",
    "Данные объединяются в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a9902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "transformer = DataTransformer() #инициализируем трансформер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ced4dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начало открытого теста: 2023-04-01 00:00:00     конец открытого теста: 2023-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "all_ds, test_begin, test_end = transformer.open_file() #оставляем поле пустым что бы использовать открытый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3340c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40152, 7)\n"
     ]
    }
   ],
   "source": [
    "print(all_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "563ce304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date:  0\n",
      "fill_weather_columns:  0\n",
      "размер DS (40152, 13) дубликатов -  0\n",
      "размер DS (43008, 15) дубликатов -  2856\n",
      "размер DS (43008, 15) дубликатов -  2856\n",
      "размер DS (43008, 15) дубликатов -  2856\n",
      "holydays:  5712\n",
      "create_lags:  168\n",
      "VVP:  168\n",
      "true weather:  168\n"
     ]
    }
   ],
   "source": [
    "all_ds = transformer.transform(all_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38179a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = all_ds.duplicated()\n",
    "\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc76ee",
   "metadata": {},
   "source": [
    "#### 1.10 Демонстрация сформированного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итоговый набор колонок\n",
    "all_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ds[duplicates].sort_values(['date','time']).tail(56)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69383cb",
   "metadata": {},
   "source": [
    "#### 1.11 Исключение лишних колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем признаки. Все лишние колонки здесь отбрасываем, кроме 'date', которую уберем позже \n",
    "\n",
    "feature_cols = list(all_ds.columns)\n",
    "\n",
    "# выбрасываем взгляд в прошлое и расшифрованную погоду\n",
    "drop_list = ['target', 'weather_pred', 'weather_fact', 'temp']\n",
    "\n",
    "# выбрасываем признаки, найденные процедурно в процессе оптимизации\n",
    "# КОМАНДЕ: здесь можно добавлять признаки на выброс с целью оптимизации\n",
    "drop_list = drop_list + ['target_lag_48', 'target_lag_168', 'target_lag_336',\n",
    "                        'target_lag_24', 'windy', 'clear',\n",
    "                        'target_lag_72','has_rain_probability', #'temp_last_day',\n",
    "                        'N', 'S', 'W', 'E', 'P','U', 'WW', 'Td', 'preholidays',  'cloudy',\n",
    " 'rainy',\n",
    " 'rain_probability','temp_pred', 'holidays', 'VVP'] \n",
    "\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)\n",
    "\n",
    "# Итоговый список признаков\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f34c90",
   "metadata": {},
   "source": [
    "#### 1.12 Выделение наборов данных для обучения, валидации и тестирования\n",
    "\n",
    "Выделялось два набора данных для обучения и валидации:\n",
    "1. Обучение на данных с 2019 по 2021 с валидацией на 2022\n",
    "2. Обучение на данных с 2019 по 2022 с валидацией на первом квартале 2023\n",
    "\n",
    "Первый набор позволяет оценить влияние сезонности на обучение и предсказания, второй позволяет обучить модель на большем объеме данных и на более актуальных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем набор датасетов для обучения и проверки\n",
    "\n",
    "features = all_ds[feature_cols]\n",
    "target = all_ds['target']\n",
    "\n",
    "# Функция для выделения временных интервалов из таблиц признаков и целей\n",
    "# на этом этапе отбрасываем колонку 'date'\n",
    "def features_interval(features, target, date1, date2):\n",
    "    \n",
    "    features_interval = features[ (features['date']>=date1) & (features['date']<date2) ]\n",
    "    target_interval = target[features_interval.index]\n",
    "    \n",
    "\n",
    "    features_interval.loc[:, 'date'] = pd.to_datetime(features_interval['date'])\n",
    "\n",
    "    # Преобразование столбца 'time' в timedelta\n",
    "    features_interval.loc[:, 'time'] = pd.to_timedelta(features_interval['time'], unit='h')\n",
    "\n",
    "    # Создание нового столбца 'datetime', объединяющего 'date' и 'time'\n",
    "    features_interval.loc[:, 'datetime'] = features_interval['date'] + features_interval['time']\n",
    "\n",
    "    # Установка столбца 'datetime' в качестве индекса\n",
    "    features_interval.set_index('datetime', inplace=True)\n",
    "\n",
    "    features_interval = features_interval.drop('date', axis=1)\n",
    "    features_interval = features_interval.drop('time', axis=1)\n",
    "    target_interval.index = features_interval.index\n",
    "\n",
    "    return features_interval, target_interval\n",
    "\n",
    "\n",
    "# для проверки на тестовой выборке будем учиться на всем тренировочном датасете\n",
    "features_all_train, target_all_train = features_interval(features, target, '2019-01-01', test_begin)\n",
    "features_open_test, target_open_test = features_interval(features, target, test_begin, test_end )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_f = features_all_train.index.duplicated()\n",
    "\n",
    "duplicates_f.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicates_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b537cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_train[duplicates_f].sort_values('datetime').head(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08709d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_open_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da3e16",
   "metadata": {},
   "source": [
    "## AUTO TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autots import AutoTS, load_daily, load_hourly, load_live_daily, create_regressor\n",
    "from autots.models.model_list import model_lists\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.core.module import LightningModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd48ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian = holidays.RU()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64dbe7",
   "metadata": {},
   "source": [
    "from sklearn.metrics import pairwise\n",
    "#import neuralprophet\n",
    "import scipy\n",
    "from arch import arch_model\n",
    "import pytorch_forecasting \n",
    "from neuralprophet import NeuralProphet\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gluonts.model\n",
    "from prophet import Prophet\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5cf018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_lists.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f4e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_autots = pd.concat([target_all_train, features_all_train ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_autots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df_train_autots.index.duplicated()\n",
    "\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_autots = pd.concat([target_open_test, features_open_test ], axis=1)\n",
    "df_test_autots.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config\n",
    "forecast_length=24\n",
    "frequency='infer'\n",
    "drop_most_recent=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f46458",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_train, regr_fcst = create_regressor(\n",
    "    df_train_autots,\n",
    "    forecast_length=forecast_length,\n",
    "    frequency=frequency,\n",
    "    drop_most_recent=drop_most_recent,\n",
    "   # scale=True,\n",
    "   # summarize=\"auto\",\n",
    "   # backfill=\"bfill\",\n",
    "   # fill_na=\"spline\",\n",
    "    #holiday_countries=\"RU\",  # requires holidays package\n",
    "    #encode_holiday_type=True,\n",
    "    # datepart_method=\"simple_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8dc052",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_weighting = {\n",
    "    'mae_weighting': 5,\n",
    "    'mape_weighting': 3,\n",
    "    'rmse_weighting': 2,\n",
    "#    'made_weighting': 0.5,\n",
    "#    'mage_weighting': 1,\n",
    "#    'mle_weighting': 0,\n",
    "    'imle_weighting': 0,\n",
    "#    'spl_weighting': 3,\n",
    "    'containment_weighting': 0,\n",
    "    'contour_weighting': 1,\n",
    "    'runtime_weighting': 0.05,\n",
    "}\n",
    "model = AutoTS(\n",
    "    forecast_length=forecast_length,\n",
    "    frequency='infer',\n",
    "    prediction_interval=0.95,\n",
    "    ensemble='simple',\n",
    "    model_list=\"regressor\", #model_list_2,  \"superfast\", \"default\", \"fast_parallel\", 'fast'\n",
    "    transformer_list=\"fast\",  # \"superfast\",\n",
    "    metric_weighting=metric_weighting,\n",
    "    drop_most_recent=0,\n",
    "    max_generations=1,\n",
    "    n_jobs='auto',\n",
    "    num_validations=0,\n",
    "    validation_method=\"backwards\",\n",
    "    verbose=1,\n",
    "    #holiday_country = \"RU\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = model.import_template('AutoTS_best_models_n7.csv', method='only',  include_ensemble=True) # method='add on'\n",
    "print(\"Overwrite template is: {}\".format(str(model.initial_template)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae761aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = model.fit(\n",
    "    df_train_autots,\n",
    "    weights={'target': 20}, future_regressor=regr_train\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f327e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#joblib.dump(model, 'Autots_best_model_1.pkl')\n",
    "#model = joblib.load('Autots_regr_temp_target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bf7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ts_model = \"AutoTS_best_models_n7.csv\"  # .csv/.json\n",
    "model.export_template(auto_ts_model, models='best',\n",
    "                      n=7, max_per_model_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict()\n",
    "# plot a sample\n",
    "prediction.plot(model.df_wide_numeric,\n",
    "                series=model.df_wide_numeric.columns[0],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cee82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of all tried model results\n",
    "model_results = model.results()\n",
    "# and aggregated from cross validation\n",
    "validation_results = model.results(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results.sort_values('mae', ascending=True).head(5) #.to_csv('result_val_auto_ts_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd44049",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_validations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9241ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(forecast_length=24)\n",
    "out = prediction.forecast\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28916269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame()\n",
    "#res_df = pd.concat([res_df, out])\n",
    "df_test_autots['date'] = df_test_autots.index.date\n",
    "temp_train = df_train_autots\n",
    "for date, df in df_test_autots.groupby('date'):\n",
    "    temp_train_df = df.drop(columns='date')\n",
    "    temp_train = pd.concat([temp_train, temp_train_df])\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        model = model.fit(\n",
    "            temp_train,\n",
    "            \n",
    "            weights={'target': 20} \n",
    "        )\n",
    "        pred = model.predict()\n",
    "        out = pred.forecast\n",
    "    \n",
    "        if out['target'].isnull().sum() != 0:\n",
    "            print('Missing forecast ', date)\n",
    "        \n",
    "    except:\n",
    "        print('Did not execute ', date)\n",
    "    res_df = pd.concat([res_df, out])\n",
    "df_test_autots.drop(columns='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88505c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test_autots.shape, res_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68adaaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(df_test_autots['target'], res_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "        model = model.fit(\n",
    "            temp_train,\n",
    "            \n",
    "            weights={'target': 20} \n",
    "        )\n",
    "        pred = model.predict()\n",
    "        out = pred.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_autots.drop(columns='date')\n",
    "df_test_autots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ade17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd530523",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bfc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(model.best_model_transformation_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc8a63",
   "metadata": {},
   "source": [
    "### on new training\n",
    "model = AutoTS(forecast_length=forecast_length,\n",
    "               frequency='infer', max_generations=0,\n",
    "               num_validations=0, verbose=0)\n",
    "model = model.import_template(example_filename, method='only') # method='add on'\n",
    "print(\"Overwrite template is: {}\".format(str(model.initial_template)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рисуем графическое представление предсказания на 2022 год\n",
    "\n",
    "y_true_copy = pd.DataFrame(target_valid).reset_index(drop=True)\n",
    "y_true_copy['day'] = y_true_copy.index // 24\n",
    "y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "y_true_grouped\n",
    "y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "\n",
    "#pd.DataFrame(date_valid)\n",
    "tmpdf = pd.DataFrame(train_ds.loc[features_valid.index,:]['date']).groupby(by='date').count().reset_index().join(y_true_grouped)\n",
    "tmpdf.plot(x='date', y='target', figsize=(18,5))\n",
    "ax=plt.gca()\n",
    "tmpdf = pd.DataFrame(train_ds.loc[features_valid.index,:]['date']).groupby(by='date').count().reset_index().join(y_pred_grouped)\n",
    "tmpdf.plot(ax=ax, x='date', y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказываем той же моделью (19-21) тренировочный кусок 2023 (первый квартал)\n",
    "mae = mae_day(target_2023, lgbm_model.predict(features_2023))\n",
    "print(f'mae = {mae}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
