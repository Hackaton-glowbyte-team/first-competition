{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e97d1d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mНе удалось запустить ядро. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/ipykernel_launcher.py\", line 15, in <module>\n",
      "\u001b[1;31m    from ipykernel import kernelapp as app\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 19, in <module>\n",
      "\u001b[1;31m    from IPython.core.application import (  # type:ignore[attr-defined]\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/IPython/__init__.py\", line 54, in <module>\n",
      "\u001b[1;31m    from .terminal.embed import embed\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/IPython/terminal/embed.py\", line 15, in <module>\n",
      "\u001b[1;31m    from IPython.core.interactiveshell import DummyMod, InteractiveShell\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 73, in <module>\n",
      "\u001b[1;31m    from IPython.core.history import HistoryManager\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/IPython/core/history.py\", line 11, in <module>\n",
      "\u001b[1;31m    import sqlite3\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/sqlite3/__init__.py\", line 57, in <module>\n",
      "\u001b[1;31m    from sqlite3.dbapi2 import *\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/sqlite3/dbapi2.py\", line 27, in <module>\n",
      "\u001b[1;31m    from _sqlite3 import *\n",
      "\u001b[1;31mImportError: dlopen(/opt/anaconda3/envs/p311/lib/python3.11/lib-dynload/_sqlite3.cpython-311-darwin.so, 0x0002): Symbol not found: _sqlite3_enable_load_extension\n",
      "\u001b[1;31m  Referenced from: <48908431-D963-32A7-A3B8-A9EF727C6C75> /opt/anaconda3/envs/p311/lib/python3.11/lib-dynload/_sqlite3.cpython-311-darwin.so\n",
      "\u001b[1;31m  Expected in:     <C077C127-D692-3836-B28D-BA51860A6839> /usr/lib/libsqlite3.dylib. \n",
      "\u001b[1;31mПодробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4351135",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mНе удалось запустить ядро. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/ipykernel_launcher.py\", line 15, in <module>\n",
      "\u001b[1;31m    from ipykernel import kernelapp as app\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 19, in <module>\n",
      "\u001b[1;31m    from IPython.core.application import (  # type:ignore[attr-defined]\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/IPython/__init__.py\", line 54, in <module>\n",
      "\u001b[1;31m    from .terminal.embed import embed\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/IPython/terminal/embed.py\", line 15, in <module>\n",
      "\u001b[1;31m    from IPython.core.interactiveshell import DummyMod, InteractiveShell\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 73, in <module>\n",
      "\u001b[1;31m    from IPython.core.history import HistoryManager\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/site-packages/IPython/core/history.py\", line 11, in <module>\n",
      "\u001b[1;31m    import sqlite3\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/sqlite3/__init__.py\", line 57, in <module>\n",
      "\u001b[1;31m    from sqlite3.dbapi2 import *\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/p311/lib/python3.11/sqlite3/dbapi2.py\", line 27, in <module>\n",
      "\u001b[1;31m    from _sqlite3 import *\n",
      "\u001b[1;31mImportError: dlopen(/opt/anaconda3/envs/p311/lib/python3.11/lib-dynload/_sqlite3.cpython-311-darwin.so, 0x0002): Symbol not found: _sqlite3_enable_load_extension\n",
      "\u001b[1;31m  Referenced from: <48908431-D963-32A7-A3B8-A9EF727C6C75> /opt/anaconda3/envs/p311/lib/python3.11/lib-dynload/_sqlite3.cpython-311-darwin.so\n",
      "\u001b[1;31m  Expected in:     <C077C127-D692-3836-B28D-BA51860A6839> /usr/lib/libsqlite3.dylib. \n",
      "\u001b[1;31mПодробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_state = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pd.read_csv('data/train_dataset.csv')\n",
    "train_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16090ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds['date'] = pd.to_datetime(train_ds['date'])\n",
    "train_ds['year'] = train_ds['date'].dt.year\n",
    "train_ds['month'] = train_ds['date'].dt.year\n",
    "train_ds['day_of_week'] = train_ds['date'].dt.month\n",
    "train_ds['day'] = train_ds['date'].dt.day\n",
    "train_ds['day_of_year'] = train_ds['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция формирует колонки 'cloudy', 'rainy', 'windy', 'clear', 'some_number'\n",
    "# в колонках число, которое 0 при отсутсвии упоминания явления в weather_pred или степень упоминания\n",
    "# функция дает в колонках номер первого списка, элемент которого есть в строке плюс 1\n",
    "# списки cloudy_list, rainy_list, windy_list, clear_list можно модифицировать\n",
    "# соответственно, можно экспериментировать с расположением значений в списках\n",
    "# например, сейчас 'дождь', 'снег', 'д+сн' - первая степень  дождя, а 'гроз', 'ливень' - вторая\n",
    "# а можно сделать снег второй, а грозу с ливнем убрать в третью\n",
    "# также сделал отдельный список для \"ясности\", чтобы выделить 'ясно' и 'солнечно'\n",
    "\n",
    "def in_what_list(weather, big_list):\n",
    "    for list_number, small_list in enumerate(big_list):\n",
    "        if any(word in weather for word in small_list):\n",
    "            return list_number+1\n",
    "    return 0\n",
    "\n",
    "def weather_split2(row):\n",
    "    weather = row['weather_pred']\n",
    "    cloudy_list = [['проясн', 'пер.об.', 'п/об'], ['пасм', 'обл']]\n",
    "    rainy_list = [['дождь', 'снег', 'д+сн'], ['гроз', 'ливень']]\n",
    "    windy_list = [['вет'],['штор']]\n",
    "    clear_list = [['проясн'], ['ясно'], ['солнеч']]\n",
    "    numbers = re.findall(r'\\d+', weather)\n",
    "    cloudy = in_what_list(weather, cloudy_list)\n",
    "    rainy = in_what_list(weather, rainy_list)\n",
    "    windy = in_what_list(weather, windy_list)\n",
    "    clear = in_what_list(weather, clear_list)\n",
    "    rain_probability = 0 if len(numbers)==0 else int(numbers[0])\n",
    "    has_rain_probability = int(len(numbers)==0)\n",
    "    return cloudy, rainy, windy, clear, rain_probability, has_rain_probability\n",
    "\n",
    "def fill_weather_columns(df):\n",
    "    df['weather_pred'] = df['weather_pred'].fillna('')\n",
    "    df['cloudy'], df['rainy'], df['windy'], df['clear'], df['rain_probability'], df['has_rain_probability'] = \\\n",
    "                zip(*df.apply(weather_split2, axis=1))\n",
    "    return df\n",
    "\n",
    "train_ds = fill_weather_columns(train_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338f929",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tmpds[(tmpds['cloudy']==0) & (tmpds['clear']==0) & (tmpds['rainy']==0)]['weather_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = list(train_ds.columns)\n",
    "drop_list = ['target', 'date', 'day_of_year', 'weather_pred', 'weather_fact', 'temp']\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)\n",
    "\n",
    "features = train_ds[feature_cols]\n",
    "target = train_ds['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features[features['year']<2023]\n",
    "target_train = target[features_train.index]\n",
    "features_valid = features[features['year']==2023]\n",
    "target_valid = target[features_valid.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features[features['year']<2022]\n",
    "target_train = target[features_train.index]\n",
    "features_valid = features[features['year']==2022]\n",
    "target_valid = target[features_valid.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8985f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    return mean_absolute_error(y_true_grouped, y_pred_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbcff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс предлагается инициализировать, затем брать значения параметра из current_value \n",
    "# и регистрировать значения метрики методом add_metric_value, пока add_metric_value не вернет True\n",
    "\n",
    "# параметры инициализации: \n",
    "# initial_values - начальный вектор значений параметра, может быть любой длины\n",
    "# stop_relation - целевое отношение соседних значений параметра для остановки поиска\n",
    "# step_method - способ формирования трех точек для первой параболы дугой вниз\n",
    "# step_method = 'geometric' - делим или умножаем значение с минимальной метрикой на geometric_step\n",
    "# step_method = 'dichotomy' - делим интервал с минимальной метрикой на границах пополам\n",
    "# step_method = 'geometric_dichotomy' - делим интервал с минимальной метрикой на границах средним геометрическим\n",
    "\n",
    "class one_parameter_parabolic_optimizer:\n",
    "    def __init__(self, initial_values, stop_relation=1.1, step_method='nothing', geometric_step=2):      \n",
    "        self.data = pd.DataFrame(columns=('parameter','metric','x2','x','1'), dtype='float')\n",
    "        self.parabolic_mode = False\n",
    "        self.parabolic_error = False\n",
    "        self.stop_relation_log = np.log(stop_relation)\n",
    "        self.initial_values = initial_values            \n",
    "        self.step_method = step_method                              \n",
    "        self.geometric_step = geometric_step\n",
    "        self.initial_counter = 0\n",
    "        self.current_value = self.initial_values[0]\n",
    "        \n",
    "    def best_value(self):\n",
    "        return self.data.loc[self.data['metric'].idxmin(), 'parameter']\n",
    "    \n",
    "# строим параболу через точку с минимальной метрикой и две соседние и ищем ее минимум\n",
    "    def next_parabolic(self):                      \n",
    "        self.data['x2'] = self.data['parameter']**2\n",
    "        self.data['x'] = self.data['parameter']\n",
    "        self.data['1'] = 1\n",
    "        self.data = self.data.astype(float).sort_values(by='parameter', ascending=True).reset_index(drop=True)\n",
    "        index_min = self.data['metric'].idxmin()\n",
    "        matrix = self.data[['x2','x','1']][index_min-1:index_min+2]\n",
    "        y = self.data['metric'][index_min-1:index_min+2]\n",
    "        vector_abc = np.linalg.inv(matrix) @ y\n",
    "        return -vector_abc[1]/vector_abc[0]/2\n",
    "\n",
    "    def next_geometric(self):\n",
    "        index_min = self.data['metric'].idxmin()\n",
    "        if index_min==0:\n",
    "            return self.data.loc[index_min, 'parameter']/self.geometric_step\n",
    "        else:\n",
    "            return self.data.loc[index_min, 'parameter']*self.geometric_step\n",
    "        \n",
    "    def next_dichotomy(self):\n",
    "        index_min = self.data['metric'].idxmin()\n",
    "        if index_min==0:\n",
    "            return (self.data.loc[index_min, 'parameter'] + self.data.loc[index_min+1, 'parameter'])/2\n",
    "        else:\n",
    "            return (self.data.loc[index_min, 'parameter'] + self.data.loc[index_min-1, 'parameter'])/2\n",
    "        \n",
    "    def next_geometric_dichotomy(self):\n",
    "        index_min = self.data['metric'].idxmin()\n",
    "        if index_min==0:\n",
    "            return (self.data.loc[index_min, 'parameter'] * self.data.loc[index_min+1, 'parameter'])**0.5\n",
    "        else:\n",
    "            return (self.data.loc[index_min, 'parameter'] * self.data.loc[index_min-1, 'parameter'])**0.5\n",
    "    \n",
    "    def add_metric_value(self, metric_value):\n",
    "        if self.parabolic_error:           # записана ошибка, выход\n",
    "                return True\n",
    "        self.data.loc[self.data.shape[0]] = [self.current_value, metric_value, 0, 0, 0]   # новое значение в таблицу\n",
    "        if self.initial_counter+1 < len(self.initial_values) :              # если начальные значения не закончились,\n",
    "            self.initial_counter+=1                                         # то считаем метрику в них\n",
    "            self.current_value = self.initial_values[self.initial_counter]\n",
    "            return False\n",
    "        self.data = self.data.astype(float).sort_values(by='parameter', ascending=True).reset_index(drop=True)\n",
    "        index_min = self.data['metric'].idxmin()         # ищем минимальную метрику\n",
    "        parabolic_ready = (index_min!=0) and (index_min!=self.data.shape[0]-1)      # и выясняем, на краю ли она таблицы\n",
    "        if parabolic_ready:\n",
    "            self.parabolic_mode = True                               # если не на краю, дальше считаем параболой                  \n",
    "            self.current_value = self.next_parabolic()\n",
    "            loglog = abs(np.array([np.log(self.data.loc[index_min-1,'parameter'])-np.log(self.data.loc[index_min,'parameter']),\n",
    "                              np.log(self.data.loc[index_min+1,'parameter']) -np.log(self.data.loc[index_min,'parameter'])]))            \n",
    "            return loglog.min() < self.stop_relation_log   # пока не выполним критерий\n",
    "        elif self.parabolic_mode:    # если уже была парабола, а теперь не получается, то пишем ошибку: метод расходится\n",
    "            return True\n",
    "        elif self.step_method == 'geometric': # если еще нет точек для параболы и задана геометрическая прогрессия\n",
    "            self.current_value = self.next_geometric()\n",
    "            return False\n",
    "        elif self.step_method == 'dichotomy': # если еще нет точек для параболы и задана дихотомия \n",
    "            self.current_value = self.next_dichotomy()\n",
    "            return False\n",
    "        elif self.step_method == 'geometric_dichotomy': # если еще нет точек для параболы и задана geometric_dichotomy \n",
    "            self.current_value = self.next_geometric_dichotomy()\n",
    "            return False\n",
    "        else: # если еще нет точек для параболы и метод поиска не задан, завершаем\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67b03b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "optimizer = one_parameter_parabolic_optimizer([0.1], 1.03, step_method='geometric')\n",
    "for i in range(10):\n",
    "    learning_rate = optimizer.current_value\n",
    "    lgbm_model = lgb.LGBMRegressor(num_leaves=15, learning_rate=learning_rate, num_iterations=5000, random_state=random_state)\n",
    "    lgbm_model.fit(features_train, target_train)\n",
    "    mae = mae_day(target_valid, lgbm_model.predict(features_valid))\n",
    "    print(f'learning rate = {learning_rate:.5f} mae = {mae:.1f}')\n",
    "    if optimizer.add_metric_value(mae):\n",
    "        break\n",
    "best_learning_rate_1000 = optimizer.best_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "optimizer = one_parameter_parabolic_optimizer([0.2, 1], 1.03, step_method='dichotomy')\n",
    "for i in range(10):\n",
    "    feature_fraction = optimizer.current_value\n",
    "    lgbm_model = lgb.LGBMRegressor(num_leaves=15, learning_rate=best_learning_rate_1000,  \n",
    "                               num_iterations=5000, \n",
    "                               feature_fraction=feature_fraction, random_state=random_state)\n",
    "    lgbm_model.fit(features_train, target_train)\n",
    "    rmse = mae_day(target_valid, lgbm_model.predict(features_valid))\n",
    "    print(f'feature_fraction = {feature_fraction:.5f} rmse = {rmse:.1f}')\n",
    "    if optimizer.add_metric_value(rmse):\n",
    "        break\n",
    "best_feature_fraction = optimizer.best_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = lgb.LGBMRegressor(num_leaves=15, learning_rate=best_learning_rate_1000, num_iterations=1000, \n",
    "                               feature_fraction=best_feature_fraction, random_state=random_state)\n",
    "lgbm_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_model.predict(features_valid)\n",
    "mae = mae_day(target_valid, y_pred)\n",
    "print(mae)\n",
    "mean_absolute_error(target_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_copy = pd.DataFrame(target_valid).reset_index(drop=True)\n",
    "y_true_copy['day'] = y_true_copy.index // 24\n",
    "y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "y_true_grouped\n",
    "y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "y_pred_grouped = y_pred_copy.groupby(by='day').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccde5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_grouped.plot(figsize=(18,5))\n",
    "ax=plt.gca()\n",
    "y_pred_grouped.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_grouped['target'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba84f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame([feature_cols, lgbm_model.feature_importances_]).T.sort_values(by = 1)\n",
    "#feature_importances.plot(kind='bar')\n",
    "feature_importances.plot(kind='barh', x=0, y=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
