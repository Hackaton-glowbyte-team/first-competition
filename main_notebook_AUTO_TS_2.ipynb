{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5606014",
   "metadata": {},
   "source": [
    "## Энергетический оракул\n",
    "Ноутбук команды #12\n",
    "\n",
    "Работа выполнена на основе модели LightGBM\n",
    "\n",
    "\n",
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4351135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_preprocess import DataTransformer\n",
    "random_state = 12345\n",
    "NUM_ITERATIONS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5eb669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления метрики mae по дням из почасовых массивов данных\n",
    "\n",
    "def mae_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    return mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "# Функция для вычисления метрик по дням из почасовых массивов данных\n",
    "\n",
    "def metrics_day(y_true, y_pred):\n",
    "    y_true_copy = pd.DataFrame(y_true).reset_index(drop=True)\n",
    "    y_true_copy['day'] = y_true_copy.index // 24\n",
    "    y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "    y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "    y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "    y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "    \n",
    "    mae = mean_absolute_error(y_true_grouped, y_pred_grouped)\n",
    "    mape = mean_absolute_percentage_error(y_true_grouped, y_pred_grouped)\n",
    "    r2 = r2_score(y_true_grouped, y_pred_grouped)\n",
    "    return mae, mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808c109",
   "metadata": {},
   "source": [
    "#### 1.5 Чтение файлов с данными\n",
    "Данные объединяются в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a9902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "transformer = DataTransformer() #инициализируем трансформер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ced4dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начало открытого теста: 2023-04-01 00:00:00     конец открытого теста: 2023-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "all_ds, test_begin, test_end = transformer.open_file() #оставляем поле пустым что бы использовать открытый датасет\n",
    "\n",
    "all_ds = transformer.transform(all_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc76ee",
   "metadata": {},
   "source": [
    "#### 1.10 Демонстрация сформированного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a939b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'time', 'target', 'temp', 'temp_pred', 'weather_pred',\n",
       "       'weather_fact', 'cloudy', 'rainy', 'windy', 'clear', 'rain_probability',\n",
       "       'has_rain_probability', 'holidays', 'preholidays', 'temp_last_day',\n",
       "       'target_lag_24', 'target_lag_48', 'target_lag_72', 'target_lag_168',\n",
       "       'target_lag_336', 'VVP', 'P', 'U', 'WW', 'Td', 'N', 'S', 'W', 'E'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Итоговый набор колонок\n",
    "all_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f51e77ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>target</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_pred</th>\n",
       "      <th>weather_pred</th>\n",
       "      <th>weather_fact</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>rainy</th>\n",
       "      <th>windy</th>\n",
       "      <th>...</th>\n",
       "      <th>target_lag_336</th>\n",
       "      <th>VVP</th>\n",
       "      <th>P</th>\n",
       "      <th>U</th>\n",
       "      <th>WW</th>\n",
       "      <th>Td</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>W</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>481.510</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>763.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>462.872</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>764.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>449.718</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>765.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>430.908</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>765.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>415.163</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>пасм, ветер</td>\n",
       "      <td>ветер, пасм</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>766.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  time   target  temp  temp_pred weather_pred weather_fact  \\\n",
       "0 2019-01-01     0  481.510   2.9        2.0  пасм, ветер        ветер   \n",
       "1 2019-01-01     1  462.872   2.9        2.0  пасм, ветер        ветер   \n",
       "2 2019-01-01     2  449.718   2.9        2.0  пасм, ветер        ветер   \n",
       "3 2019-01-01     3  430.908   4.3        2.0  пасм, ветер  ветер, пасм   \n",
       "4 2019-01-01     4  415.163   4.3        2.0  пасм, ветер  ветер, пасм   \n",
       "\n",
       "   cloudy  rainy  windy  ...  target_lag_336  VVP      P      U   WW   Td  \\\n",
       "0       2      0      1  ...             0.0  1.8  763.5  100.0  1.0  2.0   \n",
       "1       2      0      1  ...             0.0  1.8  764.3   93.0  1.0  1.0   \n",
       "2       2      0      1  ...             0.0  1.8  765.0   93.0  0.0  2.0   \n",
       "3       2      0      1  ...             0.0  1.8  765.8   87.0  0.0  1.0   \n",
       "4       2      0      1  ...             0.0  1.8  766.6   87.0  0.0  1.0   \n",
       "\n",
       "     N    S    W    E  \n",
       "0  1.0  0.0  0.0  0.0  \n",
       "1  1.0  0.0  0.0  0.0  \n",
       "2  1.0  0.0  0.0  0.0  \n",
       "3  1.0  0.0  0.0  0.0  \n",
       "4  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69383cb",
   "metadata": {},
   "source": [
    "#### 1.11 Исключение лишних колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d6619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date', 'time', 'temp_last_day']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отбираем признаки. Все лишние колонки здесь отбрасываем, кроме 'date', которую уберем позже \n",
    "\n",
    "feature_cols = list(all_ds.columns)\n",
    "\n",
    "# выбрасываем взгляд в прошлое и расшифрованную погоду\n",
    "drop_list = ['target', 'weather_pred', 'weather_fact', 'temp']\n",
    "\n",
    "# выбрасываем признаки, найденные процедурно в процессе оптимизации\n",
    "# КОМАНДЕ: здесь можно добавлять признаки на выброс с целью оптимизации\n",
    "drop_list = drop_list + ['target_lag_48', 'target_lag_168', 'target_lag_336',\n",
    "                        'target_lag_24', 'windy', 'clear',\n",
    "                        'target_lag_72','has_rain_probability', #'temp_last_day',\n",
    "                        'N', 'S', 'W', 'E', 'P','U', 'WW', 'Td', 'preholidays',  'cloudy',\n",
    " 'rainy',\n",
    " 'rain_probability','temp_pred', 'holidays', 'VVP'] \n",
    "\n",
    "for name in drop_list:\n",
    "    feature_cols.remove(name)\n",
    "\n",
    "# Итоговый список признаков\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f34c90",
   "metadata": {},
   "source": [
    "#### 1.12 Выделение наборов данных для обучения, валидации и тестирования\n",
    "\n",
    "Выделялось два набора данных для обучения и валидации:\n",
    "1. Обучение на данных с 2019 по 2021 с валидацией на 2022\n",
    "2. Обучение на данных с 2019 по 2022 с валидацией на первом квартале 2023\n",
    "\n",
    "Первый набор позволяет оценить влияние сезонности на обучение и предсказания, второй позволяет обучить модель на большем объеме данных и на более актуальных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2b8078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_4352/3202848139.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_interval.loc[:, 'date'] = pd.to_datetime(features_interval['date'])\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_4352/3202848139.py:14: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  features_interval.loc[:, 'date'] = pd.to_datetime(features_interval['date'])\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_4352/3202848139.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_interval.loc[:, 'time'] = pd.to_timedelta(features_interval['time'], unit='h')\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_4352/3202848139.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_interval.loc[:, 'datetime'] = features_interval['date'] + features_interval['time']\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_4352/3202848139.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_interval.loc[:, 'date'] = pd.to_datetime(features_interval['date'])\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_4352/3202848139.py:14: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  features_interval.loc[:, 'date'] = pd.to_datetime(features_interval['date'])\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_4352/3202848139.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_interval.loc[:, 'time'] = pd.to_timedelta(features_interval['time'], unit='h')\n",
      "/var/folders/4y/zccbjjq17fgd73999h5g3ltr0000gn/T/ipykernel_4352/3202848139.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_interval.loc[:, 'datetime'] = features_interval['date'] + features_interval['time']\n"
     ]
    }
   ],
   "source": [
    "# Формируем набор датасетов для обучения и проверки\n",
    "\n",
    "features = all_ds[feature_cols]\n",
    "target = all_ds['target']\n",
    "\n",
    "# Функция для выделения временных интервалов из таблиц признаков и целей\n",
    "# на этом этапе отбрасываем колонку 'date'\n",
    "def features_interval(features, target, date1, date2):\n",
    "    \n",
    "    features_interval = features[ (features['date']>=date1) & (features['date']<date2) ]\n",
    "    target_interval = target[features_interval.index]\n",
    "    \n",
    "\n",
    "    features_interval.loc[:, 'date'] = pd.to_datetime(features_interval['date'])\n",
    "\n",
    "    # Преобразование столбца 'time' в timedelta\n",
    "    features_interval.loc[:, 'time'] = pd.to_timedelta(features_interval['time'], unit='h')\n",
    "\n",
    "    # Создание нового столбца 'datetime', объединяющего 'date' и 'time'\n",
    "    features_interval.loc[:, 'datetime'] = features_interval['date'] + features_interval['time']\n",
    "\n",
    "    # Установка столбца 'datetime' в качестве индекса\n",
    "    features_interval.set_index('datetime', inplace=True)\n",
    "\n",
    "    features_interval = features_interval.drop('date', axis=1)\n",
    "    features_interval = features_interval.drop('time', axis=1)\n",
    "    target_interval.index = features_interval.index\n",
    "\n",
    "    return features_interval, target_interval\n",
    "\n",
    "\n",
    "# для проверки на тестовой выборке будем учиться на всем тренировочном датасете\n",
    "features_all_train, target_all_train = features_interval(features, target, '2019-01-01', test_begin)\n",
    "features_open_test, target_open_test = features_interval(features, target, test_begin, test_end )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "899b3f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_last_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temp_last_day\n",
       "datetime                          \n",
       "2019-01-01 00:00:00            2.0\n",
       "2019-01-01 01:00:00            2.0\n",
       "2019-01-01 02:00:00            2.0\n",
       "2019-01-01 03:00:00            2.0\n",
       "2019-01-01 04:00:00            2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd9b35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_last_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-01 00:00:00</th>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01 01:00:00</th>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01 02:00:00</th>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01 03:00:00</th>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01 04:00:00</th>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temp_last_day\n",
       "datetime                          \n",
       "2023-04-01 00:00:00            7.2\n",
       "2023-04-01 01:00:00            7.2\n",
       "2023-04-01 02:00:00            7.2\n",
       "2023-04-01 03:00:00            7.9\n",
       "2023-04-01 04:00:00            7.9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_open_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da3e16",
   "metadata": {},
   "source": [
    "## AUTO TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c04d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autots import AutoTS, load_daily, load_hourly\n",
    "from autots.models.model_list import model_lists\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c8fc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.core.module import LightningModule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64dbe7",
   "metadata": {},
   "source": [
    "from sklearn.metrics import pairwise\n",
    "#import neuralprophet\n",
    "import scipy\n",
    "from arch import arch_model\n",
    "import pytorch_forecasting \n",
    "from neuralprophet import NeuralProphet\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gluonts.model\n",
    "from prophet import Prophet\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b5cf018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['all', 'default', 'fast', 'superfast', 'parallel', 'fast_parallel', 'fast_parallel_no_arima', 'probabilistic', 'multivariate', 'univariate', 'no_params', 'recombination_approved', 'no_shared', 'no_shared_fast', 'experimental', 'slow', 'gpu', 'regressor', 'best', 'motifs', 'all_result_path', 'regressions', 'all_pragmatic', 'update_fit'])\n"
     ]
    }
   ],
   "source": [
    "print(model_lists.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f4e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_autots = pd.concat([target_all_train, features_all_train ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5851a638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>temp_last_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>481.510</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>462.872</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>449.718</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>430.908</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>415.163</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      target  temp_last_day\n",
       "datetime                                   \n",
       "2019-01-01 00:00:00  481.510            2.0\n",
       "2019-01-01 01:00:00  462.872            2.0\n",
       "2019-01-01 02:00:00  449.718            2.0\n",
       "2019-01-01 03:00:00  430.908            2.0\n",
       "2019-01-01 04:00:00  415.163            2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_autots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "089c72b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>temp_last_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-01 00:00:00</th>\n",
       "      <td>479.282</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01 01:00:00</th>\n",
       "      <td>445.182</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01 02:00:00</th>\n",
       "      <td>424.225</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      target  temp_last_day\n",
       "datetime                                   \n",
       "2023-04-01 00:00:00  479.282            7.2\n",
       "2023-04-01 01:00:00  445.182            7.2\n",
       "2023-04-01 02:00:00  424.225            7.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_autots = pd.concat([target_open_test, features_open_test ], axis=1)\n",
    "df_test_autots.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c543e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ConstantNaive': 1, 'LastValueNaive': 1.5, 'AverageValueNaive': 1, 'GLS': 1, 'SeasonalNaive': 1, 'GLM': 1, 'ETS': 1, 'VAR': 0.8, 'VECM': 1, 'WindowRegression': 0.5, 'DatepartRegression': 0.8, 'UnivariateMotif': 1, 'MultivariateMotif': 0.8, 'SectionalMotif': 1, 'NVAR': 1, 'MAR': 1, 'RRVAR': 1, 'KalmanStateSpace': 1, 'MetricMotif': 1, 'Cassandra': 1, 'SeasonalityMotif': 1}\n"
     ]
    }
   ],
   "source": [
    "print(model_lists['fast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52ce092a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GLM',\n",
       " 'ARIMA',\n",
       " 'FBProphet',\n",
       " 'RollingRegression',\n",
       " 'UnobservedComponents',\n",
       " 'VECM',\n",
       " 'DynamicFactor',\n",
       " 'WindowRegression',\n",
       " 'VAR',\n",
       " 'DatepartRegression',\n",
       " 'GluonTS',\n",
       " 'UnivariateRegression',\n",
       " 'MultivariateRegression',\n",
       " 'SectionalMotif',\n",
       " 'ARDL',\n",
       " 'NeuralProphet',\n",
       " 'ARCH',\n",
       " 'Cassandra',\n",
       " 'PreprocessingRegression']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lists['regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fc2ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_2 = model_lists['fast']\n",
    "\n",
    "\n",
    "model_list_2 = ['ARIMA', 'NeuralProphet', 'DatepartRegression','FBProphet' , 'Cassandra', 'GLM'] \n",
    "model_list_2 = ['ARIMA', 'FBProphet'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf8dc052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 7 cpus for n_jobs.\n"
     ]
    }
   ],
   "source": [
    "metric_weighting = {\n",
    "    'mae_weighting': 5,\n",
    "    'mape_weighting': 3,\n",
    "    'rmse_weighting': 2,\n",
    "#    'made_weighting': 0.5,\n",
    "#    'mage_weighting': 1,\n",
    "#    'mle_weighting': 0,\n",
    "    'imle_weighting': 0,\n",
    "#    'spl_weighting': 3,\n",
    "    'containment_weighting': 0,\n",
    "    'contour_weighting': 1,\n",
    "    'runtime_weighting': 0.05,\n",
    "}\n",
    "model = AutoTS(\n",
    "    forecast_length=24,\n",
    "    frequency='infer',\n",
    "    prediction_interval=0.9,\n",
    "    ensemble='simple',\n",
    "    model_list=\"regressor\", #model_list_2,  \"superfast\", \"default\", \"fast_parallel\", 'fast'\n",
    "    transformer_list=\"fast\",  # \"superfast\",\n",
    "    metric_weighting=metric_weighting,\n",
    "    drop_most_recent=1,\n",
    "    max_generations=2,\n",
    "    n_jobs='auto',\n",
    "    num_validations=4,\n",
    "    validation_method=\"backwards\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b1aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.import_template(\n",
    "    \"auto_ts_model.csv\",\n",
    "    method=\"only\",\n",
    "    enforce_model_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd3281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrite template is:                                   ID             Model  \\\n",
      "5   ff2cc3abb24d54d70d5baf7596d16148               VAR   \n",
      "6   f8628013aa1db35c5718b8c83863954f               VAR   \n",
      "7   4406dc002d51e949515c8b95afd439f8               VAR   \n",
      "15  f38f4c1ed71845e555ee023142b8c13a  WindowRegression   \n",
      "\n",
      "                                      ModelParameters  \\\n",
      "5   {\"regression_type\": null, \"maxlags\": null, \"ic...   \n",
      "6   {\"regression_type\": null, \"maxlags\": null, \"ic...   \n",
      "7   {\"regression_type\": null, \"maxlags\": null, \"ic...   \n",
      "15  {\"window_size\": 12, \"input_dim\": \"univariate\",...   \n",
      "\n",
      "                             TransformationParameters  Ensemble  \n",
      "5   {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"...         0  \n",
      "6   {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"...         0  \n",
      "7   {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"...         0  \n",
      "15  {\"fillna\": \"mean\", \"transformations\": {\"0\": \"S...         0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Overwrite template is: {}\".format(str(model.initial_template)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a388b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Загрузка модели из файла\n",
    "model = load('Autots_regr_temp_target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae761aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = model.fit(\n",
    "    df_train_autots\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict()\n",
    "# plot a sample\n",
    "prediction.plot(model.df_wide_numeric,\n",
    "                series=model.df_wide_numeric.columns[0],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of all tried model results\n",
    "model_results = model.results()\n",
    "# and aggregated from cross validation\n",
    "validation_results = model.results(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results.sort_values('mae', ascending=True).head(5) #.to_csv('result_val_auto_ts_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd44049",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_validations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9241ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = prediction.forecast()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_autots['date'] = df_test_autots.index.date\n",
    "\n",
    "for temp_train in df_test_autots:\n",
    "    \n",
    "    #print(temp_train.head(5))\n",
    "    model = model.fit(\n",
    "    temp_train,\n",
    "    \n",
    "    weights={'target': 20} \n",
    ")\n",
    "    pred = model.predict()\n",
    "    out = pred.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_autots.drop(columns='date')\n",
    "df_test_autots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "        model = model.fit(\n",
    "            temp_train,\n",
    "            \n",
    "            weights={'target': 20} \n",
    "        )\n",
    "        pred = model.predict()\n",
    "        out = pred.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame()\n",
    "res_df = pd.concat([res_df, out])\n",
    "df_test_autots['date'] = df_test_autots.index.date\n",
    "\n",
    "for date, df in df_test_autots.groupby('date'):\n",
    "    temp_train = df.drop(columns='date')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        model = model.fit(\n",
    "            temp_train,\n",
    "            \n",
    "            weights={'target': 20} \n",
    "        )\n",
    "        pred = model.predict()\n",
    "        out = pred.forecast\n",
    "    \n",
    "        if out['target'].isnull().sum() != 0:\n",
    "            print('Missing forecast ', date)\n",
    "        \n",
    "    except:\n",
    "        print('Did not execute ', date)\n",
    "    res_df = pd.concat([res_df, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ts_model = \"auto_ts_model.csv\"  # .csv/.json\n",
    "model.export_template(auto_ts_model, models='best',\n",
    "                      n=15, max_per_model_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12441d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ts_model = \"auto_ts_model.json\"  # .csv/.json\n",
    "model.export_template(auto_ts_model, models='best',\n",
    "                      n=15, max_per_model_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ade17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd530523",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bfc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(model.best_model_transformation_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc8a63",
   "metadata": {},
   "source": [
    "### on new training\n",
    "model = AutoTS(forecast_length=forecast_length,\n",
    "               frequency='infer', max_generations=0,\n",
    "               num_validations=0, verbose=0)\n",
    "model = model.import_template(example_filename, method='only') # method='add on'\n",
    "print(\"Overwrite template is: {}\".format(str(model.initial_template)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рисуем графическое представление предсказания на 2022 год\n",
    "\n",
    "y_true_copy = pd.DataFrame(target_valid).reset_index(drop=True)\n",
    "y_true_copy['day'] = y_true_copy.index // 24\n",
    "y_true_grouped = y_true_copy.groupby(by='day').sum()   \n",
    "y_true_grouped\n",
    "y_pred_copy = pd.DataFrame(y_pred).reset_index(drop=True)\n",
    "y_pred_copy['day'] = y_pred_copy.index // 24\n",
    "y_pred_grouped = y_pred_copy.groupby(by='day').sum()\n",
    "\n",
    "#pd.DataFrame(date_valid)\n",
    "tmpdf = pd.DataFrame(train_ds.loc[features_valid.index,:]['date']).groupby(by='date').count().reset_index().join(y_true_grouped)\n",
    "tmpdf.plot(x='date', y='target', figsize=(18,5))\n",
    "ax=plt.gca()\n",
    "tmpdf = pd.DataFrame(train_ds.loc[features_valid.index,:]['date']).groupby(by='date').count().reset_index().join(y_pred_grouped)\n",
    "tmpdf.plot(ax=ax, x='date', y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказываем той же моделью (19-21) тренировочный кусок 2023 (первый квартал)\n",
    "mae = mae_day(target_2023, lgbm_model.predict(features_2023))\n",
    "print(f'mae = {mae}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
